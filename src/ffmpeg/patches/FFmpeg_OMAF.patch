diff -Nur FFmpeg/.gitattributes FFmpeg_patched/.gitattributes
--- FFmpeg/.gitattributes	2022-06-29 07:15:48.287919033 +0000
+++ FFmpeg_patched/.gitattributes	1970-01-01 00:00:00.000000000 +0000
@@ -1,2 +0,0 @@
-*.pnm -diff -text
-tests/ref/fate/sub-scc eol=crlf
diff -Nur FFmpeg/.gitignore FFmpeg_patched/.gitignore
--- FFmpeg/.gitignore	2022-06-29 07:15:48.287919033 +0000
+++ FFmpeg_patched/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,39 +0,0 @@
-*.a
-*.o
-*.o.*
-*.d
-*.def
-*.dll
-*.dylib
-*.exe
-*.exp
-*.gcda
-*.gcno
-*.h.c
-*.ilk
-*.lib
-*.pc
-*.pdb
-*.so
-*.so.*
-*.swp
-*.ver
-*.version
-*.ptx
-*.ptx.c
-*_g
-\#*
-.\#*
-/.config
-/.version
-/ffmpeg
-/ffplay
-/ffprobe
-/config.asm
-/config.h
-/coverage.info
-/avversion.h
-/lcov/
-/src
-/mapfile
-/tools/python/__pycache__/
diff -Nur FFmpeg/DASH_packing_sample/DASH_packing_sample.c FFmpeg_patched/DASH_packing_sample/DASH_packing_sample.c
--- FFmpeg/DASH_packing_sample/DASH_packing_sample.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/DASH_packing_sample.c	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,589 @@
+#include <stdint.h>
+#include <stdlib.h>
+#include <stdio.h>
+#include <unistd.h>
+#include <string.h>
+#include <math.h>
+#include <libavutil/avassert.h>
+#include <libavutil/channel_layout.h>
+#include <libavutil/opt.h>
+#include <libavutil/mathematics.h>
+#include <libavutil/timestamp.h>
+#include <libavformat/avformat.h>
+#include <libswscale/swscale.h>
+#include <libswresample/swresample.h>
+#include "./ParsePackingParam/PackingParamsDef.h"
+#include "./ParsePackingParam/ParsePackingParamAPI.h"
+
+#define H265_NAL_TYPE_VPS 32
+#define H265_NAL_TYPE_SPS 33
+#define H265_NAL_TYPE_PPS 34
+#define H265_NAL_TYPE_PREFIX_SEI 39
+
+extern int ff_alloc_packet2(AVCodecContext *avctx, AVPacket *avpkt, int64_t size, int64_t min_size);
+
+int32_t find_next_start_code(const uint8_t *buf, const uint8_t *next_avc, int32_t *startCodesNum)
+{
+    int32_t i = 0;
+    int32_t nalu_size = 0;
+    if (buf + 3 > next_avc)
+        return -1;
+    while ((buf + i + 3) <= next_avc) {
+        if (buf[i] == 0 && buf[i + 1] == 0 && buf[i + 2] == 1)
+        {
+            if (i > 0)
+            {
+                if (buf[i - 1] == 0)
+                {
+                    *startCodesNum = 4;
+                }
+                else
+                {
+                    *startCodesNum = 3;
+                }
+            }
+            else
+            {
+                *startCodesNum = 3;
+            }
+            break;
+        }
+        i++;
+    }
+    if ((buf + i + 3) > next_avc)
+    {
+        return -1;
+    }
+    i = 0;
+    int32_t extraZeroNum = 0;
+    const uint8_t *temp = buf + (*startCodesNum);
+    while ((temp + i + 3) <= next_avc) {
+        if (temp[i] == 0 && temp[i + 1] == 0 && temp[i + 2] == 1)
+        {
+            if (i > 0)
+            {
+                if (temp[i - 1] == 0)
+                {
+                    extraZeroNum = 1;
+                }
+                else
+                {
+                    extraZeroNum = 0;
+                }
+            }
+            break;
+        }
+        i++;
+    }
+    nalu_size = i - extraZeroNum + (*startCodesNum);
+    return nalu_size;
+}
+
+int32_t ReadH265Head(uint8_t *frameData, int32_t frameDataLen, uint8_t *headData, int32_t *headLen)
+{
+    uint8_t *currentFrameData = frameData;
+    uint8_t *frameDataEnd = frameData + frameDataLen;
+    int32_t offset = 0;
+    int32_t NALType = 0;
+    *headLen = 0;
+    int32_t i = 0;
+    while (1) {
+        int32_t startCodesNum = 0;
+        offset = find_next_start_code(currentFrameData, frameDataEnd, &startCodesNum);
+        if (offset < 0)
+            break;
+        NALType = (currentFrameData[startCodesNum] & 0x7E) >> 1;
+        if (NALType == H265_NAL_TYPE_VPS || NALType == H265_NAL_TYPE_SPS || NALType == H265_NAL_TYPE_PPS) {
+            memcpy(headData + i, frameData + i, offset);
+            i += offset;
+        }
+        else if (NALType == H265_NAL_TYPE_PREFIX_SEI) {
+            memcpy(headData + i, frameData + i, offset);
+            i += offset;
+        }
+        currentFrameData += offset;
+    }
+    *headLen = i;
+    return 0;
+}
+
+typedef struct _DASH_CONTEXT {
+    AVFormatContext *formatContext;
+    AVStream* input_streams[1024];
+    AVCodecContext *codecContext;
+    AVCodec *codec;
+    int32_t PTS;
+    int32_t GOPSize;
+    int32_t frameCount;
+} DASH_CONTEXT;
+
+int32_t DASHClose(DASH_CONTEXT *inPointer)
+{
+    DASH_CONTEXT *dash_context = inPointer;
+    if (dash_context != NULL)
+    {
+        if (dash_context->formatContext != NULL)
+            av_write_trailer(dash_context->formatContext);
+
+        if (dash_context->codecContext != NULL)
+        {
+            avcodec_close(dash_context->codecContext);
+            avcodec_free_context(&(dash_context->codecContext));
+            dash_context->codecContext = NULL;
+        }
+
+        if (dash_context->formatContext != NULL)
+        {
+            AVOutputFormat *outFormat = dash_context->formatContext->oformat;
+            if (!(outFormat->flags & AVFMT_NOFILE))
+                avio_closep(&(dash_context->formatContext->pb));
+            avformat_free_context(dash_context->formatContext);
+            dash_context->formatContext = NULL;
+        }
+
+        free(dash_context);
+        dash_context = NULL;
+    }
+    return 0;
+}
+
+DASH_CONTEXT *DASHOpen(DASH_IN_PARAM *dash_params)
+{
+    int32_t ret = 0;
+    DASH_CONTEXT *dash_context = (DASH_CONTEXT *)malloc(sizeof(DASH_CONTEXT));
+    if (NULL == dash_context)
+    {
+        printf("Failed to alloc memory for DASH context !\n");
+        return NULL;
+    }
+
+    uint32_t url_len = strlen(dash_params->packing_param.base_url);
+    if (dash_params->packing_param.base_url[url_len - 1] != '/')
+    {
+        printf("Incorrect base url setting !\n");
+        return NULL;
+    }
+
+    uint32_t idx = 0;
+    for (idx = (url_len - 2); idx >= 0; idx--)
+    {
+        if (dash_params->packing_param.base_url[idx] == '/')
+            break;
+    }
+
+    char folder_name[128] = { 0 };
+    strncpy(folder_name, (dash_params->packing_param.base_url + idx + 1), (url_len - idx - 2));
+    char fileName[256] = {0};
+    snprintf(fileName, 256, "/usr/local/nginx/html/%s/", folder_name);
+    AVFormatContext *formatContext = NULL;
+    avformat_alloc_output_context2(&formatContext, NULL, "omaf_packing", fileName);
+    if (NULL == formatContext)
+    {
+        printf("Failed to alloc omaf_packing context !\n");
+        DASHClose(dash_context);
+        return NULL;
+    }
+
+    formatContext->oformat->video_codec = AV_CODEC_ID_HEVC;
+    AVOutputFormat *outFormat = formatContext->oformat;
+    dash_context->formatContext = formatContext;
+    AVCodec *codec = avcodec_find_encoder(outFormat->video_codec);
+    if (NULL == codec)
+    {
+        printf("Failed to find HEVC codec !\n");
+        DASHClose(dash_context);
+        return NULL;
+    }
+
+    dash_context->codec = codec;
+    AVCodecContext *codecContext = avcodec_alloc_context3(codec);
+    if (NULL == codecContext)
+    {
+        printf("Failed to alloc codec context !\n");
+        DASHClose(dash_context);
+        return NULL;
+    }
+
+    codecContext->codec_id = outFormat->video_codec;
+    codecContext->time_base.num = dash_params->videos_param[0].frame_rate;
+    codecContext->time_base.den = 1;
+    codecContext->framerate.num = dash_params->videos_param[0].frame_rate;
+    codecContext->framerate.den = 1;
+    codecContext->gop_size = dash_params->videos_param[0].gop_size;
+    codecContext->pix_fmt = AV_PIX_FMT_YUV420P;
+    if (formatContext->oformat->flags & AVFMT_GLOBALHEADER)
+        codecContext->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;
+
+    dash_context->codecContext = codecContext;
+    for (uint8_t stream_id = 1; stream_id <= dash_params->in_videos_num; stream_id++)
+    {
+        AVStream *input_stream = avformat_new_stream(dash_context->formatContext, NULL);
+        if (NULL == input_stream)
+        {
+            printf("Failed to create AVStream !\n");
+            DASHClose(dash_context);
+            return NULL;
+        }
+
+        input_stream->id = stream_id - 1;
+        input_stream->time_base.den = 1;
+        input_stream->time_base.num = dash_params->videos_param[stream_id - 1].frame_rate;
+        input_stream->avg_frame_rate.num = dash_params->videos_param[stream_id - 1].frame_rate;
+        input_stream->avg_frame_rate.den = 1;
+        codecContext->bit_rate = dash_params->videos_param[stream_id - 1].bit_rate;
+        codecContext->width = dash_params->videos_param[stream_id - 1].width;
+        codecContext->height = dash_params->videos_param[stream_id - 1].height;
+        dash_context->input_streams[stream_id - 1] = input_stream;
+        int32_t ret = 0;
+        ret = avcodec_parameters_from_context(input_stream->codecpar, codecContext);
+        if (ret < 0)
+        {
+            printf("Failed to copy the stream codec parameters !\n");
+            DASHClose(dash_context);
+            return NULL;
+        }
+    }
+
+    av_dump_format(formatContext, 0, fileName, 1);
+    av_opt_set(formatContext->priv_data, "packing_proj_type", dash_params->packing_param.proj_type, 0);
+    av_opt_set(formatContext->priv_data, "cubemap_face_file", dash_params->packing_param.face_file, 0);
+    av_opt_set(formatContext->priv_data, "viewport_w", dash_params->packing_param.viewport_w, 0);
+    av_opt_set(formatContext->priv_data, "viewport_h", dash_params->packing_param.viewport_h, 0);
+    av_opt_set(formatContext->priv_data, "viewport_yaw", dash_params->packing_param.viewport_yaw, 0);
+    av_opt_set(formatContext->priv_data, "viewport_pitch", dash_params->packing_param.viewport_pitch, 0);
+    av_opt_set(formatContext->priv_data, "viewport_fov_hor", dash_params->packing_param.viewport_fov_hor, 0);
+    av_opt_set(formatContext->priv_data, "viewport_fov_ver", dash_params->packing_param.viewport_fov_ver, 0);
+    av_opt_set(formatContext->priv_data, "window_size", dash_params->packing_param.window_size, 0);
+    av_opt_set(formatContext->priv_data, "extra_window_size", dash_params->packing_param.extra_window_size, 0);
+    av_opt_set(formatContext->priv_data, "split_tile", dash_params->packing_param.split_tile, 0);
+    av_opt_set(formatContext->priv_data, "seg_duration", dash_params->packing_param.seg_duration, 0);
+    av_opt_set(formatContext->priv_data, "is_live", dash_params->packing_param.is_live, 0);
+    av_opt_set(formatContext->priv_data, "base_url", dash_params->packing_param.base_url, 0);
+    av_opt_set(formatContext->priv_data, "out_name", dash_params->packing_param.out_name, 0);
+    av_opt_set(formatContext->priv_data, "need_buffered_frames", dash_params->packing_param.need_buffered_frames, 0);
+    av_opt_set(formatContext->priv_data, "extractors_per_thread", dash_params->packing_param.extractors_per_thread, 0);
+    av_opt_set(formatContext->priv_data, "has_extractor", dash_params->packing_param.has_extractor, 0);
+    av_opt_set(formatContext->priv_data, "packing_plugin_path", dash_params->packing_param.packingPluginPath, 0);
+    av_opt_set(formatContext->priv_data, "packing_plugin_name", dash_params->packing_param.packingPluginName, 0);
+    av_opt_set(formatContext->priv_data, "video_plugin_path", dash_params->packing_param.videoPluginPath, 0);
+    av_opt_set(formatContext->priv_data, "video_plugin_name", dash_params->packing_param.videoPluginName, 0);
+    av_opt_set(formatContext->priv_data, "audio_plugin_path", dash_params->packing_param.audioPluginPath, 0);
+    av_opt_set(formatContext->priv_data, "audio_plugin_name", dash_params->packing_param.audioPluginName, 0);
+    av_opt_set(formatContext->priv_data, "fixed_extractors_res", dash_params->packing_param.fixedPackedPicRes, 0);
+    av_opt_set(formatContext->priv_data, "cmaf_enabled", dash_params->packing_param.cmafEnabled, 0);
+    av_opt_set(formatContext->priv_data, "chunk_dur", dash_params->packing_param.chunkDur, 0);
+    av_opt_set(formatContext->priv_data, "seg_writer_path", dash_params->packing_param.segWriterPluginPath, 0);
+    av_opt_set(formatContext->priv_data, "seg_writer_name", dash_params->packing_param.segWriterPluginName, 0);
+    av_opt_set(formatContext->priv_data, "mpd_writer_path", dash_params->packing_param.mpdWriterPluginPath, 0);
+    av_opt_set(formatContext->priv_data, "mpd_writer_name", dash_params->packing_param.mpdWriterPluginName, 0);
+    av_opt_set(formatContext->priv_data, "target_latency", dash_params->packing_param.target_latency, 0);
+    av_opt_set(formatContext->priv_data, "min_latency", dash_params->packing_param.min_latency, 0);
+    av_opt_set(formatContext->priv_data, "max_latency", dash_params->packing_param.max_latency, 0);
+    av_opt_set(formatContext->priv_data, "need_external_log", dash_params->packing_param.need_external_log, 0);
+    av_opt_set(formatContext->priv_data, "min_log_level", dash_params->packing_param.min_log_level, 0);
+
+    if (!(outFormat->flags & AVFMT_NOFILE))
+    {
+        ret = avio_open(&formatContext->pb, fileName, AVIO_FLAG_WRITE);
+        if (ret < 0)
+        {
+            printf("Failed to open '%s'!\n", fileName);
+            DASHClose(dash_context);
+            return NULL;
+        }
+    }
+
+    ret = avformat_write_header(formatContext, NULL);
+    if (ret < 0)
+    {
+        printf("Error occurred when opening output file !\n");
+        DASHClose(dash_context);
+        return NULL;
+    }
+
+    dash_context->GOPSize = dash_params->videos_param[0].gop_size;
+    dash_context->frameCount = 0;
+    return dash_context;
+}
+
+int32_t DASHMuxing(DASH_IN_PARAM *dash_params, DASH_CONTEXT *inPointer, uint8_t *frame_data[], int32_t frame_size[])
+{
+    DASH_CONTEXT *dash_context = inPointer;
+    int32_t ret = 0;
+
+    for (uint8_t stream_id = 1; stream_id <= dash_params->in_videos_num; stream_id++)
+    {
+        AVPacket packet;
+        av_new_packet(&packet, frame_size[stream_id - 1]);//(frame_size[stream_id - 1] + 1));
+        if ((ret = ff_alloc_packet2(NULL, &packet, frame_size[stream_id - 1], 0)) < 0)
+        {
+            av_log(NULL, AV_LOG_ERROR, "Failed to allocate packet.\n");
+            return ret;
+        }
+
+        if (packet.data == NULL)
+        {
+            printf("pkt.data is NULL\n");
+            return -1;
+        }
+
+        int32_t GOPSize = dash_context->GOPSize;
+        if (dash_context->frameCount % GOPSize == 0)
+            packet.flags = 1;
+        else
+            packet.flags = 0;
+
+        packet.dts = packet.pts = dash_context->frameCount;
+        AVStream *one_stream = dash_context->input_streams[stream_id - 1];
+        packet.stream_index = stream_id - 1;
+        one_stream->index = stream_id - 1;
+        memcpy(packet.data, frame_data[stream_id - 1], frame_size[stream_id - 1]);
+        packet.size = frame_size[stream_id - 1];
+
+        if (dash_context->frameCount == 0)
+        {
+            uint8_t *headerData = (uint8_t *)malloc(4096);
+            if (headerData == NULL)
+            {
+                printf("headerData is NULL\n");
+                free(packet.data);
+                packet.data = NULL;
+                return -1;
+            }
+
+            packet.side_data = (AVPacketSideData *)malloc(sizeof(AVPacketSideData));
+            packet.side_data[0].size = 4096;
+            packet.side_data[0].data = av_malloc(packet.side_data->size + AV_INPUT_BUFFER_PADDING_SIZE);
+            packet.side_data[0].type = AV_PKT_DATA_NEW_EXTRADATA;
+            packet.side_data_elems = 1;
+            int32_t headerSize= 0;
+            ReadH265Head(frame_data[stream_id - 1], frame_size[stream_id - 1], headerData, &headerSize);
+            packet.side_data[0].size = headerSize;
+            //printf("video stream %d has header size %d \n", stream_id, headerSize);
+            memcpy(packet.side_data[0].data, headerData, headerSize);
+            free(headerData);
+            headerData = NULL;
+        }
+
+        av_packet_rescale_ts(&packet, dash_context->codecContext->time_base, one_stream->time_base);
+        packet.stream_index = one_stream->index;
+        ret = av_interleaved_write_frame(dash_context->formatContext, &packet);
+        if (ret < 0) {
+            printf("Failed to pack video frame: %s !\n", av_err2str(ret));
+            free(packet.data);
+            packet.data = NULL;
+            return -1;
+        }
+    }
+    dash_context->frameCount++;
+    return 0;
+}
+
+int32_t PackStreams(DASH_IN_PARAM *dash_params)
+{
+    int32_t ret = 0;
+    size_t ret1 = 0;
+    uint32_t streams_num = dash_params->in_videos_num;
+    FILE* streams_file[1024] = { NULL };
+    FILE* frame_len_file[1024] = { NULL };
+
+    for (uint32_t stream_id = 1; stream_id <= streams_num; stream_id++)
+    {
+        streams_file[stream_id - 1] = fopen(dash_params->videos_param[stream_id - 1].video_file_name, "rb");
+        if (NULL == streams_file[stream_id - 1])
+        {
+            printf("Failed to open %s !\n", dash_params->videos_param[stream_id - 1].video_file_name);
+            goto now_free;
+        }
+
+        frame_len_file[stream_id - 1] = fopen(dash_params->videos_param[stream_id - 1].frame_len_name, "r");
+        if (NULL == frame_len_file[stream_id - 1])
+        {
+            printf("Failed to open %s !\n", dash_params->videos_param[stream_id - 1].frame_len_name);
+            goto now_free;
+        }
+    }
+
+    void *ctx = DASHOpen(dash_params);
+    uint8_t* video_frame_data[1024] = { NULL };
+    for (uint8_t stream_id = 1; stream_id <= dash_params->in_videos_num; stream_id++)
+    {
+        int32_t width = dash_params->videos_param[stream_id - 1].width;
+        int32_t height = dash_params->videos_param[stream_id - 1].height;
+        video_frame_data[stream_id - 1] = (uint8_t *)malloc(width * height * 3 / 2);
+        if (NULL == video_frame_data[stream_id - 1])
+        {
+            printf("Failed in mallocing video frame data !\n");
+            goto now_free;
+        }
+    }
+
+    int32_t frame_data_size[1024] = { 0 };
+    uint64_t frameNum = dash_params->packing_frames_num;;
+    for (uint64_t i = 0; i < frameNum; i++)
+    {
+        for (uint32_t stream_id = 1; stream_id <= dash_params->in_videos_num; stream_id++)
+        {
+            if (dash_params->packing_param.live_mode)
+            {
+                int32_t frame_rate = dash_params->videos_param[0].frame_rate;
+                int32_t frame_dur = (int32_t)((1000000 / frame_rate) / 2);
+                frame_dur = (frame_dur / 100 - 1) * 100;
+                usleep(frame_dur);
+            }
+
+            ret = fscanf(frame_len_file[stream_id - 1], "%d,", &(frame_data_size[stream_id - 1]));
+            if (ret == -1)
+            {
+                printf("frame data size file has EOF !\n");
+            }
+
+            ret1 = fread(video_frame_data[stream_id - 1], 1, frame_data_size[stream_id - 1], streams_file[stream_id - 1]);
+            if (ret1 < frame_data_size[stream_id - 1])
+            {
+                printf("Error in reading frame data, waiting for next judgement !\n");
+            }
+
+            if (feof(frame_len_file[stream_id - 1]) && feof(streams_file[stream_id - 1]))
+            {
+                fclose(frame_len_file[stream_id - 1]);
+                frame_len_file[stream_id - 1] = NULL;
+                fclose(streams_file[stream_id - 1]);
+                streams_file[stream_id - 1] = NULL;
+                streams_file[stream_id - 1] = fopen(dash_params->videos_param[stream_id - 1].video_file_name, "rb");
+
+                if (NULL == streams_file[stream_id - 1])
+                {
+                    printf("Failed to open %s again !\n", dash_params->videos_param[stream_id - 1].video_file_name);
+                    goto now_free;
+                }
+                frame_len_file[stream_id - 1] = fopen(dash_params->videos_param[stream_id - 1].frame_len_name, "r");
+
+                if (NULL == frame_len_file[stream_id - 1])
+                {
+                    printf("Failed to open %s again !\n", dash_params->videos_param[stream_id - 1].frame_len_name);
+                    goto now_free;
+                }
+
+                ret = fscanf(frame_len_file[stream_id - 1], "%d,", &(frame_data_size[stream_id - 1]));
+                if (ret == -1)
+                {
+                    printf("frame data size file has EOF !\n");
+                    goto now_free;
+                }
+
+                ret1 = fread(video_frame_data[stream_id - 1], 1, frame_data_size[stream_id - 1], streams_file[stream_id - 1]);
+                if (ret1 < frame_data_size[stream_id - 1])
+                {
+                    printf("Error in reading frame data !\n");
+                    goto now_free;
+                }
+            }
+            else if (!feof(frame_len_file[stream_id - 1]) && feof(streams_file[stream_id - 1]))
+            {
+                printf("Incorrect EOF happens between stream file and frame size file !\n");
+                goto now_free;
+            }
+            else if (feof(frame_len_file[stream_id - 1]) && !feof(streams_file[stream_id - 1]))
+            {
+                printf("Incorrect EOF happens between stream file and frame size file !\n");
+                goto now_free;
+            }
+        }
+
+        DASHMuxing(dash_params, ctx, video_frame_data, frame_data_size);
+    }
+
+    DASHClose(ctx);
+
+now_free:
+    for (uint32_t stream_id = 0; stream_id < dash_params->in_videos_num; stream_id++)
+    {
+        if (video_frame_data[stream_id])
+        {
+            free(video_frame_data[stream_id]);
+            video_frame_data[stream_id] = NULL;
+        }
+
+        if (streams_file[stream_id])
+        {
+            fclose(streams_file[stream_id]);
+            streams_file[stream_id] = NULL;
+        }
+
+        if (frame_len_file[stream_id])
+        {
+            fclose(frame_len_file[stream_id]);
+            frame_len_file[stream_id] = NULL;
+        }
+    }
+    return 0;
+}
+
+int32_t main(int32_t argc, char *argv[])
+{
+    DASH_IN_PARAM *dash_in_param = NULL;
+    char *dash_config_file = NULL;
+    int32_t ret = 0;
+
+    if (argc < 3)
+    {
+        printf("Not enough input parameters !\n");
+        return -1;
+    }
+
+    if (strncmp(argv[1], "-i", 2) == 0)
+    {
+        dash_config_file = argv[2];
+        printf("Input configuration file is %s !\n", dash_config_file);
+    }
+
+    if (NULL == dash_config_file)
+    {
+        printf("There is no configuration file for the packing !\n");
+        return -1;
+    }
+
+    dash_in_param = (DASH_IN_PARAM *)malloc(sizeof(DASH_IN_PARAM));
+    if (NULL == dash_in_param)
+    {
+        printf("Failed to alloc memory for packing params !\n");
+        return -1;
+    }
+
+    memset(dash_in_param, 0, sizeof(DASH_IN_PARAM));
+
+    void *parser_hdl = ParsePackingParamInit();
+    if (NULL == parser_hdl)
+    {
+        printf("Failed to create packing params parser !\n");
+        free(dash_in_param);
+        dash_in_param = NULL;
+        return -1;
+    }
+
+    ret = ParsePackingParamParse(parser_hdl, dash_config_file, (void*)dash_in_param);
+    if (ret)
+    {
+        printf("Error in parsing configuration file !\n");
+        goto fail;
+    }
+
+    ret = PackStreams(dash_in_param);
+    if (ret)
+    {
+        printf("Error in packing input streams !\n");
+        goto fail;
+    }
+
+fail:
+    if (dash_in_param)
+    {
+        free(dash_in_param);
+        dash_in_param = NULL;
+    }
+
+    ParsePackingParamClose(parser_hdl);
+
+    return ret;
+}
diff -Nur FFmpeg/DASH_packing_sample/ParsePackingParam/CMakeLists.txt FFmpeg_patched/DASH_packing_sample/ParsePackingParam/CMakeLists.txt
--- FFmpeg/DASH_packing_sample/ParsePackingParam/CMakeLists.txt	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/ParsePackingParam/CMakeLists.txt	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,30 @@
+CMAKE_MINIMUM_REQUIRED(VERSION 2.8)
+PROJECT(ParsePackingParam)
+
+AUX_SOURCE_DIRECTORY(. DIR_SRC)
+
+ADD_DEFINITIONS("-g -c -fPIC -std=c++11 -D_GLIBCXX_USE_CXX11_ABI=0
+                 -z noexecstack -z relro -z now -fstack-protector-strong
+                 -fPIE -fPIC -pie -O2 -D_FORTIFY_SOURCE=2 -Wformat
+                 -Wformat-security -Wl,-S -Wall -Werror")
+
+
+INCLUDE_DIRECTORIES(/usr/local/include)
+LINK_DIRECTORIES(/usr/local/lib)
+
+SET(DIR_SRC
+    ${DIR_SRC}
+)
+
+ADD_LIBRARY(ParsePackingParam SHARED ${DIR_SRC})
+
+TARGET_LINK_LIBRARIES(ParsePackingParam dl)
+
+INSTALL(TARGETS ParsePackingParam
+        RUNTIME DESTINATION bin
+        LIBRARY DESTINATION lib
+        ARCHIVE DESTINATION lib/static)
+
+INSTALL(FILES ${PROJECT_SOURCE_DIR}/PackingParamsDef.h DESTINATION include)
+INSTALL(FILES ${PROJECT_SOURCE_DIR}/ParsePackingParamAPI.h DESTINATION include)
+INSTALL(FILES ${PROJECT_SOURCE_DIR}/ParsePackingParam.pc DESTINATION lib/pkgconfig)
diff -Nur FFmpeg/DASH_packing_sample/ParsePackingParam/PackingParamsDef.h FFmpeg_patched/DASH_packing_sample/ParsePackingParam/PackingParamsDef.h
--- FFmpeg/DASH_packing_sample/ParsePackingParam/PackingParamsDef.h	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/ParsePackingParam/PackingParamsDef.h	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,67 @@
+#include <stdint.h>
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+#include <math.h>
+
+#ifndef DATA_DEF_H
+#define DATA_DEF_H
+
+typedef struct _PACKING_IN_PARAM {
+    char     proj_type[1024];
+    char     face_file[1024];
+    char     viewport_w[1024];
+    char     viewport_h[1024];
+    char     viewport_yaw[1024];
+    char     viewport_pitch[1024];
+    char     viewport_fov_hor[1024];
+    char     viewport_fov_ver[1024];
+    char     window_size[1024];
+    char     extra_window_size[1024];
+    char     split_tile[1024];
+    char     seg_duration[1024];
+    char     is_live[1024];
+    int32_t  live_mode;
+    char     base_url[1024];
+    char     out_name[1024];
+    char     need_buffered_frames[1024];
+    char     extractors_per_thread[1024];
+    char     has_extractor[1024];
+    char     packingPluginPath[1024];
+    char     packingPluginName[1024];
+    char     videoPluginPath[1024];
+    char     videoPluginName[1024];
+    char     audioPluginPath[1024];
+    char     audioPluginName[1024];
+    char     fixedPackedPicRes[1024];
+    char     cmafEnabled[1024];
+    char     chunkDur[1024];
+    char     segWriterPluginPath[1024];
+    char     segWriterPluginName[1024];
+    char     mpdWriterPluginPath[1024];
+    char     mpdWriterPluginName[1024];
+    char     target_latency[1024];
+    char     min_latency[1024];
+    char     max_latency[1024];
+    char     need_external_log[1024];
+    char     min_log_level[1024];
+} PACKING_IN_PARAM;
+
+typedef struct _VIDEO_IN_PARAM {
+    const char     *video_file_name;
+    int32_t        width;
+    int32_t        height;
+    uint64_t       bit_rate;
+    uint16_t       frame_rate;
+    uint32_t       gop_size;
+    const char     *frame_len_name;
+} VIDEO_IN_PARAM;
+
+typedef struct _DASH_IN_PARAM {
+    PACKING_IN_PARAM packing_param;
+    uint32_t         in_videos_num;
+    VIDEO_IN_PARAM   videos_param[1024];
+    uint64_t         packing_frames_num;
+} DASH_IN_PARAM;
+
+#endif
diff -Nur FFmpeg/DASH_packing_sample/ParsePackingParam/ParamParser.cpp FFmpeg_patched/DASH_packing_sample/ParsePackingParam/ParamParser.cpp
--- FFmpeg/DASH_packing_sample/ParsePackingParam/ParamParser.cpp	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/ParsePackingParam/ParamParser.cpp	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,300 @@
+#include "ParamParser.h"
+#include "tinyxml2.h"
+
+using namespace tinyxml2;
+
+int32_t ParamParser::Parse(char *config_file, void *param_pointer)
+{
+    int32_t ret = 0;
+
+    if (NULL == config_file)
+    {
+        printf("Configuration file in NULL !\n");
+        return -1;
+    }
+
+    XMLDocument *doc = new XMLDocument();
+    if (NULL == doc)
+    {
+        printf("Failed to create XML document !\n");
+        return -1;
+    }
+
+    ret = doc->LoadFile(config_file);
+    if (ret)
+    {
+        printf("Failed to load input configuration file, error %d !\n", ret);
+
+        delete doc;
+        doc = NULL;
+
+        return -1;
+    }
+
+    DASH_IN_PARAM *dash_params = (DASH_IN_PARAM *)param_pointer;
+    if (NULL == dash_params)
+    {
+        printf("NULL pointer for params !\n");
+
+        delete doc;
+        doc = NULL;
+
+        return -1;
+    }
+
+    XMLElement *root = doc->RootElement();
+    XMLElement *params = root->FirstChildElement("OptionsList");
+    XMLElement *option = params->FirstChildElement();
+    const XMLAttribute *attr1 = option->FirstAttribute();
+    const char* proj_type = attr1->Value();
+    strncpy(dash_params->packing_param.proj_type, proj_type, 1024);
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr2 = option->FirstAttribute();
+    const char* face_file = attr2->Value();
+    strncpy(dash_params->packing_param.face_file, face_file, 1024);// = attr2->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr3 = option->FirstAttribute();
+    const char* viewport_w = attr3->Value();
+    strncpy(dash_params->packing_param.viewport_w, viewport_w, 1024);// = attr3->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr4 = option->FirstAttribute();
+    const char* viewport_h = attr4->Value();
+    strncpy(dash_params->packing_param.viewport_h, viewport_h, 1024);// = attr4->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr5 = option->FirstAttribute();
+    const char* viewport_yaw = attr5->Value();
+    strncpy(dash_params->packing_param.viewport_yaw, viewport_yaw, 1024);// = attr5->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr6 = option->FirstAttribute();
+    const char* viewport_pitch = attr6->Value();
+    strncpy(dash_params->packing_param.viewport_pitch, viewport_pitch, 1024);// = attr6->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr7 = option->FirstAttribute();
+    const char* viewport_fov_hor = attr7->Value();
+    strncpy(dash_params->packing_param.viewport_fov_hor, viewport_fov_hor, 1024);// = attr7->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr8 = option->FirstAttribute();
+    const char* viewport_fov_ver = attr8->Value();
+    strncpy(dash_params->packing_param.viewport_fov_ver, viewport_fov_ver, 1024);// = attr8->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr9 = option->FirstAttribute();
+    const char* window_size = attr9->Value();
+    strncpy(dash_params->packing_param.window_size, window_size, 1024);// = attr9->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr10 = option->FirstAttribute();
+    const char* extra_window_size = attr10->Value();
+    strncpy(dash_params->packing_param.extra_window_size, extra_window_size, 1024);// = attr10->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr11 = option->FirstAttribute();
+    const char* split_tile = attr11->Value();
+    strncpy(dash_params->packing_param.split_tile, split_tile, 1024);// = attr11->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr12 = option->FirstAttribute();
+    const char* seg_duration = attr12->Value();
+    strncpy(dash_params->packing_param.seg_duration, seg_duration, 1024);// = attr12->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr13 = option->FirstAttribute();
+    const char* is_live = attr13->Value();
+    strncpy(dash_params->packing_param.is_live, is_live, 1024);// = attr13->Value();
+    dash_params->packing_param.live_mode = attr13->IntValue();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr14 = option->FirstAttribute();
+    const char* base_url = attr14->Value();
+    strncpy(dash_params->packing_param.base_url, base_url, 1024);// = attr14->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr15 = option->FirstAttribute();
+    const char* out_name = attr15->Value();
+    strncpy(dash_params->packing_param.out_name, out_name, 1024);// = attr15->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr16 = option->FirstAttribute();
+    const char* need_buffered_frames = attr16->Value();
+    strncpy(dash_params->packing_param.need_buffered_frames, need_buffered_frames, 1024);// = attr16->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr17 = option->FirstAttribute();
+    const char* packingPluginPath = attr17->Value();
+    strncpy(dash_params->packing_param.packingPluginPath, packingPluginPath, 1024);// = attr17->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr18 = option->FirstAttribute();
+    const char* packingPluginName = attr18->Value();
+    strncpy(dash_params->packing_param.packingPluginName, packingPluginName, 1024);// = attr18->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr19 = option->FirstAttribute();
+    const char* videoPluginPath = attr19->Value();
+    strncpy(dash_params->packing_param.videoPluginPath, videoPluginPath, 1024);// = attr19->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr20 = option->FirstAttribute();
+    const char* videoPluginName = attr20->Value();
+    strncpy(dash_params->packing_param.videoPluginName, videoPluginName, 1024);// = attr20->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr21 = option->FirstAttribute();
+    const char* audioPluginPath = attr21->Value();
+    strncpy(dash_params->packing_param.audioPluginPath, audioPluginPath, 1024);// = attr21->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr22 = option->FirstAttribute();
+    const char* audioPluginName = attr22->Value();
+    strncpy(dash_params->packing_param.audioPluginName, audioPluginName, 1024);// = attr22->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr23 = option->FirstAttribute();
+    const char* has_extractor = attr23->Value();
+    strncpy(dash_params->packing_param.has_extractor, has_extractor, 1024);// = attr23->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr24 = option->FirstAttribute();
+    const char* extractors_per_thread = attr24->Value();
+    strncpy(dash_params->packing_param.extractors_per_thread, extractors_per_thread, 1024);// = attr24->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr25 = option->FirstAttribute();
+    const char* fixedPackedPicRes = attr25->Value();
+    strncpy(dash_params->packing_param.fixedPackedPicRes, fixedPackedPicRes, 1024);// = attr25->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr26 = option->FirstAttribute();
+    const char* cmafEnabled = attr26->Value();
+    strncpy(dash_params->packing_param.cmafEnabled, cmafEnabled, 1024);// = attr26->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr27 = option->FirstAttribute();
+    const char* chunkDur = attr27->Value();
+    strncpy(dash_params->packing_param.chunkDur, chunkDur, 1024);// = attr27->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr28 = option->FirstAttribute();
+    const char* segWriterPluginPath = attr28->Value();
+    strncpy(dash_params->packing_param.segWriterPluginPath, segWriterPluginPath, 1024);//  = attr28->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr29 = option->FirstAttribute();
+    const char* segWriterPluginName = attr29->Value();
+    strncpy(dash_params->packing_param.segWriterPluginName, segWriterPluginName, 1024);// = attr29->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr30 = option->FirstAttribute();
+    const char* mpdWriterPluginPath = attr30->Value();
+    strncpy(dash_params->packing_param.mpdWriterPluginPath, mpdWriterPluginPath, 1024);// = attr30->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr31 = option->FirstAttribute();
+    const char* mpdWriterPluginName = attr31->Value();
+    strncpy(dash_params->packing_param.mpdWriterPluginName, mpdWriterPluginName, 1024);//  = attr31->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr32 = option->FirstAttribute();
+    const char* target_latency = attr32->Value();
+    strncpy(dash_params->packing_param.target_latency, target_latency, 1024);// = attr32->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr33 = option->FirstAttribute();
+    const char* min_latency = attr33->Value();
+    strncpy(dash_params->packing_param.min_latency, min_latency, 1024);// = attr33->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr34 = option->FirstAttribute();
+    const char* max_latency = attr34->Value();
+    strncpy(dash_params->packing_param.max_latency, max_latency, 1024);// = attr34->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr35 = option->FirstAttribute();
+    const char* need_external_log = attr35->Value();
+    strncpy(dash_params->packing_param.need_external_log, need_external_log, 1024);// = attr35->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr36 = option->FirstAttribute();
+    const char* min_log_level = attr36->Value();
+    strncpy(dash_params->packing_param.min_log_level, min_log_level, 1024);// = attr36->Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr37 = option->FirstAttribute();
+    dash_params->packing_frames_num = attr37->Int64Value();
+
+    option = option->NextSiblingElement();
+    const XMLAttribute *attr38 = option->FirstAttribute();
+    dash_params->in_videos_num = attr38->UnsignedValue();
+
+    //High resolution video
+    XMLElement *video1 = root->FirstChildElement("Video1");
+    XMLElement *video_ele = video1->FirstChildElement();
+    const XMLAttribute *video1_attr1 = video_ele->FirstAttribute();
+    dash_params->videos_param[0].video_file_name = video1_attr1->Value();
+
+    video_ele = video_ele->NextSiblingElement();
+    const XMLAttribute *video1_attr2 = video_ele->FirstAttribute();
+    dash_params->videos_param[0].width = video1_attr2->IntValue();
+
+    video_ele = video_ele->NextSiblingElement();
+    const XMLAttribute *video1_attr3 = video_ele->FirstAttribute();
+    dash_params->videos_param[0].height = video1_attr3->IntValue();
+
+    video_ele = video_ele->NextSiblingElement();
+    const XMLAttribute *video1_attr4 = video_ele->FirstAttribute();
+    dash_params->videos_param[0].bit_rate = video1_attr4->Int64Value();
+
+    video_ele = video_ele->NextSiblingElement();
+    const XMLAttribute *video1_attr5 = video_ele->FirstAttribute();
+    dash_params->videos_param[0].frame_rate = video1_attr5->UnsignedValue();
+
+    video_ele = video_ele->NextSiblingElement();
+    const XMLAttribute *video1_attr6 = video_ele->FirstAttribute();
+    dash_params->videos_param[0].gop_size = video1_attr6->UnsignedValue();
+
+    video_ele = video_ele->NextSiblingElement();
+    const XMLAttribute *video1_attr7 = video_ele->FirstAttribute();
+    dash_params->videos_param[0].frame_len_name = video1_attr7->Value();
+
+    //Low resolution video
+    XMLElement *video2 = root->FirstChildElement("Video2");
+    video_ele = video2->FirstChildElement();
+    const XMLAttribute *video2_attr1 = video_ele->FirstAttribute();
+    dash_params->videos_param[1].video_file_name = video2_attr1->Value();
+
+    video_ele = video_ele->NextSiblingElement();
+    const XMLAttribute *video2_attr2 = video_ele->FirstAttribute();
+    dash_params->videos_param[1].width = video2_attr2->IntValue();
+
+    video_ele = video_ele->NextSiblingElement();
+    const XMLAttribute *video2_attr3 = video_ele->FirstAttribute();
+    dash_params->videos_param[1].height = video2_attr3->IntValue();
+
+    video_ele = video_ele->NextSiblingElement();
+    const XMLAttribute *video2_attr4 = video_ele->FirstAttribute();
+    dash_params->videos_param[1].bit_rate = video2_attr4->Int64Value();
+
+    video_ele = video_ele->NextSiblingElement();
+    const XMLAttribute *video2_attr5 = video_ele->FirstAttribute();
+    dash_params->videos_param[1].frame_rate = video2_attr5->UnsignedValue();
+
+    video_ele = video_ele->NextSiblingElement();
+    const XMLAttribute *video2_attr6 = video_ele->FirstAttribute();
+    dash_params->videos_param[1].gop_size = video2_attr6->UnsignedValue();
+
+    video_ele = video_ele->NextSiblingElement();
+    const XMLAttribute *video2_attr7 = video_ele->FirstAttribute();
+    dash_params->videos_param[1].frame_len_name = video2_attr7->Value();
+
+    delete doc;
+    doc = NULL;
+
+    return 0;
+}
diff -Nur FFmpeg/DASH_packing_sample/ParsePackingParam/ParamParser.h FFmpeg_patched/DASH_packing_sample/ParsePackingParam/ParamParser.h
--- FFmpeg/DASH_packing_sample/ParsePackingParam/ParamParser.h	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/ParsePackingParam/ParamParser.h	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,19 @@
+#include <stdint.h>
+
+#include "PackingParamsDef.h"
+
+#ifndef _PARAMPARSER_H_
+#define _PARAMPARSER_H_
+
+class ParamParser
+{
+public:
+    ParamParser() {};
+
+    ~ParamParser() {};
+
+    int32_t Parse(char *config_file, void *param_pointer);
+private:
+};
+
+#endif /* _PARAMPARSER_H_ */
diff -Nur FFmpeg/DASH_packing_sample/ParsePackingParam/ParsePackingParam.pc FFmpeg_patched/DASH_packing_sample/ParsePackingParam/ParsePackingParam.pc
--- FFmpeg/DASH_packing_sample/ParsePackingParam/ParsePackingParam.pc	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/ParsePackingParam/ParsePackingParam.pc	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,10 @@
+prefix=/usr/local
+exec_prefix=${prefix}
+libdir=${exec_prefix}/lib
+includedir=${exec_prefix}/include
+
+Name:VR DASH Packing Params Parser
+Description: VR DASH packing library parameters parser
+Version:0.0.1-DEV
+Cflags: -I${prefix}/include
+Libs: -L${libdir} -lParsePackingParam -static-libstdc++ -lpthread -L/usr/local/lib64
diff -Nur FFmpeg/DASH_packing_sample/ParsePackingParam/ParsePackingParamAPI.h FFmpeg_patched/DASH_packing_sample/ParsePackingParam/ParsePackingParamAPI.h
--- FFmpeg/DASH_packing_sample/ParsePackingParam/ParsePackingParamAPI.h	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/ParsePackingParam/ParsePackingParamAPI.h	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,22 @@
+#ifndef _PARSEPACKINGPARAM_H_
+#define _PARSEPACKINGPARAM_H_
+
+#include <stdint.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+typedef void* Handler;
+
+Handler ParsePackingParamInit();
+
+int32_t ParsePackingParamParse(Handler hdl, char *config_file, void *param_pointer);
+
+int32_t ParsePackingParamClose(Handler hdl);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif /* _PARSEPACKINGPARAM_H_ */
diff -Nur FFmpeg/DASH_packing_sample/ParsePackingParam/ParsePackingParamAPIImpl.cpp FFmpeg_patched/DASH_packing_sample/ParsePackingParam/ParsePackingParamAPIImpl.cpp
--- FFmpeg/DASH_packing_sample/ParsePackingParam/ParsePackingParamAPIImpl.cpp	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/ParsePackingParam/ParsePackingParamAPIImpl.cpp	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,34 @@
+#include "ParsePackingParamAPI.h"
+#include "ParamParser.h"
+
+Handler ParsePackingParamInit()
+{
+    ParamParser *parser = new ParamParser();
+    if (!parser)
+        return NULL;
+
+    return (Handler)((long)parser);
+}
+
+int32_t ParsePackingParamParse(Handler hdl, char *config_file, void *param_pointer)
+{
+    ParamParser *parser = (ParamParser *)hdl;
+    if (!parser)
+        return -1;
+
+    int32_t ret = parser->Parse(config_file, param_pointer);
+
+    return ret;
+}
+
+int32_t ParsePackingParamClose(Handler hdl)
+{
+    ParamParser *parser = (ParamParser *)hdl;
+    if (parser)
+    {
+        delete parser;
+        parser = NULL;
+    }
+
+    return 0;
+}
diff -Nur FFmpeg/DASH_packing_sample/ParsePackingParam/tinyxml2.cpp FFmpeg_patched/DASH_packing_sample/ParsePackingParam/tinyxml2.cpp
--- FFmpeg/DASH_packing_sample/ParsePackingParam/tinyxml2.cpp	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/ParsePackingParam/tinyxml2.cpp	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,2837 @@
+/*
+Original code by Lee Thomason (www.grinninglizard.com)
+
+This software is provided 'as-is', without any express or implied
+warranty. In no event will the authors be held liable for any
+damages arising from the use of this software.
+
+Permission is granted to anyone to use this software for any
+purpose, including commercial applications, and to alter it and
+redistribute it freely, subject to the following restrictions:
+
+1. The origin of this software must not be misrepresented; you must
+not claim that you wrote the original software. If you use this
+software in a product, an acknowledgment in the product documentation
+would be appreciated but is not required.
+
+2. Altered source versions must be plainly marked as such, and
+must not be misrepresented as being the original software.
+
+3. This notice may not be removed or altered from any source
+distribution.
+*/
+
+#include "tinyxml2.h"
+
+#include <new>		// yes, this one new style header, is in the Android SDK.
+#if defined(ANDROID_NDK) || defined(__BORLANDC__) || defined(__QNXNTO__)
+#   include <stddef.h>
+#   include <stdarg.h>
+#else
+#   include <cstddef>
+#   include <cstdarg>
+#endif
+
+#if defined(_MSC_VER) && (_MSC_VER >= 1400 ) && (!defined WINCE)
+	// Microsoft Visual Studio, version 2005 and higher. Not WinCE.
+	/*int _snprintf_s(
+	   char *buffer,
+	   size_t sizeOfBuffer,
+	   size_t count,
+	   const char *format [,
+		  argument] ...
+	);*/
+	static inline int TIXML_SNPRINTF( char* buffer, size_t size, const char* format, ... )
+	{
+		va_list va;
+		va_start( va, format );
+		const int result = vsnprintf_s( buffer, size, _TRUNCATE, format, va );
+		va_end( va );
+		return result;
+	}
+
+	static inline int TIXML_VSNPRINTF( char* buffer, size_t size, const char* format, va_list va )
+	{
+		const int result = vsnprintf_s( buffer, size, _TRUNCATE, format, va );
+		return result;
+	}
+
+	#define TIXML_VSCPRINTF	_vscprintf
+	#define TIXML_SSCANF	sscanf_s
+#elif defined _MSC_VER
+	// Microsoft Visual Studio 2003 and earlier or WinCE
+	#define TIXML_SNPRINTF	_snprintf
+	#define TIXML_VSNPRINTF _vsnprintf
+	#define TIXML_SSCANF	sscanf
+	#if (_MSC_VER < 1400 ) && (!defined WINCE)
+		// Microsoft Visual Studio 2003 and not WinCE.
+		#define TIXML_VSCPRINTF   _vscprintf // VS2003's C runtime has this, but VC6 C runtime or WinCE SDK doesn't have.
+	#else
+		// Microsoft Visual Studio 2003 and earlier or WinCE.
+		static inline int TIXML_VSCPRINTF( const char* format, va_list va )
+		{
+			int len = 512;
+			for (;;) {
+				len = len*2;
+				char* str = new char[len]();
+				const int required = _vsnprintf(str, len, format, va);
+				delete[] str;
+				if ( required != -1 ) {
+					TIXMLASSERT( required >= 0 );
+					len = required;
+					break;
+				}
+			}
+			TIXMLASSERT( len >= 0 );
+			return len;
+		}
+	#endif
+#else
+	// GCC version 3 and higher
+	//#warning( "Using sn* functions." )
+	#define TIXML_SNPRINTF	snprintf
+	#define TIXML_VSNPRINTF	vsnprintf
+	static inline int TIXML_VSCPRINTF( const char* format, va_list va )
+	{
+		int len = vsnprintf( 0, 0, format, va );
+		TIXMLASSERT( len >= 0 );
+		return len;
+	}
+	#define TIXML_SSCANF   sscanf
+#endif
+
+
+static const char LINE_FEED				= (char)0x0a;			// all line endings are normalized to LF
+static const char LF = LINE_FEED;
+static const char CARRIAGE_RETURN		= (char)0x0d;			// CR gets filtered out
+static const char CR = CARRIAGE_RETURN;
+static const char SINGLE_QUOTE			= '\'';
+static const char DOUBLE_QUOTE			= '\"';
+
+// Bunch of unicode info at:
+//		http://www.unicode.org/faq/utf_bom.html
+//	ef bb bf (Microsoft "lead bytes") - designates UTF-8
+
+static const unsigned char TIXML_UTF_LEAD_0 = 0xefU;
+static const unsigned char TIXML_UTF_LEAD_1 = 0xbbU;
+static const unsigned char TIXML_UTF_LEAD_2 = 0xbfU;
+
+namespace tinyxml2
+{
+
+struct Entity {
+    const char* pattern;
+    int length;
+    char value;
+};
+
+static const int NUM_ENTITIES = 5;
+static const Entity entities[NUM_ENTITIES] = {
+    { "quot", 4,	DOUBLE_QUOTE },
+    { "amp", 3,		'&'  },
+    { "apos", 4,	SINGLE_QUOTE },
+    { "lt",	2, 		'<'	 },
+    { "gt",	2,		'>'	 }
+};
+
+
+StrPair::~StrPair()
+{
+    Reset();
+}
+
+
+void StrPair::TransferTo( StrPair* other )
+{
+    if ( this == other ) {
+        return;
+    }
+    // This in effect implements the assignment operator by "moving"
+    // ownership (as in auto_ptr).
+
+    TIXMLASSERT( other != 0 );
+    TIXMLASSERT( other->_flags == 0 );
+    TIXMLASSERT( other->_start == 0 );
+    TIXMLASSERT( other->_end == 0 );
+
+    other->Reset();
+
+    other->_flags = _flags;
+    other->_start = _start;
+    other->_end = _end;
+
+    _flags = 0;
+    _start = 0;
+    _end = 0;
+}
+
+
+void StrPair::Reset()
+{
+    if ( _flags & NEEDS_DELETE ) {
+        delete [] _start;
+    }
+    _flags = 0;
+    _start = 0;
+    _end = 0;
+}
+
+
+void StrPair::SetStr( const char* str, int flags )
+{
+    TIXMLASSERT( str );
+    Reset();
+    size_t len = strlen( str );
+    TIXMLASSERT( _start == 0 );
+    _start = new char[ len+1 ];
+    memcpy( _start, str, len+1 );
+    _end = _start + len;
+    _flags = flags | NEEDS_DELETE;
+}
+
+
+char* StrPair::ParseText( char* p, const char* endTag, int strFlags, int* curLineNumPtr )
+{
+    TIXMLASSERT( p );
+    TIXMLASSERT( endTag && *endTag );
+	TIXMLASSERT(curLineNumPtr);
+
+    char* start = p;
+    const char  endChar = *endTag;
+    size_t length = strlen( endTag );
+
+    // Inner loop of text parsing.
+    while ( *p ) {
+        if ( *p == endChar && strncmp( p, endTag, length ) == 0 ) {
+            Set( start, p, strFlags );
+            return p + length;
+        } else if (*p == '\n') {
+            ++(*curLineNumPtr);
+        }
+        ++p;
+        TIXMLASSERT( p );
+    }
+    return 0;
+}
+
+
+char* StrPair::ParseName( char* p )
+{
+    if ( !p || !(*p) ) {
+        return 0;
+    }
+    if ( !XMLUtil::IsNameStartChar( *p ) ) {
+        return 0;
+    }
+
+    char* const start = p;
+    ++p;
+    while ( *p && XMLUtil::IsNameChar( *p ) ) {
+        ++p;
+    }
+
+    Set( start, p, 0 );
+    return p;
+}
+
+
+void StrPair::CollapseWhitespace()
+{
+    // Adjusting _start would cause undefined behavior on delete[]
+    TIXMLASSERT( ( _flags & NEEDS_DELETE ) == 0 );
+    // Trim leading space.
+    _start = XMLUtil::SkipWhiteSpace( _start, 0 );
+
+    if ( *_start ) {
+        const char* p = _start;	// the read pointer
+        char* q = _start;	// the write pointer
+
+        while( *p ) {
+            if ( XMLUtil::IsWhiteSpace( *p )) {
+                p = XMLUtil::SkipWhiteSpace( p, 0 );
+                if ( *p == 0 ) {
+                    break;    // don't write to q; this trims the trailing space.
+                }
+                *q = ' ';
+                ++q;
+            }
+            *q = *p;
+            ++q;
+            ++p;
+        }
+        *q = 0;
+    }
+}
+
+
+const char* StrPair::GetStr()
+{
+    TIXMLASSERT( _start );
+    TIXMLASSERT( _end );
+    if ( _flags & NEEDS_FLUSH ) {
+        *_end = 0;
+        _flags ^= NEEDS_FLUSH;
+
+        if ( _flags ) {
+            const char* p = _start;	// the read pointer
+            char* q = _start;	// the write pointer
+
+            while( p < _end ) {
+                if ( (_flags & NEEDS_NEWLINE_NORMALIZATION) && *p == CR ) {
+                    // CR-LF pair becomes LF
+                    // CR alone becomes LF
+                    // LF-CR becomes LF
+                    if ( *(p+1) == LF ) {
+                        p += 2;
+                    }
+                    else {
+                        ++p;
+                    }
+                    *q = LF;
+                    ++q;
+                }
+                else if ( (_flags & NEEDS_NEWLINE_NORMALIZATION) && *p == LF ) {
+                    if ( *(p+1) == CR ) {
+                        p += 2;
+                    }
+                    else {
+                        ++p;
+                    }
+                    *q = LF;
+                    ++q;
+                }
+                else if ( (_flags & NEEDS_ENTITY_PROCESSING) && *p == '&' ) {
+                    // Entities handled by tinyXML2:
+                    // - special entities in the entity table [in/out]
+                    // - numeric character reference [in]
+                    //   &#20013; or &#x4e2d;
+
+                    if ( *(p+1) == '#' ) {
+                        const int buflen = 10;
+                        char buf[buflen] = { 0 };
+                        int len = 0;
+                        const char* adjusted = const_cast<char*>( XMLUtil::GetCharacterRef( p, buf, &len ) );
+                        if ( adjusted == 0 ) {
+                            *q = *p;
+                            ++p;
+                            ++q;
+                        }
+                        else {
+                            TIXMLASSERT( 0 <= len && len <= buflen );
+                            TIXMLASSERT( q + len <= adjusted );
+                            p = adjusted;
+                            memcpy( q, buf, len );
+                            q += len;
+                        }
+                    }
+                    else {
+                        bool entityFound = false;
+                        for( int i = 0; i < NUM_ENTITIES; ++i ) {
+                            const Entity& entity = entities[i];
+                            if ( strncmp( p + 1, entity.pattern, entity.length ) == 0
+                                    && *( p + entity.length + 1 ) == ';' ) {
+                                // Found an entity - convert.
+                                *q = entity.value;
+                                ++q;
+                                p += entity.length + 2;
+                                entityFound = true;
+                                break;
+                            }
+                        }
+                        if ( !entityFound ) {
+                            // fixme: treat as error?
+                            ++p;
+                            ++q;
+                        }
+                    }
+                }
+                else {
+                    *q = *p;
+                    ++p;
+                    ++q;
+                }
+            }
+            *q = 0;
+        }
+        // The loop below has plenty going on, and this
+        // is a less useful mode. Break it out.
+        if ( _flags & NEEDS_WHITESPACE_COLLAPSING ) {
+            CollapseWhitespace();
+        }
+        _flags = (_flags & NEEDS_DELETE);
+    }
+    TIXMLASSERT( _start );
+    return _start;
+}
+
+
+
+
+// --------- XMLUtil ----------- //
+
+const char* XMLUtil::writeBoolTrue  = "true";
+const char* XMLUtil::writeBoolFalse = "false";
+
+void XMLUtil::SetBoolSerialization(const char* writeTrue, const char* writeFalse)
+{
+	static const char* defTrue  = "true";
+	static const char* defFalse = "false";
+
+	writeBoolTrue = (writeTrue) ? writeTrue : defTrue;
+	writeBoolFalse = (writeFalse) ? writeFalse : defFalse;
+}
+
+
+const char* XMLUtil::ReadBOM( const char* p, bool* bom )
+{
+    TIXMLASSERT( p );
+    TIXMLASSERT( bom );
+    *bom = false;
+    const unsigned char* pu = reinterpret_cast<const unsigned char*>(p);
+    // Check for BOM:
+    if (    *(pu+0) == TIXML_UTF_LEAD_0
+            && *(pu+1) == TIXML_UTF_LEAD_1
+            && *(pu+2) == TIXML_UTF_LEAD_2 ) {
+        *bom = true;
+        p += 3;
+    }
+    TIXMLASSERT( p );
+    return p;
+}
+
+
+void XMLUtil::ConvertUTF32ToUTF8( unsigned long input, char* output, int* length )
+{
+    const unsigned long BYTE_MASK = 0xBF;
+    const unsigned long BYTE_MARK = 0x80;
+    const unsigned long FIRST_BYTE_MARK[7] = { 0x00, 0x00, 0xC0, 0xE0, 0xF0, 0xF8, 0xFC };
+
+    if (input < 0x80) {
+        *length = 1;
+    }
+    else if ( input < 0x800 ) {
+        *length = 2;
+    }
+    else if ( input < 0x10000 ) {
+        *length = 3;
+    }
+    else if ( input < 0x200000 ) {
+        *length = 4;
+    }
+    else {
+        *length = 0;    // This code won't convert this correctly anyway.
+        return;
+    }
+
+    output += *length;
+
+    // Scary scary fall throughs are annotated with carefully designed comments
+    // to suppress compiler warnings such as -Wimplicit-fallthrough in gcc
+    switch (*length) {
+        case 4:
+            --output;
+            *output = (char)((input | BYTE_MARK) & BYTE_MASK);
+            input >>= 6;
+            //fall through
+        case 3:
+            --output;
+            *output = (char)((input | BYTE_MARK) & BYTE_MASK);
+            input >>= 6;
+            //fall through
+        case 2:
+            --output;
+            *output = (char)((input | BYTE_MARK) & BYTE_MASK);
+            input >>= 6;
+            //fall through
+        case 1:
+            --output;
+            *output = (char)(input | FIRST_BYTE_MARK[*length]);
+            break;
+        default:
+            TIXMLASSERT( false );
+    }
+}
+
+
+const char* XMLUtil::GetCharacterRef( const char* p, char* value, int* length )
+{
+    // Presume an entity, and pull it out.
+    *length = 0;
+
+    if ( *(p+1) == '#' && *(p+2) ) {
+        unsigned long ucs = 0;
+        TIXMLASSERT( sizeof( ucs ) >= 4 );
+        ptrdiff_t delta = 0;
+        unsigned mult = 1;
+        static const char SEMICOLON = ';';
+
+        if ( *(p+2) == 'x' ) {
+            // Hexadecimal.
+            const char* q = p+3;
+            if ( !(*q) ) {
+                return 0;
+            }
+
+            q = strchr( q, SEMICOLON );
+
+            if ( !q ) {
+                return 0;
+            }
+            TIXMLASSERT( *q == SEMICOLON );
+
+            delta = q-p;
+            --q;
+
+            while ( *q != 'x' ) {
+                unsigned int digit = 0;
+
+                if ( *q >= '0' && *q <= '9' ) {
+                    digit = *q - '0';
+                }
+                else if ( *q >= 'a' && *q <= 'f' ) {
+                    digit = *q - 'a' + 10;
+                }
+                else if ( *q >= 'A' && *q <= 'F' ) {
+                    digit = *q - 'A' + 10;
+                }
+                else {
+                    return 0;
+                }
+                TIXMLASSERT( digit < 16 );
+                TIXMLASSERT( digit == 0 || mult <= UINT_MAX / digit );
+                const unsigned int digitScaled = mult * digit;
+                TIXMLASSERT( ucs <= ULONG_MAX - digitScaled );
+                ucs += digitScaled;
+                TIXMLASSERT( mult <= UINT_MAX / 16 );
+                mult *= 16;
+                --q;
+            }
+        }
+        else {
+            // Decimal.
+            const char* q = p+2;
+            if ( !(*q) ) {
+                return 0;
+            }
+
+            q = strchr( q, SEMICOLON );
+
+            if ( !q ) {
+                return 0;
+            }
+            TIXMLASSERT( *q == SEMICOLON );
+
+            delta = q-p;
+            --q;
+
+            while ( *q != '#' ) {
+                if ( *q >= '0' && *q <= '9' ) {
+                    const unsigned int digit = *q - '0';
+                    TIXMLASSERT( digit < 10 );
+                    TIXMLASSERT( digit == 0 || mult <= UINT_MAX / digit );
+                    const unsigned int digitScaled = mult * digit;
+                    TIXMLASSERT( ucs <= ULONG_MAX - digitScaled );
+                    ucs += digitScaled;
+                }
+                else {
+                    return 0;
+                }
+                TIXMLASSERT( mult <= UINT_MAX / 10 );
+                mult *= 10;
+                --q;
+            }
+        }
+        // convert the UCS to UTF-8
+        ConvertUTF32ToUTF8( ucs, value, length );
+        return p + delta + 1;
+    }
+    return p+1;
+}
+
+
+void XMLUtil::ToStr( int v, char* buffer, int bufferSize )
+{
+    TIXML_SNPRINTF( buffer, bufferSize, "%d", v );
+}
+
+
+void XMLUtil::ToStr( unsigned v, char* buffer, int bufferSize )
+{
+    TIXML_SNPRINTF( buffer, bufferSize, "%u", v );
+}
+
+
+void XMLUtil::ToStr( bool v, char* buffer, int bufferSize )
+{
+    TIXML_SNPRINTF( buffer, bufferSize, "%s", v ? writeBoolTrue : writeBoolFalse);
+}
+
+/*
+	ToStr() of a number is a very tricky topic.
+	https://github.com/leethomason/tinyxml2/issues/106
+*/
+void XMLUtil::ToStr( float v, char* buffer, int bufferSize )
+{
+    TIXML_SNPRINTF( buffer, bufferSize, "%.8g", v );
+}
+
+
+void XMLUtil::ToStr( double v, char* buffer, int bufferSize )
+{
+    TIXML_SNPRINTF( buffer, bufferSize, "%.17g", v );
+}
+
+
+void XMLUtil::ToStr(int64_t v, char* buffer, int bufferSize)
+{
+	// horrible syntax trick to make the compiler happy about %lld
+	TIXML_SNPRINTF(buffer, bufferSize, "%lld", (long long)v);
+}
+
+
+bool XMLUtil::ToInt( const char* str, int* value )
+{
+    if ( TIXML_SSCANF( str, "%d", value ) == 1 ) {
+        return true;
+    }
+    return false;
+}
+
+bool XMLUtil::ToUnsigned( const char* str, unsigned *value )
+{
+    if ( TIXML_SSCANF( str, "%u", value ) == 1 ) {
+        return true;
+    }
+    return false;
+}
+
+bool XMLUtil::ToBool( const char* str, bool* value )
+{
+    int ival = 0;
+    if ( ToInt( str, &ival )) {
+        *value = (ival==0) ? false : true;
+        return true;
+    }
+    if ( StringEqual( str, "true" ) ) {
+        *value = true;
+        return true;
+    }
+    else if ( StringEqual( str, "false" ) ) {
+        *value = false;
+        return true;
+    }
+    return false;
+}
+
+
+bool XMLUtil::ToFloat( const char* str, float* value )
+{
+    if ( TIXML_SSCANF( str, "%f", value ) == 1 ) {
+        return true;
+    }
+    return false;
+}
+
+
+bool XMLUtil::ToDouble( const char* str, double* value )
+{
+    if ( TIXML_SSCANF( str, "%lf", value ) == 1 ) {
+        return true;
+    }
+    return false;
+}
+
+
+bool XMLUtil::ToInt64(const char* str, int64_t* value)
+{
+	long long v = 0;	// horrible syntax trick to make the compiler happy about %lld
+	if (TIXML_SSCANF(str, "%lld", &v) == 1) {
+		*value = (int64_t)v;
+		return true;
+	}
+	return false;
+}
+
+
+char* XMLDocument::Identify( char* p, XMLNode** node )
+{
+    TIXMLASSERT( node );
+    TIXMLASSERT( p );
+    char* const start = p;
+    int const startLine = _parseCurLineNum;
+    p = XMLUtil::SkipWhiteSpace( p, &_parseCurLineNum );
+    if( !*p ) {
+        *node = 0;
+        TIXMLASSERT( p );
+        return p;
+    }
+
+    // These strings define the matching patterns:
+    static const char* xmlHeader		= { "<?" };
+    static const char* commentHeader	= { "<!--" };
+    static const char* cdataHeader		= { "<![CDATA[" };
+    static const char* dtdHeader		= { "<!" };
+    static const char* elementHeader	= { "<" };	// and a header for everything else; check last.
+
+    static const int xmlHeaderLen		= 2;
+    static const int commentHeaderLen	= 4;
+    static const int cdataHeaderLen		= 9;
+    static const int dtdHeaderLen		= 2;
+    static const int elementHeaderLen	= 1;
+
+    TIXMLASSERT( sizeof( XMLComment ) == sizeof( XMLUnknown ) );		// use same memory pool
+    TIXMLASSERT( sizeof( XMLComment ) == sizeof( XMLDeclaration ) );	// use same memory pool
+    XMLNode* returnNode = 0;
+    if ( XMLUtil::StringEqual( p, xmlHeader, xmlHeaderLen ) ) {
+        returnNode = CreateUnlinkedNode<XMLDeclaration>( _commentPool );
+        returnNode->_parseLineNum = _parseCurLineNum;
+        p += xmlHeaderLen;
+    }
+    else if ( XMLUtil::StringEqual( p, commentHeader, commentHeaderLen ) ) {
+        returnNode = CreateUnlinkedNode<XMLComment>( _commentPool );
+        returnNode->_parseLineNum = _parseCurLineNum;
+        p += commentHeaderLen;
+    }
+    else if ( XMLUtil::StringEqual( p, cdataHeader, cdataHeaderLen ) ) {
+        XMLText* text = CreateUnlinkedNode<XMLText>( _textPool );
+        returnNode = text;
+        returnNode->_parseLineNum = _parseCurLineNum;
+        p += cdataHeaderLen;
+        text->SetCData( true );
+    }
+    else if ( XMLUtil::StringEqual( p, dtdHeader, dtdHeaderLen ) ) {
+        returnNode = CreateUnlinkedNode<XMLUnknown>( _commentPool );
+        returnNode->_parseLineNum = _parseCurLineNum;
+        p += dtdHeaderLen;
+    }
+    else if ( XMLUtil::StringEqual( p, elementHeader, elementHeaderLen ) ) {
+        returnNode =  CreateUnlinkedNode<XMLElement>( _elementPool );
+        returnNode->_parseLineNum = _parseCurLineNum;
+        p += elementHeaderLen;
+    }
+    else {
+        returnNode = CreateUnlinkedNode<XMLText>( _textPool );
+        returnNode->_parseLineNum = _parseCurLineNum; // Report line of first non-whitespace character
+        p = start;	// Back it up, all the text counts.
+        _parseCurLineNum = startLine;
+    }
+
+    TIXMLASSERT( returnNode );
+    TIXMLASSERT( p );
+    *node = returnNode;
+    return p;
+}
+
+
+bool XMLDocument::Accept( XMLVisitor* visitor ) const
+{
+    TIXMLASSERT( visitor );
+    if ( visitor->VisitEnter( *this ) ) {
+        for ( const XMLNode* node=FirstChild(); node; node=node->NextSibling() ) {
+            if ( !node->Accept( visitor ) ) {
+                break;
+            }
+        }
+    }
+    return visitor->VisitExit( *this );
+}
+
+
+// --------- XMLNode ----------- //
+
+XMLNode::XMLNode( XMLDocument* doc ) :
+    _document( doc ),
+    _parent( 0 ),
+    _value(),
+    _parseLineNum( 0 ),
+    _firstChild( 0 ), _lastChild( 0 ),
+    _prev( 0 ), _next( 0 ),
+	_userData( 0 ),
+    _memPool( 0 )
+{
+}
+
+
+XMLNode::~XMLNode()
+{
+    DeleteChildren();
+    if ( _parent ) {
+        _parent->Unlink( this );
+    }
+}
+
+const char* XMLNode::Value() const
+{
+    // Edge case: XMLDocuments don't have a Value. Return null.
+    if ( this->ToDocument() )
+        return 0;
+    return _value.GetStr();
+}
+
+void XMLNode::SetValue( const char* str, bool staticMem )
+{
+    if ( staticMem ) {
+        _value.SetInternedStr( str );
+    }
+    else {
+        _value.SetStr( str );
+    }
+}
+
+XMLNode* XMLNode::DeepClone(XMLDocument* target) const
+{
+	XMLNode* clone = this->ShallowClone(target);
+	if (!clone) return 0;
+
+	for (const XMLNode* child = this->FirstChild(); child; child = child->NextSibling()) {
+		XMLNode* childClone = child->DeepClone(target);
+		TIXMLASSERT(childClone);
+		clone->InsertEndChild(childClone);
+	}
+	return clone;
+}
+
+void XMLNode::DeleteChildren()
+{
+    while( _firstChild ) {
+        TIXMLASSERT( _lastChild );
+        DeleteChild( _firstChild );
+    }
+    _firstChild = _lastChild = 0;
+}
+
+
+void XMLNode::Unlink( XMLNode* child )
+{
+    TIXMLASSERT( child );
+    TIXMLASSERT( child->_document == _document );
+    TIXMLASSERT( child->_parent == this );
+    if ( child == _firstChild ) {
+        _firstChild = _firstChild->_next;
+    }
+    if ( child == _lastChild ) {
+        _lastChild = _lastChild->_prev;
+    }
+
+    if ( child->_prev ) {
+        child->_prev->_next = child->_next;
+    }
+    if ( child->_next ) {
+        child->_next->_prev = child->_prev;
+    }
+	child->_next = 0;
+	child->_prev = 0;
+	child->_parent = 0;
+}
+
+
+void XMLNode::DeleteChild( XMLNode* node )
+{
+    TIXMLASSERT( node );
+    TIXMLASSERT( node->_document == _document );
+    TIXMLASSERT( node->_parent == this );
+    Unlink( node );
+	TIXMLASSERT(node->_prev == 0);
+	TIXMLASSERT(node->_next == 0);
+	TIXMLASSERT(node->_parent == 0);
+    DeleteNode( node );
+}
+
+
+XMLNode* XMLNode::InsertEndChild( XMLNode* addThis )
+{
+    TIXMLASSERT( addThis );
+    if ( addThis->_document != _document ) {
+        TIXMLASSERT( false );
+        return 0;
+    }
+    InsertChildPreamble( addThis );
+
+    if ( _lastChild ) {
+        TIXMLASSERT( _firstChild );
+        TIXMLASSERT( _lastChild->_next == 0 );
+        _lastChild->_next = addThis;
+        addThis->_prev = _lastChild;
+        _lastChild = addThis;
+
+        addThis->_next = 0;
+    }
+    else {
+        TIXMLASSERT( _firstChild == 0 );
+        _firstChild = _lastChild = addThis;
+
+        addThis->_prev = 0;
+        addThis->_next = 0;
+    }
+    addThis->_parent = this;
+    return addThis;
+}
+
+
+XMLNode* XMLNode::InsertFirstChild( XMLNode* addThis )
+{
+    TIXMLASSERT( addThis );
+    if ( addThis->_document != _document ) {
+        TIXMLASSERT( false );
+        return 0;
+    }
+    InsertChildPreamble( addThis );
+
+    if ( _firstChild ) {
+        TIXMLASSERT( _lastChild );
+        TIXMLASSERT( _firstChild->_prev == 0 );
+
+        _firstChild->_prev = addThis;
+        addThis->_next = _firstChild;
+        _firstChild = addThis;
+
+        addThis->_prev = 0;
+    }
+    else {
+        TIXMLASSERT( _lastChild == 0 );
+        _firstChild = _lastChild = addThis;
+
+        addThis->_prev = 0;
+        addThis->_next = 0;
+    }
+    addThis->_parent = this;
+    return addThis;
+}
+
+
+XMLNode* XMLNode::InsertAfterChild( XMLNode* afterThis, XMLNode* addThis )
+{
+    TIXMLASSERT( addThis );
+    if ( addThis->_document != _document ) {
+        TIXMLASSERT( false );
+        return 0;
+    }
+
+    TIXMLASSERT( afterThis );
+
+    if ( afterThis->_parent != this ) {
+        TIXMLASSERT( false );
+        return 0;
+    }
+    if ( afterThis == addThis ) {
+        // Current state: BeforeThis -> AddThis -> OneAfterAddThis
+        // Now AddThis must disappear from it's location and then
+        // reappear between BeforeThis and OneAfterAddThis.
+        // So just leave it where it is.
+        return addThis;
+    }
+
+    if ( afterThis->_next == 0 ) {
+        // The last node or the only node.
+        return InsertEndChild( addThis );
+    }
+    InsertChildPreamble( addThis );
+    addThis->_prev = afterThis;
+    addThis->_next = afterThis->_next;
+    afterThis->_next->_prev = addThis;
+    afterThis->_next = addThis;
+    addThis->_parent = this;
+    return addThis;
+}
+
+
+
+
+const XMLElement* XMLNode::FirstChildElement( const char* name ) const
+{
+    for( const XMLNode* node = _firstChild; node; node = node->_next ) {
+        const XMLElement* element = node->ToElementWithName( name );
+        if ( element ) {
+            return element;
+        }
+    }
+    return 0;
+}
+
+
+const XMLElement* XMLNode::LastChildElement( const char* name ) const
+{
+    for( const XMLNode* node = _lastChild; node; node = node->_prev ) {
+        const XMLElement* element = node->ToElementWithName( name );
+        if ( element ) {
+            return element;
+        }
+    }
+    return 0;
+}
+
+
+const XMLElement* XMLNode::NextSiblingElement( const char* name ) const
+{
+    for( const XMLNode* node = _next; node; node = node->_next ) {
+        const XMLElement* element = node->ToElementWithName( name );
+        if ( element ) {
+            return element;
+        }
+    }
+    return 0;
+}
+
+
+const XMLElement* XMLNode::PreviousSiblingElement( const char* name ) const
+{
+    for( const XMLNode* node = _prev; node; node = node->_prev ) {
+        const XMLElement* element = node->ToElementWithName( name );
+        if ( element ) {
+            return element;
+        }
+    }
+    return 0;
+}
+
+
+char* XMLNode::ParseDeep( char* p, StrPair* parentEndTag, int* curLineNumPtr )
+{
+    // This is a recursive method, but thinking about it "at the current level"
+    // it is a pretty simple flat list:
+    //		<foo/>
+    //		<!-- comment -->
+    //
+    // With a special case:
+    //		<foo>
+    //		</foo>
+    //		<!-- comment -->
+    //
+    // Where the closing element (/foo) *must* be the next thing after the opening
+    // element, and the names must match. BUT the tricky bit is that the closing
+    // element will be read by the child.
+    //
+    // 'endTag' is the end tag for this node, it is returned by a call to a child.
+    // 'parentEnd' is the end tag for the parent, which is filled in and returned.
+
+	XMLDocument::DepthTracker tracker(_document);
+	if (_document->Error())
+		return 0;
+
+	while( p && *p ) {
+        XMLNode* node = 0;
+
+        p = _document->Identify( p, &node );
+        TIXMLASSERT( p );
+        if ( node == 0 ) {
+            break;
+        }
+
+       const int initialLineNum = node->_parseLineNum;
+
+        StrPair endTag;
+        p = node->ParseDeep( p, &endTag, curLineNumPtr );
+        if ( !p ) {
+            DeleteNode( node );
+            if ( !_document->Error() ) {
+                _document->SetError( XML_ERROR_PARSING, initialLineNum, 0);
+            }
+            break;
+        }
+
+        const XMLDeclaration* const decl = node->ToDeclaration();
+        if ( decl ) {
+            // Declarations are only allowed at document level
+            //
+            // Multiple declarations are allowed but all declarations
+            // must occur before anything else.
+            //
+            // Optimized due to a security test case. If the first node is
+            // a declaration, and the last node is a declaration, then only
+            // declarations have so far been added.
+            bool wellLocated = false;
+
+            if (ToDocument()) {
+                if (FirstChild()) {
+                    wellLocated =
+                        FirstChild() &&
+                        FirstChild()->ToDeclaration() &&
+                        LastChild() &&
+                        LastChild()->ToDeclaration();
+                }
+                else {
+                    wellLocated = true;
+                }
+            }
+            if ( !wellLocated ) {
+                _document->SetError( XML_ERROR_PARSING_DECLARATION, initialLineNum, "XMLDeclaration value=%s", decl->Value());
+                DeleteNode( node );
+                break;
+            }
+        }
+
+        XMLElement* ele = node->ToElement();
+        if ( ele ) {
+            // We read the end tag. Return it to the parent.
+            if ( ele->ClosingType() == XMLElement::CLOSING ) {
+                if ( parentEndTag ) {
+                    ele->_value.TransferTo( parentEndTag );
+                }
+                node->_memPool->SetTracked();   // created and then immediately deleted.
+                DeleteNode( node );
+                return p;
+            }
+
+            // Handle an end tag returned to this level.
+            // And handle a bunch of annoying errors.
+            bool mismatch = false;
+            if ( endTag.Empty() ) {
+                if ( ele->ClosingType() == XMLElement::OPEN ) {
+                    mismatch = true;
+                }
+            }
+            else {
+                if ( ele->ClosingType() != XMLElement::OPEN ) {
+                    mismatch = true;
+                }
+                else if ( !XMLUtil::StringEqual( endTag.GetStr(), ele->Name() ) ) {
+                    mismatch = true;
+                }
+            }
+            if ( mismatch ) {
+                _document->SetError( XML_ERROR_MISMATCHED_ELEMENT, initialLineNum, "XMLElement name=%s", ele->Name());
+                DeleteNode( node );
+                break;
+            }
+        }
+        InsertEndChild( node );
+    }
+    return 0;
+}
+
+/*static*/ void XMLNode::DeleteNode( XMLNode* node )
+{
+    if ( node == 0 ) {
+        return;
+    }
+	TIXMLASSERT(node->_document);
+	if (!node->ToDocument()) {
+		node->_document->MarkInUse(node);
+	}
+
+    MemPool* pool = node->_memPool;
+    node->~XMLNode();
+    pool->Free( node );
+}
+
+void XMLNode::InsertChildPreamble( XMLNode* insertThis ) const
+{
+    TIXMLASSERT( insertThis );
+    TIXMLASSERT( insertThis->_document == _document );
+
+	if (insertThis->_parent) {
+        insertThis->_parent->Unlink( insertThis );
+	}
+	else {
+		insertThis->_document->MarkInUse(insertThis);
+        insertThis->_memPool->SetTracked();
+	}
+}
+
+const XMLElement* XMLNode::ToElementWithName( const char* name ) const
+{
+    const XMLElement* element = this->ToElement();
+    if ( element == 0 ) {
+        return 0;
+    }
+    if ( name == 0 ) {
+        return element;
+    }
+    if ( XMLUtil::StringEqual( element->Name(), name ) ) {
+       return element;
+    }
+    return 0;
+}
+
+// --------- XMLText ---------- //
+char* XMLText::ParseDeep( char* p, StrPair*, int* curLineNumPtr )
+{
+    if ( this->CData() ) {
+        p = _value.ParseText( p, "]]>", StrPair::NEEDS_NEWLINE_NORMALIZATION, curLineNumPtr );
+        if ( !p ) {
+            _document->SetError( XML_ERROR_PARSING_CDATA, _parseLineNum, 0 );
+        }
+        return p;
+    }
+    else {
+        int flags = _document->ProcessEntities() ? StrPair::TEXT_ELEMENT : StrPair::TEXT_ELEMENT_LEAVE_ENTITIES;
+        if ( _document->WhitespaceMode() == COLLAPSE_WHITESPACE ) {
+            flags |= StrPair::NEEDS_WHITESPACE_COLLAPSING;
+        }
+
+        p = _value.ParseText( p, "<", flags, curLineNumPtr );
+        if ( p && *p ) {
+            return p-1;
+        }
+        if ( !p ) {
+            _document->SetError( XML_ERROR_PARSING_TEXT, _parseLineNum, 0 );
+        }
+    }
+    return 0;
+}
+
+
+XMLNode* XMLText::ShallowClone( XMLDocument* doc ) const
+{
+    if ( !doc ) {
+        doc = _document;
+    }
+    XMLText* text = doc->NewText( Value() );	// fixme: this will always allocate memory. Intern?
+    text->SetCData( this->CData() );
+    return text;
+}
+
+
+bool XMLText::ShallowEqual( const XMLNode* compare ) const
+{
+    TIXMLASSERT( compare );
+    const XMLText* text = compare->ToText();
+    return ( text && XMLUtil::StringEqual( text->Value(), Value() ) );
+}
+
+
+bool XMLText::Accept( XMLVisitor* visitor ) const
+{
+    TIXMLASSERT( visitor );
+    return visitor->Visit( *this );
+}
+
+
+// --------- XMLComment ---------- //
+
+XMLComment::XMLComment( XMLDocument* doc ) : XMLNode( doc )
+{
+}
+
+
+XMLComment::~XMLComment()
+{
+}
+
+
+char* XMLComment::ParseDeep( char* p, StrPair*, int* curLineNumPtr )
+{
+    // Comment parses as text.
+    p = _value.ParseText( p, "-->", StrPair::COMMENT, curLineNumPtr );
+    if ( p == 0 ) {
+        _document->SetError( XML_ERROR_PARSING_COMMENT, _parseLineNum, 0 );
+    }
+    return p;
+}
+
+
+XMLNode* XMLComment::ShallowClone( XMLDocument* doc ) const
+{
+    if ( !doc ) {
+        doc = _document;
+    }
+    XMLComment* comment = doc->NewComment( Value() );	// fixme: this will always allocate memory. Intern?
+    return comment;
+}
+
+
+bool XMLComment::ShallowEqual( const XMLNode* compare ) const
+{
+    TIXMLASSERT( compare );
+    const XMLComment* comment = compare->ToComment();
+    return ( comment && XMLUtil::StringEqual( comment->Value(), Value() ));
+}
+
+
+bool XMLComment::Accept( XMLVisitor* visitor ) const
+{
+    TIXMLASSERT( visitor );
+    return visitor->Visit( *this );
+}
+
+
+// --------- XMLDeclaration ---------- //
+
+XMLDeclaration::XMLDeclaration( XMLDocument* doc ) : XMLNode( doc )
+{
+}
+
+
+XMLDeclaration::~XMLDeclaration()
+{
+    //printf( "~XMLDeclaration\n" );
+}
+
+
+char* XMLDeclaration::ParseDeep( char* p, StrPair*, int* curLineNumPtr )
+{
+    // Declaration parses as text.
+    p = _value.ParseText( p, "?>", StrPair::NEEDS_NEWLINE_NORMALIZATION, curLineNumPtr );
+    if ( p == 0 ) {
+        _document->SetError( XML_ERROR_PARSING_DECLARATION, _parseLineNum, 0 );
+    }
+    return p;
+}
+
+
+XMLNode* XMLDeclaration::ShallowClone( XMLDocument* doc ) const
+{
+    if ( !doc ) {
+        doc = _document;
+    }
+    XMLDeclaration* dec = doc->NewDeclaration( Value() );	// fixme: this will always allocate memory. Intern?
+    return dec;
+}
+
+
+bool XMLDeclaration::ShallowEqual( const XMLNode* compare ) const
+{
+    TIXMLASSERT( compare );
+    const XMLDeclaration* declaration = compare->ToDeclaration();
+    return ( declaration && XMLUtil::StringEqual( declaration->Value(), Value() ));
+}
+
+
+
+bool XMLDeclaration::Accept( XMLVisitor* visitor ) const
+{
+    TIXMLASSERT( visitor );
+    return visitor->Visit( *this );
+}
+
+// --------- XMLUnknown ---------- //
+
+XMLUnknown::XMLUnknown( XMLDocument* doc ) : XMLNode( doc )
+{
+}
+
+
+XMLUnknown::~XMLUnknown()
+{
+}
+
+
+char* XMLUnknown::ParseDeep( char* p, StrPair*, int* curLineNumPtr )
+{
+    // Unknown parses as text.
+    p = _value.ParseText( p, ">", StrPair::NEEDS_NEWLINE_NORMALIZATION, curLineNumPtr );
+    if ( !p ) {
+        _document->SetError( XML_ERROR_PARSING_UNKNOWN, _parseLineNum, 0 );
+    }
+    return p;
+}
+
+
+XMLNode* XMLUnknown::ShallowClone( XMLDocument* doc ) const
+{
+    if ( !doc ) {
+        doc = _document;
+    }
+    XMLUnknown* text = doc->NewUnknown( Value() );	// fixme: this will always allocate memory. Intern?
+    return text;
+}
+
+
+bool XMLUnknown::ShallowEqual( const XMLNode* compare ) const
+{
+    TIXMLASSERT( compare );
+    const XMLUnknown* unknown = compare->ToUnknown();
+    return ( unknown && XMLUtil::StringEqual( unknown->Value(), Value() ));
+}
+
+
+bool XMLUnknown::Accept( XMLVisitor* visitor ) const
+{
+    TIXMLASSERT( visitor );
+    return visitor->Visit( *this );
+}
+
+// --------- XMLAttribute ---------- //
+
+const char* XMLAttribute::Name() const
+{
+    return _name.GetStr();
+}
+
+const char* XMLAttribute::Value() const
+{
+    return _value.GetStr();
+}
+
+char* XMLAttribute::ParseDeep( char* p, bool processEntities, int* curLineNumPtr )
+{
+    // Parse using the name rules: bug fix, was using ParseText before
+    p = _name.ParseName( p );
+    if ( !p || !*p ) {
+        return 0;
+    }
+
+    // Skip white space before =
+    p = XMLUtil::SkipWhiteSpace( p, curLineNumPtr );
+    if ( *p != '=' ) {
+        return 0;
+    }
+
+    ++p;	// move up to opening quote
+    p = XMLUtil::SkipWhiteSpace( p, curLineNumPtr );
+    if ( *p != '\"' && *p != '\'' ) {
+        return 0;
+    }
+
+    const char endTag[2] = { *p, 0 };
+    ++p;	// move past opening quote
+
+    p = _value.ParseText( p, endTag, processEntities ? StrPair::ATTRIBUTE_VALUE : StrPair::ATTRIBUTE_VALUE_LEAVE_ENTITIES, curLineNumPtr );
+    return p;
+}
+
+
+void XMLAttribute::SetName( const char* n )
+{
+    _name.SetStr( n );
+}
+
+
+XMLError XMLAttribute::QueryIntValue( int* value ) const
+{
+    if ( XMLUtil::ToInt( Value(), value )) {
+        return XML_SUCCESS;
+    }
+    return XML_WRONG_ATTRIBUTE_TYPE;
+}
+
+
+XMLError XMLAttribute::QueryUnsignedValue( unsigned int* value ) const
+{
+    if ( XMLUtil::ToUnsigned( Value(), value )) {
+        return XML_SUCCESS;
+    }
+    return XML_WRONG_ATTRIBUTE_TYPE;
+}
+
+
+XMLError XMLAttribute::QueryInt64Value(int64_t* value) const
+{
+	if (XMLUtil::ToInt64(Value(), value)) {
+		return XML_SUCCESS;
+	}
+	return XML_WRONG_ATTRIBUTE_TYPE;
+}
+
+
+XMLError XMLAttribute::QueryBoolValue( bool* value ) const
+{
+    if ( XMLUtil::ToBool( Value(), value )) {
+        return XML_SUCCESS;
+    }
+    return XML_WRONG_ATTRIBUTE_TYPE;
+}
+
+
+XMLError XMLAttribute::QueryFloatValue( float* value ) const
+{
+    if ( XMLUtil::ToFloat( Value(), value )) {
+        return XML_SUCCESS;
+    }
+    return XML_WRONG_ATTRIBUTE_TYPE;
+}
+
+
+XMLError XMLAttribute::QueryDoubleValue( double* value ) const
+{
+    if ( XMLUtil::ToDouble( Value(), value )) {
+        return XML_SUCCESS;
+    }
+    return XML_WRONG_ATTRIBUTE_TYPE;
+}
+
+
+void XMLAttribute::SetAttribute( const char* v )
+{
+    _value.SetStr( v );
+}
+
+
+void XMLAttribute::SetAttribute( int v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    _value.SetStr( buf );
+}
+
+
+void XMLAttribute::SetAttribute( unsigned v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    _value.SetStr( buf );
+}
+
+
+void XMLAttribute::SetAttribute(int64_t v)
+{
+	char buf[BUF_SIZE];
+	XMLUtil::ToStr(v, buf, BUF_SIZE);
+	_value.SetStr(buf);
+}
+
+
+
+void XMLAttribute::SetAttribute( bool v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    _value.SetStr( buf );
+}
+
+void XMLAttribute::SetAttribute( double v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    _value.SetStr( buf );
+}
+
+void XMLAttribute::SetAttribute( float v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    _value.SetStr( buf );
+}
+
+
+// --------- XMLElement ---------- //
+XMLElement::XMLElement( XMLDocument* doc ) : XMLNode( doc ),
+    _closingType( OPEN ),
+    _rootAttribute( 0 )
+{
+}
+
+
+XMLElement::~XMLElement()
+{
+    while( _rootAttribute ) {
+        XMLAttribute* next = _rootAttribute->_next;
+        DeleteAttribute( _rootAttribute );
+        _rootAttribute = next;
+    }
+}
+
+
+const XMLAttribute* XMLElement::FindAttribute( const char* name ) const
+{
+    for( XMLAttribute* a = _rootAttribute; a; a = a->_next ) {
+        if ( XMLUtil::StringEqual( a->Name(), name ) ) {
+            return a;
+        }
+    }
+    return 0;
+}
+
+
+const char* XMLElement::Attribute( const char* name, const char* value ) const
+{
+    const XMLAttribute* a = FindAttribute( name );
+    if ( !a ) {
+        return 0;
+    }
+    if ( !value || XMLUtil::StringEqual( a->Value(), value )) {
+        return a->Value();
+    }
+    return 0;
+}
+
+int XMLElement::IntAttribute(const char* name, int defaultValue) const
+{
+	int i = defaultValue;
+	QueryIntAttribute(name, &i);
+	return i;
+}
+
+unsigned XMLElement::UnsignedAttribute(const char* name, unsigned defaultValue) const
+{
+	unsigned i = defaultValue;
+	QueryUnsignedAttribute(name, &i);
+	return i;
+}
+
+int64_t XMLElement::Int64Attribute(const char* name, int64_t defaultValue) const
+{
+	int64_t i = defaultValue;
+	QueryInt64Attribute(name, &i);
+	return i;
+}
+
+bool XMLElement::BoolAttribute(const char* name, bool defaultValue) const
+{
+	bool b = defaultValue;
+	QueryBoolAttribute(name, &b);
+	return b;
+}
+
+double XMLElement::DoubleAttribute(const char* name, double defaultValue) const
+{
+	double d = defaultValue;
+	QueryDoubleAttribute(name, &d);
+	return d;
+}
+
+float XMLElement::FloatAttribute(const char* name, float defaultValue) const
+{
+	float f = defaultValue;
+	QueryFloatAttribute(name, &f);
+	return f;
+}
+
+const char* XMLElement::GetText() const
+{
+    if ( FirstChild() && FirstChild()->ToText() ) {
+        return FirstChild()->Value();
+    }
+    return 0;
+}
+
+
+void	XMLElement::SetText( const char* inText )
+{
+	if ( FirstChild() && FirstChild()->ToText() )
+		FirstChild()->SetValue( inText );
+	else {
+		XMLText*	theText = GetDocument()->NewText( inText );
+		InsertFirstChild( theText );
+	}
+}
+
+
+void XMLElement::SetText( int v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    SetText( buf );
+}
+
+
+void XMLElement::SetText( unsigned v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    SetText( buf );
+}
+
+
+void XMLElement::SetText(int64_t v)
+{
+	char buf[BUF_SIZE];
+	XMLUtil::ToStr(v, buf, BUF_SIZE);
+	SetText(buf);
+}
+
+
+void XMLElement::SetText( bool v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    SetText( buf );
+}
+
+
+void XMLElement::SetText( float v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    SetText( buf );
+}
+
+
+void XMLElement::SetText( double v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    SetText( buf );
+}
+
+
+XMLError XMLElement::QueryIntText( int* ival ) const
+{
+    if ( FirstChild() && FirstChild()->ToText() ) {
+        const char* t = FirstChild()->Value();
+        if ( XMLUtil::ToInt( t, ival ) ) {
+            return XML_SUCCESS;
+        }
+        return XML_CAN_NOT_CONVERT_TEXT;
+    }
+    return XML_NO_TEXT_NODE;
+}
+
+
+XMLError XMLElement::QueryUnsignedText( unsigned* uval ) const
+{
+    if ( FirstChild() && FirstChild()->ToText() ) {
+        const char* t = FirstChild()->Value();
+        if ( XMLUtil::ToUnsigned( t, uval ) ) {
+            return XML_SUCCESS;
+        }
+        return XML_CAN_NOT_CONVERT_TEXT;
+    }
+    return XML_NO_TEXT_NODE;
+}
+
+
+XMLError XMLElement::QueryInt64Text(int64_t* ival) const
+{
+	if (FirstChild() && FirstChild()->ToText()) {
+		const char* t = FirstChild()->Value();
+		if (XMLUtil::ToInt64(t, ival)) {
+			return XML_SUCCESS;
+		}
+		return XML_CAN_NOT_CONVERT_TEXT;
+	}
+	return XML_NO_TEXT_NODE;
+}
+
+
+XMLError XMLElement::QueryBoolText( bool* bval ) const
+{
+    if ( FirstChild() && FirstChild()->ToText() ) {
+        const char* t = FirstChild()->Value();
+        if ( XMLUtil::ToBool( t, bval ) ) {
+            return XML_SUCCESS;
+        }
+        return XML_CAN_NOT_CONVERT_TEXT;
+    }
+    return XML_NO_TEXT_NODE;
+}
+
+
+XMLError XMLElement::QueryDoubleText( double* dval ) const
+{
+    if ( FirstChild() && FirstChild()->ToText() ) {
+        const char* t = FirstChild()->Value();
+        if ( XMLUtil::ToDouble( t, dval ) ) {
+            return XML_SUCCESS;
+        }
+        return XML_CAN_NOT_CONVERT_TEXT;
+    }
+    return XML_NO_TEXT_NODE;
+}
+
+
+XMLError XMLElement::QueryFloatText( float* fval ) const
+{
+    if ( FirstChild() && FirstChild()->ToText() ) {
+        const char* t = FirstChild()->Value();
+        if ( XMLUtil::ToFloat( t, fval ) ) {
+            return XML_SUCCESS;
+        }
+        return XML_CAN_NOT_CONVERT_TEXT;
+    }
+    return XML_NO_TEXT_NODE;
+}
+
+int XMLElement::IntText(int defaultValue) const
+{
+	int i = defaultValue;
+	QueryIntText(&i);
+	return i;
+}
+
+unsigned XMLElement::UnsignedText(unsigned defaultValue) const
+{
+	unsigned i = defaultValue;
+	QueryUnsignedText(&i);
+	return i;
+}
+
+int64_t XMLElement::Int64Text(int64_t defaultValue) const
+{
+	int64_t i = defaultValue;
+	QueryInt64Text(&i);
+	return i;
+}
+
+bool XMLElement::BoolText(bool defaultValue) const
+{
+	bool b = defaultValue;
+	QueryBoolText(&b);
+	return b;
+}
+
+double XMLElement::DoubleText(double defaultValue) const
+{
+	double d = defaultValue;
+	QueryDoubleText(&d);
+	return d;
+}
+
+float XMLElement::FloatText(float defaultValue) const
+{
+	float f = defaultValue;
+	QueryFloatText(&f);
+	return f;
+}
+
+
+XMLAttribute* XMLElement::FindOrCreateAttribute( const char* name )
+{
+    XMLAttribute* last = 0;
+    XMLAttribute* attrib = 0;
+    for( attrib = _rootAttribute;
+            attrib;
+            last = attrib, attrib = attrib->_next ) {
+        if ( XMLUtil::StringEqual( attrib->Name(), name ) ) {
+            break;
+        }
+    }
+    if ( !attrib ) {
+        attrib = CreateAttribute();
+        TIXMLASSERT( attrib );
+        if ( last ) {
+            TIXMLASSERT( last->_next == 0 );
+            last->_next = attrib;
+        }
+        else {
+            TIXMLASSERT( _rootAttribute == 0 );
+            _rootAttribute = attrib;
+        }
+        attrib->SetName( name );
+    }
+    return attrib;
+}
+
+
+void XMLElement::DeleteAttribute( const char* name )
+{
+    XMLAttribute* prev = 0;
+    for( XMLAttribute* a=_rootAttribute; a; a=a->_next ) {
+        if ( XMLUtil::StringEqual( name, a->Name() ) ) {
+            if ( prev ) {
+                prev->_next = a->_next;
+            }
+            else {
+                _rootAttribute = a->_next;
+            }
+            DeleteAttribute( a );
+            break;
+        }
+        prev = a;
+    }
+}
+
+
+char* XMLElement::ParseAttributes( char* p, int* curLineNumPtr )
+{
+    XMLAttribute* prevAttribute = 0;
+
+    // Read the attributes.
+    while( p ) {
+        p = XMLUtil::SkipWhiteSpace( p, curLineNumPtr );
+        if ( !(*p) ) {
+            _document->SetError( XML_ERROR_PARSING_ELEMENT, _parseLineNum, "XMLElement name=%s", Name() );
+            return 0;
+        }
+
+        // attribute.
+        if (XMLUtil::IsNameStartChar( *p ) ) {
+            XMLAttribute* attrib = CreateAttribute();
+            TIXMLASSERT( attrib );
+            attrib->_parseLineNum = _document->_parseCurLineNum;
+
+            const int attrLineNum = attrib->_parseLineNum;
+
+            p = attrib->ParseDeep( p, _document->ProcessEntities(), curLineNumPtr );
+            if ( !p || Attribute( attrib->Name() ) ) {
+                DeleteAttribute( attrib );
+                _document->SetError( XML_ERROR_PARSING_ATTRIBUTE, attrLineNum, "XMLElement name=%s", Name() );
+                return 0;
+            }
+            // There is a minor bug here: if the attribute in the source xml
+            // document is duplicated, it will not be detected and the
+            // attribute will be doubly added. However, tracking the 'prevAttribute'
+            // avoids re-scanning the attribute list. Preferring performance for
+            // now, may reconsider in the future.
+            if ( prevAttribute ) {
+                TIXMLASSERT( prevAttribute->_next == 0 );
+                prevAttribute->_next = attrib;
+            }
+            else {
+                TIXMLASSERT( _rootAttribute == 0 );
+                _rootAttribute = attrib;
+            }
+            prevAttribute = attrib;
+        }
+        // end of the tag
+        else if ( *p == '>' ) {
+            ++p;
+            break;
+        }
+        // end of the tag
+        else if ( *p == '/' && *(p+1) == '>' ) {
+            _closingType = CLOSED;
+            return p+2;	// done; sealed element.
+        }
+        else {
+            _document->SetError( XML_ERROR_PARSING_ELEMENT, _parseLineNum, 0 );
+            return 0;
+        }
+    }
+    return p;
+}
+
+void XMLElement::DeleteAttribute( XMLAttribute* attribute )
+{
+    if ( attribute == 0 ) {
+        return;
+    }
+    MemPool* pool = attribute->_memPool;
+    attribute->~XMLAttribute();
+    pool->Free( attribute );
+}
+
+XMLAttribute* XMLElement::CreateAttribute()
+{
+    TIXMLASSERT( sizeof( XMLAttribute ) == _document->_attributePool.ItemSize() );
+    XMLAttribute* attrib = new (_document->_attributePool.Alloc() ) XMLAttribute();
+    TIXMLASSERT( attrib );
+    attrib->_memPool = &_document->_attributePool;
+    attrib->_memPool->SetTracked();
+    return attrib;
+}
+
+//
+//	<ele></ele>
+//	<ele>foo<b>bar</b></ele>
+//
+char* XMLElement::ParseDeep( char* p, StrPair* parentEndTag, int* curLineNumPtr )
+{
+    // Read the element name.
+    p = XMLUtil::SkipWhiteSpace( p, curLineNumPtr );
+
+    // The closing element is the </element> form. It is
+    // parsed just like a regular element then deleted from
+    // the DOM.
+    if ( *p == '/' ) {
+        _closingType = CLOSING;
+        ++p;
+    }
+
+    p = _value.ParseName( p );
+    if ( _value.Empty() ) {
+        return 0;
+    }
+
+    p = ParseAttributes( p, curLineNumPtr );
+    if ( !p || !*p || _closingType != OPEN ) {
+        return p;
+    }
+
+    p = XMLNode::ParseDeep( p, parentEndTag, curLineNumPtr );
+    return p;
+}
+
+
+
+XMLNode* XMLElement::ShallowClone( XMLDocument* doc ) const
+{
+    if ( !doc ) {
+        doc = _document;
+    }
+    XMLElement* element = doc->NewElement( Value() );					// fixme: this will always allocate memory. Intern?
+    for( const XMLAttribute* a=FirstAttribute(); a; a=a->Next() ) {
+        element->SetAttribute( a->Name(), a->Value() );					// fixme: this will always allocate memory. Intern?
+    }
+    return element;
+}
+
+
+bool XMLElement::ShallowEqual( const XMLNode* compare ) const
+{
+    TIXMLASSERT( compare );
+    const XMLElement* other = compare->ToElement();
+    if ( other && XMLUtil::StringEqual( other->Name(), Name() )) {
+
+        const XMLAttribute* a=FirstAttribute();
+        const XMLAttribute* b=other->FirstAttribute();
+
+        while ( a && b ) {
+            if ( !XMLUtil::StringEqual( a->Value(), b->Value() ) ) {
+                return false;
+            }
+            a = a->Next();
+            b = b->Next();
+        }
+        if ( a || b ) {
+            // different count
+            return false;
+        }
+        return true;
+    }
+    return false;
+}
+
+
+bool XMLElement::Accept( XMLVisitor* visitor ) const
+{
+    TIXMLASSERT( visitor );
+    if ( visitor->VisitEnter( *this, _rootAttribute ) ) {
+        for ( const XMLNode* node=FirstChild(); node; node=node->NextSibling() ) {
+            if ( !node->Accept( visitor ) ) {
+                break;
+            }
+        }
+    }
+    return visitor->VisitExit( *this );
+}
+
+
+// --------- XMLDocument ----------- //
+
+// Warning: List must match 'enum XMLError'
+const char* XMLDocument::_errorNames[XML_ERROR_COUNT] = {
+    "XML_SUCCESS",
+    "XML_NO_ATTRIBUTE",
+    "XML_WRONG_ATTRIBUTE_TYPE",
+    "XML_ERROR_FILE_NOT_FOUND",
+    "XML_ERROR_FILE_COULD_NOT_BE_OPENED",
+    "XML_ERROR_FILE_READ_ERROR",
+    "XML_ERROR_PARSING_ELEMENT",
+    "XML_ERROR_PARSING_ATTRIBUTE",
+    "XML_ERROR_PARSING_TEXT",
+    "XML_ERROR_PARSING_CDATA",
+    "XML_ERROR_PARSING_COMMENT",
+    "XML_ERROR_PARSING_DECLARATION",
+    "XML_ERROR_PARSING_UNKNOWN",
+    "XML_ERROR_EMPTY_DOCUMENT",
+    "XML_ERROR_MISMATCHED_ELEMENT",
+    "XML_ERROR_PARSING",
+    "XML_CAN_NOT_CONVERT_TEXT",
+    "XML_NO_TEXT_NODE",
+	"XML_ELEMENT_DEPTH_EXCEEDED"
+};
+
+
+XMLDocument::XMLDocument( bool processEntities, Whitespace whitespaceMode ) :
+    XMLNode( 0 ),
+    _writeBOM( false ),
+    _processEntities( processEntities ),
+    _errorID(XML_SUCCESS),
+    _whitespaceMode( whitespaceMode ),
+    _errorStr(),
+    _errorLineNum( 0 ),
+    _charBuffer( 0 ),
+    _parseCurLineNum( 0 ),
+	_parsingDepth(0),
+    _unlinked(),
+    _elementPool(),
+    _attributePool(),
+    _textPool(),
+    _commentPool()
+{
+    // avoid VC++ C4355 warning about 'this' in initializer list (C4355 is off by default in VS2012+)
+    _document = this;
+}
+
+
+XMLDocument::~XMLDocument()
+{
+    Clear();
+}
+
+
+void XMLDocument::MarkInUse(XMLNode* node)
+{
+	TIXMLASSERT(node);
+	TIXMLASSERT(node->_parent == 0);
+
+	for (int i = 0; i < _unlinked.Size(); ++i) {
+		if (node == _unlinked[i]) {
+			_unlinked.SwapRemove(i);
+			break;
+		}
+	}
+}
+
+void XMLDocument::Clear()
+{
+    DeleteChildren();
+	while( _unlinked.Size()) {
+		DeleteNode(_unlinked[0]);	// Will remove from _unlinked as part of delete.
+	}
+
+#ifdef TINYXML2_DEBUG
+    const bool hadError = Error();
+#endif
+    ClearError();
+
+    delete [] _charBuffer;
+    _charBuffer = 0;
+	_parsingDepth = 0;
+
+#if 0
+    _textPool.Trace( "text" );
+    _elementPool.Trace( "element" );
+    _commentPool.Trace( "comment" );
+    _attributePool.Trace( "attribute" );
+#endif
+
+#ifdef TINYXML2_DEBUG
+    if ( !hadError ) {
+        TIXMLASSERT( _elementPool.CurrentAllocs()   == _elementPool.Untracked() );
+        TIXMLASSERT( _attributePool.CurrentAllocs() == _attributePool.Untracked() );
+        TIXMLASSERT( _textPool.CurrentAllocs()      == _textPool.Untracked() );
+        TIXMLASSERT( _commentPool.CurrentAllocs()   == _commentPool.Untracked() );
+    }
+#endif
+}
+
+
+void XMLDocument::DeepCopy(XMLDocument* target) const
+{
+	TIXMLASSERT(target);
+    if (target == this) {
+        return; // technically success - a no-op.
+    }
+
+	target->Clear();
+	for (const XMLNode* node = this->FirstChild(); node; node = node->NextSibling()) {
+		target->InsertEndChild(node->DeepClone(target));
+	}
+}
+
+XMLElement* XMLDocument::NewElement( const char* name )
+{
+    XMLElement* ele = CreateUnlinkedNode<XMLElement>( _elementPool );
+    ele->SetName( name );
+    return ele;
+}
+
+
+XMLComment* XMLDocument::NewComment( const char* str )
+{
+    XMLComment* comment = CreateUnlinkedNode<XMLComment>( _commentPool );
+    comment->SetValue( str );
+    return comment;
+}
+
+
+XMLText* XMLDocument::NewText( const char* str )
+{
+    XMLText* text = CreateUnlinkedNode<XMLText>( _textPool );
+    text->SetValue( str );
+    return text;
+}
+
+
+XMLDeclaration* XMLDocument::NewDeclaration( const char* str )
+{
+    XMLDeclaration* dec = CreateUnlinkedNode<XMLDeclaration>( _commentPool );
+    dec->SetValue( str ? str : "xml version=\"1.0\" encoding=\"UTF-8\"" );
+    return dec;
+}
+
+
+XMLUnknown* XMLDocument::NewUnknown( const char* str )
+{
+    XMLUnknown* unk = CreateUnlinkedNode<XMLUnknown>( _commentPool );
+    unk->SetValue( str );
+    return unk;
+}
+
+static FILE* callfopen( const char* filepath, const char* mode )
+{
+    TIXMLASSERT( filepath );
+    TIXMLASSERT( mode );
+#if defined(_MSC_VER) && (_MSC_VER >= 1400 ) && (!defined WINCE)
+    FILE* fp = 0;
+    const errno_t err = fopen_s( &fp, filepath, mode );
+    if ( err ) {
+        return 0;
+    }
+#else
+    FILE* fp = fopen( filepath, mode );
+#endif
+    return fp;
+}
+
+void XMLDocument::DeleteNode( XMLNode* node )	{
+    TIXMLASSERT( node );
+    TIXMLASSERT(node->_document == this );
+    if (node->_parent) {
+        node->_parent->DeleteChild( node );
+    }
+    else {
+        // Isn't in the tree.
+        // Use the parent delete.
+        // Also, we need to mark it tracked: we 'know'
+        // it was never used.
+        node->_memPool->SetTracked();
+        // Call the static XMLNode version:
+        XMLNode::DeleteNode(node);
+    }
+}
+
+
+XMLError XMLDocument::LoadFile( const char* filename )
+{
+    if ( !filename ) {
+        TIXMLASSERT( false );
+        SetError( XML_ERROR_FILE_COULD_NOT_BE_OPENED, 0, "filename=<null>" );
+        return _errorID;
+    }
+
+    Clear();
+    FILE* fp = callfopen( filename, "rb" );
+    if ( !fp ) {
+        SetError( XML_ERROR_FILE_NOT_FOUND, 0, "filename=%s", filename );
+        return _errorID;
+    }
+    LoadFile( fp );
+    fclose( fp );
+    return _errorID;
+}
+
+// This is likely overengineered template art to have a check that unsigned long value incremented
+// by one still fits into size_t. If size_t type is larger than unsigned long type
+// (x86_64-w64-mingw32 target) then the check is redundant and gcc and clang emit
+// -Wtype-limits warning. This piece makes the compiler select code with a check when a check
+// is useful and code with no check when a check is redundant depending on how size_t and unsigned long
+// types sizes relate to each other.
+template
+<bool = (sizeof(unsigned long) >= sizeof(size_t))>
+struct LongFitsIntoSizeTMinusOne {
+    static bool Fits( unsigned long value )
+    {
+        return value < (size_t)-1;
+    }
+};
+
+template <>
+struct LongFitsIntoSizeTMinusOne<false> {
+    static bool Fits( unsigned long )
+    {
+        return true;
+    }
+};
+
+XMLError XMLDocument::LoadFile( FILE* fp )
+{
+    Clear();
+
+    fseek( fp, 0, SEEK_SET );
+    if ( fgetc( fp ) == EOF && ferror( fp ) != 0 ) {
+        SetError( XML_ERROR_FILE_READ_ERROR, 0, 0 );
+        return _errorID;
+    }
+
+    fseek( fp, 0, SEEK_END );
+    const long filelength = ftell( fp );
+    fseek( fp, 0, SEEK_SET );
+    if ( filelength == -1L ) {
+        SetError( XML_ERROR_FILE_READ_ERROR, 0, 0 );
+        return _errorID;
+    }
+    TIXMLASSERT( filelength >= 0 );
+
+    if ( !LongFitsIntoSizeTMinusOne<>::Fits( filelength ) ) {
+        // Cannot handle files which won't fit in buffer together with null terminator
+        SetError( XML_ERROR_FILE_READ_ERROR, 0, 0 );
+        return _errorID;
+    }
+
+    if ( filelength == 0 ) {
+        SetError( XML_ERROR_EMPTY_DOCUMENT, 0, 0 );
+        return _errorID;
+    }
+
+    const size_t size = filelength;
+    TIXMLASSERT( _charBuffer == 0 );
+    _charBuffer = new char[size+1];
+    const size_t read = fread( _charBuffer, 1, size, fp );
+    if ( read != size ) {
+        SetError( XML_ERROR_FILE_READ_ERROR, 0, 0 );
+        return _errorID;
+    }
+
+    _charBuffer[size] = 0;
+
+    Parse();
+    return _errorID;
+}
+
+
+XMLError XMLDocument::SaveFile( const char* filename, bool compact )
+{
+    if ( !filename ) {
+        TIXMLASSERT( false );
+        SetError( XML_ERROR_FILE_COULD_NOT_BE_OPENED, 0, "filename=<null>" );
+        return _errorID;
+    }
+
+    FILE* fp = callfopen( filename, "w" );
+    if ( !fp ) {
+        SetError( XML_ERROR_FILE_COULD_NOT_BE_OPENED, 0, "filename=%s", filename );
+        return _errorID;
+    }
+    SaveFile(fp, compact);
+    fclose( fp );
+    return _errorID;
+}
+
+
+XMLError XMLDocument::SaveFile( FILE* fp, bool compact )
+{
+    // Clear any error from the last save, otherwise it will get reported
+    // for *this* call.
+    ClearError();
+    XMLPrinter stream( fp, compact );
+    Print( &stream );
+    return _errorID;
+}
+
+
+XMLError XMLDocument::Parse( const char* p, size_t len )
+{
+    Clear();
+
+    if ( len == 0 || !p || !*p ) {
+        SetError( XML_ERROR_EMPTY_DOCUMENT, 0, 0 );
+        return _errorID;
+    }
+    if ( len == (size_t)(-1) ) {
+        len = strlen( p );
+    }
+    TIXMLASSERT( _charBuffer == 0 );
+    _charBuffer = new char[ len+1 ];
+    memcpy( _charBuffer, p, len );
+    _charBuffer[len] = 0;
+
+    Parse();
+    if ( Error() ) {
+        // clean up now essentially dangling memory.
+        // and the parse fail can put objects in the
+        // pools that are dead and inaccessible.
+        DeleteChildren();
+        _elementPool.Clear();
+        _attributePool.Clear();
+        _textPool.Clear();
+        _commentPool.Clear();
+    }
+    return _errorID;
+}
+
+
+void XMLDocument::Print( XMLPrinter* streamer ) const
+{
+    if ( streamer ) {
+        Accept( streamer );
+    }
+    else {
+        XMLPrinter stdoutStreamer( stdout );
+        Accept( &stdoutStreamer );
+    }
+}
+
+
+void XMLDocument::SetError( XMLError error, int lineNum, const char* format, ... )
+{
+    TIXMLASSERT( error >= 0 && error < XML_ERROR_COUNT );
+    _errorID = error;
+    _errorLineNum = lineNum;
+	_errorStr.Reset();
+
+    const size_t BUFFER_SIZE = 1000;
+    char* buffer = new char[BUFFER_SIZE];
+
+    TIXMLASSERT(sizeof(error) <= sizeof(int));
+    TIXML_SNPRINTF(buffer, BUFFER_SIZE, "Error=%s ErrorID=%d (0x%x) Line number=%d", ErrorIDToName(error), int(error), int(error), lineNum);
+
+	if (format) {
+		size_t len = strlen(buffer);
+		TIXML_SNPRINTF(buffer + len, BUFFER_SIZE - len, ": ");
+		len = strlen(buffer);
+
+		va_list va;
+		va_start(va, format);
+		TIXML_VSNPRINTF(buffer + len, BUFFER_SIZE - len, format, va);
+		va_end(va);
+	}
+	_errorStr.SetStr(buffer);
+	delete[] buffer;
+}
+
+
+/*static*/ const char* XMLDocument::ErrorIDToName(XMLError errorID)
+{
+	TIXMLASSERT( errorID >= 0 && errorID < XML_ERROR_COUNT );
+    const char* errorName = _errorNames[errorID];
+    TIXMLASSERT( errorName && errorName[0] );
+    return errorName;
+}
+
+const char* XMLDocument::ErrorStr() const
+{
+	return _errorStr.Empty() ? "" : _errorStr.GetStr();
+}
+
+
+void XMLDocument::PrintError() const
+{
+    printf("%s\n", ErrorStr());
+}
+
+const char* XMLDocument::ErrorName() const
+{
+    return ErrorIDToName(_errorID);
+}
+
+void XMLDocument::Parse()
+{
+    TIXMLASSERT( NoChildren() ); // Clear() must have been called previously
+    TIXMLASSERT( _charBuffer );
+    _parseCurLineNum = 1;
+    _parseLineNum = 1;
+    char* p = _charBuffer;
+    p = XMLUtil::SkipWhiteSpace( p, &_parseCurLineNum );
+    p = const_cast<char*>( XMLUtil::ReadBOM( p, &_writeBOM ) );
+    if ( !*p ) {
+        SetError( XML_ERROR_EMPTY_DOCUMENT, 0, 0 );
+        return;
+    }
+    ParseDeep(p, 0, &_parseCurLineNum );
+}
+
+void XMLDocument::PushDepth()
+{
+	_parsingDepth++;
+	if (_parsingDepth == TINYXML2_MAX_ELEMENT_DEPTH) {
+		SetError(XML_ELEMENT_DEPTH_EXCEEDED, _parseCurLineNum, "Element nesting is too deep." );
+	}
+}
+
+void XMLDocument::PopDepth()
+{
+	TIXMLASSERT(_parsingDepth > 0);
+	--_parsingDepth;
+}
+
+XMLPrinter::XMLPrinter( FILE* file, bool compact, int depth ) :
+    _elementJustOpened( false ),
+    _stack(),
+    _firstElement( true ),
+    _fp( file ),
+    _depth( depth ),
+    _textDepth( -1 ),
+    _processEntities( true ),
+    _compactMode( compact ),
+    _buffer()
+{
+    for( int i=0; i<ENTITY_RANGE; ++i ) {
+        _entityFlag[i] = false;
+        _restrictedEntityFlag[i] = false;
+    }
+    for( int i=0; i<NUM_ENTITIES; ++i ) {
+        const char entityValue = entities[i].value;
+        const unsigned char flagIndex = (unsigned char)entityValue;
+        TIXMLASSERT( flagIndex < ENTITY_RANGE );
+        _entityFlag[flagIndex] = true;
+    }
+    _restrictedEntityFlag[(unsigned char)'&'] = true;
+    _restrictedEntityFlag[(unsigned char)'<'] = true;
+    _restrictedEntityFlag[(unsigned char)'>'] = true;	// not required, but consistency is nice
+    _buffer.Push( 0 );
+}
+
+
+void XMLPrinter::Print( const char* format, ... )
+{
+    va_list     va;
+    va_start( va, format );
+
+    if ( _fp ) {
+        vfprintf( _fp, format, va );
+    }
+    else {
+        const int len = TIXML_VSCPRINTF( format, va );
+        // Close out and re-start the va-args
+        va_end( va );
+        TIXMLASSERT( len >= 0 );
+        va_start( va, format );
+        TIXMLASSERT( _buffer.Size() > 0 && _buffer[_buffer.Size() - 1] == 0 );
+        char* p = _buffer.PushArr( len ) - 1;	// back up over the null terminator.
+		TIXML_VSNPRINTF( p, len+1, format, va );
+    }
+    va_end( va );
+}
+
+
+void XMLPrinter::Write( const char* data, size_t size )
+{
+    if ( _fp ) {
+        fwrite ( data , sizeof(char), size, _fp);
+    }
+    else {
+        char* p = _buffer.PushArr( static_cast<int>(size) ) - 1;   // back up over the null terminator.
+        memcpy( p, data, size );
+        p[size] = 0;
+    }
+}
+
+
+void XMLPrinter::Putc( char ch )
+{
+    if ( _fp ) {
+        fputc ( ch, _fp);
+    }
+    else {
+        char* p = _buffer.PushArr( sizeof(char) ) - 1;   // back up over the null terminator.
+        p[0] = ch;
+        p[1] = 0;
+    }
+}
+
+
+void XMLPrinter::PrintSpace( int depth )
+{
+    for( int i=0; i<depth; ++i ) {
+        Write( "    " );
+    }
+}
+
+
+void XMLPrinter::PrintString( const char* p, bool restricted )
+{
+    // Look for runs of bytes between entities to print.
+    const char* q = p;
+
+    if ( _processEntities ) {
+        const bool* flag = restricted ? _restrictedEntityFlag : _entityFlag;
+        while ( *q ) {
+            TIXMLASSERT( p <= q );
+            // Remember, char is sometimes signed. (How many times has that bitten me?)
+            if ( *q > 0 && *q < ENTITY_RANGE ) {
+                // Check for entities. If one is found, flush
+                // the stream up until the entity, write the
+                // entity, and keep looking.
+                if ( flag[(unsigned char)(*q)] ) {
+                    while ( p < q ) {
+                        const size_t delta = q - p;
+                        const int toPrint = ( INT_MAX < delta ) ? INT_MAX : (int)delta;
+                        Write( p, toPrint );
+                        p += toPrint;
+                    }
+                    bool entityPatternPrinted = false;
+                    for( int i=0; i<NUM_ENTITIES; ++i ) {
+                        if ( entities[i].value == *q ) {
+                            Putc( '&' );
+                            Write( entities[i].pattern, entities[i].length );
+                            Putc( ';' );
+                            entityPatternPrinted = true;
+                            break;
+                        }
+                    }
+                    if ( !entityPatternPrinted ) {
+                        // TIXMLASSERT( entityPatternPrinted ) causes gcc -Wunused-but-set-variable in release
+                        TIXMLASSERT( false );
+                    }
+                    ++p;
+                }
+            }
+            ++q;
+            TIXMLASSERT( p <= q );
+        }
+        // Flush the remaining string. This will be the entire
+        // string if an entity wasn't found.
+        if ( p < q ) {
+            const size_t delta = q - p;
+            const int toPrint = ( INT_MAX < delta ) ? INT_MAX : (int)delta;
+            Write( p, toPrint );
+        }
+    }
+    else {
+        Write( p );
+    }
+}
+
+
+void XMLPrinter::PushHeader( bool writeBOM, bool writeDec )
+{
+    if ( writeBOM ) {
+        static const unsigned char bom[] = { TIXML_UTF_LEAD_0, TIXML_UTF_LEAD_1, TIXML_UTF_LEAD_2, 0 };
+        Write( reinterpret_cast< const char* >( bom ) );
+    }
+    if ( writeDec ) {
+        PushDeclaration( "xml version=\"1.0\"" );
+    }
+}
+
+
+void XMLPrinter::OpenElement( const char* name, bool compactMode )
+{
+    SealElementIfJustOpened();
+    _stack.Push( name );
+
+    if ( _textDepth < 0 && !_firstElement && !compactMode ) {
+        Putc( '\n' );
+    }
+    if ( !compactMode ) {
+        PrintSpace( _depth );
+    }
+
+    Write ( "<" );
+    Write ( name );
+
+    _elementJustOpened = true;
+    _firstElement = false;
+    ++_depth;
+}
+
+
+void XMLPrinter::PushAttribute( const char* name, const char* value )
+{
+    TIXMLASSERT( _elementJustOpened );
+    Putc ( ' ' );
+    Write( name );
+    Write( "=\"" );
+    PrintString( value, false );
+    Putc ( '\"' );
+}
+
+
+void XMLPrinter::PushAttribute( const char* name, int v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    PushAttribute( name, buf );
+}
+
+
+void XMLPrinter::PushAttribute( const char* name, unsigned v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    PushAttribute( name, buf );
+}
+
+
+void XMLPrinter::PushAttribute(const char* name, int64_t v)
+{
+	char buf[BUF_SIZE];
+	XMLUtil::ToStr(v, buf, BUF_SIZE);
+	PushAttribute(name, buf);
+}
+
+
+void XMLPrinter::PushAttribute( const char* name, bool v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    PushAttribute( name, buf );
+}
+
+
+void XMLPrinter::PushAttribute( const char* name, double v )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( v, buf, BUF_SIZE );
+    PushAttribute( name, buf );
+}
+
+
+void XMLPrinter::CloseElement( bool compactMode )
+{
+    --_depth;
+    const char* name = _stack.Pop();
+
+    if ( _elementJustOpened ) {
+        Write( "/>" );
+    }
+    else {
+        if ( _textDepth < 0 && !compactMode) {
+            Putc( '\n' );
+            PrintSpace( _depth );
+        }
+        Write ( "</" );
+        Write ( name );
+        Write ( ">" );
+    }
+
+    if ( _textDepth == _depth ) {
+        _textDepth = -1;
+    }
+    if ( _depth == 0 && !compactMode) {
+        Putc( '\n' );
+    }
+    _elementJustOpened = false;
+}
+
+
+void XMLPrinter::SealElementIfJustOpened()
+{
+    if ( !_elementJustOpened ) {
+        return;
+    }
+    _elementJustOpened = false;
+    Putc( '>' );
+}
+
+
+void XMLPrinter::PushText( const char* text, bool cdata )
+{
+    _textDepth = _depth-1;
+
+    SealElementIfJustOpened();
+    if ( cdata ) {
+        Write( "<![CDATA[" );
+        Write( text );
+        Write( "]]>" );
+    }
+    else {
+        PrintString( text, true );
+    }
+}
+
+void XMLPrinter::PushText( int64_t value )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( value, buf, BUF_SIZE );
+    PushText( buf, false );
+}
+
+void XMLPrinter::PushText( int value )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( value, buf, BUF_SIZE );
+    PushText( buf, false );
+}
+
+
+void XMLPrinter::PushText( unsigned value )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( value, buf, BUF_SIZE );
+    PushText( buf, false );
+}
+
+
+void XMLPrinter::PushText( bool value )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( value, buf, BUF_SIZE );
+    PushText( buf, false );
+}
+
+
+void XMLPrinter::PushText( float value )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( value, buf, BUF_SIZE );
+    PushText( buf, false );
+}
+
+
+void XMLPrinter::PushText( double value )
+{
+    char buf[BUF_SIZE];
+    XMLUtil::ToStr( value, buf, BUF_SIZE );
+    PushText( buf, false );
+}
+
+
+void XMLPrinter::PushComment( const char* comment )
+{
+    SealElementIfJustOpened();
+    if ( _textDepth < 0 && !_firstElement && !_compactMode) {
+        Putc( '\n' );
+        PrintSpace( _depth );
+    }
+    _firstElement = false;
+
+    Write( "<!--" );
+    Write( comment );
+    Write( "-->" );
+}
+
+
+void XMLPrinter::PushDeclaration( const char* value )
+{
+    SealElementIfJustOpened();
+    if ( _textDepth < 0 && !_firstElement && !_compactMode) {
+        Putc( '\n' );
+        PrintSpace( _depth );
+    }
+    _firstElement = false;
+
+    Write( "<?" );
+    Write( value );
+    Write( "?>" );
+}
+
+
+void XMLPrinter::PushUnknown( const char* value )
+{
+    SealElementIfJustOpened();
+    if ( _textDepth < 0 && !_firstElement && !_compactMode) {
+        Putc( '\n' );
+        PrintSpace( _depth );
+    }
+    _firstElement = false;
+
+    Write( "<!" );
+    Write( value );
+    Putc( '>' );
+}
+
+
+bool XMLPrinter::VisitEnter( const XMLDocument& doc )
+{
+    _processEntities = doc.ProcessEntities();
+    if ( doc.HasBOM() ) {
+        PushHeader( true, false );
+    }
+    return true;
+}
+
+
+bool XMLPrinter::VisitEnter( const XMLElement& element, const XMLAttribute* attribute )
+{
+    const XMLElement* parentElem = 0;
+    if ( element.Parent() ) {
+        parentElem = element.Parent()->ToElement();
+    }
+    const bool compactMode = parentElem ? CompactMode( *parentElem ) : _compactMode;
+    OpenElement( element.Name(), compactMode );
+    while ( attribute ) {
+        PushAttribute( attribute->Name(), attribute->Value() );
+        attribute = attribute->Next();
+    }
+    return true;
+}
+
+
+bool XMLPrinter::VisitExit( const XMLElement& element )
+{
+    CloseElement( CompactMode(element) );
+    return true;
+}
+
+
+bool XMLPrinter::Visit( const XMLText& text )
+{
+    PushText( text.Value(), text.CData() );
+    return true;
+}
+
+
+bool XMLPrinter::Visit( const XMLComment& comment )
+{
+    PushComment( comment.Value() );
+    return true;
+}
+
+bool XMLPrinter::Visit( const XMLDeclaration& declaration )
+{
+    PushDeclaration( declaration.Value() );
+    return true;
+}
+
+
+bool XMLPrinter::Visit( const XMLUnknown& unknown )
+{
+    PushUnknown( unknown.Value() );
+    return true;
+}
+
+}   // namespace tinyxml2
diff -Nur FFmpeg/DASH_packing_sample/ParsePackingParam/tinyxml2.h FFmpeg_patched/DASH_packing_sample/ParsePackingParam/tinyxml2.h
--- FFmpeg/DASH_packing_sample/ParsePackingParam/tinyxml2.h	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/ParsePackingParam/tinyxml2.h	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,2309 @@
+/*
+Original code by Lee Thomason (www.grinninglizard.com)
+
+This software is provided 'as-is', without any express or implied
+warranty. In no event will the authors be held liable for any
+damages arising from the use of this software.
+
+Permission is granted to anyone to use this software for any
+purpose, including commercial applications, and to alter it and
+redistribute it freely, subject to the following restrictions:
+
+1. The origin of this software must not be misrepresented; you must
+not claim that you wrote the original software. If you use this
+software in a product, an acknowledgment in the product documentation
+would be appreciated but is not required.
+
+2. Altered source versions must be plainly marked as such, and
+must not be misrepresented as being the original software.
+
+3. This notice may not be removed or altered from any source
+distribution.
+*/
+
+#ifndef TINYXML2_INCLUDED
+#define TINYXML2_INCLUDED
+
+#if defined(ANDROID_NDK) || defined(__BORLANDC__) || defined(__QNXNTO__)
+#   include <ctype.h>
+#   include <limits.h>
+#   include <stdio.h>
+#   include <stdlib.h>
+#   include <string.h>
+#	if defined(__PS3__)
+#		include <stddef.h>
+#	endif
+#else
+#   include <cctype>
+#   include <climits>
+#   include <cstdio>
+#   include <cstdlib>
+#   include <cstring>
+#endif
+#include <stdint.h>
+
+/*
+   TODO: intern strings instead of allocation.
+*/
+/*
+	gcc:
+        g++ -Wall -DTINYXML2_DEBUG tinyxml2.cpp xmltest.cpp -o gccxmltest.exe
+
+    Formatting, Artistic Style:
+        AStyle.exe --style=1tbs --indent-switches --break-closing-brackets --indent-preprocessor tinyxml2.cpp tinyxml2.h
+*/
+
+#if defined( _DEBUG ) || defined (__DEBUG__)
+#   ifndef TINYXML2_DEBUG
+#       define TINYXML2_DEBUG
+#   endif
+#endif
+
+#ifdef _MSC_VER
+#   pragma warning(push)
+#   pragma warning(disable: 4251)
+#endif
+
+#ifdef _WIN32
+#   ifdef TINYXML2_EXPORT
+#       define TINYXML2_LIB __declspec(dllexport)
+#   elif defined(TINYXML2_IMPORT)
+#       define TINYXML2_LIB __declspec(dllimport)
+#   else
+#       define TINYXML2_LIB
+#   endif
+#elif __GNUC__ >= 4
+#   define TINYXML2_LIB __attribute__((visibility("default")))
+#else
+#   define TINYXML2_LIB
+#endif
+
+
+#if defined(TINYXML2_DEBUG)
+#   if defined(_MSC_VER)
+#       // "(void)0," is for suppressing C4127 warning in "assert(false)", "assert(true)" and the like
+#       define TIXMLASSERT( x )           if ( !((void)0,(x))) { __debugbreak(); }
+#   elif defined (ANDROID_NDK)
+#       include <android/log.h>
+#       define TIXMLASSERT( x )           if ( !(x)) { __android_log_assert( "assert", "grinliz", "ASSERT in '%s' at %d.", __FILE__, __LINE__ ); }
+#   else
+#       include <assert.h>
+#       define TIXMLASSERT                assert
+#   endif
+#else
+#   define TIXMLASSERT( x )               {}
+#endif
+
+
+/* Versioning, past 1.0.14:
+	http://semver.org/
+*/
+static const int TIXML2_MAJOR_VERSION = 7;
+static const int TIXML2_MINOR_VERSION = 0;
+static const int TIXML2_PATCH_VERSION = 1;
+
+#define TINYXML2_MAJOR_VERSION 7
+#define TINYXML2_MINOR_VERSION 0
+#define TINYXML2_PATCH_VERSION 1
+
+// A fixed element depth limit is problematic. There needs to be a
+// limit to avoid a stack overflow. However, that limit varies per
+// system, and the capacity of the stack. On the other hand, it's a trivial
+// attack that can result from ill, malicious, or even correctly formed XML,
+// so there needs to be a limit in place.
+static const int TINYXML2_MAX_ELEMENT_DEPTH = 100;
+
+namespace tinyxml2
+{
+class XMLDocument;
+class XMLElement;
+class XMLAttribute;
+class XMLComment;
+class XMLText;
+class XMLDeclaration;
+class XMLUnknown;
+class XMLPrinter;
+
+/*
+	A class that wraps strings. Normally stores the start and end
+	pointers into the XML file itself, and will apply normalization
+	and entity translation if actually read. Can also store (and memory
+	manage) a traditional char[]
+
+    Isn't clear why TINYXML2_LIB is needed; but seems to fix #719
+*/
+class TINYXML2_LIB StrPair
+{
+public:
+    enum {
+        NEEDS_ENTITY_PROCESSING			= 0x01,
+        NEEDS_NEWLINE_NORMALIZATION		= 0x02,
+        NEEDS_WHITESPACE_COLLAPSING     = 0x04,
+
+        TEXT_ELEMENT		            = NEEDS_ENTITY_PROCESSING | NEEDS_NEWLINE_NORMALIZATION,
+        TEXT_ELEMENT_LEAVE_ENTITIES		= NEEDS_NEWLINE_NORMALIZATION,
+        ATTRIBUTE_NAME		            = 0,
+        ATTRIBUTE_VALUE		            = NEEDS_ENTITY_PROCESSING | NEEDS_NEWLINE_NORMALIZATION,
+        ATTRIBUTE_VALUE_LEAVE_ENTITIES  = NEEDS_NEWLINE_NORMALIZATION,
+        COMMENT							= NEEDS_NEWLINE_NORMALIZATION
+    };
+
+    StrPair() : _flags( 0 ), _start( 0 ), _end( 0 ) {}
+    ~StrPair();
+
+    void Set( char* start, char* end, int flags ) {
+        TIXMLASSERT( start );
+        TIXMLASSERT( end );
+        Reset();
+        _start  = start;
+        _end    = end;
+        _flags  = flags | NEEDS_FLUSH;
+    }
+
+    const char* GetStr();
+
+    bool Empty() const {
+        return _start == _end;
+    }
+
+    void SetInternedStr( const char* str ) {
+        Reset();
+        _start = const_cast<char*>(str);
+    }
+
+    void SetStr( const char* str, int flags=0 );
+
+    char* ParseText( char* in, const char* endTag, int strFlags, int* curLineNumPtr );
+    char* ParseName( char* in );
+
+    void TransferTo( StrPair* other );
+	void Reset();
+
+private:
+    void CollapseWhitespace();
+
+    enum {
+        NEEDS_FLUSH = 0x100,
+        NEEDS_DELETE = 0x200
+    };
+
+    int     _flags;
+    char*   _start;
+    char*   _end;
+
+    StrPair( const StrPair& other );	// not supported
+    void operator=( const StrPair& other );	// not supported, use TransferTo()
+};
+
+
+/*
+	A dynamic array of Plain Old Data. Doesn't support constructors, etc.
+	Has a small initial memory pool, so that low or no usage will not
+	cause a call to new/delete
+*/
+template <class T, int INITIAL_SIZE>
+class DynArray
+{
+public:
+    DynArray() :
+        _mem( _pool ),
+        _allocated( INITIAL_SIZE ),
+        _size( 0 )
+    {
+    }
+
+    ~DynArray() {
+        if ( _mem != _pool ) {
+            delete [] _mem;
+        }
+    }
+
+    void Clear() {
+        _size = 0;
+    }
+
+    void Push( T t ) {
+        TIXMLASSERT( _size < INT_MAX );
+        EnsureCapacity( _size+1 );
+        _mem[_size] = t;
+        ++_size;
+    }
+
+    T* PushArr( int count ) {
+        TIXMLASSERT( count >= 0 );
+        TIXMLASSERT( _size <= INT_MAX - count );
+        EnsureCapacity( _size+count );
+        T* ret = &_mem[_size];
+        _size += count;
+        return ret;
+    }
+
+    T Pop() {
+        TIXMLASSERT( _size > 0 );
+        --_size;
+        return _mem[_size];
+    }
+
+    void PopArr( int count ) {
+        TIXMLASSERT( _size >= count );
+        _size -= count;
+    }
+
+    bool Empty() const					{
+        return _size == 0;
+    }
+
+    T& operator[](int i)				{
+        TIXMLASSERT( i>= 0 && i < _size );
+        return _mem[i];
+    }
+
+    const T& operator[](int i) const	{
+        TIXMLASSERT( i>= 0 && i < _size );
+        return _mem[i];
+    }
+
+    const T& PeekTop() const            {
+        TIXMLASSERT( _size > 0 );
+        return _mem[ _size - 1];
+    }
+
+    int Size() const					{
+        TIXMLASSERT( _size >= 0 );
+        return _size;
+    }
+
+    int Capacity() const				{
+        TIXMLASSERT( _allocated >= INITIAL_SIZE );
+        return _allocated;
+    }
+
+	void SwapRemove(int i) {
+		TIXMLASSERT(i >= 0 && i < _size);
+		TIXMLASSERT(_size > 0);
+		_mem[i] = _mem[_size - 1];
+		--_size;
+	}
+
+    const T* Mem() const				{
+        TIXMLASSERT( _mem );
+        return _mem;
+    }
+
+    T* Mem() {
+        TIXMLASSERT( _mem );
+        return _mem;
+    }
+
+private:
+    DynArray( const DynArray& ); // not supported
+    void operator=( const DynArray& ); // not supported
+
+    void EnsureCapacity( int cap ) {
+        TIXMLASSERT( cap > 0 );
+        if ( cap > _allocated ) {
+            TIXMLASSERT( cap <= INT_MAX / 2 );
+            const int newAllocated = cap * 2;
+            T* newMem = new T[newAllocated];
+            TIXMLASSERT( newAllocated >= _size );
+            memcpy( newMem, _mem, sizeof(T)*_size );	// warning: not using constructors, only works for PODs
+            if ( _mem != _pool ) {
+                delete [] _mem;
+            }
+            _mem = newMem;
+            _allocated = newAllocated;
+        }
+    }
+
+    T*  _mem;
+    T   _pool[INITIAL_SIZE];
+    int _allocated;		// objects allocated
+    int _size;			// number objects in use
+};
+
+
+/*
+	Parent virtual class of a pool for fast allocation
+	and deallocation of objects.
+*/
+class MemPool
+{
+public:
+    MemPool() {}
+    virtual ~MemPool() {}
+
+    virtual int ItemSize() const = 0;
+    virtual void* Alloc() = 0;
+    virtual void Free( void* ) = 0;
+    virtual void SetTracked() = 0;
+};
+
+
+/*
+	Template child class to create pools of the correct type.
+*/
+template< int ITEM_SIZE >
+class MemPoolT : public MemPool
+{
+public:
+    MemPoolT() : _blockPtrs(), _root(0), _currentAllocs(0), _nAllocs(0), _maxAllocs(0), _nUntracked(0)	{}
+    ~MemPoolT() {
+        MemPoolT< ITEM_SIZE >::Clear();
+    }
+
+    void Clear() {
+        // Delete the blocks.
+        while( !_blockPtrs.Empty()) {
+            Block* lastBlock = _blockPtrs.Pop();
+            delete lastBlock;
+        }
+        _root = 0;
+        _currentAllocs = 0;
+        _nAllocs = 0;
+        _maxAllocs = 0;
+        _nUntracked = 0;
+    }
+
+    virtual int ItemSize() const	{
+        return ITEM_SIZE;
+    }
+    int CurrentAllocs() const		{
+        return _currentAllocs;
+    }
+
+    virtual void* Alloc() {
+        if ( !_root ) {
+            // Need a new block.
+            Block* block = new Block();
+            _blockPtrs.Push( block );
+
+            Item* blockItems = block->items;
+            for( int i = 0; i < ITEMS_PER_BLOCK - 1; ++i ) {
+                blockItems[i].next = &(blockItems[i + 1]);
+            }
+            blockItems[ITEMS_PER_BLOCK - 1].next = 0;
+            _root = blockItems;
+        }
+        Item* const result = _root;
+        TIXMLASSERT( result != 0 );
+        _root = _root->next;
+
+        ++_currentAllocs;
+        if ( _currentAllocs > _maxAllocs ) {
+            _maxAllocs = _currentAllocs;
+        }
+        ++_nAllocs;
+        ++_nUntracked;
+        return result;
+    }
+
+    virtual void Free( void* mem ) {
+        if ( !mem ) {
+            return;
+        }
+        --_currentAllocs;
+        Item* item = static_cast<Item*>( mem );
+#ifdef TINYXML2_DEBUG
+        memset( item, 0xfe, sizeof( *item ) );
+#endif
+        item->next = _root;
+        _root = item;
+    }
+    void Trace( const char* name ) {
+        printf( "Mempool %s watermark=%d [%dk] current=%d size=%d nAlloc=%d blocks=%d\n",
+                name, _maxAllocs, _maxAllocs * ITEM_SIZE / 1024, _currentAllocs,
+                ITEM_SIZE, _nAllocs, _blockPtrs.Size() );
+    }
+
+    void SetTracked() {
+        --_nUntracked;
+    }
+
+    int Untracked() const {
+        return _nUntracked;
+    }
+
+	// This number is perf sensitive. 4k seems like a good tradeoff on my machine.
+	// The test file is large, 170k.
+	// Release:		VS2010 gcc(no opt)
+	//		1k:		4000
+	//		2k:		4000
+	//		4k:		3900	21000
+	//		16k:	5200
+	//		32k:	4300
+	//		64k:	4000	21000
+    // Declared public because some compilers do not accept to use ITEMS_PER_BLOCK
+    // in private part if ITEMS_PER_BLOCK is private
+    enum { ITEMS_PER_BLOCK = (4 * 1024) / ITEM_SIZE };
+
+private:
+    MemPoolT( const MemPoolT& ); // not supported
+    void operator=( const MemPoolT& ); // not supported
+
+    union Item {
+        Item*   next;
+        char    itemData[ITEM_SIZE];
+    };
+    struct Block {
+        Item items[ITEMS_PER_BLOCK];
+    };
+    DynArray< Block*, 10 > _blockPtrs;
+    Item* _root;
+
+    int _currentAllocs;
+    int _nAllocs;
+    int _maxAllocs;
+    int _nUntracked;
+};
+
+
+
+/**
+	Implements the interface to the "Visitor pattern" (see the Accept() method.)
+	If you call the Accept() method, it requires being passed a XMLVisitor
+	class to handle callbacks. For nodes that contain other nodes (Document, Element)
+	you will get called with a VisitEnter/VisitExit pair. Nodes that are always leafs
+	are simply called with Visit().
+
+	If you return 'true' from a Visit method, recursive parsing will continue. If you return
+	false, <b>no children of this node or its siblings</b> will be visited.
+
+	All flavors of Visit methods have a default implementation that returns 'true' (continue
+	visiting). You need to only override methods that are interesting to you.
+
+	Generally Accept() is called on the XMLDocument, although all nodes support visiting.
+
+	You should never change the document from a callback.
+
+	@sa XMLNode::Accept()
+*/
+class TINYXML2_LIB XMLVisitor
+{
+public:
+    virtual ~XMLVisitor() {}
+
+    /// Visit a document.
+    virtual bool VisitEnter( const XMLDocument& /*doc*/ )			{
+        return true;
+    }
+    /// Visit a document.
+    virtual bool VisitExit( const XMLDocument& /*doc*/ )			{
+        return true;
+    }
+
+    /// Visit an element.
+    virtual bool VisitEnter( const XMLElement& /*element*/, const XMLAttribute* /*firstAttribute*/ )	{
+        return true;
+    }
+    /// Visit an element.
+    virtual bool VisitExit( const XMLElement& /*element*/ )			{
+        return true;
+    }
+
+    /// Visit a declaration.
+    virtual bool Visit( const XMLDeclaration& /*declaration*/ )		{
+        return true;
+    }
+    /// Visit a text node.
+    virtual bool Visit( const XMLText& /*text*/ )					{
+        return true;
+    }
+    /// Visit a comment node.
+    virtual bool Visit( const XMLComment& /*comment*/ )				{
+        return true;
+    }
+    /// Visit an unknown node.
+    virtual bool Visit( const XMLUnknown& /*unknown*/ )				{
+        return true;
+    }
+};
+
+// WARNING: must match XMLDocument::_errorNames[]
+enum XMLError {
+    XML_SUCCESS = 0,
+    XML_NO_ATTRIBUTE,
+    XML_WRONG_ATTRIBUTE_TYPE,
+    XML_ERROR_FILE_NOT_FOUND,
+    XML_ERROR_FILE_COULD_NOT_BE_OPENED,
+    XML_ERROR_FILE_READ_ERROR,
+    XML_ERROR_PARSING_ELEMENT,
+    XML_ERROR_PARSING_ATTRIBUTE,
+    XML_ERROR_PARSING_TEXT,
+    XML_ERROR_PARSING_CDATA,
+    XML_ERROR_PARSING_COMMENT,
+    XML_ERROR_PARSING_DECLARATION,
+    XML_ERROR_PARSING_UNKNOWN,
+    XML_ERROR_EMPTY_DOCUMENT,
+    XML_ERROR_MISMATCHED_ELEMENT,
+    XML_ERROR_PARSING,
+    XML_CAN_NOT_CONVERT_TEXT,
+    XML_NO_TEXT_NODE,
+	XML_ELEMENT_DEPTH_EXCEEDED,
+
+	XML_ERROR_COUNT
+};
+
+
+/*
+	Utility functionality.
+*/
+class TINYXML2_LIB XMLUtil
+{
+public:
+    static const char* SkipWhiteSpace( const char* p, int* curLineNumPtr )	{
+        TIXMLASSERT( p );
+
+        while( IsWhiteSpace(*p) ) {
+            if (curLineNumPtr && *p == '\n') {
+                ++(*curLineNumPtr);
+            }
+            ++p;
+        }
+        TIXMLASSERT( p );
+        return p;
+    }
+    static char* SkipWhiteSpace( char* p, int* curLineNumPtr )				{
+        return const_cast<char*>( SkipWhiteSpace( const_cast<const char*>(p), curLineNumPtr ) );
+    }
+
+    // Anything in the high order range of UTF-8 is assumed to not be whitespace. This isn't
+    // correct, but simple, and usually works.
+    static bool IsWhiteSpace( char p )					{
+        return !IsUTF8Continuation(p) && isspace( static_cast<unsigned char>(p) );
+    }
+
+    inline static bool IsNameStartChar( unsigned char ch ) {
+        if ( ch >= 128 ) {
+            // This is a heuristic guess in attempt to not implement Unicode-aware isalpha()
+            return true;
+        }
+        if ( isalpha( ch ) ) {
+            return true;
+        }
+        return ch == ':' || ch == '_';
+    }
+
+    inline static bool IsNameChar( unsigned char ch ) {
+        return IsNameStartChar( ch )
+               || isdigit( ch )
+               || ch == '.'
+               || ch == '-';
+    }
+
+    inline static bool StringEqual( const char* p, const char* q, int nChar=INT_MAX )  {
+        if ( p == q ) {
+            return true;
+        }
+        TIXMLASSERT( p );
+        TIXMLASSERT( q );
+        TIXMLASSERT( nChar >= 0 );
+        return strncmp( p, q, nChar ) == 0;
+    }
+
+    inline static bool IsUTF8Continuation( char p ) {
+        return ( p & 0x80 ) != 0;
+    }
+
+    static const char* ReadBOM( const char* p, bool* hasBOM );
+    // p is the starting location,
+    // the UTF-8 value of the entity will be placed in value, and length filled in.
+    static const char* GetCharacterRef( const char* p, char* value, int* length );
+    static void ConvertUTF32ToUTF8( unsigned long input, char* output, int* length );
+
+    // converts primitive types to strings
+    static void ToStr( int v, char* buffer, int bufferSize );
+    static void ToStr( unsigned v, char* buffer, int bufferSize );
+    static void ToStr( bool v, char* buffer, int bufferSize );
+    static void ToStr( float v, char* buffer, int bufferSize );
+    static void ToStr( double v, char* buffer, int bufferSize );
+	static void ToStr(int64_t v, char* buffer, int bufferSize);
+
+    // converts strings to primitive types
+    static bool	ToInt( const char* str, int* value );
+    static bool ToUnsigned( const char* str, unsigned* value );
+    static bool	ToBool( const char* str, bool* value );
+    static bool	ToFloat( const char* str, float* value );
+    static bool ToDouble( const char* str, double* value );
+	static bool ToInt64(const char* str, int64_t* value);
+
+	// Changes what is serialized for a boolean value.
+	// Default to "true" and "false". Shouldn't be changed
+	// unless you have a special testing or compatibility need.
+	// Be careful: static, global, & not thread safe.
+	// Be sure to set static const memory as parameters.
+	static void SetBoolSerialization(const char* writeTrue, const char* writeFalse);
+
+private:
+	static const char* writeBoolTrue;
+	static const char* writeBoolFalse;
+};
+
+
+/** XMLNode is a base class for every object that is in the
+	XML Document Object Model (DOM), except XMLAttributes.
+	Nodes have siblings, a parent, and children which can
+	be navigated. A node is always in a XMLDocument.
+	The type of a XMLNode can be queried, and it can
+	be cast to its more defined type.
+
+	A XMLDocument allocates memory for all its Nodes.
+	When the XMLDocument gets deleted, all its Nodes
+	will also be deleted.
+
+	@verbatim
+	A Document can contain:	Element	(container or leaf)
+							Comment (leaf)
+							Unknown (leaf)
+							Declaration( leaf )
+
+	An Element can contain:	Element (container or leaf)
+							Text	(leaf)
+							Attributes (not on tree)
+							Comment (leaf)
+							Unknown (leaf)
+
+	@endverbatim
+*/
+class TINYXML2_LIB XMLNode
+{
+    friend class XMLDocument;
+    friend class XMLElement;
+public:
+
+    /// Get the XMLDocument that owns this XMLNode.
+    const XMLDocument* GetDocument() const	{
+        TIXMLASSERT( _document );
+        return _document;
+    }
+    /// Get the XMLDocument that owns this XMLNode.
+    XMLDocument* GetDocument()				{
+        TIXMLASSERT( _document );
+        return _document;
+    }
+
+    /// Safely cast to an Element, or null.
+    virtual XMLElement*		ToElement()		{
+        return 0;
+    }
+    /// Safely cast to Text, or null.
+    virtual XMLText*		ToText()		{
+        return 0;
+    }
+    /// Safely cast to a Comment, or null.
+    virtual XMLComment*		ToComment()		{
+        return 0;
+    }
+    /// Safely cast to a Document, or null.
+    virtual XMLDocument*	ToDocument()	{
+        return 0;
+    }
+    /// Safely cast to a Declaration, or null.
+    virtual XMLDeclaration*	ToDeclaration()	{
+        return 0;
+    }
+    /// Safely cast to an Unknown, or null.
+    virtual XMLUnknown*		ToUnknown()		{
+        return 0;
+    }
+
+    virtual const XMLElement*		ToElement() const		{
+        return 0;
+    }
+    virtual const XMLText*			ToText() const			{
+        return 0;
+    }
+    virtual const XMLComment*		ToComment() const		{
+        return 0;
+    }
+    virtual const XMLDocument*		ToDocument() const		{
+        return 0;
+    }
+    virtual const XMLDeclaration*	ToDeclaration() const	{
+        return 0;
+    }
+    virtual const XMLUnknown*		ToUnknown() const		{
+        return 0;
+    }
+
+    /** The meaning of 'value' changes for the specific type.
+    	@verbatim
+    	Document:	empty (NULL is returned, not an empty string)
+    	Element:	name of the element
+    	Comment:	the comment text
+    	Unknown:	the tag contents
+    	Text:		the text string
+    	@endverbatim
+    */
+    const char* Value() const;
+
+    /** Set the Value of an XML node.
+    	@sa Value()
+    */
+    void SetValue( const char* val, bool staticMem=false );
+
+    /// Gets the line number the node is in, if the document was parsed from a file.
+    int GetLineNum() const { return _parseLineNum; }
+
+    /// Get the parent of this node on the DOM.
+    const XMLNode*	Parent() const			{
+        return _parent;
+    }
+
+    XMLNode* Parent()						{
+        return _parent;
+    }
+
+    /// Returns true if this node has no children.
+    bool NoChildren() const					{
+        return !_firstChild;
+    }
+
+    /// Get the first child node, or null if none exists.
+    const XMLNode*  FirstChild() const		{
+        return _firstChild;
+    }
+
+    XMLNode*		FirstChild()			{
+        return _firstChild;
+    }
+
+    /** Get the first child element, or optionally the first child
+        element with the specified name.
+    */
+    const XMLElement* FirstChildElement( const char* name = 0 ) const;
+
+    XMLElement* FirstChildElement( const char* name = 0 )	{
+        return const_cast<XMLElement*>(const_cast<const XMLNode*>(this)->FirstChildElement( name ));
+    }
+
+    /// Get the last child node, or null if none exists.
+    const XMLNode*	LastChild() const						{
+        return _lastChild;
+    }
+
+    XMLNode*		LastChild()								{
+        return _lastChild;
+    }
+
+    /** Get the last child element or optionally the last child
+        element with the specified name.
+    */
+    const XMLElement* LastChildElement( const char* name = 0 ) const;
+
+    XMLElement* LastChildElement( const char* name = 0 )	{
+        return const_cast<XMLElement*>(const_cast<const XMLNode*>(this)->LastChildElement(name) );
+    }
+
+    /// Get the previous (left) sibling node of this node.
+    const XMLNode*	PreviousSibling() const					{
+        return _prev;
+    }
+
+    XMLNode*	PreviousSibling()							{
+        return _prev;
+    }
+
+    /// Get the previous (left) sibling element of this node, with an optionally supplied name.
+    const XMLElement*	PreviousSiblingElement( const char* name = 0 ) const ;
+
+    XMLElement*	PreviousSiblingElement( const char* name = 0 ) {
+        return const_cast<XMLElement*>(const_cast<const XMLNode*>(this)->PreviousSiblingElement( name ) );
+    }
+
+    /// Get the next (right) sibling node of this node.
+    const XMLNode*	NextSibling() const						{
+        return _next;
+    }
+
+    XMLNode*	NextSibling()								{
+        return _next;
+    }
+
+    /// Get the next (right) sibling element of this node, with an optionally supplied name.
+    const XMLElement*	NextSiblingElement( const char* name = 0 ) const;
+
+    XMLElement*	NextSiblingElement( const char* name = 0 )	{
+        return const_cast<XMLElement*>(const_cast<const XMLNode*>(this)->NextSiblingElement( name ) );
+    }
+
+    /**
+    	Add a child node as the last (right) child.
+		If the child node is already part of the document,
+		it is moved from its old location to the new location.
+		Returns the addThis argument or 0 if the node does not
+		belong to the same document.
+    */
+    XMLNode* InsertEndChild( XMLNode* addThis );
+
+    XMLNode* LinkEndChild( XMLNode* addThis )	{
+        return InsertEndChild( addThis );
+    }
+    /**
+    	Add a child node as the first (left) child.
+		If the child node is already part of the document,
+		it is moved from its old location to the new location.
+		Returns the addThis argument or 0 if the node does not
+		belong to the same document.
+    */
+    XMLNode* InsertFirstChild( XMLNode* addThis );
+    /**
+    	Add a node after the specified child node.
+		If the child node is already part of the document,
+		it is moved from its old location to the new location.
+		Returns the addThis argument or 0 if the afterThis node
+		is not a child of this node, or if the node does not
+		belong to the same document.
+    */
+    XMLNode* InsertAfterChild( XMLNode* afterThis, XMLNode* addThis );
+
+    /**
+    	Delete all the children of this node.
+    */
+    void DeleteChildren();
+
+    /**
+    	Delete a child of this node.
+    */
+    void DeleteChild( XMLNode* node );
+
+    /**
+    	Make a copy of this node, but not its children.
+    	You may pass in a Document pointer that will be
+    	the owner of the new Node. If the 'document' is
+    	null, then the node returned will be allocated
+    	from the current Document. (this->GetDocument())
+
+    	Note: if called on a XMLDocument, this will return null.
+    */
+    virtual XMLNode* ShallowClone( XMLDocument* document ) const = 0;
+
+	/**
+		Make a copy of this node and all its children.
+
+		If the 'target' is null, then the nodes will
+		be allocated in the current document. If 'target'
+        is specified, the memory will be allocated is the
+        specified XMLDocument.
+
+		NOTE: This is probably not the correct tool to
+		copy a document, since XMLDocuments can have multiple
+		top level XMLNodes. You probably want to use
+        XMLDocument::DeepCopy()
+	*/
+	XMLNode* DeepClone( XMLDocument* target ) const;
+
+    /**
+    	Test if 2 nodes are the same, but don't test children.
+    	The 2 nodes do not need to be in the same Document.
+
+    	Note: if called on a XMLDocument, this will return false.
+    */
+    virtual bool ShallowEqual( const XMLNode* compare ) const = 0;
+
+    /** Accept a hierarchical visit of the nodes in the TinyXML-2 DOM. Every node in the
+    	XML tree will be conditionally visited and the host will be called back
+    	via the XMLVisitor interface.
+
+    	This is essentially a SAX interface for TinyXML-2. (Note however it doesn't re-parse
+    	the XML for the callbacks, so the performance of TinyXML-2 is unchanged by using this
+    	interface versus any other.)
+
+    	The interface has been based on ideas from:
+
+    	- http://www.saxproject.org/
+    	- http://c2.com/cgi/wiki?HierarchicalVisitorPattern
+
+    	Which are both good references for "visiting".
+
+    	An example of using Accept():
+    	@verbatim
+    	XMLPrinter printer;
+    	tinyxmlDoc.Accept( &printer );
+    	const char* xmlcstr = printer.CStr();
+    	@endverbatim
+    */
+    virtual bool Accept( XMLVisitor* visitor ) const = 0;
+
+	/**
+		Set user data into the XMLNode. TinyXML-2 in
+		no way processes or interprets user data.
+		It is initially 0.
+	*/
+	void SetUserData(void* userData)	{ _userData = userData; }
+
+	/**
+		Get user data set into the XMLNode. TinyXML-2 in
+		no way processes or interprets user data.
+		It is initially 0.
+	*/
+	void* GetUserData() const			{ return _userData; }
+
+protected:
+    explicit XMLNode( XMLDocument* );
+    virtual ~XMLNode();
+
+    virtual char* ParseDeep( char* p, StrPair* parentEndTag, int* curLineNumPtr);
+
+    XMLDocument*	_document;
+    XMLNode*		_parent;
+    mutable StrPair	_value;
+    int             _parseLineNum;
+
+    XMLNode*		_firstChild;
+    XMLNode*		_lastChild;
+
+    XMLNode*		_prev;
+    XMLNode*		_next;
+
+	void*			_userData;
+
+private:
+    MemPool*		_memPool;
+    void Unlink( XMLNode* child );
+    static void DeleteNode( XMLNode* node );
+    void InsertChildPreamble( XMLNode* insertThis ) const;
+    const XMLElement* ToElementWithName( const char* name ) const;
+
+    XMLNode( const XMLNode& );	// not supported
+    XMLNode& operator=( const XMLNode& );	// not supported
+};
+
+
+/** XML text.
+
+	Note that a text node can have child element nodes, for example:
+	@verbatim
+	<root>This is <b>bold</b></root>
+	@endverbatim
+
+	A text node can have 2 ways to output the next. "normal" output
+	and CDATA. It will default to the mode it was parsed from the XML file and
+	you generally want to leave it alone, but you can change the output mode with
+	SetCData() and query it with CData().
+*/
+class TINYXML2_LIB XMLText : public XMLNode
+{
+    friend class XMLDocument;
+public:
+    virtual bool Accept( XMLVisitor* visitor ) const;
+
+    virtual XMLText* ToText()			{
+        return this;
+    }
+    virtual const XMLText* ToText() const	{
+        return this;
+    }
+
+    /// Declare whether this should be CDATA or standard text.
+    void SetCData( bool isCData )			{
+        _isCData = isCData;
+    }
+    /// Returns true if this is a CDATA text element.
+    bool CData() const						{
+        return _isCData;
+    }
+
+    virtual XMLNode* ShallowClone( XMLDocument* document ) const;
+    virtual bool ShallowEqual( const XMLNode* compare ) const;
+
+protected:
+    explicit XMLText( XMLDocument* doc )	: XMLNode( doc ), _isCData( false )	{}
+    virtual ~XMLText()												{}
+
+    char* ParseDeep( char* p, StrPair* parentEndTag, int* curLineNumPtr );
+
+private:
+    bool _isCData;
+
+    XMLText( const XMLText& );	// not supported
+    XMLText& operator=( const XMLText& );	// not supported
+};
+
+
+/** An XML Comment. */
+class TINYXML2_LIB XMLComment : public XMLNode
+{
+    friend class XMLDocument;
+public:
+    virtual XMLComment*	ToComment()					{
+        return this;
+    }
+    virtual const XMLComment* ToComment() const		{
+        return this;
+    }
+
+    virtual bool Accept( XMLVisitor* visitor ) const;
+
+    virtual XMLNode* ShallowClone( XMLDocument* document ) const;
+    virtual bool ShallowEqual( const XMLNode* compare ) const;
+
+protected:
+    explicit XMLComment( XMLDocument* doc );
+    virtual ~XMLComment();
+
+    char* ParseDeep( char* p, StrPair* parentEndTag, int* curLineNumPtr);
+
+private:
+    XMLComment( const XMLComment& );	// not supported
+    XMLComment& operator=( const XMLComment& );	// not supported
+};
+
+
+/** In correct XML the declaration is the first entry in the file.
+	@verbatim
+		<?xml version="1.0" standalone="yes"?>
+	@endverbatim
+
+	TinyXML-2 will happily read or write files without a declaration,
+	however.
+
+	The text of the declaration isn't interpreted. It is parsed
+	and written as a string.
+*/
+class TINYXML2_LIB XMLDeclaration : public XMLNode
+{
+    friend class XMLDocument;
+public:
+    virtual XMLDeclaration*	ToDeclaration()					{
+        return this;
+    }
+    virtual const XMLDeclaration* ToDeclaration() const		{
+        return this;
+    }
+
+    virtual bool Accept( XMLVisitor* visitor ) const;
+
+    virtual XMLNode* ShallowClone( XMLDocument* document ) const;
+    virtual bool ShallowEqual( const XMLNode* compare ) const;
+
+protected:
+    explicit XMLDeclaration( XMLDocument* doc );
+    virtual ~XMLDeclaration();
+
+    char* ParseDeep( char* p, StrPair* parentEndTag, int* curLineNumPtr );
+
+private:
+    XMLDeclaration( const XMLDeclaration& );	// not supported
+    XMLDeclaration& operator=( const XMLDeclaration& );	// not supported
+};
+
+
+/** Any tag that TinyXML-2 doesn't recognize is saved as an
+	unknown. It is a tag of text, but should not be modified.
+	It will be written back to the XML, unchanged, when the file
+	is saved.
+
+	DTD tags get thrown into XMLUnknowns.
+*/
+class TINYXML2_LIB XMLUnknown : public XMLNode
+{
+    friend class XMLDocument;
+public:
+    virtual XMLUnknown*	ToUnknown()					{
+        return this;
+    }
+    virtual const XMLUnknown* ToUnknown() const		{
+        return this;
+    }
+
+    virtual bool Accept( XMLVisitor* visitor ) const;
+
+    virtual XMLNode* ShallowClone( XMLDocument* document ) const;
+    virtual bool ShallowEqual( const XMLNode* compare ) const;
+
+protected:
+    explicit XMLUnknown( XMLDocument* doc );
+    virtual ~XMLUnknown();
+
+    char* ParseDeep( char* p, StrPair* parentEndTag, int* curLineNumPtr );
+
+private:
+    XMLUnknown( const XMLUnknown& );	// not supported
+    XMLUnknown& operator=( const XMLUnknown& );	// not supported
+};
+
+
+
+/** An attribute is a name-value pair. Elements have an arbitrary
+	number of attributes, each with a unique name.
+
+	@note The attributes are not XMLNodes. You may only query the
+	Next() attribute in a list.
+*/
+class TINYXML2_LIB XMLAttribute
+{
+    friend class XMLElement;
+public:
+    /// The name of the attribute.
+    const char* Name() const;
+
+    /// The value of the attribute.
+    const char* Value() const;
+
+    /// Gets the line number the attribute is in, if the document was parsed from a file.
+    int GetLineNum() const { return _parseLineNum; }
+
+    /// The next attribute in the list.
+    const XMLAttribute* Next() const {
+        return _next;
+    }
+
+    /** IntValue interprets the attribute as an integer, and returns the value.
+        If the value isn't an integer, 0 will be returned. There is no error checking;
+    	use QueryIntValue() if you need error checking.
+    */
+	int	IntValue() const {
+		int i = 0;
+		QueryIntValue(&i);
+		return i;
+	}
+
+	int64_t Int64Value() const {
+		int64_t i = 0;
+		QueryInt64Value(&i);
+		return i;
+	}
+
+    /// Query as an unsigned integer. See IntValue()
+    unsigned UnsignedValue() const			{
+        unsigned i=0;
+        QueryUnsignedValue( &i );
+        return i;
+    }
+    /// Query as a boolean. See IntValue()
+    bool	 BoolValue() const				{
+        bool b=false;
+        QueryBoolValue( &b );
+        return b;
+    }
+    /// Query as a double. See IntValue()
+    double 	 DoubleValue() const			{
+        double d=0;
+        QueryDoubleValue( &d );
+        return d;
+    }
+    /// Query as a float. See IntValue()
+    float	 FloatValue() const				{
+        float f=0;
+        QueryFloatValue( &f );
+        return f;
+    }
+
+    /** QueryIntValue interprets the attribute as an integer, and returns the value
+    	in the provided parameter. The function will return XML_SUCCESS on success,
+    	and XML_WRONG_ATTRIBUTE_TYPE if the conversion is not successful.
+    */
+    XMLError QueryIntValue( int* value ) const;
+    /// See QueryIntValue
+    XMLError QueryUnsignedValue( unsigned int* value ) const;
+	/// See QueryIntValue
+	XMLError QueryInt64Value(int64_t* value) const;
+	/// See QueryIntValue
+    XMLError QueryBoolValue( bool* value ) const;
+    /// See QueryIntValue
+    XMLError QueryDoubleValue( double* value ) const;
+    /// See QueryIntValue
+    XMLError QueryFloatValue( float* value ) const;
+
+    /// Set the attribute to a string value.
+    void SetAttribute( const char* value );
+    /// Set the attribute to value.
+    void SetAttribute( int value );
+    /// Set the attribute to value.
+    void SetAttribute( unsigned value );
+	/// Set the attribute to value.
+	void SetAttribute(int64_t value);
+	/// Set the attribute to value.
+    void SetAttribute( bool value );
+    /// Set the attribute to value.
+    void SetAttribute( double value );
+    /// Set the attribute to value.
+    void SetAttribute( float value );
+
+private:
+    enum { BUF_SIZE = 200 };
+
+    XMLAttribute() : _name(), _value(),_parseLineNum( 0 ), _next( 0 ), _memPool( 0 ) {}
+    virtual ~XMLAttribute()	{}
+
+    XMLAttribute( const XMLAttribute& );	// not supported
+    void operator=( const XMLAttribute& );	// not supported
+    void SetName( const char* name );
+
+    char* ParseDeep( char* p, bool processEntities, int* curLineNumPtr );
+
+    mutable StrPair _name;
+    mutable StrPair _value;
+    int             _parseLineNum;
+    XMLAttribute*   _next;
+    MemPool*        _memPool;
+};
+
+
+/** The element is a container class. It has a value, the element name,
+	and can contain other elements, text, comments, and unknowns.
+	Elements also contain an arbitrary number of attributes.
+*/
+class TINYXML2_LIB XMLElement : public XMLNode
+{
+    friend class XMLDocument;
+public:
+    /// Get the name of an element (which is the Value() of the node.)
+    const char* Name() const		{
+        return Value();
+    }
+    /// Set the name of the element.
+    void SetName( const char* str, bool staticMem=false )	{
+        SetValue( str, staticMem );
+    }
+
+    virtual XMLElement* ToElement()				{
+        return this;
+    }
+    virtual const XMLElement* ToElement() const {
+        return this;
+    }
+    virtual bool Accept( XMLVisitor* visitor ) const;
+
+    /** Given an attribute name, Attribute() returns the value
+    	for the attribute of that name, or null if none
+    	exists. For example:
+
+    	@verbatim
+    	const char* value = ele->Attribute( "foo" );
+    	@endverbatim
+
+    	The 'value' parameter is normally null. However, if specified,
+    	the attribute will only be returned if the 'name' and 'value'
+    	match. This allow you to write code:
+
+    	@verbatim
+    	if ( ele->Attribute( "foo", "bar" ) ) callFooIsBar();
+    	@endverbatim
+
+    	rather than:
+    	@verbatim
+    	if ( ele->Attribute( "foo" ) ) {
+    		if ( strcmp( ele->Attribute( "foo" ), "bar" ) == 0 ) callFooIsBar();
+    	}
+    	@endverbatim
+    */
+    const char* Attribute( const char* name, const char* value=0 ) const;
+
+    /** Given an attribute name, IntAttribute() returns the value
+    	of the attribute interpreted as an integer. The default
+        value will be returned if the attribute isn't present,
+        or if there is an error. (For a method with error
+    	checking, see QueryIntAttribute()).
+    */
+	int IntAttribute(const char* name, int defaultValue = 0) const;
+    /// See IntAttribute()
+	unsigned UnsignedAttribute(const char* name, unsigned defaultValue = 0) const;
+	/// See IntAttribute()
+	int64_t Int64Attribute(const char* name, int64_t defaultValue = 0) const;
+	/// See IntAttribute()
+	bool BoolAttribute(const char* name, bool defaultValue = false) const;
+    /// See IntAttribute()
+	double DoubleAttribute(const char* name, double defaultValue = 0) const;
+    /// See IntAttribute()
+	float FloatAttribute(const char* name, float defaultValue = 0) const;
+
+    /** Given an attribute name, QueryIntAttribute() returns
+    	XML_SUCCESS, XML_WRONG_ATTRIBUTE_TYPE if the conversion
+    	can't be performed, or XML_NO_ATTRIBUTE if the attribute
+    	doesn't exist. If successful, the result of the conversion
+    	will be written to 'value'. If not successful, nothing will
+    	be written to 'value'. This allows you to provide default
+    	value:
+
+    	@verbatim
+    	int value = 10;
+    	QueryIntAttribute( "foo", &value );		// if "foo" isn't found, value will still be 10
+    	@endverbatim
+    */
+    XMLError QueryIntAttribute( const char* name, int* value ) const				{
+        const XMLAttribute* a = FindAttribute( name );
+        if ( !a ) {
+            return XML_NO_ATTRIBUTE;
+        }
+        return a->QueryIntValue( value );
+    }
+
+	/// See QueryIntAttribute()
+    XMLError QueryUnsignedAttribute( const char* name, unsigned int* value ) const	{
+        const XMLAttribute* a = FindAttribute( name );
+        if ( !a ) {
+            return XML_NO_ATTRIBUTE;
+        }
+        return a->QueryUnsignedValue( value );
+    }
+
+	/// See QueryIntAttribute()
+	XMLError QueryInt64Attribute(const char* name, int64_t* value) const {
+		const XMLAttribute* a = FindAttribute(name);
+		if (!a) {
+			return XML_NO_ATTRIBUTE;
+		}
+		return a->QueryInt64Value(value);
+	}
+
+	/// See QueryIntAttribute()
+    XMLError QueryBoolAttribute( const char* name, bool* value ) const				{
+        const XMLAttribute* a = FindAttribute( name );
+        if ( !a ) {
+            return XML_NO_ATTRIBUTE;
+        }
+        return a->QueryBoolValue( value );
+    }
+    /// See QueryIntAttribute()
+    XMLError QueryDoubleAttribute( const char* name, double* value ) const			{
+        const XMLAttribute* a = FindAttribute( name );
+        if ( !a ) {
+            return XML_NO_ATTRIBUTE;
+        }
+        return a->QueryDoubleValue( value );
+    }
+    /// See QueryIntAttribute()
+    XMLError QueryFloatAttribute( const char* name, float* value ) const			{
+        const XMLAttribute* a = FindAttribute( name );
+        if ( !a ) {
+            return XML_NO_ATTRIBUTE;
+        }
+        return a->QueryFloatValue( value );
+    }
+
+	/// See QueryIntAttribute()
+	XMLError QueryStringAttribute(const char* name, const char** value) const {
+		const XMLAttribute* a = FindAttribute(name);
+		if (!a) {
+			return XML_NO_ATTRIBUTE;
+		}
+		*value = a->Value();
+		return XML_SUCCESS;
+	}
+
+
+
+    /** Given an attribute name, QueryAttribute() returns
+    	XML_SUCCESS, XML_WRONG_ATTRIBUTE_TYPE if the conversion
+    	can't be performed, or XML_NO_ATTRIBUTE if the attribute
+    	doesn't exist. It is overloaded for the primitive types,
+		and is a generally more convenient replacement of
+		QueryIntAttribute() and related functions.
+
+		If successful, the result of the conversion
+    	will be written to 'value'. If not successful, nothing will
+    	be written to 'value'. This allows you to provide default
+    	value:
+
+    	@verbatim
+    	int value = 10;
+    	QueryAttribute( "foo", &value );		// if "foo" isn't found, value will still be 10
+    	@endverbatim
+    */
+	XMLError QueryAttribute( const char* name, int* value ) const {
+		return QueryIntAttribute( name, value );
+	}
+
+	XMLError QueryAttribute( const char* name, unsigned int* value ) const {
+		return QueryUnsignedAttribute( name, value );
+	}
+
+	XMLError QueryAttribute(const char* name, int64_t* value) const {
+		return QueryInt64Attribute(name, value);
+	}
+
+	XMLError QueryAttribute( const char* name, bool* value ) const {
+		return QueryBoolAttribute( name, value );
+	}
+
+	XMLError QueryAttribute( const char* name, double* value ) const {
+		return QueryDoubleAttribute( name, value );
+	}
+
+	XMLError QueryAttribute( const char* name, float* value ) const {
+		return QueryFloatAttribute( name, value );
+	}
+
+	/// Sets the named attribute to value.
+    void SetAttribute( const char* name, const char* value )	{
+        XMLAttribute* a = FindOrCreateAttribute( name );
+        a->SetAttribute( value );
+    }
+    /// Sets the named attribute to value.
+    void SetAttribute( const char* name, int value )			{
+        XMLAttribute* a = FindOrCreateAttribute( name );
+        a->SetAttribute( value );
+    }
+    /// Sets the named attribute to value.
+    void SetAttribute( const char* name, unsigned value )		{
+        XMLAttribute* a = FindOrCreateAttribute( name );
+        a->SetAttribute( value );
+    }
+
+	/// Sets the named attribute to value.
+	void SetAttribute(const char* name, int64_t value) {
+		XMLAttribute* a = FindOrCreateAttribute(name);
+		a->SetAttribute(value);
+	}
+
+	/// Sets the named attribute to value.
+    void SetAttribute( const char* name, bool value )			{
+        XMLAttribute* a = FindOrCreateAttribute( name );
+        a->SetAttribute( value );
+    }
+    /// Sets the named attribute to value.
+    void SetAttribute( const char* name, double value )		{
+        XMLAttribute* a = FindOrCreateAttribute( name );
+        a->SetAttribute( value );
+    }
+    /// Sets the named attribute to value.
+    void SetAttribute( const char* name, float value )		{
+        XMLAttribute* a = FindOrCreateAttribute( name );
+        a->SetAttribute( value );
+    }
+
+    /**
+    	Delete an attribute.
+    */
+    void DeleteAttribute( const char* name );
+
+    /// Return the first attribute in the list.
+    const XMLAttribute* FirstAttribute() const {
+        return _rootAttribute;
+    }
+    /// Query a specific attribute in the list.
+    const XMLAttribute* FindAttribute( const char* name ) const;
+
+    /** Convenience function for easy access to the text inside an element. Although easy
+    	and concise, GetText() is limited compared to getting the XMLText child
+    	and accessing it directly.
+
+    	If the first child of 'this' is a XMLText, the GetText()
+    	returns the character string of the Text node, else null is returned.
+
+    	This is a convenient method for getting the text of simple contained text:
+    	@verbatim
+    	<foo>This is text</foo>
+    		const char* str = fooElement->GetText();
+    	@endverbatim
+
+    	'str' will be a pointer to "This is text".
+
+    	Note that this function can be misleading. If the element foo was created from
+    	this XML:
+    	@verbatim
+    		<foo><b>This is text</b></foo>
+    	@endverbatim
+
+    	then the value of str would be null. The first child node isn't a text node, it is
+    	another element. From this XML:
+    	@verbatim
+    		<foo>This is <b>text</b></foo>
+    	@endverbatim
+    	GetText() will return "This is ".
+    */
+    const char* GetText() const;
+
+    /** Convenience function for easy access to the text inside an element. Although easy
+    	and concise, SetText() is limited compared to creating an XMLText child
+    	and mutating it directly.
+
+    	If the first child of 'this' is a XMLText, SetText() sets its value to
+		the given string, otherwise it will create a first child that is an XMLText.
+
+    	This is a convenient method for setting the text of simple contained text:
+    	@verbatim
+    	<foo>This is text</foo>
+    		fooElement->SetText( "Hullaballoo!" );
+     	<foo>Hullaballoo!</foo>
+		@endverbatim
+
+    	Note that this function can be misleading. If the element foo was created from
+    	this XML:
+    	@verbatim
+    		<foo><b>This is text</b></foo>
+    	@endverbatim
+
+    	then it will not change "This is text", but rather prefix it with a text element:
+    	@verbatim
+    		<foo>Hullaballoo!<b>This is text</b></foo>
+    	@endverbatim
+
+		For this XML:
+    	@verbatim
+    		<foo />
+    	@endverbatim
+    	SetText() will generate
+    	@verbatim
+    		<foo>Hullaballoo!</foo>
+    	@endverbatim
+    */
+	void SetText( const char* inText );
+    /// Convenience method for setting text inside an element. See SetText() for important limitations.
+    void SetText( int value );
+    /// Convenience method for setting text inside an element. See SetText() for important limitations.
+    void SetText( unsigned value );
+	/// Convenience method for setting text inside an element. See SetText() for important limitations.
+	void SetText(int64_t value);
+	/// Convenience method for setting text inside an element. See SetText() for important limitations.
+    void SetText( bool value );
+    /// Convenience method for setting text inside an element. See SetText() for important limitations.
+    void SetText( double value );
+    /// Convenience method for setting text inside an element. See SetText() for important limitations.
+    void SetText( float value );
+
+    /**
+    	Convenience method to query the value of a child text node. This is probably best
+    	shown by example. Given you have a document is this form:
+    	@verbatim
+    		<point>
+    			<x>1</x>
+    			<y>1.4</y>
+    		</point>
+    	@endverbatim
+
+    	The QueryIntText() and similar functions provide a safe and easier way to get to the
+    	"value" of x and y.
+
+    	@verbatim
+    		int x = 0;
+    		float y = 0;	// types of x and y are contrived for example
+    		const XMLElement* xElement = pointElement->FirstChildElement( "x" );
+    		const XMLElement* yElement = pointElement->FirstChildElement( "y" );
+    		xElement->QueryIntText( &x );
+    		yElement->QueryFloatText( &y );
+    	@endverbatim
+
+    	@returns XML_SUCCESS (0) on success, XML_CAN_NOT_CONVERT_TEXT if the text cannot be converted
+    			 to the requested type, and XML_NO_TEXT_NODE if there is no child text to query.
+
+    */
+    XMLError QueryIntText( int* ival ) const;
+    /// See QueryIntText()
+    XMLError QueryUnsignedText( unsigned* uval ) const;
+	/// See QueryIntText()
+	XMLError QueryInt64Text(int64_t* uval) const;
+	/// See QueryIntText()
+    XMLError QueryBoolText( bool* bval ) const;
+    /// See QueryIntText()
+    XMLError QueryDoubleText( double* dval ) const;
+    /// See QueryIntText()
+    XMLError QueryFloatText( float* fval ) const;
+
+	int IntText(int defaultValue = 0) const;
+
+	/// See QueryIntText()
+	unsigned UnsignedText(unsigned defaultValue = 0) const;
+	/// See QueryIntText()
+	int64_t Int64Text(int64_t defaultValue = 0) const;
+	/// See QueryIntText()
+	bool BoolText(bool defaultValue = false) const;
+	/// See QueryIntText()
+	double DoubleText(double defaultValue = 0) const;
+	/// See QueryIntText()
+	float FloatText(float defaultValue = 0) const;
+
+    // internal:
+    enum ElementClosingType {
+        OPEN,		// <foo>
+        CLOSED,		// <foo/>
+        CLOSING		// </foo>
+    };
+    ElementClosingType ClosingType() const {
+        return _closingType;
+    }
+    virtual XMLNode* ShallowClone( XMLDocument* document ) const;
+    virtual bool ShallowEqual( const XMLNode* compare ) const;
+
+protected:
+    char* ParseDeep( char* p, StrPair* parentEndTag, int* curLineNumPtr );
+
+private:
+    XMLElement( XMLDocument* doc );
+    virtual ~XMLElement();
+    XMLElement( const XMLElement& );	// not supported
+    void operator=( const XMLElement& );	// not supported
+
+    XMLAttribute* FindOrCreateAttribute( const char* name );
+    char* ParseAttributes( char* p, int* curLineNumPtr );
+    static void DeleteAttribute( XMLAttribute* attribute );
+    XMLAttribute* CreateAttribute();
+
+    enum { BUF_SIZE = 200 };
+    ElementClosingType _closingType;
+    // The attribute list is ordered; there is no 'lastAttribute'
+    // because the list needs to be scanned for dupes before adding
+    // a new attribute.
+    XMLAttribute* _rootAttribute;
+};
+
+
+enum Whitespace {
+    PRESERVE_WHITESPACE,
+    COLLAPSE_WHITESPACE
+};
+
+
+/** A Document binds together all the functionality.
+	It can be saved, loaded, and printed to the screen.
+	All Nodes are connected and allocated to a Document.
+	If the Document is deleted, all its Nodes are also deleted.
+*/
+class TINYXML2_LIB XMLDocument : public XMLNode
+{
+    friend class XMLElement;
+    // Gives access to SetError and Push/PopDepth, but over-access for everything else.
+    // Wishing C++ had "internal" scope.
+    friend class XMLNode;
+    friend class XMLText;
+    friend class XMLComment;
+    friend class XMLDeclaration;
+    friend class XMLUnknown;
+public:
+    /// constructor
+    XMLDocument( bool processEntities = true, Whitespace whitespaceMode = PRESERVE_WHITESPACE );
+    ~XMLDocument();
+
+    virtual XMLDocument* ToDocument()				{
+        TIXMLASSERT( this == _document );
+        return this;
+    }
+    virtual const XMLDocument* ToDocument() const	{
+        TIXMLASSERT( this == _document );
+        return this;
+    }
+
+    /**
+    	Parse an XML file from a character string.
+    	Returns XML_SUCCESS (0) on success, or
+    	an errorID.
+
+    	You may optionally pass in the 'nBytes', which is
+    	the number of bytes which will be parsed. If not
+    	specified, TinyXML-2 will assume 'xml' points to a
+    	null terminated string.
+    */
+    XMLError Parse( const char* xml, size_t nBytes=(size_t)(-1) );
+
+    /**
+    	Load an XML file from disk.
+    	Returns XML_SUCCESS (0) on success, or
+    	an errorID.
+    */
+    XMLError LoadFile( const char* filename );
+
+    /**
+    	Load an XML file from disk. You are responsible
+    	for providing and closing the FILE*.
+
+        NOTE: The file should be opened as binary ("rb")
+        not text in order for TinyXML-2 to correctly
+        do newline normalization.
+
+    	Returns XML_SUCCESS (0) on success, or
+    	an errorID.
+    */
+    XMLError LoadFile( FILE* );
+
+    /**
+    	Save the XML file to disk.
+    	Returns XML_SUCCESS (0) on success, or
+    	an errorID.
+    */
+    XMLError SaveFile( const char* filename, bool compact = false );
+
+    /**
+    	Save the XML file to disk. You are responsible
+    	for providing and closing the FILE*.
+
+    	Returns XML_SUCCESS (0) on success, or
+    	an errorID.
+    */
+    XMLError SaveFile( FILE* fp, bool compact = false );
+
+    bool ProcessEntities() const		{
+        return _processEntities;
+    }
+    Whitespace WhitespaceMode() const	{
+        return _whitespaceMode;
+    }
+
+    /**
+    	Returns true if this document has a leading Byte Order Mark of UTF8.
+    */
+    bool HasBOM() const {
+        return _writeBOM;
+    }
+    /** Sets whether to write the BOM when writing the file.
+    */
+    void SetBOM( bool useBOM ) {
+        _writeBOM = useBOM;
+    }
+
+    /** Return the root element of DOM. Equivalent to FirstChildElement().
+        To get the first node, use FirstChild().
+    */
+    XMLElement* RootElement()				{
+        return FirstChildElement();
+    }
+    const XMLElement* RootElement() const	{
+        return FirstChildElement();
+    }
+
+    /** Print the Document. If the Printer is not provided, it will
+        print to stdout. If you provide Printer, this can print to a file:
+    	@verbatim
+    	XMLPrinter printer( fp );
+    	doc.Print( &printer );
+    	@endverbatim
+
+    	Or you can use a printer to print to memory:
+    	@verbatim
+    	XMLPrinter printer;
+    	doc.Print( &printer );
+    	// printer.CStr() has a const char* to the XML
+    	@endverbatim
+    */
+    void Print( XMLPrinter* streamer=0 ) const;
+    virtual bool Accept( XMLVisitor* visitor ) const;
+
+    /**
+    	Create a new Element associated with
+    	this Document. The memory for the Element
+    	is managed by the Document.
+    */
+    XMLElement* NewElement( const char* name );
+    /**
+    	Create a new Comment associated with
+    	this Document. The memory for the Comment
+    	is managed by the Document.
+    */
+    XMLComment* NewComment( const char* comment );
+    /**
+    	Create a new Text associated with
+    	this Document. The memory for the Text
+    	is managed by the Document.
+    */
+    XMLText* NewText( const char* text );
+    /**
+    	Create a new Declaration associated with
+    	this Document. The memory for the object
+    	is managed by the Document.
+
+    	If the 'text' param is null, the standard
+    	declaration is used.:
+    	@verbatim
+    		<?xml version="1.0" encoding="UTF-8"?>
+    	@endverbatim
+    */
+    XMLDeclaration* NewDeclaration( const char* text=0 );
+    /**
+    	Create a new Unknown associated with
+    	this Document. The memory for the object
+    	is managed by the Document.
+    */
+    XMLUnknown* NewUnknown( const char* text );
+
+    /**
+    	Delete a node associated with this document.
+    	It will be unlinked from the DOM.
+    */
+    void DeleteNode( XMLNode* node );
+
+    void ClearError() {
+        SetError(XML_SUCCESS, 0, 0);
+    }
+
+    /// Return true if there was an error parsing the document.
+    bool Error() const {
+        return _errorID != XML_SUCCESS;
+    }
+    /// Return the errorID.
+    XMLError  ErrorID() const {
+        return _errorID;
+    }
+	const char* ErrorName() const;
+    static const char* ErrorIDToName(XMLError errorID);
+
+    /** Returns a "long form" error description. A hopefully helpful
+        diagnostic with location, line number, and/or additional info.
+    */
+	const char* ErrorStr() const;
+
+    /// A (trivial) utility function that prints the ErrorStr() to stdout.
+    void PrintError() const;
+
+    /// Return the line where the error occurred, or zero if unknown.
+    int ErrorLineNum() const
+    {
+        return _errorLineNum;
+    }
+
+    /// Clear the document, resetting it to the initial state.
+    void Clear();
+
+	/**
+		Copies this document to a target document.
+		The target will be completely cleared before the copy.
+		If you want to copy a sub-tree, see XMLNode::DeepClone().
+
+		NOTE: that the 'target' must be non-null.
+	*/
+	void DeepCopy(XMLDocument* target) const;
+
+	// internal
+    char* Identify( char* p, XMLNode** node );
+
+	// internal
+	void MarkInUse(XMLNode*);
+
+    virtual XMLNode* ShallowClone( XMLDocument* /*document*/ ) const	{
+        return 0;
+    }
+    virtual bool ShallowEqual( const XMLNode* /*compare*/ ) const	{
+        return false;
+    }
+
+private:
+    XMLDocument( const XMLDocument& );	// not supported
+    void operator=( const XMLDocument& );	// not supported
+
+    bool			_writeBOM;
+    bool			_processEntities;
+    XMLError		_errorID;
+    Whitespace		_whitespaceMode;
+    mutable StrPair	_errorStr;
+    int             _errorLineNum;
+    char*			_charBuffer;
+    int				_parseCurLineNum;
+	int				_parsingDepth;
+	// Memory tracking does add some overhead.
+	// However, the code assumes that you don't
+	// have a bunch of unlinked nodes around.
+	// Therefore it takes less memory to track
+	// in the document vs. a linked list in the XMLNode,
+	// and the performance is the same.
+	DynArray<XMLNode*, 10> _unlinked;
+
+    MemPoolT< sizeof(XMLElement) >	 _elementPool;
+    MemPoolT< sizeof(XMLAttribute) > _attributePool;
+    MemPoolT< sizeof(XMLText) >		 _textPool;
+    MemPoolT< sizeof(XMLComment) >	 _commentPool;
+
+	static const char* _errorNames[XML_ERROR_COUNT];
+
+    void Parse();
+
+    void SetError( XMLError error, int lineNum, const char* format, ... );
+
+	// Something of an obvious security hole, once it was discovered.
+	// Either an ill-formed XML or an excessively deep one can overflow
+	// the stack. Track stack depth, and error out if needed.
+	class DepthTracker {
+	public:
+		explicit DepthTracker(XMLDocument * document) {
+			this->_document = document;
+			document->PushDepth();
+		}
+		~DepthTracker() {
+			_document->PopDepth();
+		}
+	private:
+		XMLDocument * _document;
+	};
+	void PushDepth();
+	void PopDepth();
+
+    template<class NodeType, int PoolElementSize>
+    NodeType* CreateUnlinkedNode( MemPoolT<PoolElementSize>& pool );
+};
+
+template<class NodeType, int PoolElementSize>
+inline NodeType* XMLDocument::CreateUnlinkedNode( MemPoolT<PoolElementSize>& pool )
+{
+    TIXMLASSERT( sizeof( NodeType ) == PoolElementSize );
+    TIXMLASSERT( sizeof( NodeType ) == pool.ItemSize() );
+    NodeType* returnNode = new (pool.Alloc()) NodeType( this );
+    TIXMLASSERT( returnNode );
+    returnNode->_memPool = &pool;
+
+	_unlinked.Push(returnNode);
+    return returnNode;
+}
+
+/**
+	A XMLHandle is a class that wraps a node pointer with null checks; this is
+	an incredibly useful thing. Note that XMLHandle is not part of the TinyXML-2
+	DOM structure. It is a separate utility class.
+
+	Take an example:
+	@verbatim
+	<Document>
+		<Element attributeA = "valueA">
+			<Child attributeB = "value1" />
+			<Child attributeB = "value2" />
+		</Element>
+	</Document>
+	@endverbatim
+
+	Assuming you want the value of "attributeB" in the 2nd "Child" element, it's very
+	easy to write a *lot* of code that looks like:
+
+	@verbatim
+	XMLElement* root = document.FirstChildElement( "Document" );
+	if ( root )
+	{
+		XMLElement* element = root->FirstChildElement( "Element" );
+		if ( element )
+		{
+			XMLElement* child = element->FirstChildElement( "Child" );
+			if ( child )
+			{
+				XMLElement* child2 = child->NextSiblingElement( "Child" );
+				if ( child2 )
+				{
+					// Finally do something useful.
+	@endverbatim
+
+	And that doesn't even cover "else" cases. XMLHandle addresses the verbosity
+	of such code. A XMLHandle checks for null pointers so it is perfectly safe
+	and correct to use:
+
+	@verbatim
+	XMLHandle docHandle( &document );
+	XMLElement* child2 = docHandle.FirstChildElement( "Document" ).FirstChildElement( "Element" ).FirstChildElement().NextSiblingElement();
+	if ( child2 )
+	{
+		// do something useful
+	@endverbatim
+
+	Which is MUCH more concise and useful.
+
+	It is also safe to copy handles - internally they are nothing more than node pointers.
+	@verbatim
+	XMLHandle handleCopy = handle;
+	@endverbatim
+
+	See also XMLConstHandle, which is the same as XMLHandle, but operates on const objects.
+*/
+class TINYXML2_LIB XMLHandle
+{
+public:
+    /// Create a handle from any node (at any depth of the tree.) This can be a null pointer.
+    explicit XMLHandle( XMLNode* node ) : _node( node ) {
+    }
+    /// Create a handle from a node.
+    explicit XMLHandle( XMLNode& node ) : _node( &node ) {
+    }
+    /// Copy constructor
+    XMLHandle( const XMLHandle& ref ) : _node( ref._node ) {
+    }
+    /// Assignment
+    XMLHandle& operator=( const XMLHandle& ref )							{
+        _node = ref._node;
+        return *this;
+    }
+
+    /// Get the first child of this handle.
+    XMLHandle FirstChild() 													{
+        return XMLHandle( _node ? _node->FirstChild() : 0 );
+    }
+    /// Get the first child element of this handle.
+    XMLHandle FirstChildElement( const char* name = 0 )						{
+        return XMLHandle( _node ? _node->FirstChildElement( name ) : 0 );
+    }
+    /// Get the last child of this handle.
+    XMLHandle LastChild()													{
+        return XMLHandle( _node ? _node->LastChild() : 0 );
+    }
+    /// Get the last child element of this handle.
+    XMLHandle LastChildElement( const char* name = 0 )						{
+        return XMLHandle( _node ? _node->LastChildElement( name ) : 0 );
+    }
+    /// Get the previous sibling of this handle.
+    XMLHandle PreviousSibling()												{
+        return XMLHandle( _node ? _node->PreviousSibling() : 0 );
+    }
+    /// Get the previous sibling element of this handle.
+    XMLHandle PreviousSiblingElement( const char* name = 0 )				{
+        return XMLHandle( _node ? _node->PreviousSiblingElement( name ) : 0 );
+    }
+    /// Get the next sibling of this handle.
+    XMLHandle NextSibling()													{
+        return XMLHandle( _node ? _node->NextSibling() : 0 );
+    }
+    /// Get the next sibling element of this handle.
+    XMLHandle NextSiblingElement( const char* name = 0 )					{
+        return XMLHandle( _node ? _node->NextSiblingElement( name ) : 0 );
+    }
+
+    /// Safe cast to XMLNode. This can return null.
+    XMLNode* ToNode()							{
+        return _node;
+    }
+    /// Safe cast to XMLElement. This can return null.
+    XMLElement* ToElement() 					{
+        return ( _node ? _node->ToElement() : 0 );
+    }
+    /// Safe cast to XMLText. This can return null.
+    XMLText* ToText() 							{
+        return ( _node ? _node->ToText() : 0 );
+    }
+    /// Safe cast to XMLUnknown. This can return null.
+    XMLUnknown* ToUnknown() 					{
+        return ( _node ? _node->ToUnknown() : 0 );
+    }
+    /// Safe cast to XMLDeclaration. This can return null.
+    XMLDeclaration* ToDeclaration() 			{
+        return ( _node ? _node->ToDeclaration() : 0 );
+    }
+
+private:
+    XMLNode* _node;
+};
+
+
+/**
+	A variant of the XMLHandle class for working with const XMLNodes and Documents. It is the
+	same in all regards, except for the 'const' qualifiers. See XMLHandle for API.
+*/
+class TINYXML2_LIB XMLConstHandle
+{
+public:
+    explicit XMLConstHandle( const XMLNode* node ) : _node( node ) {
+    }
+    explicit XMLConstHandle( const XMLNode& node ) : _node( &node ) {
+    }
+    XMLConstHandle( const XMLConstHandle& ref ) : _node( ref._node ) {
+    }
+
+    XMLConstHandle& operator=( const XMLConstHandle& ref )							{
+        _node = ref._node;
+        return *this;
+    }
+
+    const XMLConstHandle FirstChild() const											{
+        return XMLConstHandle( _node ? _node->FirstChild() : 0 );
+    }
+    const XMLConstHandle FirstChildElement( const char* name = 0 ) const				{
+        return XMLConstHandle( _node ? _node->FirstChildElement( name ) : 0 );
+    }
+    const XMLConstHandle LastChild()	const										{
+        return XMLConstHandle( _node ? _node->LastChild() : 0 );
+    }
+    const XMLConstHandle LastChildElement( const char* name = 0 ) const				{
+        return XMLConstHandle( _node ? _node->LastChildElement( name ) : 0 );
+    }
+    const XMLConstHandle PreviousSibling() const									{
+        return XMLConstHandle( _node ? _node->PreviousSibling() : 0 );
+    }
+    const XMLConstHandle PreviousSiblingElement( const char* name = 0 ) const		{
+        return XMLConstHandle( _node ? _node->PreviousSiblingElement( name ) : 0 );
+    }
+    const XMLConstHandle NextSibling() const										{
+        return XMLConstHandle( _node ? _node->NextSibling() : 0 );
+    }
+    const XMLConstHandle NextSiblingElement( const char* name = 0 ) const			{
+        return XMLConstHandle( _node ? _node->NextSiblingElement( name ) : 0 );
+    }
+
+
+    const XMLNode* ToNode() const				{
+        return _node;
+    }
+    const XMLElement* ToElement() const			{
+        return ( _node ? _node->ToElement() : 0 );
+    }
+    const XMLText* ToText() const				{
+        return ( _node ? _node->ToText() : 0 );
+    }
+    const XMLUnknown* ToUnknown() const			{
+        return ( _node ? _node->ToUnknown() : 0 );
+    }
+    const XMLDeclaration* ToDeclaration() const	{
+        return ( _node ? _node->ToDeclaration() : 0 );
+    }
+
+private:
+    const XMLNode* _node;
+};
+
+
+/**
+	Printing functionality. The XMLPrinter gives you more
+	options than the XMLDocument::Print() method.
+
+	It can:
+	-# Print to memory.
+	-# Print to a file you provide.
+	-# Print XML without a XMLDocument.
+
+	Print to Memory
+
+	@verbatim
+	XMLPrinter printer;
+	doc.Print( &printer );
+	SomeFunction( printer.CStr() );
+	@endverbatim
+
+	Print to a File
+
+	You provide the file pointer.
+	@verbatim
+	XMLPrinter printer( fp );
+	doc.Print( &printer );
+	@endverbatim
+
+	Print without a XMLDocument
+
+	When loading, an XML parser is very useful. However, sometimes
+	when saving, it just gets in the way. The code is often set up
+	for streaming, and constructing the DOM is just overhead.
+
+	The Printer supports the streaming case. The following code
+	prints out a trivially simple XML file without ever creating
+	an XML document.
+
+	@verbatim
+	XMLPrinter printer( fp );
+	printer.OpenElement( "foo" );
+	printer.PushAttribute( "foo", "bar" );
+	printer.CloseElement();
+	@endverbatim
+*/
+class TINYXML2_LIB XMLPrinter : public XMLVisitor
+{
+public:
+    /** Construct the printer. If the FILE* is specified,
+    	this will print to the FILE. Else it will print
+    	to memory, and the result is available in CStr().
+    	If 'compact' is set to true, then output is created
+    	with only required whitespace and newlines.
+    */
+    XMLPrinter( FILE* file=0, bool compact = false, int depth = 0 );
+    virtual ~XMLPrinter()	{}
+
+    /** If streaming, write the BOM and declaration. */
+    void PushHeader( bool writeBOM, bool writeDeclaration );
+    /** If streaming, start writing an element.
+        The element must be closed with CloseElement()
+    */
+    void OpenElement( const char* name, bool compactMode=false );
+    /// If streaming, add an attribute to an open element.
+    void PushAttribute( const char* name, const char* value );
+    void PushAttribute( const char* name, int value );
+    void PushAttribute( const char* name, unsigned value );
+	void PushAttribute(const char* name, int64_t value);
+	void PushAttribute( const char* name, bool value );
+    void PushAttribute( const char* name, double value );
+    /// If streaming, close the Element.
+    virtual void CloseElement( bool compactMode=false );
+
+    /// Add a text node.
+    void PushText( const char* text, bool cdata=false );
+    /// Add a text node from an integer.
+    void PushText( int value );
+    /// Add a text node from an unsigned.
+    void PushText( unsigned value );
+	/// Add a text node from an unsigned.
+	void PushText(int64_t value);
+	/// Add a text node from a bool.
+    void PushText( bool value );
+    /// Add a text node from a float.
+    void PushText( float value );
+    /// Add a text node from a double.
+    void PushText( double value );
+
+    /// Add a comment
+    void PushComment( const char* comment );
+
+    void PushDeclaration( const char* value );
+    void PushUnknown( const char* value );
+
+    virtual bool VisitEnter( const XMLDocument& /*doc*/ );
+    virtual bool VisitExit( const XMLDocument& /*doc*/ )			{
+        return true;
+    }
+
+    virtual bool VisitEnter( const XMLElement& element, const XMLAttribute* attribute );
+    virtual bool VisitExit( const XMLElement& element );
+
+    virtual bool Visit( const XMLText& text );
+    virtual bool Visit( const XMLComment& comment );
+    virtual bool Visit( const XMLDeclaration& declaration );
+    virtual bool Visit( const XMLUnknown& unknown );
+
+    /**
+    	If in print to memory mode, return a pointer to
+    	the XML file in memory.
+    */
+    const char* CStr() const {
+        return _buffer.Mem();
+    }
+    /**
+    	If in print to memory mode, return the size
+    	of the XML file in memory. (Note the size returned
+    	includes the terminating null.)
+    */
+    int CStrSize() const {
+        return _buffer.Size();
+    }
+    /**
+    	If in print to memory mode, reset the buffer to the
+    	beginning.
+    */
+    void ClearBuffer() {
+        _buffer.Clear();
+        _buffer.Push(0);
+		_firstElement = true;
+    }
+
+protected:
+	virtual bool CompactMode( const XMLElement& )	{ return _compactMode; }
+
+	/** Prints out the space before an element. You may override to change
+	    the space and tabs used. A PrintSpace() override should call Print().
+	*/
+    virtual void PrintSpace( int depth );
+    void Print( const char* format, ... );
+    void Write( const char* data, size_t size );
+    inline void Write( const char* data )           { Write( data, strlen( data ) ); }
+    void Putc( char ch );
+
+    void SealElementIfJustOpened();
+    bool _elementJustOpened;
+    DynArray< const char*, 10 > _stack;
+
+private:
+    void PrintString( const char*, bool restrictedEntitySet );	// prints out, after detecting entities.
+
+    bool _firstElement;
+    FILE* _fp;
+    int _depth;
+    int _textDepth;
+    bool _processEntities;
+	bool _compactMode;
+
+    enum {
+        ENTITY_RANGE = 64,
+        BUF_SIZE = 200
+    };
+    bool _entityFlag[ENTITY_RANGE];
+    bool _restrictedEntityFlag[ENTITY_RANGE];
+
+    DynArray< char, 20 > _buffer;
+
+    // Prohibit cloning, intentionally not implemented
+    XMLPrinter( const XMLPrinter& );
+    XMLPrinter& operator=( const XMLPrinter& );
+};
+
+
+}	// tinyxml2
+
+#if defined(_MSC_VER)
+#   pragma warning(pop)
+#endif
+
+#endif // TINYXML2_INCLUDED
diff -Nur FFmpeg/DASH_packing_sample/compile.sh FFmpeg_patched/DASH_packing_sample/compile.sh
--- FFmpeg/DASH_packing_sample/compile.sh	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/compile.sh	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,38 @@
+#!/bin/sh
+
+rm -rf ffmpeg_lib
+rm -rf ParsePackingParam/build
+rm -f *.o
+
+cd ../
+mkdir build_test
+cd build_test
+export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH
+../configure --prefix=/usr --libdir=/usr/lib --enable-static --disable-shared --enable-pic --disable-debug --enable-gpl --enable-nonfree --disable-optimizations --disable-vaapi --enable-libDistributedEncoder --enable-libVROmafPacking
+make -j$(nproc)
+cd ..
+
+cd DASH_packing_sample
+mkdir ffmpeg_lib
+cd ffmpeg_lib
+rm -f *.*
+cp ../../build_test/libavcodec/libavcodec.a ./
+cp ../../build_test/libavdevice/libavdevice.a ./
+cp ../../build_test/libavfilter/libavfilter.a ./
+cp ../../build_test/libavformat/libavformat.a ./
+cp ../../build_test/libavutil/libavutil.a ./
+cp ../../build_test/libpostproc/libpostproc.a ./
+cp ../../build_test/libswresample/libswresample.a ./
+cp ../../build_test/libswscale/libswscale.a ./
+cd ..
+
+cd ParsePackingParam
+mkdir build
+cd build
+cmake ..
+make
+sudo make install
+cd ../..
+
+gcc -c -z noexecstack -z relro -z now -fstack-protector-strong -fPIE -pie -fPIC -O2 -D_FORTIFY_SOURCE=2 -Wformat -Wformat-security -Wl,-S -Wall -Werror DASH_packing_sample.c
+gcc -I/usr/include/ -L/usr/local/lib DASH_packing_sample.o -o DASH_packing_sample -L/usr/local/lib -z now -fPIE -pie -fPIC -Wl,--gc-sections -Wl,--strip-all -lpthread -lm -llzma -lz /usr/lib64/libbz2.so.1 /usr/local/lib/libParsePackingParam.so /usr/local/lib/libDistributedEncoder.so /usr/local/lib/libthrift-0.12.0.so ./ffmpeg_lib/libavformat.a ./ffmpeg_lib/libavcodec.a ./ffmpeg_lib/libavutil.a ./ffmpeg_lib/libswscale.a ./ffmpeg_lib/libswresample.a /usr/local/lib/lib360SCVP.so -lglog /usr/local/lib/libVROmafPacking.so
diff -Nur FFmpeg/DASH_packing_sample/packing_config.xml FFmpeg_patched/DASH_packing_sample/packing_config.xml
--- FFmpeg/DASH_packing_sample/packing_config.xml	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/packing_config.xml	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,61 @@
+<?txt version="1.0" encoding="UTF-8"?>
+<PackingCfg>
+    <OptionsList>
+        <option packing_proj_type="ERP" />
+        <option cubemap_face_file="0" />
+        <option viewport_w="1024" />
+        <option viewport_h="1024" />
+        <option viewport_yaw="90" />
+        <option viewport_pitch="0" />
+        <option viewport_fov_hor="80" />
+        <option viewport_fov_ver="80" />
+        <option window_size="5" />
+        <option extra_window_size="15" />
+        <option split_tile="1" />
+        <option seg_duration="5" />
+        <option is_live="1" />
+        <option base_url="http://xx.xx.xx.xx:8080/packing_sample_test/" />
+        <option out_name="Test" />
+        <option need_buffered_frames="15" />
+        <option packing_plugin_path="/usr/local/lib" />
+        <option packing_plugin_name="HighResPlusFullLowResPacking" />
+        <option video_plugin_path="/usr/local/lib" />
+        <option video_plugin_name="HevcVideoStreamProcess" />
+        <option audio_plugin_path="0" />
+        <option audio_plugin_name="0" />
+        <option has_extractor="1" />
+        <option extractors_per_thread="4" />
+        <option fixed_extractors_res="0" />
+        <option cmaf_enabled="1" />
+        <option chunk_dur="500" />
+        <option seg_writer_path="/usr/local/lib" />
+        <option seg_writer_name="CMAFSegmentWriter" />
+        <option mpd_writer_path="/usr/local/lib" />
+        <option mpd_writer_name="MPDWriter" />
+        <option target_latency="3500" />
+        <option min_latency="2000" />
+        <option max_latency="10000" />
+        <option need_external_log="1" />
+        <option min_log_level="0" />
+        <option packing_frames_cnt="3000000000" />
+        <option input_videos_num="2" />
+    </OptionsList>
+    <Video1>
+        <info file_name="high_res.h265" />
+        <info width="7680" />
+        <info height="3840" />
+        <info bit_rate="60000" />
+        <info frame_rate="30" />
+        <info gop_size="15" />
+        <info frame_size_file="high_res_frame_size.txt" />
+    </Video1>
+    <Video2>
+        <info file_name="low_res.h265" />
+        <info width="1280" />
+        <info height="640" />
+        <info bit_rate="1000" />
+        <info frame_rate="30" />
+        <info gop_size="15" />
+        <info frame_size_file="low_res_frame_size.txt" />
+    </Video2>
+</PackingCfg>
diff -Nur FFmpeg/DASH_packing_sample/readme.txt FFmpeg_patched/DASH_packing_sample/readme.txt
--- FFmpeg/DASH_packing_sample/readme.txt	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/DASH_packing_sample/readme.txt	2022-06-29 07:16:09.587918780 +0000
@@ -0,0 +1,10 @@
+How to compile:
+./compile.sh
+
+How to run:
+./DASH_packing_sample -i packing_config.xml
+One sample "packing_config.xml" is included.
+The frame_size_file in packing_config.xml includes each frame length for corresponding video bitstream. And the format of this file should be as follows:
+12345,
+23698,
+...
diff -Nur FFmpeg/VERSION FFmpeg_patched/VERSION
--- FFmpeg/VERSION	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/VERSION	2022-06-29 07:16:09.367918783 +0000
@@ -0,0 +1 @@
+4.3.1
diff -Nur FFmpeg/build_ffmpeg_with_cubification.sh FFmpeg_patched/build_ffmpeg_with_cubification.sh
--- FFmpeg/build_ffmpeg_with_cubification.sh	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/build_ffmpeg_with_cubification.sh	2022-06-29 07:16:09.727918778 +0000
@@ -0,0 +1,19 @@
+#!/bin/bash
+
+
+../configure \
+    --prefix=/usr/local \
+    --libdir=/usr/local/lib \
+    --enable-static \
+    --disable-shared \
+    --enable-gpl \
+    --enable-nonfree \
+    --disable-optimizations \
+    --enable-libmfx \
+    --enable-libDistributedEncoder \
+    --enable-libvr360filter_mdf \
+    #--extra-cflags='-I../libavfilter/vr360filter/MDF_SG1_PV1.2/SG1_PV1.2/ ' \
+    #--extra-ldflags='-L/opt/intel/common/mdf/lib64' \
+    #--extra-libs="-lstdc++ -ligfxcmrt " \
+    #--extra-cxxflags="-fpermissive" \
+
diff -Nur FFmpeg/configure FFmpeg_patched/configure
--- FFmpeg/configure	2022-06-29 07:15:48.295919033 +0000
+++ FFmpeg_patched/configure	2022-06-29 07:16:09.767918778 +0000
@@ -252,6 +252,7 @@
   --enable-libopencv       enable video filtering via libopencv [no]
   --enable-libopenh264     enable H.264 encoding via OpenH264 [no]
   --enable-libopenjpeg     enable JPEG 2000 de/encoding via OpenJPEG [no]
+  --enable-libopenhevc     enable HEVC decoding via OpenHEVC [no]
   --enable-libopenmpt      enable decoding tracked files via libopenmpt [no]
   --enable-libopus         enable Opus de/encoding via libopus [no]
   --enable-libpulse        enable Pulseaudio input via libpulse [no]
@@ -293,6 +294,17 @@
   --enable-libxcb-shape    enable X11 grabbing shape rendering [autodetect]
   --enable-libxvid         enable Xvid encoding via xvidcore,
                            native MPEG-4/Xvid encoder exists [no]
+  --enable-libsvthevc             enable HEVC encodig via SVT [no]
+  --enable-libDistributedEncoder  enable Distributed Encoder [no]
+  --enable-libvr360filter_mdf     enable vr360filter_mdf [no]
+  --enable-hevctile               enable HEVC tile encodig via SVT or x265 [no]
+  --enable-libstitch              enable HEVC tile stitch library [no]
+  --enable-libgpac                enable DASH mux with libgpac [no]
+  --enable-libVROmafPacking       enable OMAF Compliance packing muxer [no]
+  --enable-libVRDashStreaming     enable VR DASH streaming and demuxer library [no]
+  --enable-libOmafDashAccess      enable OMAF Compliance DASH streaming and demuxer library [no]
+  --enable-libtransform360        enable Transform360 to transform projection from ERP to cubemap [no]
+  --enable-libxcam                enable image processing via xcam [no]
   --enable-libxml2         enable XML parsing using the C library libxml2, needed
                            for dash demuxing support [no]
   --enable-libzimg         enable z.lib, needed for zscale filter [no]
@@ -1721,6 +1733,7 @@
     libdavs2
     librubberband
     libvidstab
+    libsvthevc
     libx264
     libx265
     libxavs
@@ -1783,6 +1796,14 @@
     libjack
     libklvanc
     libkvazaar
+    libgpac
+    libstitch
+    libDistributedEncoder
+    libvr360filter_mdf
+    libtransform360
+    libVRDashStreaming
+    libOmafDashAccess
+    libVROmafPacking
     libmodplug
     libmp3lame
     libmysofa
@@ -1791,6 +1812,7 @@
     libopenjpeg
     libopenmpt
     libopus
+    libopenhevc
     libpulse
     librabbitmq
     librav1e
@@ -1812,6 +1834,7 @@
     libvpx
     libwavpack
     libwebp
+    libxcam
     libxml2
     libzimg
     libzmq
@@ -3194,8 +3217,13 @@
 chromaprint_muxer_deps="chromaprint"
 h264_videotoolbox_encoder_deps="pthreads"
 h264_videotoolbox_encoder_select="videotoolbox_encoder"
+hevc_svt_encoder_deps="libsvthevc"
+distributed_encoder_deps="libDistributedEncoder"
+hevc_tile_encoder_deps="libsvthevc libstitch"
 hevc_videotoolbox_encoder_deps="pthreads"
 hevc_videotoolbox_encoder_select="videotoolbox_encoder"
+libopenhevc_decoder_deps="libopenhevc"
+libsvt_hevc_encoder_deps="libsvthevc"
 libaom_av1_decoder_deps="libaom"
 libaom_av1_encoder_deps="libaom"
 libaom_av1_encoder_select="extract_extradata_bsf"
@@ -3343,9 +3371,14 @@
 spx_muxer_select="ogg_muxer"
 swf_demuxer_suggest="zlib"
 tak_demuxer_select="tak_parser"
+tile_dash_muxer_select="libgpac"
+tile_dash_demuxer_select="libOmafDashAccess"
+omaf_packing_muxer_select="libVROmafPacking"
 truehd_demuxer_select="mlp_parser"
 tg2_muxer_select="mov_muxer"
 tgp_muxer_select="mov_muxer"
+tile_dash_demuxer_select="libOmafDashAccess"
+omaf_packing_muxer_select="libVROmafPacking"
 vobsub_demuxer_select="mpegps_demuxer"
 w64_demuxer_select="wav_demuxer"
 w64_muxer_select="wav_muxer"
@@ -3522,6 +3555,7 @@
 elbg_filter_deps="avcodec"
 eq_filter_deps="gpl"
 erosion_opencl_filter_deps="opencl"
+erp2cubmap_mdf_filter_deps="libvr360filter_mdf"
 fftfilt_filter_deps="avcodec"
 fftfilt_filter_select="rdft"
 fftdnoiz_filter_deps="avcodec"
@@ -3559,6 +3593,7 @@
 overlay_qsv_filter_deps="libmfx"
 overlay_qsv_filter_select="qsvvpp"
 overlay_vulkan_filter_deps="vulkan libglslang"
+xcam_filter_deps="libxcam"
 owdenoise_filter_deps="gpl"
 pad_opencl_filter_deps="opencl"
 pan_filter_deps="swresample"
@@ -3613,6 +3648,8 @@
 tinterlace_filter_deps="gpl"
 tinterlace_merge_test_deps="tinterlace_filter"
 tinterlace_pad_test_deps="tinterlace_filter"
+transform360_filter_deps="libtransform360"
+transform360_filter_select="libtransform360"
 tonemap_filter_deps="const_nan"
 tonemap_vaapi_filter_deps="vaapi VAProcFilterParameterBufferHDRToneMapping"
 tonemap_opencl_filter_deps="opencl const_nan"
@@ -6314,6 +6351,13 @@
 enabled libgsm            && { for gsm_hdr in "gsm.h" "gsm/gsm.h"; do
                                    check_lib libgsm "${gsm_hdr}" gsm_create -lgsm && break;
                                done || die "ERROR: libgsm not found"; }
+enabled libgpac           && require_pkg_config libgpac gpac gpac/dash.h gf_dash_new
+enabled libVROmafPacking  && require_pkg_config libVROmafPacking VROmafPacking VROmafPackingAPI.h VROmafPackingInit
+enabled libVRDashStreaming && require_pkg_config libVRDashStreaming VRDashStreaming VRDashStreamingAPI.h DashStreaming_Init
+enabled libOmafDashAccess && require_pkg_config libOmafDashAccess OmafDashAccess OmafDashAccessApi.h OmafAccess_Init
+enabled libxcam           && { check_pkg_config libxcam "libxcam >= 1.4.0" "capi/xcam_handle.h" xcam_create_handle ||
+                               die "ERROR: libxcam must be installed and version must be >= 1.4.0"; }
+
 enabled libilbc           && require libilbc ilbc.h WebRtcIlbcfix_InitDecode -lilbc $pthreads_extralibs
 enabled libklvanc         && require libklvanc libklvanc/vanc.h klvanc_context_create -lklvanc
 enabled libkvazaar        && require_pkg_config libkvazaar "kvazaar >= 0.8.1" kvazaar.h kvz_api_get
@@ -6344,6 +6388,7 @@
                                  require libopencv opencv2/core/core_c.h cvCreateImageHeader -lopencv_core -lopencv_imgproc; } ||
                                require_pkg_config libopencv opencv opencv/cxcore.h cvCreateImageHeader; }
 enabled libopenh264       && require_pkg_config libopenh264 openh264 wels/codec_api.h WelsGetCodecVersion
+enabled libopenhevc       && require libopenhevc libopenhevc/openhevc.h  oh_decode -lopenhevc -lm
 enabled libopenjpeg       && { check_pkg_config libopenjpeg "libopenjp2 >= 2.1.0" openjpeg.h opj_version ||
                                { require_pkg_config libopenjpeg "libopenjp2 >= 2.1.0" openjpeg.h opj_version -DOPJ_STATIC && add_cppflags -DOPJ_STATIC; } }
 enabled libopenmpt        && require_pkg_config libopenmpt "libopenmpt >= 0.2.6557" libopenmpt/libopenmpt.h openmpt_module_create -lstdc++ && append libopenmpt_extralibs "-lstdc++"
@@ -6369,6 +6414,11 @@
 enabled libssh            && require_pkg_config libssh libssh libssh/sftp.h sftp_init
 enabled libspeex          && require_pkg_config libspeex speex speex/speex.h speex_decoder_init
 enabled libsrt            && require_pkg_config libsrt "srt >= 1.3.0" srt/srt.h srt_socket
+enabled libsvthevc        && require_pkg_config libsvthevc SvtHevcEnc EbApi.h EbInitHandle
+enabled libDistributedEncoder && require_pkg_config libDistributedEncoder DistributedEncoder DistributedEncoderAPI.h DistributedEncoder_Init
+enabled libvr360filter_mdf && require_pkg_config libvr360filter_mdf vr360filter_mdf wrapper.h create
+enabled libtransform360   && require_pkg_config libtranform360 Transform360 VideoFrameTransformHandler.h VideoFrameTransform_new
+enabled libstitch         && require_pkg_config libstitch stitch genTiledstreamAPI.h genTiledStream_Init
 enabled libtensorflow     && require libtensorflow tensorflow/c/c_api.h TF_Version -ltensorflow
 enabled libtesseract      && require_pkg_config libtesseract tesseract tesseract/capi.h TessBaseAPICreate
 enabled libtheora         && require libtheora theora/theoraenc.h th_info_init -ltheoraenc -ltheoradec -logg
diff -Nur FFmpeg/doc/.gitignore FFmpeg_patched/doc/.gitignore
--- FFmpeg/doc/.gitignore	2022-06-29 07:15:48.295919033 +0000
+++ FFmpeg_patched/doc/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,9 +0,0 @@
-/*.1
-/*.3
-/*.html
-/*.pod
-/config.texi
-/avoptions_codec.texi
-/avoptions_format.texi
-/fate.txt
-/print_options
diff -Nur FFmpeg/doc/doxy/.gitignore FFmpeg_patched/doc/doxy/.gitignore
--- FFmpeg/doc/doxy/.gitignore	2022-06-29 07:15:48.295919033 +0000
+++ FFmpeg_patched/doc/doxy/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1 +0,0 @@
-/html/
diff -Nur FFmpeg/doc/examples/.gitignore FFmpeg_patched/doc/examples/.gitignore
--- FFmpeg/doc/examples/.gitignore	2022-06-29 07:15:48.299919033 +0000
+++ FFmpeg_patched/doc/examples/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,24 +0,0 @@
-/avio_list_dir
-/avio_reading
-/decode_audio
-/decode_video
-/demuxing_decoding
-/encode_audio
-/encode_video
-/extract_mvs
-/filter_audio
-/filtering_audio
-/filtering_video
-/http_multiclient
-/hw_decode
-/metadata
-/muxing
-/pc-uninstalled
-/qsvdec
-/remuxing
-/resampling_audio
-/scaling_video
-/transcode_aac
-/transcoding
-/vaapi_encode
-/vaapi_transcode
diff -Nur FFmpeg/doc/filters.texi FFmpeg_patched/doc/filters.texi
--- FFmpeg/doc/filters.texi	2022-06-29 07:15:48.307919033 +0000
+++ FFmpeg_patched/doc/filters.texi	2022-06-29 07:16:09.535918781 +0000
@@ -25732,3 +25732,79 @@
 @end table

 @c man end MULTIMEDIA SOURCES
+
+@section xcam
+Image processing supported through libXCam.
+
+To enable compilation of @var{xcam} filter you need to configure FFmpeg with
+@code{--enable-libxcam}.
+
+libXCam supports automotive surround view stitching, 360 video stitching,
+digital video stabilization, noise reduction and so on. For more information
+about libxcam see @url{https://github.com/intel/libxcam}.
+
+@subsection Options
+
+@table @option
+
+@item inputs
+The number of inputs. Default is @code{1}. 3dnr, waveletnr, fisheye, defog
+and dvs handlers support one input, stitch and stitchcl handlers support
+dynamic inputs.
+
+@item w
+Output video width. Default is @code{0}.
+If the value is 0, the corresponding input width is used for the output.
+
+@item h
+Output video height. Default is @code{0}.
+If the value is 0, the corresponding input height is used for the output.
+
+@item fmt
+Pixel format. Default is @code{auto}.
+
+@table @samp
+@item auto
+Negotiate pixel format automatically, selects the input pixel format as the
+processing format.
+@item nv12
+NV12 format. All handlers support NV12 format.
+@item yuv420
+YUV420 format. Currently, only @b{soft} stitching supports YUV420 format.
+@end table
+
+@item name
+Handler name. Default is @code{stitch}.
+
+@table @samp
+@item 3dnr
+3D denoising
+@item waveletnr
+Wavelet denoising
+@item fisheye
+Fisheye calibration
+@item defog
+Fog removal
+@item dvs
+Digital video stabilizer
+@item stitch
+Soft/GLES/Vulkan stitching, supports automotive surround view stitching and
+360 video stitching.
+@item stitchcl
+OpenCL stitching, supports automotive surround view stitching and 360 video
+stitching.
+@end table
+
+@item allocoutbuf
+Whether or not to allocate output buffer. Default is @code{1}.
+
+@item params
+Private parameters for each handler. Currently, only @b{stitch} and
+@b{stitchcl} handlers have private parameters.
+
+@end table
+
+@subsection Examples
+
+For more detailed examples see @url{https://github.com/intel/libxcam/wiki/Tests#1-ffmpeg-xcam}.
+
diff -Nur FFmpeg/enabling_mdf_cubification_SG1.sh FFmpeg_patched/enabling_mdf_cubification_SG1.sh
--- FFmpeg/enabling_mdf_cubification_SG1.sh	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/enabling_mdf_cubification_SG1.sh	2022-06-29 07:16:09.727918778 +0000
@@ -0,0 +1,35 @@
+#!/bin/bash
+
+curr_dir=`pwd`
+
+if [ ! -e "/opt/intel/mediasdk/include/mfx" ] ; then
+    cd /opt/intel/mediasdk/include
+    mkdir mfx
+    cd mfx
+    cp ../*.h ./
+    cd ..
+fi
+
+cd $curr_dir
+cd ../hwaccel/vr360filter_mdf/
+mkdir build
+cd build
+cmake ..
+make -j8
+make install
+cd ../
+
+cd ../../FFmpeg
+mkdir build_with_cubification
+cd build_with_cubification
+cp ../build_ffmpeg_with_cubification.sh ./
+export PKG_CONFIG_PATH=/opt/intel/mediasdk/lib64/pkgconfig:$PKG_CONFIG_PATH
+export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH
+./build_ffmpeg_with_cubification.sh
+make -j8
+
+#mv ../h265_3840x1920.h265 ./
+mv ../h265_7680x3840.h265 ./
+cp ../config_high.xml ./
+cp ../run_cubification.sh ./
+./run_cubification.sh
diff -Nur FFmpeg/ffbuild/.gitignore FFmpeg_patched/ffbuild/.gitignore
--- FFmpeg/ffbuild/.gitignore	2022-06-29 07:15:48.311919033 +0000
+++ FFmpeg_patched/ffbuild/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,5 +0,0 @@
-/.config
-/config.fate
-/config.log
-/config.mak
-/config.sh
diff -Nur FFmpeg/fftools/ffmpeg.c FFmpeg_patched/fftools/ffmpeg.c
--- FFmpeg/fftools/ffmpeg.c	2022-06-29 07:15:48.311919033 +0000
+++ FFmpeg_patched/fftools/ffmpeg.c	2022-06-29 07:16:09.535918781 +0000
@@ -1314,6 +1314,7 @@
             if (ost->logfile && enc->stats_out) {
                 fprintf(ost->logfile, "%s", enc->stats_out);
             }
+            break;
         }
         ost->sync_opts++;
         /*
@@ -1508,6 +1509,7 @@
             }
 
             av_frame_unref(filtered_frame);
+            break;
         }
     }
 
diff -Nur FFmpeg/fftools/ffplay.c FFmpeg_patched/fftools/ffplay.c
--- FFmpeg/fftools/ffplay.c	2022-06-29 07:15:48.315919033 +0000
+++ FFmpeg_patched/fftools/ffplay.c	2022-06-29 07:16:09.535918781 +0000
@@ -3355,15 +3355,22 @@
                 seek_chapter(cur_stream, -1);
                 break;
             case SDLK_LEFT:
-                incr = seek_interval ? -seek_interval : -10.0;
-                goto do_seek;
+                {
+                    incr = seek_interval ? -seek_interval : -10.0;
+                    goto do_seek;
+                }
             case SDLK_RIGHT:
-                incr = seek_interval ? seek_interval : 10.0;
-                goto do_seek;
+                {
+                    incr = seek_interval ? seek_interval : 10.0;
+                    goto do_seek;
+                }
             case SDLK_UP:
-                incr = 60.0;
-                goto do_seek;
+                {
+                    incr = 60.0;
+                    goto do_seek;
+                }
             case SDLK_DOWN:
+                {
                 incr = -60.0;
             do_seek:
                     if (seek_by_bytes) {
@@ -3390,6 +3397,7 @@
                         stream_seek(cur_stream, (int64_t)(pos * AV_TIME_BASE), (int64_t)(incr * AV_TIME_BASE), 0);
                     }
                 break;
+                }
             default:
                 break;
             }
diff -Nur FFmpeg/libavcodec/.gitignore FFmpeg_patched/libavcodec/.gitignore
--- FFmpeg/libavcodec/.gitignore	2022-06-29 07:15:48.315919033 +0000
+++ FFmpeg_patched/libavcodec/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,6 +0,0 @@
-/*_tablegen
-/*_tables.c
-/*_tables.h
-/bsf_list.c
-/codec_list.c
-/parser_list.c
diff -Nur FFmpeg/libavcodec/Makefile FFmpeg_patched/libavcodec/Makefile
--- FFmpeg/libavcodec/Makefile	2022-06-29 07:15:48.315919033 +0000
+++ FFmpeg_patched/libavcodec/Makefile	2022-06-29 07:16:09.415918782 +0000
@@ -96,6 +96,7 @@
 OBJS-$(CONFIG_H264PRED)                += h264pred.o
 OBJS-$(CONFIG_H264QPEL)                += h264qpel.o
 OBJS-$(CONFIG_HEVCPARSE)               += hevc_parse.o h2645_parse.o hevc_ps.o hevc_sei.o hevc_data.o
+OBJS-$(CONFIG_LIBOPENHEVC_DECODER)	   += libopenhevc.o
 OBJS-$(CONFIG_HPELDSP)                 += hpeldsp.o
 OBJS-$(CONFIG_HUFFMAN)                 += huffman.o
 OBJS-$(CONFIG_HUFFYUVDSP)              += huffyuvdsp.o
@@ -387,6 +388,10 @@
 OBJS-$(CONFIG_HEVC_MF_ENCODER)         += mfenc.o mf_utils.o
 OBJS-$(CONFIG_HEVC_NVENC_ENCODER)      += nvenc_hevc.o
 OBJS-$(CONFIG_NVENC_HEVC_ENCODER)      += nvenc_hevc.o
+OBJS-$(CONFIG_LIBSVT_HEVC_ENCODER)     += libsvt_hevc.o
+OBJS-$(CONFIG_DISTRIBUTED_ENCODER)     += distributed_encoder.o
+OBJS-$(CONFIG_HEVC_TILE_ENCODER)       += tile_encoder.o \
+                                          tile_encode_svt_impl.o
 OBJS-$(CONFIG_HEVC_QSV_DECODER)        += qsvdec_h2645.o
 OBJS-$(CONFIG_HEVC_QSV_ENCODER)        += qsvenc_hevc.o hevc_ps_enc.o       \
                                           hevc_data.o
@@ -568,6 +573,8 @@
 OBJS-$(CONFIG_RA_288_DECODER)          += ra288.o celp_filters.o
 OBJS-$(CONFIG_RALF_DECODER)            += ralf.o
 OBJS-$(CONFIG_RASC_DECODER)            += rasc.o
+OBJS-$(CONFIG_HEVC_BYPASSVIDEO_DECODER) += bypass_hevc_decoder.o
+OBJS-$(CONFIG_H264_BYPASSVIDEO_DECODER) += bypass_h264_decoder.o
 OBJS-$(CONFIG_RAWVIDEO_DECODER)        += rawdec.o
 OBJS-$(CONFIG_RAWVIDEO_ENCODER)        += rawenc.o
 OBJS-$(CONFIG_REALTEXT_DECODER)        += realtextdec.o ass.o
diff -Nur FFmpeg/libavcodec/allcodecs.c FFmpeg_patched/libavcodec/allcodecs.c
--- FFmpeg/libavcodec/allcodecs.c	2022-06-29 07:15:48.335919033 +0000
+++ FFmpeg_patched/libavcodec/allcodecs.c	2022-06-29 07:16:09.519918781 +0000
@@ -146,7 +146,10 @@
 extern AVCodec ff_h264_rkmpp_decoder;
 extern AVCodec ff_hap_encoder;
 extern AVCodec ff_hap_decoder;
+extern AVCodec ff_hevc_bypassvideo_decoder;
+extern AVCodec ff_h264_bypassvideo_decoder;
 extern AVCodec ff_hevc_decoder;
+extern AVCodec ff_libopenhevc_decoder;
 extern AVCodec ff_hevc_qsv_decoder;
 extern AVCodec ff_hevc_rkmpp_decoder;
 extern AVCodec ff_hevc_v4l2m2m_decoder;
@@ -781,6 +784,9 @@
 extern AVCodec ff_hevc_mf_encoder;
 extern AVCodec ff_hevc_nvenc_encoder;
 extern AVCodec ff_hevc_qsv_encoder;
+extern AVCodec ff_libsvt_hevc_encoder;
+extern AVCodec ff_distributed_encoder;
+extern AVCodec ff_hevc_tile_encoder;
 extern AVCodec ff_hevc_v4l2m2m_encoder;
 extern AVCodec ff_hevc_vaapi_encoder;
 extern AVCodec ff_hevc_videotoolbox_encoder;
diff -Nur FFmpeg/libavcodec/bypass_decoder.h FFmpeg_patched/libavcodec/bypass_decoder.h
--- FFmpeg/libavcodec/bypass_decoder.h	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavcodec/bypass_decoder.h	2022-06-29 07:16:09.395918782 +0000
@@ -0,0 +1,63 @@
+/*
+ * Raw Video Decoder
+ * Copyright (c) 2001 Fabrice Bellard
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * Raw Video Decoder
+ */
+
+#include "avcodec.h"
+#include "bswapdsp.h"
+#include "get_bits.h"
+#include "raw.h"
+#include "internal.h"
+#include "libavutil/avassert.h"
+#include "libavutil/buffer.h"
+#include "libavutil/common.h"
+#include "libavutil/intreadwrite.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/opt.h"
+
+typedef struct ByPassVideoContext {
+    int frame_size;  /* size of the frame in bytes */
+    int flip;
+    int is_1_2_4_8_bpp; // 1, 2, 4 and 8 bpp in avi/mov, 1 and 8 bpp in nut
+    int is_mono;
+    int is_pal8;
+    int is_nut_mono;
+    int is_nut_pal8;
+    int is_yuv2;
+    int is_lt_16bpp; // 16bpp pixfmt and bits_per_coded_sample < 16
+    int tff;
+    // user options
+    int frameWidth;
+    int frameHeight;
+} ByPassVideoContext;
+
+#define OFFSET(x) offsetof(ByPassVideoContext, x)
+#define VE (AV_OPT_FLAG_DECODING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    {"W", "input bitstream width", OFFSET(frameWidth), AV_OPT_TYPE_INT, {.i64 = 0}, 0, INT_MAX, VE},
+    {"H", "input bitstream height", OFFSET(frameHeight), AV_OPT_TYPE_INT, {.i64 = 0}, 0, INT_MAX, VE},
+    {NULL}
+};
+
+
diff -Nur FFmpeg/libavcodec/bypass_h264_decoder.c FFmpeg_patched/libavcodec/bypass_h264_decoder.c
--- FFmpeg/libavcodec/bypass_h264_decoder.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavcodec/bypass_h264_decoder.c	2022-06-29 07:16:09.415918782 +0000
@@ -0,0 +1,150 @@
+/*
+ * Raw Video Decoder
+ * Copyright (c) 2001 Fabrice Bellard
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * Raw Video Decoder
+ */
+
+#include "bypass_decoder.h"
+
+static const AVClass bypassdec_class = {
+    .class_name = "bypassdec",
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static av_cold int h264_bypass_init_decoder(AVCodecContext *avctx)
+{
+    ByPassVideoContext *context = avctx->priv_data;
+    const AVPixFmtDescriptor *desc;
+
+    if (   avctx->codec_tag == MKTAG('r','a','w',' ')
+        || avctx->codec_tag == MKTAG('N','O','1','6'))
+        avctx->pix_fmt = avpriv_find_pix_fmt(avpriv_pix_fmt_bps_mov,
+                                      avctx->bits_per_coded_sample);
+    else if (avctx->codec_tag == MKTAG('W', 'R', 'A', 'W'))
+        avctx->pix_fmt = avpriv_find_pix_fmt(avpriv_pix_fmt_bps_avi,
+                                      avctx->bits_per_coded_sample);
+    else if (avctx->codec_tag && (avctx->codec_tag & 0xFFFFFF) != MKTAG('B','I','T', 0))
+        avctx->pix_fmt = avpriv_find_pix_fmt(ff_raw_pix_fmt_tags, avctx->codec_tag);
+    else if (avctx->pix_fmt == AV_PIX_FMT_NONE && avctx->bits_per_coded_sample)
+        avctx->pix_fmt = avpriv_find_pix_fmt(avpriv_pix_fmt_bps_avi,
+                                      avctx->bits_per_coded_sample);
+
+    return 0;
+}
+
+static int h264_bypass_decode(AVCodecContext *avctx, void *data, int *got_frame,
+                      AVPacket *avpkt)
+{
+    const AVPixFmtDescriptor *desc;
+    ByPassVideoContext *context       = avctx->priv_data;
+    const uint8_t *buf             = avpkt->data;
+    int buf_size                   = avpkt->size;
+    int linesize_align             = 4;
+    int stride;
+    int res, len;
+    int need_copy;
+
+    AVFrame   *frame   = data;
+
+    avctx->width = context->frameWidth;
+    avctx->height = context->frameHeight;
+
+    if (avctx->width <= 0) {
+        av_log(avctx, AV_LOG_ERROR, "width is not set\n");
+        return AVERROR_INVALIDDATA;
+    }
+    if (avctx->height <= 0) {
+        av_log(avctx, AV_LOG_ERROR, "height is not set\n");
+        return AVERROR_INVALIDDATA;
+    }
+
+    if (context->is_nut_mono)
+        stride = avctx->width / 8 + (avctx->width & 7 ? 1 : 0);
+    else if (context->is_nut_pal8)
+        stride = avctx->width;
+    else
+        stride = avpkt->size / avctx->height;
+
+    av_log(avctx, AV_LOG_DEBUG, "PACKET SIZE: %d, STRIDE: %d\n", avpkt->size, stride);
+
+    avctx->pix_fmt = AV_PIX_FMT_YUV420P;
+
+    need_copy = !avpkt->buf || context->is_1_2_4_8_bpp || context->is_yuv2 || context->is_lt_16bpp;
+
+    frame->pict_type        = AV_PICTURE_TYPE_I;
+    frame->key_frame        = 1;
+
+    res = ff_decode_frame_props(avctx, frame);
+    if (res < 0)
+        return res;
+
+    frame->pkt_pos      = avctx->internal->last_pkt_props->pos;
+    frame->pkt_duration = avctx->internal->last_pkt_props->duration;
+
+    if (context->tff >= 0) {
+        frame->interlaced_frame = 1;
+        frame->top_field_first  = context->tff;
+    }
+
+    if ((res = av_image_check_size(avctx->width, avctx->height, 0, avctx)) < 0)
+        return res;
+
+    if (need_copy)
+        frame->buf[0] = av_buffer_alloc(FFMAX(context->frame_size, buf_size));
+    else
+        frame->buf[0] = av_buffer_ref(avpkt->buf);
+    if (!frame->buf[0])
+        return AVERROR(ENOMEM);
+
+    if (need_copy) {
+        memcpy(frame->buf[0]->data, buf, buf_size);
+        buf = frame->buf[0]->data;
+    }
+
+    frame->data[0] = buf;
+    frame->linesize[0] = buf_size;
+
+    *got_frame = 1;
+    return buf_size;
+}
+
+static av_cold int h264_bypass_close_decoder(AVCodecContext *avctx)
+{
+    ByPassVideoContext *context = avctx->priv_data;
+
+    return 0;
+}
+
+AVCodec ff_h264_bypassvideo_decoder = {
+    .name           = "h264bypassdec",
+    .long_name      = NULL_IF_CONFIG_SMALL("bypass video decoder"),
+    .type           = AVMEDIA_TYPE_VIDEO,
+    .id             = AV_CODEC_ID_H264BYPASSVIDEO,
+    .priv_data_size = sizeof(ByPassVideoContext),
+    .init           = h264_bypass_init_decoder,
+    .close          = h264_bypass_close_decoder,
+    .decode         = h264_bypass_decode,
+    .priv_class     = &bypassdec_class,
+    .capabilities   = AV_CODEC_CAP_PARAM_CHANGE,
+};
diff -Nur FFmpeg/libavcodec/bypass_hevc_decoder.c FFmpeg_patched/libavcodec/bypass_hevc_decoder.c
--- FFmpeg/libavcodec/bypass_hevc_decoder.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavcodec/bypass_hevc_decoder.c	2022-06-29 07:16:09.523918781 +0000
@@ -0,0 +1,150 @@
+/*
+ * Raw Video Decoder
+ * Copyright (c) 2001 Fabrice Bellard
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * Raw Video Decoder
+ */
+
+#include "bypass_decoder.h"
+
+static const AVClass bypassdec_class = {
+    .class_name = "bypassdec",
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static av_cold int hevc_bypass_init_decoder(AVCodecContext *avctx)
+{
+    ByPassVideoContext *context = avctx->priv_data;
+    const AVPixFmtDescriptor *desc;
+
+    if (   avctx->codec_tag == MKTAG('r','a','w',' ')
+        || avctx->codec_tag == MKTAG('N','O','1','6'))
+        avctx->pix_fmt = avpriv_find_pix_fmt(avpriv_pix_fmt_bps_mov,
+                                      avctx->bits_per_coded_sample);
+    else if (avctx->codec_tag == MKTAG('W', 'R', 'A', 'W'))
+        avctx->pix_fmt = avpriv_find_pix_fmt(avpriv_pix_fmt_bps_avi,
+                                      avctx->bits_per_coded_sample);
+    else if (avctx->codec_tag && (avctx->codec_tag & 0xFFFFFF) != MKTAG('B','I','T', 0))
+        avctx->pix_fmt = avpriv_find_pix_fmt(ff_raw_pix_fmt_tags, avctx->codec_tag);
+    else if (avctx->pix_fmt == AV_PIX_FMT_NONE && avctx->bits_per_coded_sample)
+        avctx->pix_fmt = avpriv_find_pix_fmt(avpriv_pix_fmt_bps_avi,
+                                      avctx->bits_per_coded_sample);
+
+    return 0;
+}
+
+static int hevc_bypass_decode(AVCodecContext *avctx, void *data, int *got_frame,
+                      AVPacket *avpkt)
+{
+    const AVPixFmtDescriptor *desc;
+    ByPassVideoContext *context       = avctx->priv_data;
+    const uint8_t *buf             = avpkt->data;
+    int buf_size                   = avpkt->size;
+    int linesize_align             = 4;
+    int stride;
+    int res, len;
+    int need_copy;
+
+    AVFrame   *frame   = data;
+
+    avctx->width = context->frameWidth;
+    avctx->height = context->frameHeight;
+
+    if (avctx->width <= 0) {
+        av_log(avctx, AV_LOG_ERROR, "width is not set\n");
+        return AVERROR_INVALIDDATA;
+    }
+    if (avctx->height <= 0) {
+        av_log(avctx, AV_LOG_ERROR, "height is not set\n");
+        return AVERROR_INVALIDDATA;
+    }
+
+    if (context->is_nut_mono)
+        stride = avctx->width / 8 + (avctx->width & 7 ? 1 : 0);
+    else if (context->is_nut_pal8)
+        stride = avctx->width;
+    else
+        stride = avpkt->size / avctx->height;
+
+    av_log(avctx, AV_LOG_DEBUG, "PACKET SIZE: %d, STRIDE: %d\n", avpkt->size, stride);
+
+    avctx->pix_fmt = AV_PIX_FMT_YUV420P;
+
+    need_copy = !avpkt->buf || context->is_1_2_4_8_bpp || context->is_yuv2 || context->is_lt_16bpp;
+
+    frame->pict_type        = AV_PICTURE_TYPE_I;
+    frame->key_frame        = 1;
+
+    res = ff_decode_frame_props(avctx, frame);
+    if (res < 0)
+        return res;
+
+    frame->pkt_pos      = avctx->internal->last_pkt_props->pos;
+    frame->pkt_duration = avctx->internal->last_pkt_props->duration;
+
+    if (context->tff >= 0) {
+        frame->interlaced_frame = 1;
+        frame->top_field_first  = context->tff;
+    }
+
+    if ((res = av_image_check_size(avctx->width, avctx->height, 0, avctx)) < 0)
+        return res;
+
+    if (need_copy)
+        frame->buf[0] = av_buffer_alloc(FFMAX(context->frame_size, buf_size));
+    else
+        frame->buf[0] = av_buffer_ref(avpkt->buf);
+    if (!frame->buf[0])
+        return AVERROR(ENOMEM);
+
+    if (need_copy) {
+        memcpy(frame->buf[0]->data, buf, buf_size);
+        buf = frame->buf[0]->data;
+    }
+
+    frame->data[0] = buf;
+    frame->linesize[0] = buf_size;
+
+    *got_frame = 1;
+    return buf_size;
+}
+
+static av_cold int hevc_bypass_close_decoder(AVCodecContext *avctx)
+{
+    ByPassVideoContext *context = avctx->priv_data;
+
+    return 0;
+}
+
+AVCodec ff_hevc_bypassvideo_decoder = {
+    .name           = "hevcbypassdec",
+    .long_name      = NULL_IF_CONFIG_SMALL("bypass video decoder"),
+    .type           = AVMEDIA_TYPE_VIDEO,
+    .id             = AV_CODEC_ID_HEVCBYPASSVIDEO,
+    .priv_data_size = sizeof(ByPassVideoContext),
+    .init           = hevc_bypass_init_decoder,
+    .close          = hevc_bypass_close_decoder,
+    .decode         = hevc_bypass_decode,
+    .priv_class     = &bypassdec_class,
+    .capabilities   = AV_CODEC_CAP_PARAM_CHANGE,
+};
diff -Nur FFmpeg/libavcodec/codec_desc.c FFmpeg_patched/libavcodec/codec_desc.c
--- FFmpeg/libavcodec/codec_desc.c	2022-06-29 07:15:48.367919032 +0000
+++ FFmpeg_patched/libavcodec/codec_desc.c	2022-06-29 07:16:09.483918781 +0000
@@ -130,6 +130,20 @@
         .props     = AV_CODEC_PROP_INTRA_ONLY | AV_CODEC_PROP_LOSSLESS,
     },
     {
+        .id        = AV_CODEC_ID_HEVCBYPASSVIDEO,
+        .type      = AVMEDIA_TYPE_VIDEO,
+        .name      = "hevcbypassdec",
+        .long_name = NULL_IF_CONFIG_SMALL("hevc bypass video decoder"),
+        .props     = AV_CODEC_PROP_INTRA_ONLY | AV_CODEC_PROP_LOSSLESS,
+    },
+    {
+        .id        = AV_CODEC_ID_H264BYPASSVIDEO,
+        .type      = AVMEDIA_TYPE_VIDEO,
+        .name      = "h264bypassdec",
+        .long_name = NULL_IF_CONFIG_SMALL("h264 bypass video decoder"),
+        .props     = AV_CODEC_PROP_INTRA_ONLY | AV_CODEC_PROP_LOSSLESS,
+    },
+    {
         .id        = AV_CODEC_ID_MSMPEG4V1,
         .type      = AVMEDIA_TYPE_VIDEO,
         .name      = "msmpeg4v1",
diff -Nur FFmpeg/libavcodec/codec_id.h FFmpeg_patched/libavcodec/codec_id.h
--- FFmpeg/libavcodec/codec_id.h	2022-06-29 07:15:48.367919032 +0000
+++ FFmpeg_patched/libavcodec/codec_id.h	2022-06-29 07:16:09.427918782 +0000
@@ -60,6 +60,8 @@
     AV_CODEC_ID_JPEGLS,
     AV_CODEC_ID_MPEG4,
     AV_CODEC_ID_RAWVIDEO,
+    AV_CODEC_ID_HEVCBYPASSVIDEO,
+    AV_CODEC_ID_H264BYPASSVIDEO,
     AV_CODEC_ID_MSMPEG4V1,
     AV_CODEC_ID_MSMPEG4V2,
     AV_CODEC_ID_MSMPEG4V3,
diff -Nur FFmpeg/libavcodec/distributed_encoder.c FFmpeg_patched/libavcodec/distributed_encoder.c
--- FFmpeg/libavcodec/distributed_encoder.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavcodec/distributed_encoder.c	2022-06-29 07:16:09.447918782 +0000
@@ -0,0 +1,852 @@
+/*
+* Scalable Video Technology for distributed encoder library plugin
+*
+* Copyright (c) 2019 Intel Corporation
+*
+* This file is part of FFmpeg.
+*
+* FFmpeg is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* FFmpeg is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+#include <sys/time.h>
+#include <time.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <unistd.h>
+
+#include "DistributedEncoderAPI.h"
+#include "error_code.h"
+#include "common_data.h"
+
+#include "libavutil/common.h"
+#include "libavutil/frame.h"
+#include "libavutil/opt.h"
+
+#include "internal.h"
+#include "avcodec.h"
+
+static bool glog_initialized = false;
+static int min_loglevel = 2;
+
+//#define ENABLE_DE_FRAME_LOCK
+
+static void de_log_callback(LogLevel log_level, const char* file_name, uint64_t line_num, const char* fmt, ...)
+{
+    va_list vl;
+    va_start(vl, fmt);
+
+    switch (log_level)
+    {
+        case LOG_INFO:
+        {
+            if(min_loglevel == 0)
+            {
+                av_vlog(NULL, AV_LOG_INFO, fmt, vl);
+            }
+            break;
+        }
+        case LOG_WARNING:
+        {
+            if(min_loglevel <= 1)
+            {
+                av_vlog(NULL, AV_LOG_WARNING, fmt, vl);
+            }
+            break;
+        }
+        case LOG_ERROR:
+        {
+            if(min_loglevel <= 2)
+            {
+                av_vlog(NULL, AV_LOG_ERROR, fmt, vl);
+            }
+            break;
+        }
+        case LOG_FATAL:
+        {
+            if(min_loglevel <= 3)
+            {
+                av_vlog(NULL, AV_LOG_FATAL, fmt, vl);
+            }
+            break;
+        }
+        default:
+        {
+            av_log(NULL, AV_LOG_ERROR, "Invalid log level !");
+            break;
+        }
+    }
+    va_end(vl);
+}
+
+#ifdef ENABLE_DE_FRAME_LOCK
+typedef struct DeFrameList
+{
+    AVFrame            *frame;
+    struct DeFrameList *next;
+}DeFrameList;
+#endif
+
+typedef struct DEContext {
+    const AVClass            *class;
+
+    DistributedEncoderParam  encode_params;
+    DEHandle                 handle;
+    const char*              configFile;
+    InputStreamType          input_type;
+    int                      inputCodec;
+    bool                     send_end;
+    bool                     eos_flag;
+
+    // User options.
+    int                      vui_info;
+    int                      hierarchical_level;
+    int                      la_depth;
+    int                      enc_mode;
+    int                      rc_mode;
+    int                      scd;
+    int                      tune;
+    int                      qp;
+    int                      hdr;
+    int                      asm_type;
+    int                      forced_idr;
+    int                      gpucopy;
+    int                      aud;
+    int                      profile;
+    int                      tier;
+    int                      level;
+    int                      gop_pred_structure;
+    int                      base_layer_switch_mode;
+    int                      tile_row;
+    int                      tile_column;
+    uint64_t                 frame_number;
+    bool                     in_parallel;
+    bool                     external_log_flag;
+    int                      min_log_level;
+    const char*              proj_type;
+#ifdef ENABLE_DE_FRAME_LOCK
+    DeFrameList              *DeFrameListHead;
+    DeFrameList              *DeFrameListTail;
+#endif
+} DEContext;
+
+static int set_enc_params(AVCodecContext *avctx, DistributedEncoderParam *DEparams)
+{
+    DEContext *deCxt = avctx->priv_data;
+
+    memset(DEparams, 0, sizeof(DistributedEncoderParam));
+    EncoderParam params;
+    memset(&params, 0, sizeof(EncoderParam));
+    params.bit_depth = 8;
+    params.format = PixelColor_YUV420;
+    params.vui_info = deCxt->vui_info;
+    params.hierarchical_level = deCxt->hierarchical_level;
+    if(avctx->gop_size > 0) {
+        params.intra_period = avctx->gop_size - 1;
+    }
+    params.la_depth = deCxt->la_depth;
+    params.enc_mode = deCxt->enc_mode;
+    params.rc_mode = deCxt->rc_mode;
+    params.scd = deCxt->scd;
+    params.tune = deCxt->tune;
+    params.qp = deCxt->qp;
+    params.profile = deCxt->profile;
+    params.pred_structure = deCxt->gop_pred_structure;
+    params.base_layer_switch_mode = deCxt->base_layer_switch_mode;
+    params.bit_rate = avctx->bit_rate;
+    params.intra_refresh_type = (deCxt->forced_idr > 0) ? 1 : 0;
+    params.tier = deCxt->tier;
+    params.level = deCxt->level;
+    params.aud = deCxt->aud;
+    params.asm_type = deCxt->asm_type;
+    if(avctx->framerate.num > 0 && avctx->framerate.den > 0) {
+        params.framerate_num = avctx->framerate.num;
+        params.framerate_den = avctx->framerate.den * avctx->ticks_per_frame;
+    }
+    else
+    {
+        params.framerate_num = avctx->time_base.den;
+        params.framerate_den = avctx->time_base.num * avctx->ticks_per_frame;
+    }
+
+    params.deblocking_enable = 0;
+    params.sao_enable = 0;
+    // tile related setting
+    params.tile_columnCnt = deCxt->tile_column;
+    params.tile_rowCnt = deCxt->tile_row;
+    params.frame_width = avctx->width;
+    params.frame_height = avctx->height;
+    params.target_socket = -1;
+    params.native_mode = false;
+    params.MCTS_enable = (params.tile_columnCnt * params.tile_rowCnt) > 1 ? 1 : 0;
+
+    if(deCxt->in_parallel && params.MCTS_enable)
+        params.in_parallel = true;
+    else
+        params.in_parallel = false;
+
+    params.gpucopy = deCxt->gpucopy;
+
+    memcpy(&(DEparams->encoderParams), &params, sizeof(EncoderParam));
+
+    DEparams->type = ResourceBalanced;
+
+    StreamInfo sInfo;
+    memset(&sInfo, 0, sizeof(StreamInfo));
+    sInfo.frameWidth = avctx->width;
+    sInfo.frameHeight = avctx->height;
+    sInfo.tileUniformSpacing = true;
+    sInfo.tileColumn = deCxt->tile_column;
+    sInfo.tileRow = deCxt->tile_row;
+    if(sInfo.frameWidth % sInfo.tileColumn)
+    {
+        av_log(avctx, AV_LOG_ERROR,
+                "Frame Width can't be divided by tile column number \n");
+        return -1;
+    }
+    if(((sInfo.frameWidth/sInfo.tileColumn)%64) && (sInfo.tileColumn != 1))
+    {
+        av_log(avctx, AV_LOG_ERROR,
+                "Tile width can't be divided by 64 \n");
+        return -1;
+    }
+    if(sInfo.frameHeight % sInfo.tileRow)
+    {
+        av_log(avctx, AV_LOG_ERROR,
+                "Frame Height can't be divided by tile row number \n");
+        return -1;
+    }
+    if(((sInfo.frameHeight/sInfo.tileRow)%64) && (sInfo.tileRow != 1))
+    {
+        av_log(avctx, AV_LOG_ERROR,
+                "Tile height can't be divided by 64 \n");
+        return -1;
+    }
+
+    sInfo.tileOverlapped = 0;
+    sInfo.overlapWidth = 0;
+    sInfo.overlapHeight = 0;
+    sInfo.streamType = deCxt->input_type;
+    memcpy(&(DEparams->streamInfo), &sInfo, sizeof(StreamInfo));
+
+    ProjectionInfo          projInfo;
+    memset(&projInfo, 0, sizeof(ProjectionInfo));
+    projInfo.enable = true;
+    if(0 == strncmp(deCxt->proj_type, "ERP", 3))
+    {
+        projInfo.type = E_EQUIRECT_PROJECTION;
+    }
+    else if (0 == strncmp(deCxt->proj_type, "Cube", 4))
+    {
+        projInfo.type = E_CUBEMAP_PROJECTION;
+    }
+    else if (0 == strncmp(deCxt->proj_type, "Planar", 6))
+    {
+        projInfo.enable = false;
+    }
+    else
+    {
+        av_log(avctx, AV_LOG_ERROR,
+                "Invalid input source projection type %s \n", deCxt->proj_type);
+        return -1;
+    }
+    memcpy(&(DEparams->suppleEnhanceInfo.projInfo), &projInfo, sizeof(ProjectionInfo));
+
+    CodecAppOption codecOption;
+    memset(&codecOption, 0, sizeof(CodecAppOption));
+
+    if(deCxt->input_type == encoded)
+    {
+        if(deCxt->inputCodec == 0) //HEVC
+        {
+            codecOption.decOption.decType = DecoderType_openHEVC;
+            ohOption *oh = (ohOption*)malloc(sizeof(ohOption));
+            if(!oh)
+                return AVERROR(EINVAL);
+            oh->threadCount = 16;
+            oh->threadType = 4;
+            codecOption.decOption.decSetting = (void*)oh;
+        }
+        else if(deCxt->inputCodec == 1) //AVC
+        {
+            codecOption.decOption.decType = DecoderType_ffmpeg;
+            ffmpegOption * fo = (ffmpegOption*)malloc(sizeof(ffmpegOption));
+            if(!fo)
+            {
+                return AVERROR(EINVAL);
+            }
+            fo->codecID = CodecID_H264;
+            codecOption.decOption.decSetting = (void*)fo;
+        }
+        else
+            return AVERROR(EINVAL);
+    }
+
+    DEparams->glogInitialized = glog_initialized;
+    codecOption.minLogLevel = deCxt->min_log_level;
+    min_loglevel = deCxt->min_log_level;
+    if(deCxt->external_log_flag)
+    {
+        codecOption.logFunction = (void*)(de_log_callback);
+    }
+    else
+    {
+        codecOption.logFunction = NULL;
+    }
+
+    memcpy(&(DEparams->codecOption), &codecOption, sizeof(CodecAppOption));
+
+    return 0;
+}
+
+static av_cold int de_init(AVCodecContext *avctx)
+{
+    DEContext   *deCxt = avctx->priv_data;
+
+    deCxt->eos_flag = false;
+    deCxt->send_end = false;
+    deCxt->frame_number = 0;
+#ifdef ENABLE_DE_FRAME_LOCK
+    deCxt->DeFrameListHead = NULL;
+    deCxt->DeFrameListTail = NULL;
+#endif
+
+    int ret = set_enc_params(avctx, &(deCxt->encode_params));
+    if(ret)
+        return ret;
+
+    ret = DistributedEncoder_ParseConfigFile(deCxt->configFile, &(deCxt->encode_params));
+    if (ret != DE_STATUS_SUCCESS)
+    {
+        return AVERROR(EINVAL);
+    }
+
+    deCxt->handle = DistributedEncoder_Init(&(deCxt->encode_params));
+    if(!deCxt->handle)
+    {
+        return AVERROR(EINVAL);
+    }
+    else
+    {
+        glog_initialized = true;
+    }
+
+    return 0;
+}
+
+int counter = 0;
+static int prepare_input_frame(AVCodecContext *avctx, bool isEncoded, InputFrame** inputFrame, const AVFrame *frame)
+{
+    DEContext  *deCxt = avctx->priv_data;
+    DistributedEncoderParam enc_params = deCxt->encode_params;
+    InputFrame* inFrame = *inputFrame;
+    int data_num = isEncoded ? 1 : 3;
+
+    for(int i = 0; i < data_num; i++)
+    {
+        int factor = i == 0 ? 1 : 2;
+        int copy_size = deCxt->input_type == encoded ? frame->linesize[i] : (frame->linesize[i] * enc_params.streamInfo.frameHeight / factor);
+
+        if(isEncoded)
+        {
+            inFrame->data[i] = (char*)malloc(sizeof(char*) * copy_size);
+            memcpy(inFrame->data[i], frame->data[i], copy_size);
+        }
+        else
+        {
+            inFrame->data[i] = frame->data[i];
+        }
+        inFrame->copysize[i] = copy_size;
+        inFrame->stride[i] = frame->linesize[i];
+    }
+
+    av_log(avctx, AV_LOG_DEBUG, "prepare_input_frame %d y 0x%lx u 0x%lx v 0x%lx\n", counter++,
+           (unsigned long)frame->data[0], (unsigned long)frame->data[1], (unsigned long)frame->data[2]);
+
+    *inputFrame = inFrame;
+    return 0;
+}
+
+static int de_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+{
+    DEContext  *deCxt = avctx->priv_data;
+    DistributedEncoderParam enc_params = deCxt->encode_params;
+    int err = 0;
+
+    if (!frame) {
+        InputFrame* lastFrame = (InputFrame*)malloc(sizeof(InputFrame));
+        if(!lastFrame)
+            return AVERROR(EINVAL);
+        memset(lastFrame, 0, sizeof(InputFrame));
+        lastFrame->data[0] = NULL;
+        lastFrame->stride[0] = 0;
+        lastFrame->width = enc_params.streamInfo.frameWidth;
+        lastFrame->height = enc_params.streamInfo.frameHeight;
+        lastFrame->format = enc_params.encoderParams.format;
+        lastFrame->picType = PictureType_NONE;
+        DistributedEncoder_Process(deCxt->handle, lastFrame);
+        free(lastFrame);
+        deCxt->send_end = true;
+        av_log(avctx, AV_LOG_DEBUG, "Finish sending frames!!!\n");
+        return 0;
+    }
+
+    InputFrame* inFrame = (InputFrame*)malloc(sizeof(InputFrame));
+    if(!inFrame)
+        return AVERROR(EINVAL);
+    memset(inFrame, 0 , sizeof(InputFrame));
+
+    if(deCxt->input_type != encoded && deCxt->input_type != raw)
+    {
+        free(inFrame);
+        return AVERROR(EINVAL);
+    }
+
+    bool isEncoded = (deCxt->input_type == encoded);
+    bool useSharedMem = (deCxt->input_type == raw);
+
+#ifdef ENABLE_DE_FRAME_LOCK
+    if(deCxt->input_type == raw)
+    {
+        DeFrameList *DeFrameListNode = (DeFrameList *)malloc(sizeof(DeFrameList));
+        if(!DeFrameListNode)
+        {
+            return AVERROR(ENOMEM);
+        }
+
+        DeFrameListNode->next = NULL;
+        DeFrameListNode->frame = av_frame_alloc();
+        if(!DeFrameListNode->frame)
+        {
+            free(DeFrameListNode);
+            return AVERROR(ENOMEM);
+        }
+
+        err = av_frame_ref(DeFrameListNode->frame, frame);
+        if(err != 0)
+        {
+            av_frame_free(DeFrameListNode->frame);
+            free(DeFrameListNode);
+            return err;
+        }
+
+        if(!deCxt->DeFrameListHead && !deCxt->DeFrameListTail)
+        {
+            deCxt->DeFrameListTail = deCxt->DeFrameListHead = DeFrameListNode;
+        }
+        else if(deCxt->DeFrameListHead && deCxt->DeFrameListTail)
+        {
+            deCxt->DeFrameListTail->next = DeFrameListNode;
+            deCxt->DeFrameListTail = DeFrameListNode;
+        }
+        else
+        {
+            av_frame_free(DeFrameListNode->frame);
+            free(DeFrameListNode);
+            return AVERROR(EINVAL);
+        }
+    }
+    av_log(avctx, AV_LOG_DEBUG, "de_send_frame frame 0x%lx\n", (unsigned long)deCxt->DeFrameListTail->frame);
+#endif
+
+    prepare_input_frame(avctx, isEncoded, &inFrame, frame);
+
+    inFrame->useSharedMem = useSharedMem;
+    inFrame->width = enc_params.streamInfo.frameWidth;
+    inFrame->height =enc_params.streamInfo.frameHeight ;
+    inFrame->format = enc_params.encoderParams.format;
+    switch (frame->pict_type) {
+    case AV_PICTURE_TYPE_I:
+        inFrame->picType = PictureType_I;
+        break;
+    case AV_PICTURE_TYPE_P:
+        inFrame->picType = PictureType_P;
+        break;
+    case AV_PICTURE_TYPE_B:
+        inFrame->picType = PictureType_B;
+        break;
+    default:
+        inFrame->picType = PictureType_NONE;
+        break;
+    }
+    DistributedEncoder_Process(deCxt->handle, inFrame);
+    if(inFrame)
+        free(inFrame);
+    return 0;
+}
+
+int rcounter=0;
+static int de_receive_packet(AVCodecContext *avctx, AVPacket *pkt)
+{
+    DEContext  *deCxt = avctx->priv_data;
+    int ret = 0;
+
+    if (deCxt->eos_flag)
+    {
+        av_log(avctx, AV_LOG_ERROR, "EOS reached!!\n");
+        return AVERROR_EOF;
+    }
+
+    char *data = NULL;
+    uint64_t size = 0;
+    int64_t pts = 0, dts = 0;
+    bool eos = false;
+
+    DistributedEncoder_GetPacket(deCxt->handle, &data, &size, &pts, &dts, &eos);
+    if(!data && !size && !eos && !deCxt->send_end)
+    {
+        return AVERROR(EAGAIN);
+        // *got_packet = 0;
+        // return 0;
+    }
+
+    if(!data && !size && deCxt->send_end)
+    {
+        while(!data)
+        {
+            DistributedEncoder_GetPacket(deCxt->handle, &data, &size, &pts, &dts, &eos);
+            usleep(5000);
+        }
+    }
+
+#ifdef ENABLE_DE_FRAME_LOCK
+    if(deCxt->input_type == raw)
+    {
+        DeFrameList *DeFrameListNode = NULL;
+
+        if(deCxt->DeFrameListHead && deCxt->DeFrameListTail)
+        {
+            DeFrameListNode = deCxt->DeFrameListHead;
+
+            if(deCxt->DeFrameListHead == deCxt->DeFrameListTail)
+            {
+                deCxt->DeFrameListHead = NULL;
+                deCxt->DeFrameListTail = NULL;
+            }
+            else
+            {
+                deCxt->DeFrameListHead = deCxt->DeFrameListHead->next;
+            }
+        }
+        else
+        {
+            return AVERROR(EINVAL);
+        }
+
+        av_log(avctx, AV_LOG_DEBUG, "de_receive_packet %d frame 0x%lx y 0x%lx u 0x%lx v 0x%lx\n",
+               rcounter++,
+               (unsigned long)DeFrameListNode->frame,
+               (unsigned long)DeFrameListNode->frame->data[0],
+               (unsigned long)DeFrameListNode->frame->data[1],
+               (unsigned long)DeFrameListNode->frame->data[2]);
+
+        av_frame_free(&DeFrameListNode->frame);
+        free(DeFrameListNode);
+    }
+#endif
+
+    if ((ret = ff_alloc_packet2(avctx, pkt, size, 0)) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to allocate output packet.\n");
+        free(data);
+        data = NULL;
+        return ret;
+    }
+
+    if(!data && !size)
+    {
+        return AVERROR(EAGAIN);
+    }
+    memcpy(pkt->data, data, size);
+
+    pkt->size = size;
+    pkt->pts  = pts;
+    pkt->dts = dts;
+
+    int gop = deCxt->encode_params.encoderParams.intra_period + 1;
+    if(pkt->pts % gop == 0)
+    {
+        pkt->flags |= AV_PKT_FLAG_KEY;
+    }
+
+    if (deCxt->frame_number == 0)
+    {
+        Headers* header = (Headers*)malloc(sizeof(Headers));
+        if(!header)
+        {
+             av_log(avctx, AV_LOG_ERROR, "Failed to create header for output .\n");
+             return AVERROR(ENOMEM);
+        }
+
+        ret = DistributedEncoder_GetParam(deCxt->handle, Param_Header, &header);
+
+        if(ret == DE_STATUS_SUCCESS)
+        {
+            pkt->side_data = (AVPacketSideData*)malloc(sizeof(AVPacketSideData));
+            if(!pkt->side_data)
+            {
+                free(header);
+                return AVERROR(EINVAL);
+            }
+            pkt->side_data->size = header->headerSize;
+            pkt->side_data->data = av_malloc(pkt->side_data->size + AV_INPUT_BUFFER_PADDING_SIZE);
+            if (!(pkt->side_data->data))
+            {
+                av_log(avctx, AV_LOG_ERROR,
+                    "Cannot allocate HEVC header of size %d. \n", pkt->side_data->size);
+                free(header);
+                return AVERROR(ENOMEM);
+            }
+            memcpy(pkt->side_data->data, header->headerData, pkt->side_data->size);
+
+            free(header);
+            header = NULL;
+
+            pkt->side_data->type = AV_PKT_DATA_NEW_EXTRADATA;
+            pkt->side_data_elems = 1;
+        }
+        else
+        {
+            av_log(avctx, AV_LOG_ERROR, "Failed to get bitstream header.\n");
+        }
+    }
+
+    //*got_packet = 1;
+
+    deCxt->frame_number++;
+
+    if (eos)
+    {
+        deCxt->eos_flag = true;
+    }
+
+    if(data)
+    {
+        free(data);
+        data = NULL;
+    }
+
+    return 0;
+}
+
+static int de_encode_frame(AVCodecContext *avctx, AVPacket *pkt, const AVFrame *pic, int *got_packet)
+{
+    int ret = 0;
+
+    DEContext   *deCxt = avctx->priv_data;
+    if(deCxt->eos_flag == true)
+    {
+        *got_packet = 0;
+        return 0;
+    }
+
+    ret = de_send_frame(avctx, pic);
+
+    //ret = de_receive_packet(avctx, pkt, got_packet);
+
+    if(!(*got_packet))
+    {
+        usleep(900000);
+    }
+
+    return ret;
+}
+
+static av_cold int de_close(AVCodecContext *avctx)
+{
+    DEContext *deCxt = avctx->priv_data;
+    void *setting = NULL;
+
+    if (deCxt) {
+#ifdef ENABLE_DE_FRAME_LOCK
+        if(deCxt->input_type == raw)
+        {
+            while(deCxt->DeFrameListHead)
+            {
+                DeFrameList *DeFrameListNode = deCxt->DeFrameListHead;
+
+                av_frame_free(&DeFrameListNode->frame);
+                deCxt->DeFrameListHead = deCxt->DeFrameListHead->next;
+
+                free(DeFrameListNode);
+            }
+            deCxt->DeFrameListTail = NULL;
+        }
+#endif
+
+        if (deCxt->handle) {
+            DistributedEncoder_Destroy(deCxt->handle);
+            deCxt->handle = NULL;
+        }
+
+        setting = deCxt->encode_params.codecOption.encOption.encSetting;
+        if(setting)
+        {
+            free(setting);
+            setting = NULL;
+        }
+
+        setting = deCxt->encode_params.codecOption.decOption.decSetting;
+        if(setting)
+        {
+            free(setting);
+            setting = NULL;
+        }
+
+        deCxt = NULL;
+    }
+
+    return 0;
+}
+
+#define OFFSET(x) offsetof(DEContext, x)
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+static const AVOption options[] = {
+    { "config_file", "configure file path for workers information", OFFSET(configFile),
+      AV_OPT_TYPE_STRING, { 0 }, 0, 0, VE },
+
+    { "proj_type", "input source projection type, ERP or Cubemap", OFFSET(proj_type),
+      AV_OPT_TYPE_STRING, { .str = "ERP" }, 0, 0, VE },
+
+    { "input_type", "input stream type, 0 - encoded, 1 - raw, default is 0", OFFSET(input_type),
+      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 0xff, VE},
+
+    { "input_codec", "input bitstream type, only work when input type is 0-encoded, 0 - HEVC, 1 - AVC, default is 0", OFFSET(inputCodec),
+      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 0xff, VE},
+
+    { "vui", "Enable vui info", OFFSET(vui_info),
+      AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, VE },
+
+    { "aud", "Include AUD", OFFSET(aud),
+      AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VE },
+
+    { "hielevel", "Hierarchical prediction levels setting", OFFSET(hierarchical_level),
+      AV_OPT_TYPE_INT, { .i64 = 3 }, 0, 3, VE , "hielevel"},
+        { "flat",   NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 0 },  INT_MIN, INT_MAX, VE, "hielevel" },
+        { "2level", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 1 },  INT_MIN, INT_MAX, VE, "hielevel" },
+        { "3level", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 2 },  INT_MIN, INT_MAX, VE, "hielevel" },
+        { "4level", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 3 },  INT_MIN, INT_MAX, VE, "hielevel" },
+
+    { "la_depth", "Look ahead distance [0, 256]", OFFSET(la_depth),
+      AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 256, VE },
+
+    { "preset", "Encoding preset [0, 12] for SVT ([0, 10] for >= 1080p resolution) [0, 9] for all resolution and modes) [0, 6] for MSDK",
+      OFFSET(enc_mode), AV_OPT_TYPE_INT, { .i64 = 9 }, 0, 12, VE },
+
+    { "profile", "Profile setting, Main Still Picture Profile not supported", OFFSET(profile),
+      AV_OPT_TYPE_INT, { .i64 = FF_PROFILE_HEVC_MAIN_10 }, FF_PROFILE_HEVC_MAIN, FF_PROFILE_HEVC_REXT, VE, "profile"},
+
+    { "tier", "Set tier (general_tier_flag)", OFFSET(tier),
+      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE, "tier" },
+        { "main", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 0 }, 0, 0, VE, "tier" },
+        { "high", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 1 }, 0, 0, VE, "tier" },
+
+    { "level", "Set level (level_idc)", OFFSET(level),
+      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 0xff, VE, "level" },
+
+    { "rc", "Bit rate control mode", OFFSET(rc_mode),
+      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE , "rc"},
+        { "cqp", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 0 },  INT_MIN, INT_MAX, VE, "rc" },
+        { "vbr", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 1 },  INT_MIN, INT_MAX, VE, "rc" },
+
+    { "qp", "QP value for intra frames", OFFSET(qp),
+      AV_OPT_TYPE_INT, { .i64 = 32 }, 0, 51, VE },
+
+    { "sc_detection", "Scene change detection", OFFSET(scd),
+      AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VE },
+
+    { "tune", "Quality tuning mode", OFFSET(tune), AV_OPT_TYPE_INT, { .i64 = 1 }, 0, 2, VE, "tune" },
+        { "sq", "Visually optimized mode", 0,
+          AV_OPT_TYPE_CONST, { .i64 = 0 },  INT_MIN, INT_MAX, VE, "tune" },
+        { "oq",  "PSNR / SSIM optimized mode",  0,
+          AV_OPT_TYPE_CONST, { .i64 = 1 },  INT_MIN, INT_MAX, VE, "tune" },
+        { "vmaf", "VMAF optimized mode", 0,
+          AV_OPT_TYPE_CONST, { .i64 = 2 },  INT_MIN, INT_MAX, VE, "tune" },
+
+    { "pred_struct", "Prediction structure used to construct GOP", OFFSET(gop_pred_structure),
+      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 2, VE, "pred_struct" },
+        { "IPPP", "P is low delay P", 0, AV_OPT_TYPE_CONST, { .i64 = 0 }, INT_MIN, INT_MAX, VE, "pred_struct" },
+        { "Ibbb", "b is low delay B", 1, AV_OPT_TYPE_CONST, { .i64 = 1 }, INT_MIN, INT_MAX, VE, "pred_struct" },
+        { "IBBB", "B is normal bi-directional B", 2, AV_OPT_TYPE_CONST, { .i64 = 2 }, INT_MIN, INT_MAX, VE, "pred_struct" },
+
+    { "bl_mode", "Random Access Prediction Structure type setting", OFFSET(base_layer_switch_mode),
+      AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VE },
+
+    { "forced-idr", "If forcing keyframes, force them as IDR frames.", OFFSET(forced_idr),
+      AV_OPT_TYPE_BOOL,   { .i64 = 1 }, 0, 1, VE },
+
+    { "hdr", "High dynamic range input", OFFSET(hdr),
+      AV_OPT_TYPE_BOOL,   { .i64 = 0 }, 0, 1, VE },
+
+    { "asm_type", "Assembly instruction set type [0: C Only, 1: Auto]", OFFSET(asm_type),
+      AV_OPT_TYPE_BOOL,   { .i64 = 1 }, 0, 1, VE },
+
+    { "tile_column", "Tile column count number, default is 1", OFFSET(tile_column),
+      AV_OPT_TYPE_INT, { .i64 = 1 }, 0, 256, VE },
+
+    { "tile_row", "Tile row count number, default is 1", OFFSET(tile_row),
+      AV_OPT_TYPE_INT, { .i64 = 1 }, 0, 256, VE },
+
+    { "in_parallel", "Multiple encoders running in parallel [0: Off, 1: On]", OFFSET(in_parallel),
+      AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VE },
+
+    { "gpucopy", "GPU copy trigger for MSDK (To be ignored if SVT)", OFFSET(gpucopy),
+      AV_OPT_TYPE_BOOL,   { .i64 = 1 }, 0, 1, VE },
+
+    { "external_log_flag", "whether external log callback is needed", OFFSET(external_log_flag),
+      AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VE },
+
+    { "min_log_level", "Minimal log level of output [0: INFO, 1: WARNING, 2: ERROR, 3: FATAL]", OFFSET(min_log_level),
+      AV_OPT_TYPE_INT, { .i64 = 2 }, 0, 3, VE },
+
+    {NULL},
+};
+
+static const AVClass class = {
+    .class_name = "distributed_encoder",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVCodecDefault de_defaults[] = {
+    { "b",         "7M"    },
+    { "flags",     "+cgop" },
+    { "qmin",      "10"    },
+    { "qmax",      "48"    },
+    { "g",         "-2"    },
+    { NULL },
+};
+
+AVCodec ff_distributed_encoder = {
+    .name           = "distributed_encoder",
+    .long_name      = NULL_IF_CONFIG_SMALL("distributed HEVC encoder"),
+    .priv_data_size = sizeof(DEContext),
+    .type           = AVMEDIA_TYPE_VIDEO,
+    .id             = AV_CODEC_ID_HEVC,
+    .init           = de_init,
+    .send_frame     = de_send_frame,
+    .receive_packet = de_receive_packet,
+    .close          = de_close,
+    .capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AUTO_THREADS,
+    .pix_fmts       = (const enum AVPixelFormat[]){ AV_PIX_FMT_YUV420P,
+                                                    AV_PIX_FMT_YUV420P10,
+                                                    AV_PIX_FMT_YUV422P,
+                                                    AV_PIX_FMT_YUV420P10,
+                                                    AV_PIX_FMT_YUV444P,
+                                                    AV_PIX_FMT_YUV444P10,
+                                                    AV_PIX_FMT_NONE },
+    .priv_class     = &class,
+    .defaults       = de_defaults,
+    .caps_internal  = FF_CODEC_CAP_INIT_CLEANUP,
+    .wrapper_name   = "distributed_encoder",
+};
diff -Nur FFmpeg/libavcodec/encode.c FFmpeg_patched/libavcodec/encode.c
--- FFmpeg/libavcodec/encode.c	2022-06-29 07:15:48.387919032 +0000
+++ FFmpeg_patched/libavcodec/encode.c	2022-06-29 07:16:09.415918782 +0000
@@ -430,12 +430,13 @@
         int ret;
         if (avctx->internal->draining && !(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))
             return AVERROR_EOF;
-        ret = avctx->codec->receive_packet(avctx, avpkt);
-        if (!ret)
-            // Encoders must always return ref-counted buffers.
-            // Side-data only packets have no data and can be not ref-counted.
-            av_assert0(!avpkt->data || avpkt->buf);
-        return ret;
+        // ret = avctx->codec->receive_packet(avctx, avpkt);
+        // if (!ret)
+        //     // Encoders must always return ref-counted buffers.
+        //     // Side-data only packets have no data and can be not ref-counted.
+        //     av_assert0(!avpkt->data || avpkt->buf);
+        // return ret;
+        return ret = avctx->codec->receive_packet(avctx, avpkt);
     }

     // Emulation via old API.
diff -Nur FFmpeg/libavcodec/h264_parser.c FFmpeg_patched/libavcodec/h264_parser.c
--- FFmpeg/libavcodec/h264_parser.c	2022-06-29 07:15:48.403919032 +0000
+++ FFmpeg_patched/libavcodec/h264_parser.c	2022-06-29 07:16:09.511918781 +0000
@@ -703,7 +703,7 @@
 }

 AVCodecParser ff_h264_parser = {
-    .codec_ids      = { AV_CODEC_ID_H264 },
+    .codec_ids      = { AV_CODEC_ID_H264, AV_CODEC_ID_H264BYPASSVIDEO },
     .priv_data_size = sizeof(H264ParseContext),
     .parser_init    = init,
     .parser_parse   = h264_parse,
diff -Nur FFmpeg/libavcodec/hevc_parser.c FFmpeg_patched/libavcodec/hevc_parser.c
--- FFmpeg/libavcodec/hevc_parser.c	2022-06-29 07:15:48.407919032 +0000
+++ FFmpeg_patched/libavcodec/hevc_parser.c	2022-06-29 07:16:09.483918781 +0000
@@ -381,7 +381,7 @@
 }
 
 AVCodecParser ff_hevc_parser = {
-    .codec_ids      = { AV_CODEC_ID_HEVC },
+    .codec_ids      = { AV_CODEC_ID_HEVC , AV_CODEC_ID_HEVCBYPASSVIDEO},
     .priv_data_size = sizeof(HEVCParserContext),
     .parser_parse   = hevc_parse,
     .parser_close   = hevc_parser_close,
diff -Nur FFmpeg/libavcodec/libopenhevc.c FFmpeg_patched/libavcodec/libopenhevc.c
--- FFmpeg/libavcodec/libopenhevc.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavcodec/libopenhevc.c	2022-06-29 07:16:09.515918781 +0000
@@ -0,0 +1,188 @@
+/*
+ * OpenHEVC video Decoder
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <libopenhevc/openhevc.h>
+#include "avcodec.h"
+#include "internal.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/opt.h"
+#include "libavutil/common.h"
+#include "libavutil/internal.h"
+
+//#define DEBUG
+typedef struct OpenHevcContext{
+	const AVClass *class;
+	OHHandle handle;
+#ifdef DEBUG
+	FILE *fout;
+#endif
+	int thread_count;
+	int thread_type;
+	int temporal_layer_id;
+	int quality_layer_id;
+}OpenHevcContext;
+
+static av_cold int openhevc_close(AVCodecContext *ctx)
+{
+	OpenHevcContext *c = ctx->priv_data;
+	if(c->handle){
+		oh_close(c->handle);
+		c->handle = NULL;
+	}
+#ifdef DEBUG
+	if(c->fout){
+		fclose(c->fout);
+	}
+#endif
+	return 0;
+}
+static av_cold int openhevc_init(AVCodecContext *ctx)
+{
+	OpenHevcContext *c = ctx->priv_data;
+	c->handle = oh_init(c->thread_count, c->thread_type);
+	if(!c->handle){
+		av_log(ctx,AV_LOG_ERROR,"oh_init failed\n");
+		return AVERROR_EXTERNAL;
+	}
+	size_t extra_size_alloc;
+	extra_size_alloc = ctx->extradata_size > 0 ? (ctx->extradata_size +AV_INPUT_BUFFER_PADDING_SIZE) : 0;
+	if(extra_size_alloc){
+		oh_extradata_cpy(c->handle, ctx->extradata, extra_size_alloc);
+	}
+	oh_disable_cropping(c->handle, !!(ctx->flags2 & AV_CODEC_FLAG2_IGNORE_CROP));
+	oh_start(c->handle);
+	oh_select_temporal_layer(c->handle,c->temporal_layer_id);
+	oh_select_active_layer(c->handle,c->quality_layer_id);
+	oh_select_view_layer(c->handle,c->quality_layer_id);
+#ifdef DEBUG
+	c->fout = fopen("output.yuv","wb");
+	if(!c->fout){
+		printf("open file failed !\n");
+		return -1;
+	}
+#endif
+	return 0;
+}
+
+static int openhevc_decode(AVCodecContext *ctx, void *data, int *got_frame, AVPacket *avpkt)
+{
+	OpenHevcContext *c = ctx->priv_data;
+	AVFrame *picture = data;
+	int ret;
+	OHFrame openHevcFrame;
+
+	ret = oh_decode(c->handle, avpkt->data, avpkt->size, avpkt->pts);
+
+	av_log(ctx, AV_LOG_DEBUG, "oh_decode pts %d size %ld ret %d\n", avpkt->pts, avpkt->size, ret);
+
+	if(ret<0){
+		av_log(ctx, AV_LOG_ERROR, "failed to decode frame\n");
+		return AVERROR_EXTERNAL;
+	}
+	if(ret){
+		uint8_t *data_ptr_array[4] = {NULL};
+		int stride_array[4] = {0};
+
+		oh_output_update(c->handle, 1, &openHevcFrame);
+		oh_frameinfo_update(c->handle, &openHevcFrame.frame_par);
+
+		if(av_image_check_size(openHevcFrame.frame_par.width, openHevcFrame.frame_par.height, 0, ctx))
+			return AVERROR_INVALIDDATA;
+		ctx->pix_fmt = AV_PIX_FMT_YUV420P;
+		ff_set_dimensions(ctx, openHevcFrame.frame_par.width, openHevcFrame.frame_par.height);
+
+		av_log(ctx, AV_LOG_DEBUG, "oh_decode pts %d frame 0x%lx y 0x%lx u 0x%lx v 0x%lx\n",
+			avpkt->pts, (unsigned long)picture,
+			(unsigned long)openHevcFrame.data_y_p,
+			(unsigned long)openHevcFrame.data_cb_p,
+			(unsigned long)openHevcFrame.data_cr_p);
+
+		if((ret=ff_get_buffer(ctx, picture, 0))<0)
+			return ret;
+		picture->sample_aspect_ratio.num = openHevcFrame.frame_par.sample_aspect_ratio.num;
+		picture->sample_aspect_ratio.den = openHevcFrame.frame_par.sample_aspect_ratio.den;
+
+		data_ptr_array[0] = (uint8_t *)openHevcFrame.data_y_p;
+		data_ptr_array[1] = (uint8_t *)openHevcFrame.data_cb_p;
+		data_ptr_array[2] = (uint8_t *)openHevcFrame.data_cr_p;
+
+		stride_array[0] = openHevcFrame.frame_par.linesize_y;
+		stride_array[1] = openHevcFrame.frame_par.linesize_cb;
+		stride_array[2] = openHevcFrame.frame_par.linesize_cr;
+#ifdef DEBUG
+		if(c->fout){
+		    int format = openHevcFrame.frame_par.chromat_format == OH_YUV420 ? 1 : 0;
+                    fwrite( (uint8_t *)openHevcFrame.data_y_p ,  sizeof(uint8_t) , openHevcFrame.frame_par.linesize_y  * openHevcFrame.frame_par.height,  c->fout);
+                    fwrite( (uint8_t *)openHevcFrame.data_cb_p , sizeof(uint8_t) , openHevcFrame.frame_par.linesize_cb * openHevcFrame.frame_par.height >> format, c->fout);
+                    fwrite( (uint8_t *)openHevcFrame.data_cr_p , sizeof(uint8_t) , openHevcFrame.frame_par.linesize_cr * openHevcFrame.frame_par.height >> format, c->fout);
+                }
+#endif
+//		av_image_copy(picture->data, picture->linesize, (uint8_t **)data_ptr_array, stride_array, ctx->pix_fmt, picture->width, picture->height);
+		picture->data[0] = data_ptr_array[0];
+		picture->data[1] = data_ptr_array[1];
+		picture->data[2] = data_ptr_array[2];
+		picture->linesize[0] = stride_array[0];
+		picture->linesize[1] = stride_array[1];
+		picture->linesize[2] = stride_array[2];
+		picture->format = ctx->pix_fmt;
+
+		picture->pts = avpkt->pts;
+	        picture->pkt_dts = avpkt->dts;
+		picture->pkt_duration = avpkt->duration;
+
+		*got_frame = 1;
+	}
+	return avpkt->size;
+
+}
+static void openhevc_flush(AVCodecContext *avctx)
+{
+	OpenHevcContext *c = avctx->priv_data;
+	oh_flush(c->handle);
+}
+#define OFFSET(x) offsetof(OpenHevcContext, x)
+#define VE (AV_OPT_FLAG_DECODING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+	{"thread_count", "for how many threads to be executed, 1 is for default", OFFSET(thread_count), AV_OPT_TYPE_INT, {.i64 = 1}, 0, INT_MAX, VE},
+	{"thread_type", "which multithreads methods to use, 1 is for default", OFFSET(thread_type), AV_OPT_TYPE_INT, {.i64 = 1}, 0, INT_MAX, VE},
+	{"temporal_layer_id","temporal layer id,7 is for default",OFFSET(temporal_layer_id),AV_OPT_TYPE_INT,{.i64 = 7}, 0 , INT_MAX, VE},
+	{"quality_layer_id","quality layer id,0 is for default",OFFSET(quality_layer_id),AV_OPT_TYPE_INT,{.i64 = 0}, 0 , INT_MAX, VE},
+	{NULL},
+};
+static const AVClass openhevc_class = {
+	.class_name = "libopenhevc",
+	.item_name = av_default_item_name,
+	.option = options,
+	.version = LIBAVUTIL_VERSION_INT,
+};
+AVCodec ff_libopenhevc_decoder = {
+	.name = "libopenhevc",
+	.long_name = NULL_IF_CONFIG_SMALL("libopenhevc HEVC decoder"),
+	.type = AVMEDIA_TYPE_VIDEO,
+	.id = AV_CODEC_ID_HEVC,
+	.priv_data_size = sizeof(OpenHevcContext),
+	.priv_class = &openhevc_class,
+	.init = openhevc_init,
+	.flush = openhevc_flush,
+	.close = openhevc_close,
+	.decode = openhevc_decode,
+	.capabilities = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_DR1,
+	.caps_internal = FF_CODEC_CAP_SETS_PKT_DTS | FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP,
+};
diff -Nur FFmpeg/libavcodec/libsvt_hevc.c FFmpeg_patched/libavcodec/libsvt_hevc.c
--- FFmpeg/libavcodec/libsvt_hevc.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavcodec/libsvt_hevc.c	2022-06-29 07:16:09.511918781 +0000
@@ -0,0 +1,341 @@
+/*
+* Scalable Video Technology for HEVC encoder library plugin
+*
+* Copyright (c) 2018 Intel Corporation
+*
+* This program is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+
+
+#include "EbErrorCodes.h"
+#include "EbTime.h"
+#include "EbApi.h"
+
+#include "libavutil/common.h"
+#include "libavutil/frame.h"
+#include "libavutil/opt.h"
+
+#include "internal.h"
+#include "avcodec.h"
+
+typedef struct SvtEncoder {
+    EB_H265_ENC_CONFIGURATION           enc_params;
+    EB_COMPONENTTYPE                    *svt_handle;
+    EB_BUFFERHEADERTYPE                 *in_buf;
+    EB_BUFFERHEADERTYPE                 *out_buf;
+    int                                  raw_size;
+} SvtEncoder;
+
+typedef struct SvtParams {
+    int vui_info;
+    int hierarchical_level;
+    int intra_period;
+    int la_depth;
+    int intra_ref_type;
+    int enc_mode;
+    int rc_mode;
+    int scd;
+    int tune;
+	int qp;
+    int profile;
+    int base_layer_switch_mode;
+}SvtParams;
+
+typedef struct SvtContext {
+    AVClass     *class;
+    SvtEncoder  *svt_enc;
+    SvtParams   svt_param;
+    int         eos_flag;
+} SvtContext;
+
+static void free_buffer(SvtEncoder *svt_enc)
+{
+    if (svt_enc->in_buf) {
+        EB_H265_ENC_INPUT *in_data = (EB_H265_ENC_INPUT* )svt_enc->in_buf->pBuffer;
+        if (in_data) {
+            av_freep(&in_data);
+        }
+        av_freep(&svt_enc->in_buf);
+    }
+    av_freep(&svt_enc->out_buf);
+}
+
+static EB_ERRORTYPE alloc_buffer(EB_H265_ENC_CONFIGURATION *config, SvtEncoder *svt_enc)
+{
+    EB_ERRORTYPE       ret       = EB_ErrorNone;
+
+    const int    pack_mode_10bit   = (config->encoderBitDepth > 8) && (config->compressedTenBitFormat == 0) ? 1 : 0;
+    const size_t luma_size_8bit    = config->sourceWidth * config->sourceHeight * (1 << pack_mode_10bit);
+    const size_t luma_size_10bit   = (config->encoderBitDepth > 8 && pack_mode_10bit == 0) ? luma_size_8bit : 0;
+
+    svt_enc->raw_size = (luma_size_8bit + luma_size_10bit) * 3 / 2;
+
+    // allocate buffer for in and out
+    svt_enc->in_buf           = av_mallocz(sizeof(EB_BUFFERHEADERTYPE));
+    svt_enc->out_buf          = av_mallocz(sizeof(EB_BUFFERHEADERTYPE));
+    if (!svt_enc->in_buf || !svt_enc->out_buf)
+        goto failed;
+
+    svt_enc->in_buf->pBuffer  = av_mallocz(sizeof(EB_H265_ENC_INPUT));
+    if (!svt_enc->in_buf->pBuffer)
+        goto failed;
+
+    svt_enc->in_buf->nSize        = sizeof(EB_BUFFERHEADERTYPE);
+    svt_enc->in_buf->pAppPrivate  = NULL;
+    svt_enc->out_buf->nSize       = sizeof(EB_BUFFERHEADERTYPE);
+    svt_enc->out_buf->nAllocLen   = svt_enc->raw_size;
+    svt_enc->out_buf->pAppPrivate = NULL;
+
+    return ret;
+
+failed:
+    free_buffer(svt_enc);
+    return AVERROR(ENOMEM);
+}
+
+static int error_mapping(int val)
+{
+    if (val == EB_ErrorInsufficientResources)
+        return AVERROR(ENOMEM);
+    if ((val == EB_ErrorUndefined) || (val == EB_ErrorInvalidComponent) ||
+        (val == EB_ErrorBadParameter))
+        return AVERROR(EINVAL);
+    return AVERROR_EXTERNAL;
+}
+
+static EB_ERRORTYPE config_enc_params(EB_H265_ENC_CONFIGURATION  *param, AVCodecContext *avctx)
+{
+    SvtContext *q       = avctx->priv_data;
+    SvtEncoder *svt_enc = q->svt_enc;
+    EB_ERRORTYPE    ret = EB_ErrorNone;
+    int         tenBits = 0;
+
+    param->sourceWidth     = avctx->width;
+    param->sourceHeight    = avctx->height;
+
+    if (avctx->pix_fmt == AV_PIX_FMT_YUV420P10LE) {
+        av_log(avctx, AV_LOG_DEBUG , "Encoder 10 bits depth input\n");
+        param->compressedTenBitFormat = 0;
+        tenBits = 1;
+    }
+
+    // Update param from options
+    param->hierarchicalLevels     = q->svt_param.hierarchical_level;
+    param->encMode                = q->svt_param.enc_mode;
+    param->intraRefreshType       = q->svt_param.intra_ref_type;
+    param->profile                = q->svt_param.profile;
+    param->rateControlMode        = q->svt_param.rc_mode;
+    param->sceneChangeDetection   = q->svt_param.scd;
+    param->tune                   = q->svt_param.tune;
+    param->baseLayerSwitchMode    = q->svt_param.base_layer_switch_mode;
+	param->qp                     = q->svt_param.qp;
+	param->intraPeriodLength      = q->svt_param.intra_period;
+
+    param->targetBitRate          = avctx->bit_rate;
+    param->frameRateNumerator     = avctx->time_base.den;
+    param->frameRateDenominator   = avctx->time_base.num * avctx->ticks_per_frame;
+
+    if (q->svt_param.vui_info)
+        param->videoUsabilityInfo = q->svt_param.vui_info;
+    if (q->svt_param.la_depth != -1)
+        param->lookAheadDistance  = q->svt_param.la_depth;
+
+    if (tenBits == 1) {
+        param->encoderBitDepth        = 10;
+        param->profile                = 2;
+    }
+
+    ret = alloc_buffer(param, svt_enc);
+
+    return ret;
+}
+
+static void read_in_data(EB_H265_ENC_CONFIGURATION *config, const AVFrame* frame, EB_BUFFERHEADERTYPE *headerPtr)
+{
+
+    unsigned int is16bit = config->encoderBitDepth > 8;
+    unsigned long long lumaReadSize = (unsigned long long)config->sourceWidth * config->sourceHeight<< is16bit;
+    EB_H265_ENC_INPUT *in_data = (EB_H265_ENC_INPUT*)headerPtr->pBuffer;
+
+    // support yuv420p and yuv420p010
+    in_data->luma = frame->data[0];
+    in_data->cb   = frame->data[1];
+    in_data->cr   = frame->data[2];
+	
+	// stride info
+	in_data->yStride  = frame->linesize[0] >> is16bit;
+	in_data->cbStride = frame->linesize[1] >> is16bit;
+	in_data->crStride = frame->linesize[2] >> is16bit;
+
+    headerPtr->nFilledLen   += lumaReadSize * 3/2u;
+}
+
+static av_cold int eb_enc_init(AVCodecContext *avctx)
+{
+    SvtContext   *q = avctx->priv_data;
+    SvtEncoder   *svt_enc = NULL;
+    EB_ERRORTYPE ret = EB_ErrorNone;
+
+    q->svt_enc  = av_mallocz(sizeof(*q->svt_enc));
+    if (!q->svt_enc)
+        return AVERROR(ENOMEM);
+    svt_enc = q->svt_enc;
+
+    q->eos_flag = 0;
+
+    ret = EbInitHandle(&svt_enc->svt_handle, q, &svt_enc->enc_params);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    ret = config_enc_params(&svt_enc->enc_params, avctx);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    ret = EbH265EncSetParameter(svt_enc->svt_handle, &svt_enc->enc_params);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    ret = EbInitEncoder(svt_enc->svt_handle);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+    return ret;
+
+failed_init:
+    return error_mapping(ret);
+}
+
+static int eb_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+{
+    SvtContext           *q = avctx->priv_data;
+    SvtEncoder           *svt_enc = q->svt_enc;
+    EB_BUFFERHEADERTYPE  *headerPtr = svt_enc->in_buf;
+    int                  ret = 0;
+
+    if (!frame) {
+        EB_BUFFERHEADERTYPE headerPtrLast;
+        headerPtrLast.nAllocLen = 0;
+        headerPtrLast.nFilledLen = 0;
+        headerPtrLast.nTickCount = 0;
+        headerPtrLast.pAppPrivate = NULL;
+        //headerPtrLast.nOffset = 0;
+        //headerPtrLast.nTimeStamp = 0;
+        headerPtrLast.nFlags = EB_BUFFERFLAG_EOS;
+        headerPtrLast.pBuffer = NULL;
+        EbH265EncSendPicture(svt_enc->svt_handle, &headerPtrLast);
+        q->eos_flag = 1;
+        av_log(avctx, AV_LOG_DEBUG, "Finish sending frames!!!\n");
+        return ret;
+    }
+
+    read_in_data(&svt_enc->enc_params, frame, headerPtr);
+
+    //headerPtr->nOffset    = 0;
+    headerPtr->nFlags     = 0;
+    //headerPtr->nFlags     = 0;
+    //headerPtr->nTimeStamp = 0;
+    headerPtr->pAppPrivate = NULL;
+    headerPtr->pts         = frame->pts;
+    EbH265EncSendPicture(svt_enc->svt_handle, headerPtr);
+
+    return ret;
+}
+
+static int eb_receive_packet(AVCodecContext *avctx, AVPacket *pkt)
+{
+    SvtContext  *q = avctx->priv_data;
+    SvtEncoder  *svt_enc = q->svt_enc;
+    EB_BUFFERHEADERTYPE   *headerPtr = svt_enc->out_buf;
+    EB_ERRORTYPE          stream_status = EB_ErrorNone;
+    int ret = 0;
+
+    if ((ret = ff_alloc_packet2(avctx, pkt, svt_enc->raw_size, 0)) < 0)
+        return ret;
+    headerPtr->pBuffer = pkt->data;
+    stream_status = EbH265GetPacket(svt_enc->svt_handle, headerPtr, q->eos_flag);
+    if ((stream_status == EB_NoErrorEmptyQueue))
+        return AVERROR(EAGAIN);
+
+    pkt->size = headerPtr->nFilledLen;
+    ret = (headerPtr->nFlags & EB_BUFFERFLAG_EOS) ? AVERROR_EOF : 0;
+    return ret;
+}
+
+static av_cold int eb_enc_close(AVCodecContext *avctx)
+{
+    SvtContext *q = avctx->priv_data;
+    SvtEncoder   *svt_enc = q->svt_enc;
+
+    EbDeinitEncoder(svt_enc->svt_handle);
+    EbDeinitHandle(svt_enc->svt_handle);
+
+    free_buffer(svt_enc);
+    av_freep(&svt_enc);
+
+    return 0;
+}
+
+#define OFFSET(x) offsetof(SvtContext, x)
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+static const AVOption options[] = {
+    {"vui", "Enable vui info", OFFSET(svt_param.vui_info), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },
+    {"hielevel", "Hierarchical Prediction Levels [0,3]", OFFSET(svt_param.hierarchical_level), AV_OPT_TYPE_INT, { .i64 = 3 }, 0, 3, VE },
+    {"la_depth", "Look Ahead Distance [0,256]", OFFSET(svt_param.la_depth), AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 256, VE },
+    {"intra_ref_type", "Intra Refresh Type 0: No intra refresh1: CRA (Open GOP) 2: IDR", OFFSET(svt_param.intra_ref_type), AV_OPT_TYPE_INT, { .i64 = 1 }, 1, 2, VE },
+    {"enc_p", "Encoding preset [0,12] (for tune 0 and >=4k resolution), [0,10] (for >= 1080p resolution), [0,9] (for all resolution and modes)", OFFSET(svt_param.enc_mode), AV_OPT_TYPE_INT, { .i64 = 9 }, 0, 12, VE },
+    {"profile", "Profile now support[1,2],Main Still Picture Profile not supported", OFFSET(svt_param.profile), AV_OPT_TYPE_INT, { .i64 = 2 }, 1, 2, VE },
+    {"rc", "RC mode 0: CQP 1: VBR", OFFSET(svt_param.rc_mode), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },
+	{"q", "QP value for intra frames", OFFSET(svt_param.qp), AV_OPT_TYPE_INT, { .i64 = 32 }, 0, 51, VE },
+	{"ip", "distance between intra frames", OFFSET(svt_param.intra_period), AV_OPT_TYPE_INT, { .i64 = -2 }, -2, 255, VE },
+    {"scd", "scene change detection", OFFSET(svt_param.scd), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },
+    {"tune", "tune mode: SQ/OQ[0,1]", OFFSET(svt_param.tune), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },
+    {"bl_mode", "Random Access Prediction Structure Type", OFFSET(svt_param.base_layer_switch_mode), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },
+    {NULL},
+};
+
+static const AVClass class = {
+    .class_name = "hevc_svt encoder",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVCodecDefault eb_enc_defaults[] = {
+    { "b",         "7M"    },
+    { "refs",      "0"     },
+    { "g",         "90"   },
+    { "flags",     "+cgop" },
+    { NULL },
+};
+
+AVCodec ff_hevc_svt_encoder = {
+    .name           = "libsvt_hevc",
+    .long_name      = NULL_IF_CONFIG_SMALL("SVT-HEVC(Scalable Video Technology for HEVC) encoder"),
+    .priv_data_size = sizeof(SvtContext),
+    .type           = AVMEDIA_TYPE_VIDEO,
+    .id             = AV_CODEC_ID_HEVC,
+    .init           = eb_enc_init,
+    .send_frame     = eb_send_frame,
+    .receive_packet = eb_receive_packet,
+    .close          = eb_enc_close,
+    .capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AUTO_THREADS,
+    .pix_fmts       = (const enum AVPixelFormat[]){ AV_PIX_FMT_YUV420P,
+                                                    AV_PIX_FMT_YUV420P10,
+                                                    AV_PIX_FMT_NONE },
+    .priv_class     = &class,
+    .defaults       = eb_enc_defaults,
+    .caps_internal  = FF_CODEC_CAP_INIT_CLEANUP,
+    .wrapper_name   = "libsvt_hevc",
+};
+
diff -Nur FFmpeg/libavcodec/tests/.gitignore FFmpeg_patched/libavcodec/tests/.gitignore
--- FFmpeg/libavcodec/tests/.gitignore	2022-06-29 07:15:48.519919030 +0000
+++ FFmpeg_patched/libavcodec/tests/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,24 +0,0 @@
-/avfft
-/avpacket
-/cabac
-/celp_math
-/codec_desc
-/dct
-/fft
-/fft-fixed
-/fft-fixed32
-/golomb
-/h264_levels
-/h265_levels
-/htmlsubtitles
-/iirfilter
-/imgconvert
-/jpeg2000dwt
-/mathops
-/mjpegenc_huffman
-/motion
-/mpeg12framerate
-/options
-/rangecoder
-/snowenc
-/utils
diff -Nur FFmpeg/libavcodec/tile_encode_svt_impl.c FFmpeg_patched/libavcodec/tile_encode_svt_impl.c
--- FFmpeg/libavcodec/tile_encode_svt_impl.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavcodec/tile_encode_svt_impl.c	2022-06-29 07:16:09.515918781 +0000
@@ -0,0 +1,488 @@
+/*
+ * Intel tile encoder
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+#include <sys/time.h>
+#include <time.h>
+#include <stdio.h>
+#include <stdlib.h>
+
+#include <stdint.h>
+#include <string.h>
+
+#include "libavutil/attributes.h"
+#include "libavutil/avassert.h"
+#include "libavutil/dict.h"
+#include "libavutil/error.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/internal.h"
+#include "libavutil/log.h"
+#include "libavutil/mem.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/opt.h"
+#include "libavutil/common.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+
+#include "tile_encoder.h"
+#include "EbErrorCodes.h"
+#include "EbTime.h"
+#include "EbApi.h"
+
+#include <float.h>
+
+typedef struct SvtEncoder {
+    EB_H265_ENC_CONFIGURATION           enc_params;
+    EB_COMPONENTTYPE                    *svt_handle;
+    EB_BUFFERHEADERTYPE                 *in_buf;
+    EB_BUFFERHEADERTYPE                 *out_buf;
+    int                                  raw_size;
+} SvtEncoder;
+
+typedef struct SvtParams {
+    int vui_info;
+    int hierarchical_level;
+    int intra_period;
+    int la_depth;
+    int intra_ref_type;
+    int enc_mode;
+    int rc_mode;
+    int scd;
+    int tune;
+    int qp;
+    int profile;
+    int base_layer_switch_mode;
+    int bit_rate;
+    int intra_refresh_type;
+}SvtParams;
+
+typedef struct SvtContext {
+    SvtEncoder  *svt_enc;
+    SvtParams   svt_param;
+    int         eos_flag;
+    int         i;
+} SvtContext;
+
+static int error_mapping(int val)
+{
+    if (val == EB_ErrorInsufficientResources)
+        return AVERROR(ENOMEM);
+    if ((val == EB_ErrorUndefined) || (val == EB_ErrorInvalidComponent) ||
+        (val == EB_ErrorBadParameter))
+        return AVERROR(EINVAL);
+    return AVERROR_EXTERNAL;
+}
+
+static void free_buffer(SvtEncoder *svt_enc)
+{
+    if (svt_enc->in_buf) {
+        EB_H265_ENC_INPUT *in_data = (EB_H265_ENC_INPUT* )svt_enc->in_buf->pBuffer;
+        if (in_data) {
+            av_freep(&in_data);
+        }
+        av_freep(&svt_enc->in_buf);
+    }
+    av_freep(&svt_enc->out_buf);
+}
+
+static EB_ERRORTYPE alloc_buffer(EB_H265_ENC_CONFIGURATION *config, SvtEncoder *svt_enc)
+{
+    EB_ERRORTYPE       ret       = EB_ErrorNone;
+
+    const int    pack_mode_10bit   = (config->encoderBitDepth > 8) && (config->compressedTenBitFormat == 0) ? 1 : 0;
+    const size_t luma_size_8bit    = config->sourceWidth * config->sourceHeight * (1 << pack_mode_10bit);
+    const size_t luma_size_10bit   = (config->encoderBitDepth > 8 && pack_mode_10bit == 0) ? luma_size_8bit : 0;
+
+    svt_enc->raw_size = (luma_size_8bit + luma_size_10bit) * 3 / 2;
+
+    // allocate buffer for in and out
+    svt_enc->in_buf           = av_mallocz(sizeof(EB_BUFFERHEADERTYPE));
+    svt_enc->out_buf          = av_mallocz(sizeof(EB_BUFFERHEADERTYPE));
+    if (!svt_enc->in_buf || !svt_enc->out_buf)
+        goto failed;
+
+    svt_enc->in_buf->pBuffer  = av_mallocz(sizeof(EB_H265_ENC_INPUT));
+    if (!svt_enc->in_buf->pBuffer)
+        goto failed;
+
+    svt_enc->in_buf->nSize        = sizeof(EB_BUFFERHEADERTYPE);
+    svt_enc->in_buf->pAppPrivate  = NULL;
+    svt_enc->out_buf->nSize       = sizeof(EB_BUFFERHEADERTYPE);
+    svt_enc->out_buf->nAllocLen   = svt_enc->raw_size;
+    svt_enc->out_buf->pAppPrivate = NULL;
+
+    return ret;
+
+failed:
+    free_buffer(svt_enc);
+    return AVERROR(ENOMEM);
+
+
+}
+
+static EB_ERRORTYPE config_enc_params(EncoderWrapper* wrapper, int tile_idx, EB_H265_ENC_CONFIGURATION  *param )
+{
+    AVCodecContext *avctx = wrapper->avctx;
+    SvtContext *q       = (SvtContext *)wrapper->tile_info[tile_idx].enc_ctx;
+    SvtEncoder *svt_enc = q->svt_enc;
+    EB_ERRORTYPE    ret = EB_ErrorNone;
+    int         tenBits = 0;
+
+    param->sourceWidth     = wrapper->tile_info[tile_idx].tWidth;
+    param->sourceHeight    = wrapper->tile_info[tile_idx].tHeight;
+
+    if (avctx->pix_fmt == AV_PIX_FMT_YUV420P10LE) {
+        av_log(avctx, AV_LOG_DEBUG , "Encoder 10 bits depth input\n");
+        param->compressedTenBitFormat = 0;
+        tenBits = 1;
+    }
+
+    // Update param from options
+    param->hierarchicalLevels     = q->svt_param.hierarchical_level;
+    param->encMode                = q->svt_param.enc_mode;
+    param->intraRefreshType       = q->svt_param.intra_ref_type;
+    param->profile                = q->svt_param.profile;
+    param->rateControlMode        = q->svt_param.rc_mode;
+    param->sceneChangeDetection   = q->svt_param.scd;
+    param->tune                   = q->svt_param.tune;
+    param->baseLayerSwitchMode    = q->svt_param.base_layer_switch_mode;
+
+    param->targetBitRate          = q->svt_param.bit_rate;
+    param->frameRateNumerator     = avctx->time_base.den;
+    param->frameRateDenominator   = avctx->time_base.num * avctx->ticks_per_frame;
+    // Need to disable deblock filter to disable loop_filter_across_slices_enable_flag
+    param->disableDlfFlag         = 1;
+    param->enableSaoFlag          = 0;
+    // Make encoded bitstream has I/P frame only
+    param->intraPeriodLength      = q->svt_param.intra_period;
+    param->qp                     = q->svt_param.qp;
+    param->intraRefreshType       = q->svt_param.intra_refresh_type;
+
+    if (q->svt_param.vui_info)
+        param->videoUsabilityInfo = q->svt_param.vui_info;
+    if (q->svt_param.la_depth != -1)
+        param->lookAheadDistance  = q->svt_param.la_depth;
+
+    if (tenBits == 1) {
+        param->encoderBitDepth        = 10;
+        param->profile                = 2;
+    }
+
+    ret = alloc_buffer(param, svt_enc);
+
+    return ret;
+}
+
+static int eb_enc_init(EncoderWrapper* wrapper, int tile_idx)
+{
+    SvtContext* ctx = wrapper->tile_info[tile_idx].enc_ctx;
+
+    EB_ERRORTYPE ret = EB_ErrorNone;
+    SvtEncoder* svt_enc = NULL;
+
+    ctx->svt_enc  = av_mallocz(sizeof(*ctx->svt_enc));
+    if (!ctx->svt_enc)
+        return AVERROR(ENOMEM);
+
+    svt_enc = ctx->svt_enc;
+
+    ctx->eos_flag = 0;
+
+    ret = EbInitHandle(&svt_enc->svt_handle, ctx, &svt_enc->enc_params);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    ret = config_enc_params( wrapper, tile_idx, &svt_enc->enc_params);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    ret = EbH265EncSetParameter(svt_enc->svt_handle, &svt_enc->enc_params);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    ret = EbInitEncoder(svt_enc->svt_handle);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    return ret;
+
+failed_init:
+    return error_mapping(ret);
+}
+
+static void read_in_data(EB_H265_ENC_CONFIGURATION *config, const AVFrame* frame, EB_BUFFERHEADERTYPE *headerPtr)
+{
+    unsigned int is16bit = config->encoderBitDepth > 8;
+    unsigned long long lumaReadSize = (unsigned long long)config->sourceWidth * config->sourceHeight<< is16bit;
+    EB_H265_ENC_INPUT *in_data = (EB_H265_ENC_INPUT*)headerPtr->pBuffer;
+
+    
+    // support yuv420p and yuv420p010
+    in_data->luma = frame->data[0];
+    in_data->cb   = frame->data[1];
+    in_data->cr   = frame->data[2];
+    
+	// stride info
+    in_data->yStride  = frame->linesize[0] >> is16bit;
+    in_data->cbStride = frame->linesize[1] >> is16bit;
+    in_data->crStride = frame->linesize[2] >> is16bit;
+
+    headerPtr->nFilledLen   += lumaReadSize * 3/2u;
+
+}
+
+static int eb_send_frame(EncoderWrapper* wrapper, int tile_idx, const AVFrame *frame)
+{
+    SvtContext *q       = (SvtContext *)wrapper->tile_info[tile_idx].enc_ctx;
+    SvtEncoder           *svt_enc = q->svt_enc;
+    EB_BUFFERHEADERTYPE  *headerPtr = svt_enc->in_buf;
+
+    AVFrame* tile_pic = NULL;
+    int                  ret = 0;
+
+    if (!frame) {
+        EB_BUFFERHEADERTYPE headerPtrLast;
+        headerPtrLast.nAllocLen = 0;
+        headerPtrLast.nFilledLen = 0;
+        headerPtrLast.nTickCount = 0;
+        headerPtrLast.pAppPrivate = NULL;
+        //headerPtrLast.nOffset = 0;
+        //headerPtrLast.nTimeStamp = 0;
+        headerPtrLast.nFlags = EB_BUFFERFLAG_EOS;
+        headerPtrLast.pBuffer = NULL;
+        EbH265EncSendPicture(svt_enc->svt_handle, &headerPtrLast);
+        av_log(wrapper->avctx, AV_LOG_DEBUG, "========tile id = %d NULL frame!!!\n", tile_idx);
+        q->eos_flag = 1;
+        av_log(wrapper->avctx, AV_LOG_ERROR, "Finish sending frames!!!\n");
+        return ret;
+    }
+    get_tile_frame_nocopy(wrapper, tile_idx, frame, &tile_pic);
+    av_log(wrapper->avctx, AV_LOG_DEBUG, "------tile id = %d start frame address: y=%p, u=%p, v=%p!!!\n",
+                                          tile_idx, tile_pic->data[0], tile_pic->data[1], tile_pic->data[2]);
+
+    read_in_data(&svt_enc->enc_params, tile_pic, headerPtr);
+
+    //headerPtr->nOffset    = 0;
+    headerPtr->nFlags     = 0;
+    headerPtr->pAppPrivate = NULL;
+    headerPtr->pts        = frame->pts;
+    //headerPtr->nFlags     = 0;
+    //headerPtr->nTimeStamp = 0;
+    //headerPtr->pAppPrivate = NULL;
+    headerPtr->sliceType  = INVALID_SLICE;
+    q->i += 1;
+    av_log(wrapper->avctx, AV_LOG_DEBUG, "tile id = %d start to send frame, times = %d!!!\n", tile_idx, q->i);
+
+    EbH265EncSendPicture(svt_enc->svt_handle, headerPtr);
+
+    if(NULL!= tile_pic) av_frame_free(&tile_pic);
+    return ret;
+}
+
+static int eb_receive_packet(EncoderWrapper* wrapper, int tile_idx, AVPacket *pkt)
+{
+    SvtContext *q        = (SvtContext *)wrapper->tile_info[tile_idx].enc_ctx;
+    SvtEncoder  *svt_enc = q->svt_enc;
+    EB_BUFFERHEADERTYPE   *headerPtr = svt_enc->out_buf;
+    EB_ERRORTYPE          stream_status = EB_ErrorNone;
+    
+    int ret = 0;
+
+    //if ((ret = ff_alloc_packet2(wrapper->avctx, pkt, svt_enc->raw_size, 0)) < 0){
+    //    av_log(wrapper->avctx, AV_LOG_ERROR, "tile id = %d ff_alloc_packet2 ret = %d!!!\n", tile_idx, ret);
+    //    return ret;
+    //}
+    pkt->data = malloc(svt_enc->raw_size);
+    pkt->size = svt_enc->raw_size;
+
+    headerPtr->pBuffer = pkt->data;
+    stream_status = EbH265GetPacket(svt_enc->svt_handle, headerPtr, q->eos_flag);
+    if ((stream_status == EB_NoErrorEmptyQueue)){
+        av_log(wrapper->avctx, AV_LOG_DEBUG, "tile id = %d stream_status == EB_NoErrorEmptyQueue!!!\n", tile_idx);
+        return AVERROR(EAGAIN);
+    }
+    pkt->size = headerPtr->nFilledLen;
+    pkt->pts = headerPtr->pts;
+    pkt->dts = headerPtr->dts;
+    ret = (headerPtr->nFlags & EB_BUFFERFLAG_EOS) ? AVERROR_EOF : 0;
+    
+    av_log(wrapper->avctx, AV_LOG_DEBUG, "tile id = %d ret = %d!!!\n", tile_idx, ret);
+    return ret;
+}
+
+static av_cold int eb_enc_close(EncoderWrapper* wrapper, int tile_idx)
+{
+    SvtContext *q         = (SvtContext *)wrapper->tile_info[tile_idx].enc_ctx;
+    SvtEncoder *svt_enc   = q->svt_enc;
+
+    EbDeinitEncoder(svt_enc->svt_handle);
+    EbDeinitHandle(svt_enc->svt_handle);
+
+    free_buffer(svt_enc);
+    av_freep(&svt_enc);
+
+    return 0;
+}
+
+///encode each tile with SVT
+int svt_enc_close(void* ctx)
+{
+    EncoderWrapper* wrapper = (EncoderWrapper*)ctx;
+    SvtContext* svt_ctx = NULL;
+
+    for(int i=0; i<wrapper->tile_num; i++){
+        svt_ctx = (SvtContext*)wrapper->tile_info[i].enc_ctx;
+        if( NULL != svt_ctx){
+            eb_enc_close(wrapper, i);
+            free(svt_ctx);
+        }
+        wrapper->tile_info[i].enc_ctx = NULL;
+    }
+
+    return 0;
+}
+
+int svt_enc_init(void* ctx)
+{
+    EncoderWrapper* wrapper = (EncoderWrapper*)ctx;
+    SvtContext* svt_ctx = NULL;
+    int ret = 0;
+
+    for(int i=0; i<wrapper->tile_num; i++){
+        svt_ctx = malloc(sizeof(SvtContext));
+        svt_ctx->svt_param.hierarchical_level = 3;
+        svt_ctx->svt_param.enc_mode = 9;
+        svt_ctx->svt_param.intra_ref_type = 1;
+        svt_ctx->svt_param.profile = 2;
+        svt_ctx->svt_param.rc_mode = 0;//0-CQP, 1-VBR
+        svt_ctx->svt_param.qp = 32;
+        svt_ctx->svt_param.scd = 0;
+        svt_ctx->svt_param.tune = 1;
+        svt_ctx->svt_param.intra_period = 5;
+        svt_ctx->svt_param.base_layer_switch_mode = 0;
+        svt_ctx->svt_param.vui_info = 0;
+        svt_ctx->svt_param.la_depth = -1;
+        svt_ctx->svt_param.bit_rate = wrapper->tile_info[i].tBitrate;
+        svt_ctx->i = 0;
+        svt_ctx->svt_param.intra_refresh_type = 1;//1-CRA, 2-IDR intra refresh
+        wrapper->tile_info[i].enc_ctx = svt_ctx;
+        ret = eb_enc_init(wrapper, i);
+        if( 0 != ret ) return ret;
+    }
+    wrapper->initialized = 1;
+    return 0;
+}
+
+int svt_enc_frame(void* ctx, AVPacket *pkt, const AVFrame *pic, int *got_packet)
+{
+    EncoderWrapper* wrapper = (EncoderWrapper*)ctx;
+    SvtContext *q = NULL;
+
+    int ret = 0;
+
+    for(int i=0; i<wrapper->tile_num; i++){
+        q = (SvtContext *)wrapper->tile_info[i].enc_ctx;
+        if( wrapper->tile_info[i].eos ) continue;
+
+        if(!q->eos_flag) eb_send_frame( wrapper, i, pic );
+    }
+
+    // Wake up all receive tile threads
+    if(!q->eos_flag)
+    {
+        pthread_cond_broadcast(&(wrapper->cond));
+    }
+    else
+    {
+        // Wait until all tiles are ready
+        while(0==bFifoReady(wrapper))
+        {
+            pthread_cond_broadcast(&(wrapper->cond));
+            usleep(10000);
+        }
+    }
+
+    //FIXME, suppose all encoder has the rhythm to get packet, so there is no buffer in the first time
+
+    ret = bs_tile_stitching(wrapper, pkt);
+
+    if( AVERROR_EOF == ret ){
+        return AVERROR_EOF;
+    }
+    *got_packet = 1;
+
+    if( -1 == ret ) *got_packet = 0;
+
+    return 0;
+}
+
+int svt_enc_tile(TileEncoderInfo *tile_enc_info)
+{
+    int ret = 0;
+
+    EncoderWrapper *wrapper = (EncoderWrapper*)tile_enc_info->ctx;
+    int            tile_idx = tile_enc_info->tile_idx;
+
+    while(1)
+    {
+        if(wrapper->initialized)
+            break;
+    }
+
+    SvtContext          *q         = (SvtContext *)wrapper->tile_info[tile_idx].enc_ctx;
+    SvtEncoder          *svt_enc   = q->svt_enc;
+    EB_BUFFERHEADERTYPE *headerPtr = svt_enc->out_buf;
+
+    while(!wrapper->tile_info[tile_idx].eos)
+    {
+        // Wait until next frame is sent
+        if(!q->eos_flag)
+            pthread_cond_wait(&(wrapper->cond),&(wrapper->mutex));
+
+        AVPacket tile_pkts = {0};
+        ret = eb_receive_packet(wrapper, tile_idx, &tile_pkts);
+        av_log(wrapper->avctx, AV_LOG_DEBUG, "tile id = %d begin to eb_receive_packet!!!\n", tile_idx);
+        if( 0 == ret || AVERROR_EOF == ret ){
+            av_log(wrapper->avctx, AV_LOG_DEBUG, "**********tile id = %d eb_receive_packet got packet, packet size = %d, packet addr=%p!!!\n", tile_idx, tile_pkts.size, tile_pkts.data);
+            av_fifo_generic_write( wrapper->tile_info[tile_idx].outpkt_fifo, &tile_pkts, sizeof(AVPacket), NULL);
+#ifdef FILE_DEBUG
+            wrapper->tile_info[tile_idx].nGetpkt += 1;
+            //fwrite(tile_pkts.data, 1, tile_pkts.size, wrapper->tile_info[i].file);
+#endif
+            if( AVERROR_EOF == ret ){
+                av_log(wrapper->avctx, AV_LOG_ERROR, "tile id = %d EOS!!!\n", tile_idx);
+                wrapper->tile_info[tile_idx].eos = 1;
+            }
+        }else{
+            av_packet_unref(&tile_pkts);
+            free(tile_pkts.data);
+        }
+
+    }
+
+    // Wait until all tiles are done
+    while(AVERROR_EOF!=bFifoReady(wrapper))
+    {
+        pthread_cond_wait(&(wrapper->cond),&(wrapper->mutex));
+        usleep(10000);
+    }
+
+    return ret;
+}
diff -Nur FFmpeg/libavcodec/tile_encode_x265_impl.c FFmpeg_patched/libavcodec/tile_encode_x265_impl.c
--- FFmpeg/libavcodec/tile_encode_x265_impl.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavcodec/tile_encode_x265_impl.c	2022-06-29 07:16:09.475918781 +0000
@@ -0,0 +1,477 @@
+/*
+ * Intel tile encoder
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+
+#include <stdint.h>
+#include <string.h>
+
+#include "libavutil/attributes.h"
+#include "libavutil/avassert.h"
+#include "libavutil/dict.h"
+#include "libavutil/error.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/internal.h"
+#include "libavutil/log.h"
+#include "libavutil/mem.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/opt.h"
+#include "libavutil/common.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+
+#include "tile_encoder.h"
+#include <x265.h>
+#include <float.h>
+
+typedef struct x265Context {
+    x265_encoder   *encoder;
+    x265_param     *params;
+    const x265_api *api;
+
+    int            bit_rate;
+    int            rc_max_rate;
+
+    float          crf;
+    int            forced_idr;
+    char           *preset;
+    char           *tune;
+    char           *profile;
+    char           *x265_opts;
+
+} x265Context;
+
+///encode each tile with libx265
+static int is_keyframe(NalUnitType naltype)
+{
+    switch (naltype) {
+    case NAL_UNIT_CODED_SLICE_BLA_W_LP:
+    case NAL_UNIT_CODED_SLICE_BLA_W_RADL:
+    case NAL_UNIT_CODED_SLICE_BLA_N_LP:
+    case NAL_UNIT_CODED_SLICE_IDR_W_RADL:
+    case NAL_UNIT_CODED_SLICE_IDR_N_LP:
+    case NAL_UNIT_CODED_SLICE_CRA:
+        return 1;
+    default:
+        return 0;
+    }
+}
+
+static int x265_single_close( EncoderWrapper* wrapper, int tile_idx )
+{
+    x265Context* ctx = (x265Context*)wrapper->tile_info[tile_idx].enc_ctx;
+
+    ctx->api->param_free(ctx->params);
+
+    if (ctx->encoder)
+        ctx->api->encoder_close(ctx->encoder);
+
+    return 0;
+}
+
+static int x265_single_init( EncoderWrapper* wrapper, int tile_idx )
+{
+    x265Context* ctx = wrapper->tile_info[tile_idx].enc_ctx;
+    AVCodecContext* avctx = wrapper->avctx;
+
+    ctx->api = x265_api_get(av_pix_fmt_desc_get(avctx->pix_fmt)->comp[0].depth);
+    if (!ctx->api)
+        ctx->api = x265_api_get(0);
+
+    ctx->params = ctx->api->param_alloc();
+    if (!ctx->params) {
+        av_log(avctx, AV_LOG_ERROR, "Could not allocate x265 param structure.\n");
+        return AVERROR(ENOMEM);
+    }
+
+    if (ctx->api->param_default_preset(ctx->params, ctx->preset, ctx->tune) < 0) {
+        int i;
+
+        av_log(avctx, AV_LOG_ERROR, "Error setting preset/tune %s/%s.\n", ctx->preset, ctx->tune);
+        av_log(avctx, AV_LOG_INFO, "Possible presets:");
+        for (i = 0; x265_preset_names[i]; i++)
+            av_log(avctx, AV_LOG_INFO, " %s", x265_preset_names[i]);
+
+        av_log(avctx, AV_LOG_INFO, "\n");
+        av_log(avctx, AV_LOG_INFO, "Possible tunes:");
+        for (i = 0; x265_tune_names[i]; i++)
+            av_log(avctx, AV_LOG_INFO, " %s", x265_tune_names[i]);
+
+        av_log(avctx, AV_LOG_INFO, "\n");
+
+        return AVERROR(EINVAL);
+    }
+
+    ctx->params->frameNumThreads = avctx->thread_count;
+    ctx->params->fpsNum          = avctx->time_base.den;
+    ctx->params->fpsDenom        = avctx->time_base.num * avctx->ticks_per_frame;
+    ctx->params->sourceWidth     = wrapper->tile_info[tile_idx].tWidth;
+    ctx->params->sourceHeight    = wrapper->tile_info[tile_idx].tHeight;
+    ctx->params->bEnablePsnr     = !!(avctx->flags & AV_CODEC_FLAG_PSNR);
+    ctx->params->bOpenGOP        = !(avctx->flags & AV_CODEC_FLAG_CLOSED_GOP);
+
+    /* Tune the CTU size based on input resolution. */
+    if (ctx->params->sourceWidth < 64 || ctx->params->sourceHeight < 64)
+        ctx->params->maxCUSize = 32;
+    if (ctx->params->sourceWidth < 32 || ctx->params->sourceHeight < 32)
+        ctx->params->maxCUSize = 16;
+    if (ctx->params->sourceWidth < 16 || ctx->params->sourceHeight < 16) {
+        av_log(avctx, AV_LOG_ERROR, "Image size is too small (%dx%d).\n",
+               ctx->params->sourceWidth, ctx->params->sourceHeight);
+        return AVERROR(EINVAL);
+    }
+
+    if ((avctx->color_primaries <= AVCOL_PRI_SMPTE432 &&
+         avctx->color_primaries != AVCOL_PRI_UNSPECIFIED) ||
+        (avctx->color_trc <= AVCOL_TRC_ARIB_STD_B67 &&
+         avctx->color_trc != AVCOL_TRC_UNSPECIFIED) ||
+        (avctx->colorspace <= AVCOL_SPC_ICTCP &&
+         avctx->colorspace != AVCOL_SPC_UNSPECIFIED)) {
+
+        ctx->params->vui.bEnableVideoSignalTypePresentFlag  = 1;
+        ctx->params->vui.bEnableColorDescriptionPresentFlag = 1;
+
+        // x265 validates the parameters internally
+        ctx->params->vui.colorPrimaries          = avctx->color_primaries;
+        ctx->params->vui.transferCharacteristics = avctx->color_trc;
+        ctx->params->vui.matrixCoeffs            = avctx->colorspace;
+    }
+
+    if (avctx->sample_aspect_ratio.num > 0 && avctx->sample_aspect_ratio.den > 0) {
+        char sar[12];
+        int sar_num, sar_den;
+
+        av_reduce(&sar_num, &sar_den,
+                  avctx->sample_aspect_ratio.num,
+                  avctx->sample_aspect_ratio.den, 65535);
+        snprintf(sar, sizeof(sar), "%d:%d", sar_num, sar_den);
+        if (ctx->api->param_parse(ctx->params, "sar", sar) == X265_PARAM_BAD_VALUE) {
+            av_log(avctx, AV_LOG_ERROR, "Invalid SAR: %d:%d.\n", sar_num, sar_den);
+            return AVERROR_INVALIDDATA;
+        }
+    }
+
+    switch (avctx->pix_fmt) {
+    case AV_PIX_FMT_YUV420P:
+    case AV_PIX_FMT_YUV420P10:
+    case AV_PIX_FMT_YUV420P12:
+        ctx->params->internalCsp = X265_CSP_I420;
+        break;
+    case AV_PIX_FMT_YUV422P:
+    case AV_PIX_FMT_YUV422P10:
+    case AV_PIX_FMT_YUV422P12:
+        ctx->params->internalCsp = X265_CSP_I422;
+        break;
+    case AV_PIX_FMT_GBRP:
+    case AV_PIX_FMT_GBRP10:
+    case AV_PIX_FMT_GBRP12:
+        ctx->params->vui.matrixCoeffs = AVCOL_SPC_RGB;
+        ctx->params->vui.bEnableVideoSignalTypePresentFlag  = 1;
+        ctx->params->vui.bEnableColorDescriptionPresentFlag = 1;
+    case AV_PIX_FMT_YUV444P:
+    case AV_PIX_FMT_YUV444P10:
+    case AV_PIX_FMT_YUV444P12:
+        ctx->params->internalCsp = X265_CSP_I444;
+        break;
+    case AV_PIX_FMT_GRAY8:
+    case AV_PIX_FMT_GRAY10:
+    case AV_PIX_FMT_GRAY12:
+        if (ctx->api->api_build_number < 85) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "libx265 version is %d, must be at least 85 for gray encoding.\n",
+                   ctx->api->api_build_number);
+            return AVERROR_INVALIDDATA;
+        }
+        ctx->params->internalCsp = X265_CSP_I400;
+        break;
+    }
+
+    if (ctx->crf >= 0) {
+        char crf[6];
+
+        snprintf(crf, sizeof(crf), "%2.2f", ctx->crf);
+        if (ctx->api->param_parse(ctx->params, "crf", crf) == X265_PARAM_BAD_VALUE) {
+            av_log(avctx, AV_LOG_ERROR, "Invalid crf: %2.2f.\n", ctx->crf);
+            return AVERROR(EINVAL);
+        }
+    } else if (ctx->bit_rate > 0) {
+        ctx->params->rc.bitrate         = ctx->bit_rate / 1000;
+        ctx->params->rc.rateControlMode = X265_RC_ABR;
+    }
+
+    ctx->params->rc.vbvBufferSize = ctx->bit_rate * 2 / 3000;
+    ctx->params->rc.vbvMaxBitrate = ctx->rc_max_rate    / 1000;
+
+    if (!(avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER))
+        ctx->params->bRepeatHeaders = 1;
+
+    if (ctx->x265_opts) {
+        AVDictionary *dict    = NULL;
+        AVDictionaryEntry *en = NULL;
+
+        if (!av_dict_parse_string(&dict, ctx->x265_opts, "=", ":", 0)) {
+            while ((en = av_dict_get(dict, "", en, AV_DICT_IGNORE_SUFFIX))) {
+                int parse_ret = ctx->api->param_parse(ctx->params, en->key, en->value);
+
+                switch (parse_ret) {
+                case X265_PARAM_BAD_NAME:
+                    av_log(avctx, AV_LOG_WARNING,
+                          "Unknown option: %s.\n", en->key);
+                    break;
+                case X265_PARAM_BAD_VALUE:
+                    av_log(avctx, AV_LOG_WARNING,
+                          "Invalid value for %s: %s.\n", en->key, en->value);
+                    break;
+                default:
+                    break;
+                }
+            }
+            av_dict_free(&dict);
+        }
+    }
+
+    if (ctx->params->rc.vbvBufferSize && avctx->rc_initial_buffer_occupancy > 1000 &&
+        ctx->params->rc.vbvBufferInit == 0.9) {
+        ctx->params->rc.vbvBufferInit = (float)avctx->rc_initial_buffer_occupancy / 1000;
+    }
+
+    if (ctx->profile) {
+        if (ctx->api->param_apply_profile(ctx->params, ctx->profile) < 0) {
+            int i;
+            av_log(avctx, AV_LOG_ERROR, "Invalid or incompatible profile set: %s.\n", ctx->profile);
+            av_log(avctx, AV_LOG_INFO, "Possible profiles:");
+            for (i = 0; x265_profile_names[i]; i++)
+                av_log(avctx, AV_LOG_INFO, " %s", x265_profile_names[i]);
+            av_log(avctx, AV_LOG_INFO, "\n");
+            return AVERROR(EINVAL);
+        }
+    }
+
+    ctx->encoder = ctx->api->encoder_open(ctx->params);
+    if (!ctx->encoder) {
+        av_log(avctx, AV_LOG_ERROR, "Cannot open libx265 encoder.\n");
+        x265_single_close(wrapper, tile_idx);
+        return AVERROR_INVALIDDATA;
+    }
+
+/*    if (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {
+        x265_nal *nal;
+        int nnal;
+
+        avctx->extradata_size = ctx->api->encoder_headers(ctx->encoder, &nal, &nnal);
+        if (avctx->extradata_size <= 0) {
+            av_log(avctx, AV_LOG_ERROR, "Cannot encode headers.\n");
+            libx265_encode_close(avctx);
+            return AVERROR_INVALIDDATA;
+        }
+
+        avctx->extradata = av_malloc(avctx->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);
+        if (!avctx->extradata) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Cannot allocate HEVC header of size %d.\n", avctx->extradata_size);
+            libx265_encode_close(avctx);
+            return AVERROR(ENOMEM);
+        }
+
+        memcpy(avctx->extradata, nal[0].payload, avctx->extradata_size);
+    }
+*/
+    return 0;
+}
+
+static int x265_single_frame( EncoderWrapper* wrapper, int tile_idx, AVPacket *pkt, const AVFrame *pic, int *got_packet  )
+{
+    x265Context* ctx = (x265Context*)wrapper->tile_info[tile_idx].enc_ctx;
+    AVCodecContext* avctx = wrapper->avctx;
+    AVFrame* tile_pic = NULL;
+    x265_picture x265pic;
+    x265_picture x265pic_out = { 0 };
+    x265_nal *nal;
+    uint8_t *dst;
+    int payload = 0;
+    int nnal;
+    int ret;
+    int i;
+
+    ctx->api->picture_init(ctx->params, &x265pic);
+
+    if (pic) {
+        get_tile_frame_nocopy(wrapper, tile_idx, pic, &tile_pic);
+
+        for (i = 0; i < 3; i++) {
+           x265pic.planes[i] = tile_pic->data[i];
+           x265pic.stride[i] = tile_pic->linesize[i];
+        }
+
+        x265pic.pts      = pic->pts;
+        x265pic.bitDepth = av_pix_fmt_desc_get(avctx->pix_fmt)->comp[0].depth;
+
+        x265pic.sliceType = pic->pict_type == AV_PICTURE_TYPE_I ?
+                                              (ctx->forced_idr ? X265_TYPE_IDR : X265_TYPE_I) :
+                            pic->pict_type == AV_PICTURE_TYPE_P ? X265_TYPE_P :
+                            pic->pict_type == AV_PICTURE_TYPE_B ? X265_TYPE_B :
+                            X265_TYPE_AUTO;
+    }
+
+    ret = ctx->api->encoder_encode(ctx->encoder, &nal, &nnal,
+                                   pic ? &x265pic : NULL, &x265pic_out);
+
+    if(NULL!= tile_pic) av_frame_free(&tile_pic);
+
+    if (ret < 0)
+        return AVERROR_EXTERNAL;
+
+    if (!nnal)
+        return 0;
+
+    ///FIXME, need to assign each NAL to a packet if stitching library can only process one NAL
+    for (i = 0; i < nnal; i++)
+        payload += nal[i].sizeBytes;
+
+    /*ret = ff_alloc_packet2(avctx, pkt, payload, payload);
+    if (ret < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Error getting output packet.\n");
+        return ret;
+    }*/
+    pkt->data = malloc(payload);
+    pkt->size = payload;
+    dst = pkt->data;
+
+    for (i = 0; i < nnal; i++) {
+        memcpy(dst, nal[i].payload, nal[i].sizeBytes);
+        dst += nal[i].sizeBytes;
+
+        if (is_keyframe(nal[i].type))
+            pkt->flags |= AV_PKT_FLAG_KEY;
+    }
+
+    pkt->pts = x265pic_out.pts;
+    pkt->dts = x265pic_out.dts;
+
+#if FF_API_CODED_FRAME
+FF_DISABLE_DEPRECATION_WARNINGS
+    switch (x265pic_out.sliceType) {
+    case X265_TYPE_IDR:
+    case X265_TYPE_I:
+        avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;
+        break;
+    case X265_TYPE_P:
+        avctx->coded_frame->pict_type = AV_PICTURE_TYPE_P;
+        break;
+    case X265_TYPE_B:
+        avctx->coded_frame->pict_type = AV_PICTURE_TYPE_B;
+        break;
+    }
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+
+#if X265_BUILD >= 130
+    if (x265pic_out.sliceType == X265_TYPE_B)
+#else
+    if (x265pic_out.frameData.sliceType == 'b')
+#endif
+        pkt->flags |= AV_PKT_FLAG_DISPOSABLE;
+
+    *got_packet = 1;
+
+    return 0;
+}
+
+int libx265_enc_close(void* ctx)
+{
+    EncoderWrapper* wrapper = (EncoderWrapper*)ctx;
+    x265Context* x265_ctx = NULL;
+    
+    for(int i=0; i<wrapper->tile_num; i++){
+        x265_ctx = (x265Context*)wrapper->tile_info[i].enc_ctx;
+        if( NULL != x265_ctx){
+            x265_single_close(wrapper, i);
+            free(x265_ctx);
+        }
+        wrapper->tile_info[i].enc_ctx = NULL;
+    }
+    
+    return 0;
+}
+
+int libx265_enc_init(void* ctx)
+{
+    EncoderWrapper* wrapper = (EncoderWrapper*)ctx;
+    x265Context* x265_ctx = NULL;
+    
+    for(int i=0; i<wrapper->tile_num; i++){
+        x265_ctx = malloc(sizeof(x265Context));
+        x265_ctx->api         = NULL;
+        x265_ctx->encoder     = NULL;
+        x265_ctx->x265_opts   = wrapper->enc_param;
+        x265_ctx->preset      = "fast";
+        x265_ctx->tune        = "psnr";
+        x265_ctx->crf         = -1;
+        x265_ctx->profile     = "main";
+        x265_ctx->forced_idr  = 0;
+        x265_ctx->bit_rate    = wrapper->tile_info[i].tBitrate;
+        x265_ctx->rc_max_rate = wrapper->tile_info[i].tMaxrate;
+        wrapper->tile_info[i].enc_ctx = x265_ctx;
+        x265_single_init(wrapper, i);
+    }
+    return 0;
+}
+
+int libx265_enc_frame(void* ctx, AVPacket *pkt, const AVFrame *pic, int *got_packet)
+{
+    EncoderWrapper* wrapper = (EncoderWrapper*)ctx;
+    int ret = 0;
+    int       got_pkt = 0;
+    
+    for(int i=0; i<wrapper->tile_num; i++){
+        if( wrapper->tile_info[i].eos ) continue;
+        got_pkt = 0;
+        AVPacket tile_pkts = {0};
+        
+        ret = x265_single_frame(wrapper, i, &tile_pkts, pic, &got_pkt);
+
+        if( got_pkt ){
+            av_log(wrapper->avctx, AV_LOG_DEBUG, "**********tile id = %d receive_packet got packet!!!\n", i);
+            av_fifo_generic_write( wrapper->tile_info[i].outpkt_fifo, &tile_pkts, sizeof(AVPacket), NULL);
+        }else{
+            av_packet_unref(&tile_pkts);
+            free(tile_pkts.data);
+        }
+        if( NULL==pic && !got_pkt ){
+            av_log(wrapper->avctx, AV_LOG_DEBUG, "tile id = %d EOS!!!\n", i);
+            wrapper->tile_info[i].eos = 1;
+        }
+    }
+
+    //FIXME, suppose all encoder has the rhythm to get packet, so there is no buffer in the first time 
+    ret = bs_tile_stitching(wrapper, pkt);
+
+    if( AVERROR_EOF == ret ){
+        return AVERROR_EOF;
+    }
+    *got_packet = 1;
+    
+    if( -1 == ret ) *got_packet = 0;
+    
+    return 0;
+}
\ No newline at end of file
diff -Nur FFmpeg/libavcodec/tile_encoder.c FFmpeg_patched/libavcodec/tile_encoder.c
--- FFmpeg/libavcodec/tile_encoder.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavcodec/tile_encoder.c	2022-06-29 07:16:09.395918782 +0000
@@ -0,0 +1,586 @@
+/*
+ * Intel tile encoder
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <stdint.h>
+#include <string.h>
+
+#include "libavutil/attributes.h"
+#include "libavutil/avassert.h"
+#include "libavutil/dict.h"
+#include "libavutil/error.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/internal.h"
+#include "libavutil/log.h"
+#include "libavutil/mem.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/opt.h"
+
+#include "tile_encoder.h"
+
+//pthread_mutex_t mutex;
+//pthread_cond_t cond;
+
+typedef struct TileEncoderContext {
+    const AVClass *class;
+    EncoderWrapper api;
+    enum ENC_LIB   enc_lib;
+    enum TILE_MODE tile_mode;
+    
+    //for average size tile, the input just give the layout, such as 3x3, 4x4
+    int            tiles_gw;
+    int            tiles_gh;
+    
+    //for fix size tile, the last one of colum or row is not the fixed value
+    int            fix_tiles_w;
+    int            fix_tiles_h;
+    char          *params;
+} TileEncoderContext;
+
+// Support fix size tile
+static int assign_tiles_fix( TileEncoderContext* ctx )
+{
+    EncoderWrapper* wrapper = &(ctx->api);
+
+    int *tiles_col_width, *tiles_row_height;
+    tiles_col_width = (int *)malloc(ctx->tiles_gw * sizeof(int));
+    tiles_row_height = (int *)malloc(ctx->tiles_gh * sizeof(int));
+    for (int i=0;i<ctx->tiles_gw - 1;i++)tiles_col_width[i]=ctx->fix_tiles_w;
+    for (int i=0;i<ctx->tiles_gh - 1;i++)tiles_row_height[i]=ctx->fix_tiles_h;
+
+    wrapper->tile_num = ctx->tiles_gw * ctx->tiles_gh;
+    wrapper->tile_w = ctx->tiles_gw;
+    wrapper->tile_h = ctx->tiles_gh;
+
+    for(int i = 0; i < ctx->tiles_gh; i++)
+    {
+        for(int j = 0; j < ctx->tiles_gw; j++)
+        {
+            int idx = i * ctx->tiles_gw + j;
+            wrapper->tile_info[idx].left    = (j == 0) ? 0 : wrapper->tile_info[idx - 1].left + tiles_col_width[j-1];
+            wrapper->tile_info[idx].top     = (i == 0) ? 0 : wrapper->tile_info[(i-1)*ctx->tiles_gw + j].top + tiles_row_height[i-1];
+            wrapper->tile_info[idx].tHeight = (i == ctx->tiles_gh - 1) ? wrapper->height - wrapper->tile_info[idx].top : tiles_row_height[i];
+            wrapper->tile_info[idx].tWidth  = (j == ctx->tiles_gw - 1) ? wrapper->width - wrapper->tile_info[idx].left : tiles_col_width[j];
+        }
+    }
+
+    if(tiles_col_width)
+    {
+        free(tiles_col_width);
+        tiles_col_width = NULL;
+    }
+    if(tiles_row_height)
+    {
+        free(tiles_row_height);
+        tiles_row_height = NULL;
+    }
+
+    return 0;
+}
+static int assign_tiles_avg( TileEncoderContext* ctx )
+{
+    EncoderWrapper* wrapper = &(ctx->api);
+
+    wrapper->tile_num = ctx->tiles_gw * ctx->tiles_gh;
+    wrapper->tile_w = ctx->tiles_gw;
+    wrapper->tile_h = ctx->tiles_gh;
+
+#define LCU_SIZE 64
+
+    // Width and Height should be divisible by LCU_SIZE
+    int width_in_lcu = wrapper->width / LCU_SIZE;
+    int height_in_lcu = wrapper->height / LCU_SIZE;
+
+    // (6.5.1) in Rec. ITU-T H.265 v5 (02/2018)
+    int *tiles_col_width, *tiles_row_height;
+    tiles_col_width = (int *)malloc(ctx->tiles_gw * sizeof(int));
+    tiles_row_height = (int *)malloc(ctx->tiles_gh * sizeof(int));
+    for( int i=0; i<ctx->tiles_gw; i++)
+    {
+        tiles_col_width[i] = (i+1) * width_in_lcu / ctx->tiles_gw - i * width_in_lcu / ctx->tiles_gw;
+    }
+    for( int i=0; i<ctx->tiles_gh; i++)
+    {
+        tiles_row_height[i] = (i+1) * height_in_lcu / ctx->tiles_gh - i * height_in_lcu / ctx->tiles_gh;
+
+    }
+
+    for(int i = 0; i < ctx->tiles_gh; i++)
+    {
+        for(int j = 0; j < ctx->tiles_gw; j++)
+        {
+            int idx = i * ctx->tiles_gw + j;
+            wrapper->tile_info[idx].left    = (j == 0) ? 0 : wrapper->tile_info[idx - 1].left + tiles_col_width[j-1] * LCU_SIZE;
+            wrapper->tile_info[idx].top     = (i == 0) ? 0 : wrapper->tile_info[(i-1)*ctx->tiles_gw + j].top + tiles_row_height[i-1] * LCU_SIZE;
+            wrapper->tile_info[idx].tHeight = tiles_row_height[i] * LCU_SIZE;
+            wrapper->tile_info[idx].tWidth  = tiles_col_width[j] * LCU_SIZE;
+        }
+    }
+
+    if(tiles_col_width)
+    {
+        free(tiles_col_width);
+        tiles_col_width = NULL;
+    }
+    if(tiles_row_height)
+    {
+        free(tiles_row_height);
+        tiles_row_height = NULL;
+    }
+
+    return 0;
+}
+
+/// assign bit rate for each tile.
+int get_tile_bitrate(EncoderWrapper* wrapper, int idx)
+{
+    int bit_rate = wrapper->avctx->bit_rate;
+    double percent = 0.0;
+
+    if( 0==bit_rate ) bit_rate = wrapper->avctx->bit_rate_tolerance;
+
+    ///FIXME if there is more suitable way to calculate bit rate for each tile
+    percent = (double)( wrapper->tile_info[idx].tHeight * wrapper->tile_info[idx].tWidth ) / (double)(wrapper->width * wrapper->height);
+
+    return (int) (bit_rate * percent);
+
+ }
+
+int get_tile_maxrate(EncoderWrapper* wrapper, int idx)
+{
+    int max_rate = wrapper->avctx->rc_max_rate;
+
+    ///FIXME if there is more suitable way to calculate bit rate for each tile
+    double percent = (double)( wrapper->tile_info[idx].tHeight * wrapper->tile_info[idx].tWidth ) / (double)(wrapper->width * wrapper->height);
+
+    return (int) (max_rate * percent);
+
+}
+
+int bFifoReady( EncoderWrapper* wrapper )
+{
+    int eos = 0;
+    int ready = 0;
+    for(int i=0; i<wrapper->tile_num; i++){
+        if( wrapper->tile_info[i].outpkt_fifo ){
+            if( av_fifo_size(wrapper->tile_info[i].outpkt_fifo) ){
+                ready++;
+            }else{
+                if(wrapper->tile_info[i].eos) eos++;
+            }
+        }
+    }
+    if( ready == wrapper->tile_num ) return 1;
+    if( eos == wrapper->tile_num ) return AVERROR_EOF;
+
+    return 0;
+}
+int bs_tile_stitching(EncoderWrapper* wrapper, AVPacket* outPkt)
+{
+    int ret = 0;
+    AVPacket pkt[MAX_TILES];
+    int bReady = bFifoReady(wrapper);
+    int totalsize=0;
+    uint8_t* dst = NULL;
+    if( AVERROR_EOF == bReady ) return AVERROR_EOF;
+
+    if( 1 == bReady ){
+        for(int i=0; i<wrapper->tile_num; i++){
+            av_fifo_generic_read( wrapper->tile_info[i].outpkt_fifo, &pkt[i],  sizeof(AVPacket),  NULL);
+#ifdef FILE_DEBUG
+            wrapper->tile_info[i].nSpkt += 1;
+            av_log(wrapper->avctx, AV_LOG_DEBUG, "######tile id=%d, getpkt=%d, stitched packet=%d#########\n", i, wrapper->tile_info[i].nGetpkt, wrapper->tile_info[i].nSpkt);
+            av_log(wrapper->avctx, AV_LOG_DEBUG, "**********tile id = %d, packet size = %d, packet addr=%p!!!\n", i,pkt[i].size, pkt[i].data);
+#endif
+            totalsize += pkt[i].size;
+        }
+
+        // Sometimes the size of output is larger than size of input,
+        // so we alloc 2 times larger size packet.
+        ret = ff_alloc_packet2(wrapper->avctx, outPkt, 2*totalsize, 2*totalsize);
+        if( ret < 0) return -1;
+
+        dst = outPkt->data;
+
+        // call stitching library
+        wrapper->paramTiledStream.pOutputTiledBitstream = dst;
+
+        for (int i = 0; i < wrapper->paramTiledStream.tilesHeightCount; i++)
+        {
+            for (int j = 0; j < wrapper->paramTiledStream.tilesWidthCount; j++)
+            {
+                param_oneStream_info *ptempinput = wrapper->paramTiledStream.pTiledBitstream[i*wrapper->paramTiledStream.tilesWidthCount + j];
+                ptempinput->pTiledBitstreamBuffer = pkt[i*wrapper->paramTiledStream.tilesWidthCount + j].data;
+                ptempinput->inputBufferLen = pkt[i*wrapper->paramTiledStream.tilesWidthCount + j].size;
+            }
+        }
+
+        wrapper->paramTiledStream.inputBistreamsLen = totalsize;
+        genTiledStream_process(&(wrapper->paramTiledStream), wrapper->pGen);
+        dst += wrapper->paramTiledStream.outputiledbistreamlen;
+        outPkt->size = wrapper->paramTiledStream.outputiledbistreamlen;
+/*
+#ifdef FILE_DEBUG
+        for(int i=0; i<wrapper->tile_num; i++){
+            memcpy(dst, pkt[i].data, pkt[i].size);
+            dst += pkt[i].size;
+            fwrite(pkt[i].data, 1, pkt[i].size, wrapper->tile_info[i].file);
+        }
+#endif
+*/
+        // Send vps+sps+pps info
+        AVCodecContext* avctx = wrapper->avctx;
+        if(avctx->extradata_size == 0)
+        {
+            unsigned char *headerAddr;
+            avctx->extradata_size = genTiledStream_getParam(wrapper->pGen, ID_GEN_TILED_BITSTREAMS_HEADER, &headerAddr);
+            avctx->extradata = av_malloc(avctx->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);
+            if (!avctx->extradata) {
+                av_log(avctx, AV_LOG_ERROR,
+                       "Cannot allocate HEVC header of size %d.\n", avctx->extradata_size);
+                return AVERROR(ENOMEM);
+            }
+            memcpy(avctx->extradata, headerAddr, avctx->extradata_size);
+        }
+
+        switch (wrapper->paramTiledStream.sliceType) {
+        case SLICE_IDR:
+        case SLICE_I:
+            avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;
+            break;
+        case SLICE_P:
+            avctx->coded_frame->pict_type = AV_PICTURE_TYPE_P;
+            break;
+        case SLICE_B:
+            avctx->coded_frame->pict_type = AV_PICTURE_TYPE_B;
+            break;
+        }
+
+        //outPkt->pts = paramTiledStream.pts;
+
+        ///unref the packet read from fifo
+        for(int i=0; i<wrapper->tile_num; i++){
+            av_packet_unref(&pkt[i]);
+            free(pkt[i].data);
+        }
+
+        return 0;
+    }
+    return -1;
+}
+
+int get_tile_frame_copy(EncoderWrapper* wrapper, int tile_idx, const AVFrame *pic, AVFrame** tile_pic )
+{
+    int ret = 0;
+    uint8_t* src = NULL;
+    uint8_t* dst = NULL;
+    int factor = 1;
+    AVFrame* frame = NULL;
+
+    if( NULL == *tile_pic ){
+        *tile_pic = av_frame_alloc();
+        if (!*tile_pic) {
+            av_freep(*tile_pic);
+            return AVERROR(ENOMEM);
+        }
+    }
+
+    frame = *tile_pic;
+    frame->height = wrapper->tile_info[tile_idx].tHeight;
+    frame->width  = wrapper->tile_info[tile_idx].tWidth;
+
+    frame->format = pic->format;
+
+    if (!frame->data[0]) {
+        ret = av_frame_get_buffer(frame, 32);
+        if (ret < 0){
+            av_freep(*tile_pic);
+            return ret;
+        }
+    }
+
+    ///current copy is based on YUV420p format
+    for( int planner=0; planner<3; planner++ ){
+        if( planner > 0 ){
+            factor = 2;
+        }
+        src = pic->data[planner] + pic->linesize[planner]*(wrapper->tile_info[tile_idx].top / factor) + wrapper->tile_info[tile_idx].left / factor;
+        dst = frame->data[planner];
+        for( int i=0; i<frame->height/factor; i++ ){
+            src += pic->linesize[planner];
+            dst += frame->linesize[planner];
+            memcpy( dst, src, frame->width / factor );
+        }
+    }
+
+    return ret;
+}
+
+int get_tile_frame_nocopy(EncoderWrapper* wrapper, int tile_idx, const AVFrame *pic, AVFrame** tile_pic )
+{
+    AVFrame* frame = NULL;
+    int factor = 1;
+
+    if( NULL == *tile_pic ){
+        *tile_pic = av_frame_alloc();
+        if (!*tile_pic) {
+            av_freep(*tile_pic);
+            return AVERROR(ENOMEM);
+        }
+    }
+
+    frame = *tile_pic;
+    frame->height = wrapper->tile_info[tile_idx].tHeight;
+    frame->width = wrapper->tile_info[tile_idx].tWidth;
+    frame->format = pic->format;
+
+    for( int i=0; i<4; i++ ){
+        if( i > 0 ){
+            factor = 2;
+        }
+        frame->data[i] = pic->data[i] + pic->linesize[i]*(wrapper->tile_info[tile_idx].top / factor) + wrapper->tile_info[tile_idx].left / factor;
+        frame->linesize[i] = pic->linesize[i];
+    }
+
+    return 0;
+}
+
+static av_cold int tile_encode_close(AVCodecContext *avctx)
+{
+    TileEncoderContext *ctx = avctx->priv_data;
+    EncoderWrapper *wrapper = &(ctx->api);
+    AVFifoBuffer* fifo = NULL;
+
+    if(wrapper->pGen)
+    {
+        genTiledStream_unInit(wrapper->pGen);
+    }
+
+    if (wrapper->paramTiledStream.pTiledBitstream)
+    {
+        for (int i = 0; i < wrapper->paramTiledStream.tilesHeightCount; i++)
+        {
+            for (int j = 0; j < wrapper->paramTiledStream.tilesWidthCount; j++)
+            {
+                free(wrapper->paramTiledStream.pTiledBitstream[i*wrapper->paramTiledStream.tilesWidthCount + j]);
+                wrapper->paramTiledStream.pTiledBitstream[i*wrapper->paramTiledStream.tilesWidthCount + j] = NULL;
+            }
+        }
+        free(wrapper->paramTiledStream.pTiledBitstream);
+        wrapper->paramTiledStream.pTiledBitstream = NULL;
+    }
+    if(avctx->extradata)
+    {
+        free(avctx->extradata);
+        avctx->extradata = NULL;
+    }
+
+    if(wrapper->tid)
+    {
+        free(wrapper->tid);
+        wrapper->tid = NULL;
+    }
+    if(wrapper->tile_enc_info)
+    {
+        free(wrapper->tile_enc_info);
+        wrapper->tile_enc_info = NULL;
+    }
+
+    if( NULL != ctx->api.enc_close )
+        ctx->api.enc_close(&(ctx->api));
+
+    for( int i=0; i < ctx->api.tile_num; i++ ){
+
+#ifdef FILE_DEBUG
+        if(ctx->api.tile_info[i].file) fclose(ctx->api.tile_info[i].file);
+#endif
+
+        fifo = ctx->api.tile_info[i].outpkt_fifo;
+        while ( fifo && av_fifo_size(fifo)) {
+            AVPacket pkt;
+            av_fifo_generic_read(fifo, &pkt,  sizeof(pkt),  NULL);
+            free(pkt.data);
+            av_packet_unref(&pkt);
+        }
+        av_fifo_free(fifo);
+        fifo = NULL;
+    }
+    return 0;
+}
+
+static av_cold int tile_encode_init(AVCodecContext *avctx)
+{
+    TileEncoderContext *ctx = avctx->priv_data;
+    EncoderWrapper* wrapper = &(ctx->api);
+    int ret = 0;
+    char filename[256];
+
+    wrapper->width = avctx->coded_width;
+    wrapper->height = avctx->coded_height;
+
+    wrapper->avctx = avctx;
+    switch(ctx->tile_mode){
+        case FIX_SIZE:
+            wrapper->uniform_split = false;
+            assign_tiles_fix( ctx );
+            break;
+        case AVG_SIZE:
+            wrapper->uniform_split = true;
+            assign_tiles_avg( ctx );
+            break;
+        default:
+            break;
+    }
+
+
+    switch(ctx->enc_lib){
+        case ENC_X265:
+            wrapper->enc_close = libx265_enc_close;
+            wrapper->enc_frame = libx265_enc_frame;
+            wrapper->enc_init  = libx265_enc_init;
+            break;
+        case ENC_SVT:
+            wrapper->enc_close = svt_enc_close;
+            wrapper->enc_frame = svt_enc_frame;
+            wrapper->enc_init  = svt_enc_init;
+            break;
+        default:
+            break;
+    }
+
+    pthread_mutex_init(&(wrapper->mutex), NULL);
+    pthread_cond_init(&(wrapper->cond), NULL);
+    wrapper->tid = malloc(wrapper->tile_num * sizeof(pthread_t));
+    wrapper->tile_enc_info = malloc(wrapper->tile_num * sizeof(TileEncoderInfo));
+    for(int i=0; i<wrapper->tile_num; i++){
+        wrapper->tile_info[i].tBitrate = get_tile_bitrate(wrapper, i);
+        wrapper->tile_info[i].tMaxrate = get_tile_maxrate(wrapper, i);
+        wrapper->tile_info[i].eos = 0;
+        wrapper->tile_info[i].outpkt_fifo = av_fifo_alloc( FIFO_SIZE * sizeof(AVPacket));
+#ifdef FILE_DEBUG
+        wrapper->tile_info[i].nGetpkt = 0;
+        wrapper->tile_info[i].nSpkt = 0;
+        sprintf(filename, "out_%d.265", i);
+        wrapper->tile_info[i].file = fopen(filename, "wb+");
+#endif
+        wrapper->tile_enc_info[i].ctx      = wrapper;
+        wrapper->tile_enc_info[i].tile_idx = i;
+
+        ret = pthread_create(&wrapper->tid[i], NULL, svt_enc_tile, &(wrapper->tile_enc_info[i]));
+        if(0 != ret)
+        {
+            av_log(avctx, AV_LOG_ERROR, "Cannot create thread!\n");
+            return ret;
+        }
+    }
+
+    if( NULL != ctx->api.enc_init ){
+        ret = wrapper->enc_init(wrapper);
+        if( 0 != ret ) return ret;
+    }
+
+    wrapper->paramTiledStream.tilesHeightCount = wrapper->tile_h;
+    wrapper->paramTiledStream.tilesWidthCount  = wrapper->tile_w;
+    wrapper->paramTiledStream.tilesUniformSpacing = wrapper->uniform_split;
+    wrapper->paramTiledStream.frameWidth = wrapper->width;
+    wrapper->paramTiledStream.frameHeight = wrapper->height;
+    wrapper->paramTiledStream.pTiledBitstream = (param_oneStream_info**)malloc(wrapper->tile_h * wrapper->tile_w * sizeof(param_oneStream_info *));
+    if (!wrapper->paramTiledStream.pTiledBitstream)
+    {
+        printf("memory alloc failed!");
+        return 1;
+    }
+
+    for (int i = 0; i < wrapper->paramTiledStream.tilesHeightCount; i++)
+    {
+        for (int j = 0; j < wrapper->paramTiledStream.tilesWidthCount; j++)
+        {
+            wrapper->paramTiledStream.pTiledBitstream[i*wrapper->paramTiledStream.tilesWidthCount + j] = (param_oneStream_info*)malloc(sizeof(param_oneStream_info));
+        }
+    }
+
+    wrapper->pGen = genTiledStream_Init(&(wrapper->paramTiledStream));
+    if (!wrapper->pGen)
+    {
+        printf("the initialize failed\n");
+        return 1;
+    }
+
+    return 0;
+}
+
+static int tile_encode_frame(AVCodecContext *avctx, AVPacket *pkt,
+                                const AVFrame *pic, int *got_packet)
+{
+    TileEncoderContext *ctx = avctx->priv_data;
+    if( NULL != ctx->api.enc_frame )
+        ctx->api.enc_frame(&(ctx->api), pkt, pic, got_packet);
+
+    return 0;
+}
+
+#define OFFSET(x) offsetof(TileEncoderContext, x)
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+static const AVOption options[] = {
+    { "enc", "what's the encoder for each tile. so far, x265=1, svt=2.", OFFSET(enc_lib), AV_OPT_TYPE_INT, { .i64 = 2 }, 0, 3, VE },
+    { "tile_mode", "specify how to divide the tiles of the picture: 1 fixed size tiles; 2. grid layout, 3x3, 4x4.", OFFSET(tile_mode), AV_OPT_TYPE_INT, { .i64 = 2 }, 0, 3, VE },
+    { "tiles_gw", "horizontal grid number of tiles; available when tile is divided via grid layout .", OFFSET(tiles_gw), AV_OPT_TYPE_INT, { .i64 = 1 }, 0, INT_MAX, VE },
+    { "tiles_gh", "vertical grid number of tiles; available when tile is divided via grid layout .", OFFSET(tiles_gh), AV_OPT_TYPE_INT, { .i64 = 1 }, 0, INT_MAX, VE },
+    { "tiles_fixw", "horizontal width of tiles; available when tile is divided via fixed size.", OFFSET(fix_tiles_w), AV_OPT_TYPE_INT, { .i64 = 512 }, 0, INT_MAX, VE },
+    { "tiles_fixh", "vertical height of tiles; available when tile is divided via fixed size.", OFFSET(fix_tiles_h), AV_OPT_TYPE_INT, { .i64 = 512 }, 0, INT_MAX, VE },
+    { "params", "Set parameters as a comma-separated list of key=value pairs.", OFFSET(params), AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VE },
+    { NULL },
+};
+
+static const AVClass class = {
+    .class_name = "hevc_tile_encoder",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVCodecDefault defaults[] = {
+    { "b", "0" },
+    { NULL },
+};
+
+AVCodec ff_hevc_tile_encoder = {
+    .name             = "hevc_tile_encoder",
+    .long_name        = NULL_IF_CONFIG_SMALL("distribute tile H.265 / HEVC"),
+    .type             = AVMEDIA_TYPE_VIDEO,
+    .id               = AV_CODEC_ID_HEVC,
+    .capabilities     = AV_CODEC_CAP_DELAY,
+    .pix_fmts         = (const enum AVPixelFormat[]){ AV_PIX_FMT_YUV420P,
+                                                    AV_PIX_FMT_YUV420P10,
+                                                    AV_PIX_FMT_NONE },
+
+    .priv_class       = &class,
+    .priv_data_size   = sizeof(TileEncoderContext),
+    .defaults         = defaults,
+
+    .init             = tile_encode_init,
+    .encode2          = tile_encode_frame,
+    .close            = tile_encode_close,
+
+    .caps_internal    = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP,
+
+    .wrapper_name     = "hevc_tile_encoder",
+};
diff -Nur FFmpeg/libavcodec/tile_encoder.h FFmpeg_patched/libavcodec/tile_encoder.h
--- FFmpeg/libavcodec/tile_encoder.h	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavcodec/tile_encoder.h	2022-06-29 07:16:09.511918781 +0000
@@ -0,0 +1,125 @@
+/*
+ * Intel tile encoder
+ *
+ * Copyright (c) 2018 Intel Cooperation
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef TILE_ENCODER_H
+#define TILE_ENCODER_H
+#define FILE_DEBUG
+
+#include "libavutil/fifo.h"
+
+#include "avcodec.h"
+#include "internal.h"
+#include <stdio.h>
+#include <pthread.h>
+#include <unistd.h>
+#include <stdbool.h>
+
+#include "genTiledstreamAPI.h"
+
+#define MAX_TILES 256
+#define FIFO_SIZE 8024
+
+enum ENC_LIB{
+    ENC_NULL = 0,
+    ENC_X265 = 1,
+    ENC_SVT  = 2
+};
+
+enum TILE_MODE{
+    NULL_MODE = 0,
+    FIX_SIZE  = 1,
+    AVG_SIZE  = 2
+};
+typedef int (*ENC_CLOSE)(void*);
+typedef int (*ENC_INIT)(void*);
+typedef int (*ENC_FRAME)(void*, AVPacket*, const AVFrame*, int*);
+
+typedef struct TileInfo{
+        int            top;
+        int            left;
+        int            tWidth;
+        int            tHeight;
+        int            tBitrate;
+        int            tMaxrate;
+        AVFifoBuffer*  outpkt_fifo;
+        int            proc_idx;
+        int            eos;
+        void*          enc_ctx;
+        AVPacket*      internal_pkt;
+#ifdef FILE_DEBUG
+        int            nGetpkt;
+        int            nSpkt;
+        FILE*          file;
+#endif
+} TileInfo;
+
+typedef struct TileEncoderInfo{
+    void          *ctx;
+    int           tile_idx;
+}TileEncoderInfo;
+
+typedef struct EncoderWrapper{
+        AVCodecContext* avctx;
+
+        int             width;
+        int             height;
+        void*           enc_param;
+
+        bool            uniform_split;
+        int             tile_num;
+        int             tile_w;
+        int             tile_h;
+        TileInfo        tile_info[MAX_TILES];
+
+        ENC_CLOSE       enc_close;
+        ENC_INIT        enc_init;
+        ENC_FRAME       enc_frame;
+
+        TileEncoderInfo *tile_enc_info;
+        pthread_t       *tid;
+        int             initialized;
+
+        void            *pGen;
+        param_gen_tiledStream paramTiledStream;
+        pthread_mutex_t mutex;
+        pthread_cond_t cond;
+} EncoderWrapper;
+
+int get_tile_frame_copy(EncoderWrapper* wrapper, int tile_idx, const AVFrame *pic, AVFrame** tile_pic );
+int get_tile_frame_nocopy(EncoderWrapper* wrapper, int tile_idx, const AVFrame *pic, AVFrame** tile_pic );
+
+int bs_tile_stitching(EncoderWrapper* wrapper, AVPacket* outPkt);
+int get_tile_bitrate(EncoderWrapper* wrapper, int idx);
+int get_tile_maxrate(EncoderWrapper* wrapper, int idx);
+
+int libx265_enc_close(void* ctx);
+int libx265_enc_init(void* ctx);
+int libx265_enc_frame(void* ctx, AVPacket *pkt, const AVFrame *pic, int *got_packet);
+
+int svt_enc_close(void* ctx);
+int svt_enc_init(void* ctx);
+int svt_enc_frame(void* ctx, AVPacket *pkt, const AVFrame *pic, int *got_packet);
+int svt_enc_tile(TileEncoderInfo *tile_enc_info);
+int bFifoReady( EncoderWrapper* wrapper );
+
+#endif /* TILE_ENCODER_H */
+
diff -Nur FFmpeg/libavdevice/.gitignore FFmpeg_patched/libavdevice/.gitignore
--- FFmpeg/libavdevice/.gitignore	2022-06-29 07:15:48.579919030 +0000
+++ FFmpeg_patched/libavdevice/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,2 +0,0 @@
-/indev_list.c
-/outdev_list.c
diff -Nur FFmpeg/libavdevice/tests/.gitignore FFmpeg_patched/libavdevice/tests/.gitignore
--- FFmpeg/libavdevice/tests/.gitignore	2022-06-29 07:15:48.583919030 +0000
+++ FFmpeg_patched/libavdevice/tests/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1 +0,0 @@
-/timefilter
diff -Nur FFmpeg/libavfilter/.gitignore FFmpeg_patched/libavfilter/.gitignore
--- FFmpeg/libavfilter/.gitignore	2022-06-29 07:15:48.587919030 +0000
+++ FFmpeg_patched/libavfilter/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1 +0,0 @@
-/filter_list.c
diff -Nur FFmpeg/libavfilter/Makefile FFmpeg_patched/libavfilter/Makefile
--- FFmpeg/libavfilter/Makefile	2022-06-29 07:15:48.587919030 +0000
+++ FFmpeg_patched/libavfilter/Makefile	2022-06-29 07:16:09.735918778 +0000
@@ -143,6 +143,7 @@
 OBJS-$(CONFIG_VIBRATO_FILTER)                += af_vibrato.o generate_wave_table.o
 OBJS-$(CONFIG_VOLUME_FILTER)                 += af_volume.o
 OBJS-$(CONFIG_VOLUMEDETECT_FILTER)           += af_volumedetect.o
+OBJS-$(CONFIG_XCAM_FILTER)                   += vf_xcam.o

 OBJS-$(CONFIG_AEVALSRC_FILTER)               += aeval.o
 OBJS-$(CONFIG_AFIRSRC_FILTER)                += asrc_afirsrc.o
@@ -243,6 +244,7 @@
 OBJS-$(CONFIG_EROSION_FILTER)                += vf_neighbor.o
 OBJS-$(CONFIG_EROSION_OPENCL_FILTER)         += vf_neighbor_opencl.o opencl.o \
                                                 opencl/neighbor.o
+OBJS-$(CONFIG_ERP2CUBMAP_MDF_FILTER)         += vf_erp2cubmap_mdf.o
 OBJS-$(CONFIG_EXTRACTPLANES_FILTER)          += vf_extractplanes.o
 OBJS-$(CONFIG_FADE_FILTER)                   += vf_fade.o
 OBJS-$(CONFIG_FFTDNOIZ_FILTER)               += vf_fftdnoiz.o
@@ -426,6 +428,7 @@
 OBJS-$(CONFIG_TONEMAP_FILTER)                += vf_tonemap.o colorspace.o
 OBJS-$(CONFIG_TONEMAP_OPENCL_FILTER)         += vf_tonemap_opencl.o colorspace.o opencl.o \
                                                 opencl/tonemap.o opencl/colorspace_common.o
+OBJS-$(CONFIG_TRANSFORM360_FILTER)           += vf_transform360.o
 OBJS-$(CONFIG_TONEMAP_VAAPI_FILTER)          += vf_tonemap_vaapi.o vaapi_vpp.o
 OBJS-$(CONFIG_TPAD_FILTER)                   += vf_tpad.o
 OBJS-$(CONFIG_TRANSPOSE_FILTER)              += vf_transpose.o
diff -Nur FFmpeg/libavfilter/allfilters.c FFmpeg_patched/libavfilter/allfilters.c
--- FFmpeg/libavfilter/allfilters.c	2022-06-29 07:15:48.595919030 +0000
+++ FFmpeg_patched/libavfilter/allfilters.c	2022-06-29 07:16:09.751918778 +0000
@@ -229,6 +229,7 @@
 extern AVFilter ff_vf_erosion;
 extern AVFilter ff_vf_erosion_opencl;
 extern AVFilter ff_vf_extractplanes;
+extern AVFilter ff_vf_erp2cubmap_mdf;
 extern AVFilter ff_vf_fade;
 extern AVFilter ff_vf_fftdnoiz;
 extern AVFilter ff_vf_fftfilt;
@@ -406,6 +407,7 @@
 extern AVFilter ff_vf_tmix;
 extern AVFilter ff_vf_tonemap;
 extern AVFilter ff_vf_tonemap_opencl;
+extern AVFilter ff_vf_transform360;
 extern AVFilter ff_vf_tonemap_vaapi;
 extern AVFilter ff_vf_tpad;
 extern AVFilter ff_vf_transpose;
@@ -444,6 +446,7 @@
 extern AVFilter ff_vf_zmq;
 extern AVFilter ff_vf_zoompan;
 extern AVFilter ff_vf_zscale;
+extern AVFilter ff_vf_xcam;

 extern AVFilter ff_vsrc_allrgb;
 extern AVFilter ff_vsrc_allyuv;
diff -Nur FFmpeg/libavfilter/opencl/.gitignore FFmpeg_patched/libavfilter/opencl/.gitignore
--- FFmpeg/libavfilter/opencl/.gitignore	2022-06-29 07:15:48.607919029 +0000
+++ FFmpeg_patched/libavfilter/opencl/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1 +0,0 @@
-*.c
diff -Nur FFmpeg/libavfilter/tests/.gitignore FFmpeg_patched/libavfilter/tests/.gitignore
--- FFmpeg/libavfilter/tests/.gitignore	2022-06-29 07:15:48.611919029 +0000
+++ FFmpeg_patched/libavfilter/tests/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,4 +0,0 @@
-/drawutils
-/filtfmts
-/formats
-/integral
diff -Nur FFmpeg/libavfilter/vf_erp2cubmap_mdf.c FFmpeg_patched/libavfilter/vf_erp2cubmap_mdf.c
--- FFmpeg/libavfilter/vf_erp2cubmap_mdf.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavfilter/vf_erp2cubmap_mdf.c	2022-06-29 07:16:09.747918778 +0000
@@ -0,0 +1,275 @@
+#include <string.h>
+
+#include "libavutil/avassert.h"
+#include "libavutil/mem.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale_eval.h"
+#include "video.h"
+#include "vaapi_vpp.h"
+#include "wrapper.h"
+
+#define output_w 5760
+#define output_h 3840
+static const AVRational tb={1,90000};
+
+typedef struct ERP2CubmapVAAPIContext {
+    VAAPIVPPContext vpp_ctx;
+
+    char *output_format_string;
+
+    int in_width;
+    int in_height;
+
+    char *w_expr;
+    char *h_expr;
+
+    struct filter_ctx *filter;
+} ERP2CubmapVAAPIContext;
+
+static int query_formats(AVFilterContext *ctx)
+{
+    static const enum AVPixelFormat in_pix_fmts[]={
+        AV_PIX_FMT_NV12,
+        AV_PIX_FMT_VAAPI,
+        AV_PIX_FMT_NONE
+    };
+    static const enum AVPixelFormat out_pix_fmts[]={
+        AV_PIX_FMT_NV12,
+        AV_PIX_FMT_VAAPI,
+        AV_PIX_FMT_NONE
+    };
+    AVFilterFormats *in_fmts = ff_make_format_list(in_pix_fmts);
+    AVFilterFormats *out_fmts = ff_make_format_list(out_pix_fmts);
+
+    ff_formats_ref(in_fmts, &ctx->inputs[0]->out_formats);
+    ff_formats_ref(out_fmts, &ctx->outputs[0]->in_formats);
+
+    return 0;
+}
+
+static int erp2cubmpa_mdf_config_input(AVFilterLink* inlink) {
+    AVFilterContext *avctx       = inlink->dst;
+    VAAPIVPPContext *vpp_ctx     = avctx->priv;
+    ERP2CubmapVAAPIContext *ctx  = avctx->priv;
+
+    ctx->in_width = inlink->w;
+    ctx->in_height = inlink->h;
+
+    av_log(avctx, AV_LOG_INFO, "config input: %ux%u .\n", ctx->in_width, ctx->in_height);
+
+    return ff_vaapi_vpp_config_input(inlink);
+}
+
+static int erp2cubmap_mdf_config_output(AVFilterLink *outlink) {
+    int ret;
+    //ret = ff_vaapi_vpp_config_output(outlink);
+    //if (ret < 0)
+        //return ret;
+
+    AVFilterLink *inlink         = outlink->src->inputs[0];
+    AVFilterContext *avctx       = outlink->src;
+    VAAPIVPPContext *vpp_ctx     = avctx->priv;
+    vpp_ctx->output_width = output_w;
+    vpp_ctx->output_height = output_h;
+    ret = ff_vaapi_vpp_config_output(outlink);
+    if (ret < 0)
+       return ret;
+
+    AVHWFramesContext *frames_ctx = vpp_ctx->input_frames;
+    ERP2CubmapVAAPIContext *erp2cub_ctx  = avctx->priv;
+
+    trans_config_t filter_Config;
+
+    //vpp_ctx->output_width  = 5760;//atoi((const char *)erp2cub_ctx->w_expr);
+    //vpp_ctx->output_height = 3840;//atoi((const char *)erp2cub_ctx->h_expr);
+    if (vpp_ctx->output_width <= 0) {
+        av_log(avctx, AV_LOG_INFO, "Auto set output width to %u\n", inlink->w);
+        vpp_ctx->output_width = inlink->w;
+    }
+
+    if (vpp_ctx->output_height  <= 0) {
+        av_log(avctx, AV_LOG_INFO, "Auto set output height to %u\n", inlink->h);
+        vpp_ctx->output_height = inlink->h;
+    }
+
+    if (vpp_ctx->va_context == VA_INVALID_ID) {
+        return AVERROR(EINVAL);
+    } else {
+        av_log(avctx, AV_LOG_INFO, "config output: va_context is %x, display is %x\n", vpp_ctx->va_context, vpp_ctx->hwctx->display);
+    }
+
+    outlink->w = output_w;
+    outlink->h = output_h;
+
+    av_log(avctx, AV_LOG_INFO, "config output: vpp_ctx %ux%u .\n", vpp_ctx->output_width, vpp_ctx->output_height);
+    av_log(avctx, AV_LOG_INFO, "config output: outlink %ux%u .\n", outlink->w, outlink->h);
+    av_log(avctx, AV_LOG_INFO, "config output: outlink %u, name is %s .\n", outlink->format, av_get_pix_fmt_name(outlink->format));
+
+    create(&(erp2cub_ctx->filter),(void*)((uint64_t)(vpp_ctx->hwctx->display)));
+
+    frames_ctx->width = outlink->w;
+    frames_ctx->height = outlink->h;
+    frames_ctx->sw_format = AV_PIX_FMT_NV12;
+    frames_ctx->format = AV_PIX_FMT_VAAPI;
+    frames_ctx->initial_pool_size = 0;
+
+    av_log(avctx, AV_LOG_INFO, "config output: frame_ctx %ux%u .\n", frames_ctx->width, frames_ctx->height);
+    av_log(avctx, AV_LOG_INFO, "config output: frame_ctx sw_format is %d, format is %d, pool size is %d .\n", frames_ctx->sw_format, frames_ctx->format, frames_ctx->initial_pool_size);
+    av_log(avctx, AV_LOG_INFO, "config output: frame_ctx sw_format %s, format is %s .\n", av_get_pix_fmt_name(frames_ctx->sw_format), av_get_pix_fmt_name(frames_ctx->format));
+
+    filter_Config.srcWidth        = erp2cub_ctx->in_width;//3840;
+    filter_Config.srcHeight       = erp2cub_ctx->in_height;//2048;
+    filter_Config.dstWidth        = output_w;//5760;//1664;//1664;
+    filter_Config.dstHeight       = output_h;//3840;//1152;//1152;
+    filter_Config.xCoordinateFile = "./xCooridnate.bin";
+    filter_Config.yCoordinateFile = "./yCooridnate.bin";
+    filter_Config.blockWidth      = 16;
+    filter_Config.blockHeight     = 4;
+    loadFilter(erp2cub_ctx->filter,"./Dewarp_genx.isa","dewarp");
+    setConfig(erp2cub_ctx->filter,filter_Config);
+
+
+    return 0;
+}
+
+static int erp2cubmap_mdf_filter_frame(AVFilterLink *inlink, AVFrame *input_frame) {
+    AVFilterContext *avctx              = inlink->dst;
+    AVFilterLink *outlink               = avctx->outputs[0];
+    VAAPIVPPContext *vpp_ctx            = avctx->priv;
+    ERP2CubmapVAAPIContext *erp2cub_ctx = avctx->priv;
+    AVFrame *output_frame               = NULL;
+    VASurfaceID input_surface, output_surface;
+    int err;
+
+    if (vpp_ctx->va_context == VA_INVALID_ID) {
+        return AVERROR(EINVAL);
+    } else {
+        av_log(avctx, AV_LOG_INFO, "filter frame: va_context is %x.\n", vpp_ctx->va_context);
+    }
+
+    input_surface = (VASurfaceID)(uintptr_t)input_frame->data[3];
+    av_log(avctx, AV_LOG_INFO, "Using surface %#x for input.\n",
+           input_surface);
+
+    output_frame = ff_get_video_buffer(outlink, vpp_ctx->output_width,
+            vpp_ctx->output_height);
+    //av_log(avctx, AV_LOG_INFO, "vpp_ctx->output_width %u, vpp_ctx->output_height %u \n", vpp_ctx->output_width, vpp_ctx->output_height);
+    //av_log(avctx, AV_LOG_INFO, "output_frame has width %u and height %u \n", output_frame->width, output_frame->height);
+    if (!output_frame) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+
+    output_surface = (VASurfaceID)(uintptr_t)output_frame->data[3];
+    av_log(avctx, AV_LOG_INFO, "Using surface %#x for output.\n",
+            output_surface);
+
+    updateInputOutput(erp2cub_ctx->filter, input_surface, output_surface);
+    execFilter(erp2cub_ctx->filter);
+
+    err = av_frame_copy_props(output_frame, input_frame);
+    if (err < 0)
+        goto fail;
+
+    av_frame_free(&input_frame);
+    av_log(avctx, AV_LOG_INFO, "Filter output: %s, %ux%u (%"PRId64").\n",
+            av_get_pix_fmt_name(output_frame->format),
+            output_frame->width, output_frame->height, output_frame->pts);
+
+    return ff_filter_frame(outlink, output_frame);
+
+fail:
+    av_frame_free(&input_frame);
+    av_frame_free(&output_frame);
+
+    return err;
+}
+
+static av_cold int erp2cubmap_mdf_init(AVFilterContext *avctx) {
+    VAAPIVPPContext *vpp_ctx    = avctx->priv;
+    ERP2CubmapVAAPIContext *ctx = avctx->priv;
+
+    ff_vaapi_vpp_ctx_init(avctx);
+    vpp_ctx->pipeline_uninit = ff_vaapi_vpp_pipeline_uninit;
+
+    if (ctx->output_format_string) {
+        vpp_ctx->output_format = av_get_pix_fmt(ctx->output_format_string);
+        if (vpp_ctx->output_format == AV_PIX_FMT_NONE) {
+            av_log(avctx, AV_LOG_ERROR, "Invalid output format.\n");
+            return AVERROR(EINVAL);
+        }
+    } else {
+        // Use the input format once that is configured.
+        vpp_ctx->output_format = AV_PIX_FMT_NONE;
+    }
+
+    ctx->filter = NULL;
+    return 0;
+}
+
+static void erp2cubmap_mdf_uninit(AVFilterContext *avctx) {
+    VAAPIVPPContext *vpp_ctx    = avctx->priv;
+    ERP2CubmapVAAPIContext *ctx = avctx->priv;
+
+    destroyInstance(ctx->filter);
+
+    ff_vaapi_vpp_ctx_uninit(avctx);
+}
+
+#define OFFSET(x) offsetof(ERP2CubmapVAAPIContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption erp2cubmap_mdf_options[] = {
+    { "w", "Output video width",
+        OFFSET(w_expr), AV_OPT_TYPE_STRING, {.str = "iw"}, .flags = FLAGS },
+    { "h", "Output video height",
+        OFFSET(h_expr), AV_OPT_TYPE_STRING, {.str = "ih"}, .flags = FLAGS },
+
+    {NULL}
+};
+
+//AVFILTER_DEFINE_CLASS(erp2cubmap_mdf);
+static const AVClass erp2cubmap_mdf_class = {
+    .class_name = "erp2cubmap_mdf",
+    .item_name  = av_default_item_name,
+    .option     = erp2cubmap_mdf_options,
+    .version    = LIBAVUTIL_VERSION_INT,
+    .category   = AV_CLASS_CATEGORY_FILTER,
+};
+
+static const AVFilterPad erp2cubmap_mdf_inputs[]={
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = &erp2cubmap_mdf_filter_frame,
+        .config_props = &erp2cubmpa_mdf_config_input,
+    },
+    { NULL }
+};
+
+static const AVFilterPad erp2cubmap_mdf_outputs[]={
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = &erp2cubmap_mdf_config_output,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_erp2cubmap_mdf = {
+    .name          = "erp2cubmap_mdf",
+    .description   = "filter: 360 projection remap from ERP to cubemap with Intel GPU acceleration",
+    .priv_size     = sizeof(ERP2CubmapVAAPIContext),
+    .init          = &erp2cubmap_mdf_init,
+    .uninit        = &erp2cubmap_mdf_uninit,
+    .query_formats = &ff_vaapi_vpp_query_formats,
+    .inputs        = &erp2cubmap_mdf_inputs,
+    .outputs       = &erp2cubmap_mdf_outputs,
+    .priv_class    = &erp2cubmap_mdf_class,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
+
diff -Nur FFmpeg/libavfilter/vf_transform360.c FFmpeg_patched/libavfilter/vf_transform360.c
--- FFmpeg/libavfilter/vf_transform360.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavfilter/vf_transform360.c	2022-06-29 07:16:09.747918778 +0000
@@ -0,0 +1,483 @@
+/**
+ * Copyright (c) 2015-present, Facebook, Inc.
+ * All rights reserved.
+ *
+ * This source code is licensed under the license found in the
+ * LICENSE file in the root directory of this source tree.
+ */
+
+/**
+ * @file
+ * transform360 video filter
+ */
+
+#include "libavutil/avassert.h"
+#include "libavutil/avstring.h"
+#include "libavutil/eval.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/mem.h"
+#include "libavutil/parseutils.h"
+#include "avfilter.h"
+#include "internal.h"
+#include "video.h"
+#include <stdio.h>
+
+#include "transform360/VideoFrameTransformHandler.h"
+#include "transform360/VideoFrameTransformHelper.h"
+
+static const char *const var_names[] = {
+    "out_w",  "ow",
+    "out_h",  "oh",
+    NULL
+};
+
+enum var_name {
+    VAR_OUT_W, VAR_OW,
+    VAR_OUT_H, VAR_OH,
+    VARS_NB
+};
+
+/*
+   MMMMT
+   MMMMB
+   */
+
+typedef struct TransformContext {
+    const AVClass *class;
+    int w, h;
+    int out_map_planes;
+
+    AVDictionary *opts;
+    char *w_expr;               ///< width  expression string
+    char *h_expr;               ///< height expression string
+    char *size_str;
+    int cube_edge_length;
+    int max_cube_edge_length;
+    int max_output_h;
+    int max_output_w;
+    int input_layout;
+    int output_layout;
+    int input_stereo_format;
+    int output_stereo_format;
+    int vflip;
+    int planes;
+    float input_expand_coef;
+    float expand_coef;
+    int is_horizontal_offset;
+    float fixed_yaw;    ///< Yaw (asimuth) angle, degrees
+    float fixed_pitch;  ///< Pitch (elevation) angle, degrees
+    float fixed_roll;   ///< Roll (tilt) angle, degrees
+    float fixed_hfov;   ///< Horizontal field of view, degrees
+    float fixed_vfov;   ///< Vertical field of view, degrees
+    float fixed_cube_offcenter_x; // offcenter projection x
+    float fixed_cube_offcenter_y; // offcenter projection y
+    float fixed_cube_offcenter_z; // offcenter projection z
+
+    // openCV-based transform parameters
+    VideoFrameTransform* transform;
+    int interpolation_alg;
+    float width_scale_factor;
+    float height_scale_factor;
+    int enable_low_pass_filter;
+    float kernel_height_scale_factor;
+    float min_kernel_half_height;
+    float max_kernel_half_height;
+    int enable_multi_threading;
+    int num_vertical_segments;
+    int num_horizontal_segments;
+    int adjust_kernel;
+    float kernel_adjust_factor;
+
+} TransformContext;
+
+static inline void update_plane_sizes(
+    AVPixFmtDescriptor* desc,
+    int* in_w, int* in_h, int* out_w, int* out_h) {
+    *in_w = FF_CEIL_RSHIFT(*in_w, desc->log2_chroma_w);
+    *in_h = FF_CEIL_RSHIFT(*in_h, desc->log2_chroma_h);
+    *out_w = FF_CEIL_RSHIFT(*out_w, desc->log2_chroma_w);
+    *out_h = FF_CEIL_RSHIFT(*out_h, desc->log2_chroma_h);
+}
+
+static inline int generate_map(
+    TransformContext *s, AVFilterLink *inlink,
+    AVFilterLink *outlink, AVFrame *in) {
+    AVFilterContext *ctx = outlink->src;
+    int ret = 0;
+
+    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(outlink->format);
+    s->planes = av_pix_fmt_count_planes(outlink->format);
+    s->out_map_planes = 2;
+
+    FrameTransformContext frame_transform_ctx = (FrameTransformContext) {
+      .input_layout = s->input_layout,
+      .output_layout = s->output_layout,
+      .input_stereo_format = s->input_stereo_format,
+      .output_stereo_format = s->output_stereo_format,
+      .vflip = s->vflip,
+      .input_expand_coef = s->input_expand_coef,
+      .expand_coef = s->expand_coef,
+      .interpolation_alg = s->interpolation_alg,
+      .width_scale_factor = s->width_scale_factor,
+      .height_scale_factor = s->height_scale_factor,
+      .fixed_yaw = s->fixed_yaw,
+      .fixed_pitch = s->fixed_pitch,
+      .fixed_roll = s->fixed_roll,
+      .fixed_hfov = s->fixed_hfov,
+      .fixed_vfov = s->fixed_vfov,
+      .fixed_cube_offcenter_x = s->fixed_cube_offcenter_x,
+      .fixed_cube_offcenter_y = s->fixed_cube_offcenter_y,
+      .fixed_cube_offcenter_z = s->fixed_cube_offcenter_z,
+      .is_horizontal_offset = s->is_horizontal_offset,
+      .enable_low_pass_filter = s->enable_low_pass_filter,
+      .kernel_height_scale_factor = s->kernel_height_scale_factor,
+      .min_kernel_half_height = s->min_kernel_half_height,
+      .max_kernel_half_height = s->max_kernel_half_height,
+      .enable_multi_threading = s->enable_multi_threading,
+      .num_vertical_segments = s->num_vertical_segments,
+      .num_horizontal_segments = s->num_horizontal_segments,
+      .adjust_kernel = s->adjust_kernel,
+      .kernel_adjust_factor = s->kernel_adjust_factor};
+
+    s->transform = VideoFrameTransform_new(&frame_transform_ctx);
+    if (!s->transform) {
+      return AVERROR(ENOMEM);
+    }
+
+    int in_w, in_h, out_w, out_h;
+    for (int plane = 0; plane < s->out_map_planes; ++plane) {
+      out_w = outlink->w;
+      out_h = outlink->h;
+      in_w = inlink->w;
+      in_h = inlink->h;
+
+      if (plane == 1) {
+        update_plane_sizes(desc, &in_w, &in_h, &out_w, &out_h);
+      }
+
+      if (!VideoFrameTransform_generateMapForPlane(
+            s->transform, in_w, in_h, out_w, out_h, plane)) {
+        av_log(ctx, AV_LOG_INFO, "Failed to generate map for plane %d\n", plane);
+        return AVERROR(EINVAL);
+      }
+    }
+
+    return 0;
+}
+
+static int config_output(AVFilterLink *outlink) {
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = outlink->src->inputs[0];
+    TransformContext *s = ctx->priv;
+    double var_values[VARS_NB], res;
+    char *expr;
+    int ret;
+
+    var_values[VAR_OUT_W] = var_values[VAR_OW] = NAN;
+    var_values[VAR_OUT_H] = var_values[VAR_OH] = NAN;
+
+    if (s->input_stereo_format == STEREO_FORMAT_GUESS) {
+        int aspect_ratio = inlink->w / inlink->h;
+        if (aspect_ratio == 1)
+            s->input_stereo_format = STEREO_FORMAT_TB;
+        else if (aspect_ratio == 4)
+            s->input_stereo_format = STEREO_FORMAT_LR;
+        else
+            s->input_stereo_format = STEREO_FORMAT_MONO;
+    }
+
+    if (s->output_stereo_format == STEREO_FORMAT_GUESS) {
+        if (s->input_stereo_format == STEREO_FORMAT_MONO) {
+            s->output_stereo_format = STEREO_FORMAT_MONO;
+        } else {
+            s->output_stereo_format =
+                (s->output_layout == LAYOUT_CUBEMAP_23_OFFCENTER)
+                    ? STEREO_FORMAT_LR
+                    : STEREO_FORMAT_TB;
+        }
+    }
+
+    if (s->max_cube_edge_length > 0) {
+        if (s->input_stereo_format == STEREO_FORMAT_LR) {
+            s->cube_edge_length = inlink->w / 8;
+        } else {
+            s->cube_edge_length = inlink->w / 4;
+        }
+
+        // do not exceed the max length supplied
+        if (s->cube_edge_length > s->max_cube_edge_length) {
+            s->cube_edge_length = s->max_cube_edge_length;
+        }
+    }
+
+    // ensure cube edge length is a multiple of 16 by rounding down
+    // so that macroblocks do not cross cube edge boundaries
+    s->cube_edge_length = s->cube_edge_length - (s->cube_edge_length % 16);
+
+    if (s->cube_edge_length > 0) {
+         if (s->output_layout == LAYOUT_CUBEMAP_32) {
+            outlink->w = s->cube_edge_length * 3;
+            outlink->h = s->cube_edge_length * 2;
+
+        } else if (s->output_layout == LAYOUT_CUBEMAP_23_OFFCENTER) {
+            outlink->w = s->cube_edge_length * 2;
+            outlink->h = s->cube_edge_length * 3;
+        }
+    } else {
+        var_values[VAR_OUT_W] = var_values[VAR_OW] = NAN;
+        var_values[VAR_OUT_H] = var_values[VAR_OH] = NAN;
+
+        av_expr_parse_and_eval(&res, (expr = s->w_expr),
+                var_names, var_values,
+                NULL, NULL, NULL, NULL, NULL, 0, ctx);
+        s->w = var_values[VAR_OUT_W] = var_values[VAR_OW] = res;
+        if ((ret = av_expr_parse_and_eval(&res, (expr = s->h_expr),
+                        var_names, var_values,
+                        NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0) {
+            av_log(NULL, AV_LOG_ERROR,
+                    "Error when evaluating the expression '%s'.\n"
+                    "Maybe the expression for out_w:'%s' or for out_h:'%s' is self-referencing.\n",
+                    expr, s->w_expr, s->h_expr);
+            return ret;
+        }
+        s->h = var_values[VAR_OUT_H] = var_values[VAR_OH] = res;
+        /* evaluate again the width, as it may depend on the output height */
+        if ((ret = av_expr_parse_and_eval(&res, (expr = s->w_expr),
+                        var_names, var_values,
+                        NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0) {
+            av_log(NULL, AV_LOG_ERROR,
+                    "Error when evaluating the expression '%s'.\n"
+                    "Maybe the expression for out_w:'%s' or for out_h:'%s' is self-referencing.\n",
+                    expr, s->w_expr, s->h_expr);
+            return ret;
+        }
+        s->w = res;
+
+        outlink->w = s->w;
+        outlink->h = s->h;
+    }
+
+    if (s->output_stereo_format == STEREO_FORMAT_TB) {
+        outlink->h *= 2;
+        s->h *= 2;
+    } else if (s->output_stereo_format == STEREO_FORMAT_LR) {
+        outlink->w *= 2;
+        s->w *= 2;
+    }
+
+    av_log(ctx, AV_LOG_VERBOSE, "out_w:%d out_h:%d\n",
+            outlink->w, outlink->h);
+
+    return 0;
+}
+
+static av_cold int init_dict(AVFilterContext *ctx, AVDictionary **opts) {
+    TransformContext *s = ctx->priv;
+
+    if (s->size_str && (s->w_expr || s->h_expr)) {
+        av_log(ctx, AV_LOG_ERROR,
+                "Size and width/height expressions cannot be set at the same time.\n");
+        return AVERROR(EINVAL);
+    }
+
+    if (s->w_expr && !s->h_expr)
+        FFSWAP(char *, s->w_expr, s->size_str);
+
+    av_log(ctx, AV_LOG_VERBOSE, "w:%s h:%s\n",
+            s->w_expr, s->h_expr);
+
+    s->opts = *opts;
+    *opts = NULL;
+
+    return 0;
+}
+
+static av_cold void uninit(AVFilterContext *ctx) {
+    TransformContext *s = ctx->priv;
+
+    av_dict_free(&s->opts);
+    s->opts = NULL;
+
+    VideoFrameTransform_delete(s->transform);
+    s->transform = NULL;
+}
+
+static int filter_frame(AVFilterLink *inlink, AVFrame *in) {
+    AVFilterContext *ctx = inlink->dst;
+    TransformContext *s = ctx->priv;
+    AVFilterLink *outlink = ctx->outputs[0];
+    AVFrame *out;
+    av_log(ctx, AV_LOG_VERBOSE, "Frame\n");
+
+    // map not yet set
+    if (s->out_map_planes != 2) {
+      int result = generate_map(s, inlink, outlink, in);
+      if (result != 0) {
+          av_frame_free(&in);
+          return result;
+      }
+    }
+
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    av_log(ctx, AV_LOG_VERBOSE, "Got Frame %dx%d\n", outlink->w, outlink->h);
+
+    if (!out) {
+      av_frame_free(&in);
+      return AVERROR(ENOMEM);
+    }
+    av_frame_copy_props(out, in);
+    av_log(ctx, AV_LOG_VERBOSE, "Copied props \n");
+
+    uint8_t *in_data, *out_data;
+    int out_map_plane;
+    int in_w, in_h, out_w, out_h;
+    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(outlink->format);
+    for (int plane = 0; plane < s->planes; ++plane) {
+      in_data = in->data[plane];
+      av_assert1(in_data);
+      out_data = out->data[plane];
+      out_map_plane = (plane == 1 || plane == 2) ? 1 : 0;
+
+      out_w = outlink->w;
+      out_h = outlink->h;
+      in_w = inlink->w;
+      in_h = inlink->h;
+
+      if (plane >= 1) {
+        update_plane_sizes(desc, &in_w, &in_h, &out_w, &out_h);
+      }
+
+      if (!VideoFrameTransform_transformFramePlane(
+        s->transform,
+        in_data,
+        out_data,
+        in_w,
+        in_h,
+        in->linesize[plane],
+        out_w,
+        out_h,
+        out->linesize[plane],
+        out_map_plane,
+        plane)) {
+        return AVERROR(EINVAL);
+      }
+    }
+
+    av_frame_free(&in);
+    av_log(ctx, AV_LOG_VERBOSE, "Done freeing in \n");
+    return ff_filter_frame(outlink, out);
+}
+
+#define OFFSET(x) offsetof(TransformContext, x)
+#define FLAGS AV_OPT_FLAG_VIDEO_PARAM|AV_OPT_FLAG_FILTERING_PARAM
+
+static const AVOption transform360_options[] = {
+    { "w",             "Output video width",          OFFSET(w_expr),    AV_OPT_TYPE_STRING,        .flags = FLAGS },
+    { "width",         "Output video width",          OFFSET(w_expr),    AV_OPT_TYPE_STRING,        .flags = FLAGS },
+    { "h",             "Output video height",         OFFSET(h_expr),    AV_OPT_TYPE_STRING,        .flags = FLAGS },
+    { "height",        "Output video height",         OFFSET(h_expr),    AV_OPT_TYPE_STRING,        .flags = FLAGS },
+    { "size",          "set video size",              OFFSET(size_str), AV_OPT_TYPE_STRING, {.str = NULL}, 0, FLAGS },
+    { "s",             "set video size",              OFFSET(size_str), AV_OPT_TYPE_STRING, {.str = NULL}, 0, FLAGS },
+    { "is_horizontal_offset", "Whether to use offset on the horizontal plane only. It only affects yaw.", OFFSET(is_horizontal_offset), AV_OPT_TYPE_BOOL, {.i64 =   0},     0, 1,  .flags = FLAGS },
+    { "cube_edge_length", "Length of a cube edge (for cubic transform, overrides w and h, default 0 for off)",         OFFSET(cube_edge_length),    AV_OPT_TYPE_INT,  {.i64 = 0}, 0, 16384,  .flags = FLAGS },
+    { "max_cube_edge_length", "Max length of a cube edge (for cubic transform, overrides w, h, and cube_edge_length, default 0 for off)",   OFFSET(max_cube_edge_length),    AV_OPT_TYPE_INT,  {.i64 = 0}, 0, 16384,  .flags = FLAGS },
+    { "max_output_h", "Max height of the output video (for pyramid/cone transform, overrides pyramid_height, default 0 for off)",         OFFSET(max_output_h),    AV_OPT_TYPE_INT,  {.i64 = 0}, 0, 16384,  .flags = FLAGS },
+    { "max_output_w", "Max width of the output video (for pyramid/cone transform, overrides pyramid_height, default 0 for off)",         OFFSET(max_output_w),    AV_OPT_TYPE_INT,  {.i64 = 0}, 0, 16384,  .flags = FLAGS },
+    { "input_stereo_format", "Input video stereo format",         OFFSET(input_stereo_format),    AV_OPT_TYPE_INT,  {.i64 = STEREO_FORMAT_GUESS }, 0, STEREO_FORMAT_N - 1,  .flags = FLAGS, "stereo_format" },
+    { "output_stereo_format", "Output video stereo format",         OFFSET(output_stereo_format),    AV_OPT_TYPE_INT,  {.i64 = STEREO_FORMAT_GUESS }, 0, STEREO_FORMAT_N - 1,  .flags = FLAGS, "stereo_format" },
+    { "TB",      NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_TB },      0, 0, FLAGS, "stereo_format" },
+    { "LR",      NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_LR },      0, 0, FLAGS, "stereo_format" },
+    { "MONO",    NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_MONO },    0, 0, FLAGS, "stereo_format" },
+    { "GUESS",   NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_GUESS },   0, 0, FLAGS, "stereo_format" },
+    { "tb",      NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_TB },      0, 0, FLAGS, "stereo_format" },
+    { "lr",      NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_LR },      0, 0, FLAGS, "stereo_format" },
+    { "mono",    NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_MONO },    0, 0, FLAGS, "stereo_format" },
+    { "guess",   NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_GUESS },   0, 0, FLAGS, "stereo_format" },
+    { "input_layout", "Input video layout format",          OFFSET(input_layout),     AV_OPT_TYPE_INT,  {.i64 = LAYOUT_EQUIRECT },   0, LAYOUT_N - 1,  .flags = FLAGS, "layout" },
+    { "output_layout", "Output video layout format",         OFFSET(output_layout),    AV_OPT_TYPE_INT,  {.i64 = LAYOUT_CUBEMAP_32 }, 0, LAYOUT_N - 1,  .flags = FLAGS, "layout" },
+    { "CUBEMAP_32",          NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_CUBEMAP_32 },          0, 0, FLAGS, "layout" },
+    { "CUBEMAP_23_OFFCENTER",NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_CUBEMAP_23_OFFCENTER },0, 0, FLAGS, "layout" },
+    { "EQUIRECT",NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_EQUIRECT },0, 0, FLAGS, "layout" },
+    { "BARREL",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_BARREL },  0, 0, FLAGS, "layout" },
+    { "EAC_32",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_EAC_32 },  0, 0, FLAGS, "layout" },
+    { "FLAT_FIXED",          NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_FLAT_FIXED },          0, 0, FLAGS, "layout" },
+    { "cubemap_32",          NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_CUBEMAP_32 },          0, 0, FLAGS, "layout" },
+    { "cubemap_23_offcenter",NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_CUBEMAP_23_OFFCENTER },0, 0, FLAGS, "layout" },
+    { "equirect",NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_EQUIRECT },0, 0, FLAGS, "layout" },
+    { "flat_fixed",          NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_FLAT_FIXED },          0, 0, FLAGS, "layout" },
+    { "barrel",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_BARREL },  0, 0, FLAGS, "layout" },
+    { "eac_32",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_EAC_32 },  0, 0, FLAGS, "layout" },
+    { "vflip", "Output video 2nd eye vertical flip (true, false)",         OFFSET(vflip),    AV_OPT_TYPE_INT, {.i64 = 0 }, 0, 1,     .flags = FLAGS, "vflip" },
+    { "false",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = 0 }, 0, 0, FLAGS, "vflip" },
+    { "true",   NULL, 0, AV_OPT_TYPE_CONST, {.i64 = 1 }, 0, 0, FLAGS, "vflip" },
+    { "input_expand_coef", "Expansion coeffiecient of the input",         OFFSET(input_expand_coef),    AV_OPT_TYPE_FLOAT,  {.dbl=1.01f}, 0, 10,  .flags = FLAGS },
+    { "expand_coef", "Expansion coeffiecient for each face in cubemap (default 1.01)",         OFFSET(expand_coef),    AV_OPT_TYPE_FLOAT,  {.dbl=1.01f}, 0, 10,  .flags = FLAGS },
+    { "yaw", "View orientation for flat_fixed projection, degrees",   OFFSET(fixed_yaw),          AV_OPT_TYPE_FLOAT,   {.dbl =   0.0}, -360, 360,  .flags = FLAGS },
+    { "pitch", "View orientation for flat_fixed projection, degrees", OFFSET(fixed_pitch),        AV_OPT_TYPE_FLOAT,   {.dbl =   0.0}, -180, 180,  .flags = FLAGS },
+    { "roll", "View orientation for flat_fixed projection, degrees",  OFFSET(fixed_roll),         AV_OPT_TYPE_FLOAT,   {.dbl =   0.0}, -180, 180,  .flags = FLAGS },
+    { "hfov", "Horizontal field of view for flat_fixed projection, degrees (default 120)",  OFFSET(fixed_hfov), AV_OPT_TYPE_FLOAT,   {.dbl = 120.0}, -360, 360,  .flags = FLAGS },
+    { "vfov", "Vertical field of view for flat_fixed projection, degrees (default 110)",     OFFSET(fixed_vfov), AV_OPT_TYPE_FLOAT,   {.dbl = 110.0}, -180, 180,  .flags = FLAGS },
+    { "cube_offcenter_x", "Offcenter cube displacement x",   OFFSET(fixed_cube_offcenter_x),          AV_OPT_TYPE_FLOAT,   {.dbl =   0.0}, -1, 1,  .flags = FLAGS },
+    { "cube_offcenter_y", "Offcenter cube displacement y",   OFFSET(fixed_cube_offcenter_y),          AV_OPT_TYPE_FLOAT,   {.dbl =   0.0}, -1, 1,  .flags = FLAGS },
+    { "cube_offcenter_z", "Offcenter cube displacement z",   OFFSET(fixed_cube_offcenter_z),          AV_OPT_TYPE_FLOAT,   {.dbl =   0.0}, -1, 1,  .flags = FLAGS },
+    { "NEAREST",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = NEAREST },  0, 0, FLAGS, "interpolation_alg" },
+    { "LINEAR",   NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LINEAR },   0, 0, FLAGS, "interpolation_alg" },
+    { "CUBIC",    NULL, 0, AV_OPT_TYPE_CONST, {.i64 = CUBIC },    0, 0, FLAGS, "interpolation_alg" },
+    { "LANCZOS4", NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LANCZOS4 }, 0, 0, FLAGS, "interpolation_alg" },
+    { "nearest",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = NEAREST },  0, 0, FLAGS, "interpolation_alg" },
+    { "linear",   NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LINEAR },   0, 0, FLAGS, "interpolation_alg" },
+    { "cubic",    NULL, 0, AV_OPT_TYPE_CONST, {.i64 = CUBIC },    0, 0, FLAGS, "interpolation_alg" },
+    { "lanczos4", NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LANCZOS4 }, 0, 0, FLAGS, "interpolation_alg" },
+    { "interpolation_alg", "Interpolation algorithm", OFFSET(interpolation_alg), AV_OPT_TYPE_INT, {.i64 = 2}, 0, 4, .flags = FLAGS, "interpolation_alg"},
+    { "width_scale_factor", "Scale factor of width for antialiasing", OFFSET(width_scale_factor), AV_OPT_TYPE_FLOAT, {.dbl = 1.0}, 0, 10, .flags = FLAGS, "width_scale_factor" },
+    { "height_scale_factor", "Scale factor of height for antialiasing", OFFSET(height_scale_factor), AV_OPT_TYPE_FLOAT, {.dbl = 1.0}, 0, 10, .flags = FLAGS, "height_scale_factor" },
+    { "enable_low_pass_filter", "Enable low pass filter-based antialiasing", OFFSET(enable_low_pass_filter), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, .flags = FLAGS, "enable_low_pass_filter" },
+    { "enable_multi_threading", "Enable multi-threading to speed up low pass filter-based antialiasing", OFFSET(enable_multi_threading), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, .flags = FLAGS, "enable_multi_threading" },
+    { "num_vertical_segments" , "Number of vertical segments per frame plane", OFFSET(num_vertical_segments), AV_OPT_TYPE_INT, {.i64 = 5}, 2, 500, .flags = FLAGS, "num_vertical_segments" },
+    { "num_horizontal_segments" , "Number of horizontal segments per frame plane", OFFSET(num_horizontal_segments), AV_OPT_TYPE_INT, {.i64 = 1}, 1, 500, .flags = FLAGS, "num_horizontal_segments" },
+    { "kernel_height_scale_factor", "Factor to scale the calculated kernel height for low pass filtering", OFFSET(kernel_height_scale_factor), AV_OPT_TYPE_FLOAT, {.dbl = 1.0}, 0.1, 100.0, .flags = FLAGS, "kernel_height_scale_factor" },
+    { "min_kernel_half_height", "Half of the mininum kernel height", OFFSET(min_kernel_half_height), AV_OPT_TYPE_FLOAT, {.dbl = 1.0}, 0.5, 200, .flags = FLAGS, "min_kernel_half_height" },
+    { "max_kernel_half_height", "The maximum value of the kernel height", OFFSET(max_kernel_half_height), AV_OPT_TYPE_FLOAT, {.dbl = 10000.0}, 0.5, 100000, .flags = FLAGS, "max_kernel_half_height" },
+    { "adjust_kernel", "Enable adjustment of kernel", OFFSET(adjust_kernel), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, .flags = FLAGS, "adjust_kernel" },
+    { "kernel_adjust_factor", "Factor to further adjust the kernel size", OFFSET(kernel_adjust_factor), AV_OPT_TYPE_FLOAT, {.dbl = 1.0}, 0.1, 100.0, .flags = FLAGS, "kernel_adjust_factor" },
+    { NULL }
+};
+
+static const AVClass transform360_class = {
+    .class_name       = "transform360",
+    .item_name        = av_default_item_name,
+    .option           = transform360_options,
+    .version          = LIBAVUTIL_VERSION_INT,
+    .category         = AV_CLASS_CATEGORY_FILTER,
+};
+
+static const AVFilterPad avfilter_vf_transform_inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad avfilter_vf_transform_outputs[] = {
+    {
+        .name = "default",
+        .type = AVMEDIA_TYPE_VIDEO,
+        .config_props = config_output,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_transform360 = {
+    .name        = "transform360",
+    .description = NULL_IF_CONFIG_SMALL("Transforms equirectangular input video to the other format."),
+    .init_dict   = init_dict,
+    .uninit      = uninit,
+    .priv_size   = sizeof(TransformContext),
+    .priv_class  = &transform360_class,
+    .inputs      = avfilter_vf_transform_inputs,
+    .outputs     = avfilter_vf_transform_outputs,
+};
diff -Nur FFmpeg/libavfilter/vf_xcam.c FFmpeg_patched/libavfilter/vf_xcam.c
--- FFmpeg/libavfilter/vf_xcam.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavfilter/vf_xcam.c	2022-06-29 07:16:09.759918778 +0000
@@ -0,0 +1,350 @@
+/*
+ * Copyright (c) 2020 Intel Corporation, all rights reserved.
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * libxcam wrapper functions
+ */
+
+#include <xcam/capi/xcam_handle.h>
+#include "libavutil/avstring.h"
+#include "libavutil/opt.h"
+#include "framesync.h"
+#include "internal.h"
+
+typedef struct XCamVideoFilterBuf {
+    XCamVideoBuffer buf;
+    AVFrame *frame;
+} XCamVideoFilterBuf;
+
+typedef struct XCAMContext {
+    const AVClass *class;
+
+    int nb_inputs;
+    int w;
+    int h;
+    char *fmt;
+    char *name;
+    int allocoutbuf;
+    char *params;
+
+    XCamHandle *handle;
+    uint32_t v4l2_fmt;
+
+    XCamVideoFilterBuf *inbufs[XCAM_MAX_INPUTS_NUM + 1];
+    FFFrameSync fs;
+} XCAMContext;
+
+static void xcambuf_ref(XCamVideoBuffer *buf) {
+    return;
+}
+
+static void xcambuf_unref(XCamVideoBuffer *buf) {
+    return;
+}
+
+static uint8_t *xcambuf_map(XCamVideoBuffer *buf) {
+    XCamVideoFilterBuf *avfilter_buf = (XCamVideoFilterBuf *)(buf);
+    return avfilter_buf->frame->data[0];
+}
+
+static void xcambuf_unmap(XCamVideoBuffer *buf) {
+    return;
+}
+
+static int xcambuf_get_fd(XCamVideoBuffer *buf) {
+    return 1;
+}
+
+static void fill_xcambuf_from_avframe(XCamVideoFilterBuf *buf, AVFrame *frame)
+{
+    buf->frame = frame;
+}
+
+static void fill_avframe_from_xcambuf(AVFrame *frame, XCamVideoBuffer *buf)
+{
+    XCamVideoBufferPlanarInfo planar;
+
+    uint8_t *start = xcam_video_buffer_map(buf);
+    if (!start)
+        return;
+
+    for (uint32_t idx = 0; idx < buf->info.components; idx++) {
+        uint8_t *src = start + buf->info.offsets[idx];
+        uint8_t *dest = frame->data[idx];
+        xcam_video_buffer_get_planar_info(&buf->info, &planar, idx);
+
+        for (uint32_t h = 0; h < planar.height; h++) {
+            memcpy(dest, src, frame->linesize[idx]);
+            src += buf->info.strides[idx];
+            dest += frame->linesize[idx];
+        }
+    }
+
+    xcam_video_buffer_unmap (buf);
+}
+
+static uint32_t avfmt_to_v4l2fmt(int avfmt) {
+    if (avfmt == AV_PIX_FMT_YUV420P)
+        return V4L2_PIX_FMT_YUV420;
+    return V4L2_PIX_FMT_NV12;
+}
+
+static int set_parameters(AVFilterContext *ctx, const AVFilterLink *inlink, const AVFilterLink *outlink)
+{
+    XCAMContext *s = inlink->dst->priv;
+
+    char params[XCAM_MAX_PARAMS_LENGTH] = { 0 };
+    snprintf(params, XCAM_MAX_PARAMS_LENGTH - 1, "inw=%d inh=%d outw=%d outh=%d fmt=%d allocoutbuf=%d %s",
+        inlink->w, inlink->h, outlink->w, outlink->h, s->v4l2_fmt, s->allocoutbuf, s->params);
+
+    if (xcam_handle_set_parameters(s->handle, params) != XCAM_RETURN_NO_ERROR) {
+        av_log(ctx, AV_LOG_ERROR, "xcam handler set parameters failed\n");
+        return AVERROR(EINVAL);
+    }
+
+    return 0;
+}
+
+static int
+init_xcambuf_info(XCAMContext *s, XCamVideoBuffer *buf, AVFrame *frame)
+{
+    XCamReturn ret = xcam_video_buffer_info_reset(
+        &buf->info, s->v4l2_fmt, frame->width, frame->height, frame->linesize[0], frame->height, 0);
+    if (ret != XCAM_RETURN_NO_ERROR)
+        return AVERROR(EINVAL);
+
+    for (int i = 0; frame->linesize[i]; i++) {
+        buf->info.offsets[i] = frame->data[i] - frame->data[0];
+        buf->info.strides[i] = frame->linesize[i];
+    }
+    buf->mem_type = XCAM_MEM_TYPE_CPU;
+
+    return 0;
+}
+
+static int xcam_execute(FFFrameSync *fs)
+{
+    AVFilterContext *ctx = fs->parent;
+    XCAMContext *s = fs->opaque;
+    AVFilterLink *outlink;
+    AVFrame *outframe, *frame;
+    XCamVideoBuffer *outbuf = NULL;
+
+    XCamVideoFilterBuf **inbufs = s->inbufs;
+    for (int i = 0; i < ctx->nb_inputs; i++) {
+        int error = ff_framesync_get_frame(&s->fs, i, &frame, 0);
+        if (error < 0)
+            return error;
+        if (init_xcambuf_info(s, &inbufs[i]->buf, frame) != 0)
+            return AVERROR(EINVAL);
+        fill_xcambuf_from_avframe(inbufs[i], frame);
+    }
+
+    if (xcam_handle_execute(s->handle, (XCamVideoBuffer **)inbufs, &outbuf) != XCAM_RETURN_NO_ERROR) {
+        av_log(ctx, AV_LOG_ERROR, "execute xcam handler failed\n");
+        return AVERROR(EINVAL);
+    }
+
+    outlink = ctx->outputs[0];
+    if (!(outframe = ff_get_video_buffer(outlink, outlink->w, outlink->h))) {
+        av_frame_free(&frame);
+        return AVERROR(ENOMEM);
+    }
+    av_frame_copy_props(outframe, frame);
+
+    fill_avframe_from_xcambuf(outframe, outbuf);
+    xcam_video_buffer_unref(outbuf);
+
+    return ff_filter_frame(outlink, outframe);
+}
+
+static int xcam_query_formats(AVFilterContext *ctx)
+{
+    XCAMContext *s = ctx->priv;
+    AVFilterFormats *formats = NULL;
+
+    static const enum AVPixelFormat nv12_fmts[] = {AV_PIX_FMT_NV12, AV_PIX_FMT_NONE};
+    static const enum AVPixelFormat yuv420_fmts[] = {AV_PIX_FMT_YUV420P, AV_PIX_FMT_NONE};
+    static const enum AVPixelFormat auto_fmts[] = {AV_PIX_FMT_NV12, AV_PIX_FMT_YUV420P, AV_PIX_FMT_NONE};
+
+    const enum AVPixelFormat *pix_fmts = NULL;
+    if (!av_strcasecmp(s->fmt, "nv12"))
+        pix_fmts = nv12_fmts;
+    else if (!av_strcasecmp(s->fmt, "yuv420"))
+        pix_fmts = yuv420_fmts;
+    else
+        pix_fmts = auto_fmts;
+
+    if (!(formats = ff_make_format_list(pix_fmts)))
+        return AVERROR(ENOMEM);
+
+    return ff_set_common_formats(ctx, formats);
+}
+
+static int xcam_config_output(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    XCAMContext *s = ctx->priv;
+    AVFilterLink *inlink = ctx->inputs[0];
+    int ret = 0;
+
+    s->v4l2_fmt = avfmt_to_v4l2fmt(inlink->format);
+    if (s->w && s->h) {
+        outlink->w = s->w;
+        outlink->h = s->h;
+    } else {
+        outlink->w = inlink->w;
+        outlink->h = inlink->h;
+    }
+
+    set_parameters(ctx, inlink, outlink);
+    if (xcam_handle_init(s->handle) != XCAM_RETURN_NO_ERROR) {
+        av_log(ctx, AV_LOG_ERROR, "init xcam handler failed\n");
+        return AVERROR(EINVAL);
+    }
+
+    if ((ret = ff_framesync_init(&s->fs, ctx, ctx->nb_inputs)) < 0)
+        return ret;
+    s->fs.opaque = s;
+    s->fs.on_event = xcam_execute;
+    for (int i = 0; i < ctx->nb_inputs; i++) {
+        FFFrameSyncIn *in = &s->fs.in[i];
+        in->time_base = ctx->inputs[i]->time_base;
+        in->sync      = 1;
+        in->before    = EXT_STOP;
+        in->after     = EXT_STOP;
+    }
+    ret = ff_framesync_configure(&s->fs);
+    outlink->time_base = s->fs.time_base;
+
+    return ret;
+}
+
+static av_cold int xcam_init(AVFilterContext *ctx)
+{
+    XCAMContext *s = ctx->priv;
+    int ret = 0;
+
+    s->handle = xcam_create_handle(s->name);
+    if (!s->handle) {
+        av_log(ctx, AV_LOG_ERROR, "create xcam handler failed\n");
+        return AVERROR(EINVAL);
+    }
+
+    for (int i = 0; i < s->nb_inputs; i++) {
+        s->inbufs[i] = av_mallocz_array(1, sizeof(*s->inbufs[i]));
+        if (!s->inbufs[i])
+            return AVERROR(ENOMEM);
+        s->inbufs[i]->buf.ref = xcambuf_ref;
+        s->inbufs[i]->buf.unref = xcambuf_unref;
+        s->inbufs[i]->buf.map = xcambuf_map;
+        s->inbufs[i]->buf.unmap = xcambuf_unmap;
+        s->inbufs[i]->buf.get_fd = xcambuf_get_fd;
+    }
+
+    for (int i = 0; i < s->nb_inputs; i++) {
+        AVFilterPad pad = { .type = AVMEDIA_TYPE_VIDEO };
+        pad.name = av_asprintf("input%d", i);
+        if (!pad.name)
+            return AVERROR(ENOMEM);
+
+        if ((ret = ff_insert_inpad(ctx, i, &pad)) < 0) {
+            av_freep(&pad.name);
+            return ret;
+        }
+    }
+
+    return 0;
+}
+
+static av_cold void xcam_uninit(AVFilterContext *ctx)
+{
+    XCAMContext *s = ctx->priv;
+
+    ff_framesync_uninit(&s->fs);
+    for (int i = 0; i < s->nb_inputs; i++) {
+        if (s->inbufs[i])
+            av_freep(&s->inbufs[i]);
+        if (ctx->input_pads)
+            av_freep(&ctx->input_pads[i].name);
+    }
+
+    xcam_destroy_handle(s->handle);
+    s->handle = NULL;
+}
+
+static int xcam_activate(AVFilterContext *ctx)
+{
+    XCAMContext *s = ctx->priv;
+    return ff_framesync_activate(&s->fs);
+}
+
+#define OFFSET(x) offsetof(XCAMContext, x)
+#define FLAGS AV_OPT_FLAG_VIDEO_PARAM|AV_OPT_FLAG_FILTERING_PARAM
+#define CONST_STRING(name, help, unit) \
+    { name, help, 0, AV_OPT_TYPE_CONST, { .str=name }, 0, 0, FLAGS, unit }
+
+static const AVOption xcam_options[] = {
+    { "inputs", "number of inputs", OFFSET(nb_inputs), AV_OPT_TYPE_INT, { .i64 = 1 }, 1, XCAM_MAX_INPUTS_NUM, FLAGS },
+    { "w",  "output width", OFFSET(w), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, FLAGS },
+    { "h", "output height", OFFSET(h), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, FLAGS },
+    { "fmt", "pixel format", OFFSET(fmt), AV_OPT_TYPE_STRING, { .str = "auto" }, 0, 0, FLAGS, "fmt" },
+        CONST_STRING("auto",   "automatic format negotiation", "fmt"),
+        CONST_STRING("nv12",   "NV12 format",                  "fmt"),
+        CONST_STRING("yuv420", "YUV420 format",                "fmt"),
+    { "name",   "handler name", OFFSET(name), AV_OPT_TYPE_STRING, { .str = "stitch" }, 0, 0, FLAGS, "name" },
+        CONST_STRING("3dnr",      "3d denoising",               "name"),
+        CONST_STRING("waveletnr", "wavelet denoising",          "name"),
+        CONST_STRING("fisheye",   "fisheye calibration",        "name"),
+        CONST_STRING("defog",     "fog removal",                "name"),
+        CONST_STRING("dvs",       "digital video stabilizer",   "name"),
+        CONST_STRING("stitch",    "soft/GLES/Vulkan stitching", "name"),
+        CONST_STRING("stitchcl",  "OpenCL stitching",           "name"),
+    { "allocoutbuf",  "alloc output buffer", OFFSET(allocoutbuf), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, FLAGS },
+    { "params", "private parameters for each handle, usage: params=help=1 field0=value0 field1=value1 ...",
+        OFFSET(params), AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, FLAGS },
+    { NULL }
+};
+
+AVFILTER_DEFINE_CLASS(xcam);
+
+static const AVFilterPad xcam_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = xcam_config_output
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_xcam = {
+    .name          = "xcam",
+    .description   = NULL_IF_CONFIG_SMALL("Apply image processing using libxcam"),
+    .priv_size     = sizeof(XCAMContext),
+    .priv_class    = &xcam_class,
+    .init          = xcam_init,
+    .query_formats = xcam_query_formats,
+    .outputs       = xcam_outputs,
+    .activate      = xcam_activate,
+    .uninit        = xcam_uninit,
+    .flags         = AVFILTER_FLAG_DYNAMIC_INPUTS
+};
+
diff -Nur FFmpeg/libavformat/.gitignore FFmpeg_patched/libavformat/.gitignore
--- FFmpeg/libavformat/.gitignore	2022-06-29 07:15:48.651919029 +0000
+++ FFmpeg_patched/libavformat/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,3 +0,0 @@
-/protocol_list.c
-/muxer_list.c
-/demuxer_list.c
diff -Nur FFmpeg/libavformat/Makefile FFmpeg_patched/libavformat/Makefile
--- FFmpeg/libavformat/Makefile	2022-06-29 07:15:48.651919029 +0000
+++ FFmpeg_patched/libavformat/Makefile	2022-06-29 07:16:09.543918781 +0000
@@ -148,6 +148,8 @@
 OBJS-$(CONFIG_DATA_MUXER)                += rawenc.o
 OBJS-$(CONFIG_DASH_MUXER)                += dash.o dashenc.o hlsplaylist.o
 OBJS-$(CONFIG_DASH_DEMUXER)              += dash.o dashdec.o
+OBJS-$(CONFIG_TILE_DASH_DEMUXER)         += tiled_dash_dec.o
+OBJS-$(CONFIG_LIBVROMAFPACKING)          += omaf_packing_enc.o
 OBJS-$(CONFIG_DAUD_DEMUXER)              += dauddec.o
 OBJS-$(CONFIG_DAUD_MUXER)                += daudenc.o
 OBJS-$(CONFIG_DCSTR_DEMUXER)             += dcstr.o
diff -Nur FFmpeg/libavformat/allformats.c FFmpeg_patched/libavformat/allformats.c
--- FFmpeg/libavformat/allformats.c	2022-06-29 07:15:48.651919029 +0000
+++ FFmpeg_patched/libavformat/allformats.c	2022-06-29 07:16:09.539918781 +0000
@@ -187,6 +187,8 @@
 extern AVOutputFormat ff_hds_muxer;
 extern AVInputFormat  ff_hevc_demuxer;
 extern AVOutputFormat ff_hevc_muxer;
+extern AVOutputFormat ff_omaf_packing_muxer;
+extern AVInputFormat  ff_tile_dash_demuxer;
 extern AVInputFormat  ff_hls_demuxer;
 extern AVOutputFormat ff_hls_muxer;
 extern AVInputFormat  ff_hnm_demuxer;
diff -Nur FFmpeg/libavformat/flv.h FFmpeg_patched/libavformat/flv.h
--- FFmpeg/libavformat/flv.h	2022-06-29 07:15:48.667919029 +0000
+++ FFmpeg_patched/libavformat/flv.h	2022-06-29 07:16:09.579918780 +0000
@@ -110,6 +110,7 @@
     FLV_CODECID_H264    = 7,
     FLV_CODECID_REALH263= 8,
     FLV_CODECID_MPEG4   = 9,
+    FLV_CODECID_HEVC    = 12,
 };

 enum {
diff -Nur FFmpeg/libavformat/flvdec.c FFmpeg_patched/libavformat/flvdec.c
--- FFmpeg/libavformat/flvdec.c	2022-06-29 07:15:48.667919029 +0000
+++ FFmpeg_patched/libavformat/flvdec.c	2022-06-29 07:16:09.559918780 +0000
@@ -36,6 +36,7 @@
 #include "internal.h"
 #include "avio_internal.h"
 #include "flv.h"
+#include "hevc.h"

 #define VALIDATE_INDEX_TS_THRESH 2500

@@ -318,6 +319,8 @@
         return vpar->codec_id == AV_CODEC_ID_VP6A;
     case FLV_CODECID_H264:
         return vpar->codec_id == AV_CODEC_ID_H264;
+    case FLV_CODECID_HEVC:
+        return vpar->codec_id == AV_CODEC_ID_HEVC;
     default:
         return vpar->codec_tag == flv_codecid;
     }
@@ -367,6 +370,11 @@
         par->codec_id = AV_CODEC_ID_MPEG4;
         ret = 3;
         break;
+    case FLV_CODECID_HEVC:
+        par->codec_id = AV_CODEC_ID_HEVC;
+        vstream->need_parsing = AVSTREAM_PARSE_NONE;
+        ret = 3; // not 4, reading packet type will consume one byte
+        break;
     default:
         avpriv_request_sample(s, "Video codec (%x)", flv_codecid);
         par->codec_tag = flv_codecid;
@@ -1222,6 +1230,7 @@
 
     if (st->codecpar->codec_id == AV_CODEC_ID_AAC ||
         st->codecpar->codec_id == AV_CODEC_ID_H264 ||
+        st->codecpar->codec_id == AV_CODEC_ID_HEVC ||
         st->codecpar->codec_id == AV_CODEC_ID_MPEG4) {
         int type = avio_r8(s->pb);
         size--;
@@ -1231,8 +1240,8 @@
             goto leave;
         }
 
-        if (st->codecpar->codec_id == AV_CODEC_ID_H264 || st->codecpar->codec_id == AV_CODEC_ID_MPEG4) {
-            // sign extension
+        if (st->codecpar->codec_id == AV_CODEC_ID_H264 || st->codecpar->codec_id == AV_CODEC_ID_HEVC
+                || st->codecpar->codec_id == AV_CODEC_ID_MPEG4) {// sign extension
             int32_t cts = (avio_rb24(s->pb) + 0xff800000) ^ 0xff800000;
             pts = dts + cts;
             if (cts < 0) { // dts might be wrong
@@ -1247,7 +1256,7 @@
             }
         }
         if (type == 0 && (!st->codecpar->extradata || st->codecpar->codec_id == AV_CODEC_ID_AAC ||
-            st->codecpar->codec_id == AV_CODEC_ID_H264)) {
+            st->codecpar->codec_id == AV_CODEC_ID_H264 || st->codecpar->codec_id == AV_CODEC_ID_HEVC)) {
             AVDictionaryEntry *t;
 
             if (st->codecpar->extradata) {
diff -Nur FFmpeg/libavformat/flvenc.c FFmpeg_patched/libavformat/flvenc.c
--- FFmpeg/libavformat/flvenc.c	2022-06-29 07:15:48.667919029 +0000
+++ FFmpeg_patched/libavformat/flvenc.c	2022-06-29 07:16:09.571918780 +0000
@@ -29,6 +29,7 @@
 #include "avc.h"
 #include "avformat.h"
 #include "flv.h"
+#include "hevc.h"
 #include "internal.h"
 #include "metadata.h"
 #include "libavutil/opt.h"
@@ -46,6 +47,7 @@
     { AV_CODEC_ID_VP6,      FLV_CODECID_VP6 },
     { AV_CODEC_ID_VP6A,     FLV_CODECID_VP6A },
     { AV_CODEC_ID_H264,     FLV_CODECID_H264 },
+    { AV_CODEC_ID_HEVC,     FLV_CODECID_HEVC },
     { AV_CODEC_ID_NONE,     0 }
 };
 
@@ -491,7 +493,7 @@
     FLVContext *flv = s->priv_data;
 
     if (par->codec_id == AV_CODEC_ID_AAC || par->codec_id == AV_CODEC_ID_H264
-            || par->codec_id == AV_CODEC_ID_MPEG4) {
+            || par->codec_id == AV_CODEC_ID_HEVC || par->codec_id == AV_CODEC_ID_MPEG4) {
         int64_t pos;
         avio_w8(pb,
                 par->codec_type == AVMEDIA_TYPE_VIDEO ?
@@ -537,7 +539,11 @@
             avio_w8(pb, par->codec_tag | FLV_FRAME_KEY); // flags
             avio_w8(pb, 0); // AVC sequence header
             avio_wb24(pb, 0); // composition time
-            ff_isom_write_avcc(pb, par->extradata, par->extradata_size);
+            if (par->codec_id == AV_CODEC_ID_HEVC) {
+                ff_isom_write_hvcc(pb, par->extradata, par->extradata_size, 0);
+            } else {
+                ff_isom_write_avcc(pb, par->extradata, par->extradata_size);
+            }
         }
         data_size = avio_tell(pb) - pos;
         avio_seek(pb, -data_size - 10, SEEK_CUR);
@@ -844,7 +850,7 @@
             AVCodecParameters *par = s->streams[i]->codecpar;
             FLVStreamContext *sc = s->streams[i]->priv_data;
             if (par->codec_type == AVMEDIA_TYPE_VIDEO &&
-                    (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4))
+                    (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_HEVC || par->codec_id == AV_CODEC_ID_MPEG4))
                 put_avc_eos_tag(pb, sc->last_ts);
         }
     }
@@ -895,13 +901,13 @@
     if (par->codec_id == AV_CODEC_ID_VP6F || par->codec_id == AV_CODEC_ID_VP6A ||
         par->codec_id == AV_CODEC_ID_VP6  || par->codec_id == AV_CODEC_ID_AAC)
         flags_size = 2;
-    else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4)
+    else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_HEVC ||  par->codec_id == AV_CODEC_ID_MPEG4)
         flags_size = 5;
     else
         flags_size = 1;

     if (par->codec_id == AV_CODEC_ID_AAC || par->codec_id == AV_CODEC_ID_H264
-            || par->codec_id == AV_CODEC_ID_MPEG4) {
+            || par->codec_id == AV_CODEC_ID_HEVC || par->codec_id == AV_CODEC_ID_MPEG4) {
         int side_size = 0;
         uint8_t *side = av_packet_get_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA, &side_size);
         if (side && side_size > 0 && (side_size != par->extradata_size || memcmp(side, par->extradata, side_size))) {
@@ -913,6 +919,24 @@
         }
     }
 
+    if (par->codec_id == AV_CODEC_ID_HEVC) {
+        int side_size = 0;
+        uint8_t *side = av_packet_get_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA, &side_size);
+        if (side && side_size > 0 && (side_size != par->extradata_size || memcmp(side, par->extradata, side_size))) {
+            av_free(par->extradata);
+            par->extradata = av_mallocz(side_size + AV_INPUT_BUFFER_PADDING_SIZE);
+            if (!par->extradata) {
+                par->extradata_size = 0;
+                return AVERROR(ENOMEM);
+            }
+            memcpy(par->extradata, side, side_size);
+            par->extradata_size = side_size;
+            flv_write_codec_header(s, par, pkt->dts);
+        } else {
+            flv_write_codec_header(s, par, pkt->dts);
+        }
+    }
+
     if (flv->delay == AV_NOPTS_VALUE)
         flv->delay = -pkt->dts;
 
@@ -966,6 +990,10 @@
         if (par->extradata_size > 0 && *(uint8_t*)par->extradata != 1)
             if ((ret = ff_avc_parse_nal_units_buf(pkt->data, &data, &size)) < 0)
                 return ret;
+    } else if (par->codec_id == AV_CODEC_ID_HEVC) {
+        if (par->extradata_size > 0 && *(uint8_t*)par->extradata != 1)
+            if ((ret = ff_hevc_annexb2mp4_buf(pkt->data, &data, &size, 0, NULL)) < 0)
+                return ret;
     } else if (par->codec_id == AV_CODEC_ID_AAC && pkt->size > 2 &&
                (AV_RB16(pkt->data) & 0xfff0) == 0xfff0) {
         if (!s->streams[pkt->stream_index]->nb_frames) {
@@ -1036,9 +1064,9 @@
             else
                 avio_w8(pb, ((FFALIGN(par->width,  16) - par->width) << 4) |
                              (FFALIGN(par->height, 16) - par->height));
-        } else if (par->codec_id == AV_CODEC_ID_AAC)
+        } else if (par->codec_id == AV_CODEC_ID_AAC){
             avio_w8(pb, 1); // AAC raw
-        else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4) {
+        } else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_HEVC ||  par->codec_id == AV_CODEC_ID_MPEG4) {
             avio_w8(pb, 1); // AVC NALU
             avio_wb24(pb, pkt->pts - pkt->dts);
         }
diff -Nur FFmpeg/libavformat/omaf_packing_enc.c FFmpeg_patched/libavformat/omaf_packing_enc.c
--- FFmpeg/libavformat/omaf_packing_enc.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavformat/omaf_packing_enc.c	2022-06-29 07:16:09.579918780 +0000
@@ -0,0 +1,810 @@
+/*
+ * Intel tile Dash muxer
+ *
+ * Copyright (c) 2018 Intel Cooperation
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <unistd.h>
+#include <sys/stat.h>
+
+#include "libavutil/avassert.h"
+#include "libavutil/avutil.h"
+#include "libavutil/avstring.h"
+#include "libavutil/intreadwrite.h"
+#include "libavutil/mathematics.h"
+#include "libavutil/opt.h"
+#include "libavutil/rational.h"
+#include "libavutil/time_internal.h"
+
+#include "avformat.h"
+#include "avio_internal.h"
+
+#include "360SCVPAPI.h"
+#include "VROmafPackingAPI.h"
+#include "common_data.h"
+
+static uint32_t min_loglevel = 2;
+
+typedef struct {
+    int         streamIdx;
+    FrameBSInfo *frameBSInfo;
+} BufferedFrame;
+
+typedef struct {
+    const AVClass  *class;  /* Class for private options. */
+    Handler        handler;
+    InitialInfo    *initInfo;
+    int            inStreamsNum;
+
+    const char     *proj_type;
+    const char     *face_file;
+    int            viewport_w;
+    int            viewport_h;
+    float          viewport_yaw;
+    float          viewport_pitch;
+    float          viewport_fov_hor;
+    float          viewport_fov_ver;
+    int            window_size;
+    int            extra_window_size;
+    int            has_extractor;
+    const char     *packingPluginPath;
+    const char     *packingPluginName;
+    bool           fixedPackedPicRes;
+    const char     *videoPluginPath;
+    const char     *videoPluginName;
+    const char     *audioPluginPath;
+    const char     *audioPluginName;
+    bool           cmafEnabled;
+    const char     *chunkInfoType;
+    int64_t        chunkDur;
+    const char     *segWriterPluginPath;
+    const char     *segWriterPluginName;
+    const char     *mpdWriterPluginPath;
+    const char     *mpdWriterPluginName;
+    int            need_buffered_frames;
+    uint16_t       extractors_per_thread;
+    int64_t        seg_duration;
+    int            remove_at_exit;
+    int            use_template;
+    int            use_timeline;
+    char           dirname[1024];
+    const char     *out_name;
+    const char     *base_url;
+    const char     *utc_timing_url;
+    int            is_live;
+    int64_t        target_latency;
+    int64_t        min_latency;
+    int64_t        max_latency;
+    int            split_tile;
+    int64_t        frameNum;
+    BufferedFrame  bufferedFrames[1024];
+    int            bufferedFramesNum;
+    bool           need_external_log;
+    int            min_log_level;
+    bool           first_audio_input;
+} OMAFContext;
+
+static uint8_t convert_face_index(char *face_name)
+{
+    if (0 == strncmp(face_name, "PY", 2))
+        return 0;
+    else if (0 == strncmp(face_name, "PX", 2))
+        return 1;
+    else if (0 == strncmp(face_name, "NY", 2))
+        return 2;
+    else if (0 == strncmp(face_name, "NZ", 2))
+        return 3;
+    else if (0 == strncmp(face_name, "NX", 2))
+        return 4;
+    else if (0 == strncmp(face_name, "PZ", 2))
+        return 5;
+    else
+        return 255;
+}
+
+static E_TransformType convert_transform_type(char *transform_name)
+{
+    if (0 == strncmp(transform_name, "NO_TRANSFORM", 12))
+        return NO_TRANSFORM;
+    else if (0 == strncmp(transform_name, "MIRRORING_HORIZONTALLY", 22))
+        return MIRRORING_HORIZONTALLY;
+    else if (0 == strncmp(transform_name, "ROTATION_180_ANTICLOCKWISE", 26))
+        return ROTATION_180_ANTICLOCKWISE;
+    else if (0 == strncmp(transform_name, "ROTATION_180_ANTICLOCKWISE_AFTER_MIRRORING_HOR", 46))
+        return ROTATION_180_ANTICLOCKWISE_AFTER_MIRRORING_HOR;
+    else if (0 == strncmp(transform_name, "ROTATION_90_ANTICLOCKWISE_BEFORE_MIRRORING_HOR", 46))
+        return ROTATION_90_ANTICLOCKWISE_BEFORE_MIRRORING_HOR;
+    else if (0 == strncmp(transform_name, "ROTATION_90_ANTICLOCKWISE", 25))
+        return ROTATION_90_ANTICLOCKWISE;
+    else if (0 == strncmp(transform_name, "ROTATION_270_ANTICLOCKWISE_BEFORE_MIRRORING_HOR", 47))
+        return ROTATION_270_ANTICLOCKWISE_BEFORE_MIRRORING_HOR;
+    else if (0 == strncmp(transform_name, "ROTATION_270_ANTICLOCKWISE", 26))
+        return ROTATION_270_ANTICLOCKWISE;
+    else
+        return NO_TRANSFORM;
+}
+
+static void ffmpeg_log_callback(LogLevel log_level, const char* file_name, uint64_t line_num, const char* fmt, ...)
+{
+    va_list vl;
+    va_start(vl, fmt);
+
+    switch (log_level)
+    {
+        case LOG_INFO:
+        {
+            if(min_loglevel == 0)
+            {
+                av_vlog(NULL, AV_LOG_INFO, fmt, vl);
+            }
+            break;
+        }
+        case LOG_WARNING:
+        {
+            if(min_loglevel <= 1)
+            {
+                av_vlog(NULL, AV_LOG_WARNING, fmt, vl);
+            }
+            break;
+        }
+        case LOG_ERROR:
+        {
+            if(min_loglevel <= 2)
+            {
+                av_vlog(NULL, AV_LOG_ERROR, fmt, vl);
+            }
+            break;
+        }
+        case LOG_FATAL:
+        {
+            if(min_loglevel <= 3)
+            {
+                av_vlog(NULL, AV_LOG_FATAL, fmt, vl);
+            }
+            break;
+        }
+        default:
+        {
+            av_log(NULL, AV_LOG_ERROR, "Invalid log level !");
+            break;
+        }
+    }
+    va_end(vl);
+}
+
+static int omaf_init(AVFormatContext *s)
+{
+    OMAFContext *c = s->priv_data;
+    int ret = 0;
+
+    c->frameNum = -1;
+
+    c->initInfo = (InitialInfo*)malloc(sizeof(InitialInfo));
+    if (!(c->initInfo))
+    {
+        av_log(s, AV_LOG_ERROR, "Failed to malloc memory for initial information \n");
+        return AVERROR(ENOMEM);
+    }
+    InitialInfo *initInfo = c->initInfo;
+    memset(initInfo, 0, sizeof(InitialInfo));
+
+    initInfo->bsNumVideo = 0;
+    initInfo->bsNumAudio = 0;
+
+    for (int i = 0; i < s->nb_streams; i++)
+    {
+        AVStream *st = s->streams[i];
+        switch(st->codecpar->codec_type)
+        {
+            case AVMEDIA_TYPE_VIDEO:
+                initInfo->bsNumVideo++;
+                break;
+            case AVMEDIA_TYPE_AUDIO:
+                initInfo->bsNumAudio++;
+                break;
+            default:
+                break;
+        }
+    }
+
+    if (initInfo->bsNumVideo > 2)
+    {
+        c->has_extractor = 0;
+    }
+
+    initInfo->videoProcessPluginPath = c->videoPluginPath;
+    initInfo->videoProcessPluginName = c->videoPluginName;
+
+    if (initInfo->bsNumAudio)
+    {
+        if ((0 == strncmp(c->audioPluginPath, "NULL", 4)) ||
+            (0 == strncmp(c->audioPluginName, "NULL", 4)))
+        {
+            av_log(s, AV_LOG_ERROR, "No audio stream process plugin is set but there is indeed audio stream input !\n");
+            return AVERROR_INVALIDDATA;
+        }
+
+        initInfo->audioProcessPluginPath = c->audioPluginPath;
+        initInfo->audioProcessPluginName = c->audioPluginName;
+    }
+
+    if (c->has_extractor)
+    {
+        initInfo->packingPluginPath = c->packingPluginPath;
+        if (initInfo->bsNumVideo == 1)
+        {
+            initInfo->packingPluginName = "SingleVideoPacking";
+        }
+        else if (initInfo->bsNumVideo == 2)
+        {
+            initInfo->packingPluginName = c->packingPluginName;
+        }
+        else
+        {
+            av_log(s, AV_LOG_ERROR, "Not correct video streams number for VR OMAF Packing \n");
+            return AVERROR(EINVAL);
+        }
+        initInfo->fixedPackedPicRes = c->fixedPackedPicRes;
+    }
+    else
+    {
+        initInfo->packingPluginPath = NULL;
+        initInfo->packingPluginName = NULL;
+        initInfo->fixedPackedPicRes = false;
+    }
+
+    initInfo->cmafEnabled = c->cmafEnabled;
+    printf("CMAF enabled %d \n", initInfo->cmafEnabled);
+    initInfo->segWriterPluginPath = c->segWriterPluginPath;
+    initInfo->segWriterPluginName = c->segWriterPluginName;
+    if (initInfo->cmafEnabled)
+    {
+        if (0 == strcmp(initInfo->segWriterPluginName, "SegmentWriter"))
+        {
+            av_log(s, AV_LOG_ERROR, "Plugin SegmentWriter can't generate CMAF segments !\n");
+            return AVERROR(EINVAL);
+        }
+    }
+
+    initInfo->mpdWriterPluginPath = c->mpdWriterPluginPath;
+    initInfo->mpdWriterPluginName = c->mpdWriterPluginName;
+
+    min_loglevel = c->min_log_level;
+    if (c->need_external_log)
+    {
+        initInfo->logFunction = (void*)(ffmpeg_log_callback);
+    }
+    else
+    {
+        initInfo->logFunction = NULL;
+    }
+
+    initInfo->bsBuffers = (BSBuffer*)malloc(sizeof(BSBuffer) * (initInfo->bsNumVideo + initInfo->bsNumAudio));
+    if (!(initInfo->bsBuffers))
+    {
+        av_log(s, AV_LOG_ERROR, "Failed to malloc memory for video bitstream buffer \n");
+        return AVERROR(ENOMEM);
+    }
+    memset(initInfo->bsBuffers, 0, sizeof(BSBuffer) * (initInfo->bsNumVideo + initInfo->bsNumAudio));
+    initInfo->viewportInfo = (ViewportInformation*)malloc(sizeof(ViewportInformation));
+    if (!(initInfo->viewportInfo))
+    {
+        av_log(s, AV_LOG_ERROR, "Failed to malloc memory for viewport information \n");
+        return AVERROR(ENOMEM);
+    }
+    memset(initInfo->viewportInfo, 0, sizeof(ViewportInformation));
+    initInfo->viewportInfo->viewportWidth = c->viewport_w;
+    initInfo->viewportInfo->viewportHeight = c->viewport_h;
+    initInfo->viewportInfo->viewportPitch = c->viewport_pitch;
+    initInfo->viewportInfo->viewportYaw = c->viewport_yaw;
+    initInfo->viewportInfo->horizontalFOVAngle = c->viewport_fov_hor;
+    initInfo->viewportInfo->verticalFOVAngle = c->viewport_fov_ver;
+    initInfo->viewportInfo->outGeoType = E_SVIDEO_VIEWPORT;
+    if (0 == strncmp(c->proj_type, "ERP", 3))
+    {
+        initInfo->viewportInfo->inGeoType = E_SVIDEO_EQUIRECT;
+    }
+    else if (0 == strncmp(c->proj_type, "Cube", 4))
+    {
+        initInfo->viewportInfo->inGeoType = E_SVIDEO_CUBEMAP;
+    }
+    else if (0 == strncmp(c->proj_type, "Planar", 6))
+    {
+        initInfo->viewportInfo->inGeoType = E_SVIDEO_PLANAR;
+    }
+
+    initInfo->segmentationInfo = (SegmentationInfo*)malloc(sizeof(SegmentationInfo));
+    if (!(initInfo->segmentationInfo))
+    {
+        av_log(s, AV_LOG_ERROR, "Failed to malloc memory for segmentation information \n");
+        return AVERROR(ENOMEM);
+    }
+    memset(initInfo->segmentationInfo, 0, sizeof(SegmentationInfo));
+    initInfo->segmentationInfo->windowSize = c->window_size;
+    initInfo->segmentationInfo->extraWindowSize = c->extra_window_size;
+    initInfo->segmentationInfo->needBufedFrames = c->need_buffered_frames;
+    initInfo->segmentationInfo->extractorTracksPerSegThread = c->extractors_per_thread;
+    initInfo->segmentationInfo->segDuration = c->seg_duration / 1000000;
+    initInfo->segmentationInfo->removeAtExit = c->remove_at_exit;
+    initInfo->segmentationInfo->useTemplate = c->use_template;
+    initInfo->segmentationInfo->useTimeline = c->use_timeline;
+
+    initInfo->segmentationInfo->dirName = (char*)malloc(1024 * sizeof(char));
+    av_strlcpy(initInfo->segmentationInfo->dirName, s->url, sizeof(c->dirname));
+    initInfo->segmentationInfo->outName = c->out_name;
+    initInfo->segmentationInfo->baseUrl = c->base_url;
+    initInfo->segmentationInfo->utcTimingUrl = c->utc_timing_url;
+    initInfo->segmentationInfo->isLive = c->is_live;
+    initInfo->segmentationInfo->splitTile = c->split_tile;
+    initInfo->segmentationInfo->hasMainAS = true;
+    initInfo->segmentationInfo->chunkDuration = c->chunkDur;
+    //printf("initInfo->segmentationInfo->chunkDuration %ld \n", initInfo->segmentationInfo->chunkDuration);
+    if (initInfo->cmafEnabled && !(initInfo->segmentationInfo->chunkDuration))
+    {
+        av_log(s, AV_LOG_ERROR, "Chunk duration can't be zero when CMAF ENABLED !\n");
+        return AVERROR(EINVAL);
+    }
+    if (initInfo->cmafEnabled && ((initInfo->segmentationInfo->segDuration * 1000) % (initInfo->segmentationInfo->chunkDuration)))
+    {
+        av_log(s, AV_LOG_ERROR, "Segment duration can't be divided by chunk duration !\n");
+        return AVERROR(EINVAL);
+    }
+
+    if (initInfo->segmentationInfo->isLive)
+    {
+        initInfo->segmentationInfo->targetLatency = c->target_latency;
+        initInfo->segmentationInfo->minLatency = c->min_latency;
+        initInfo->segmentationInfo->maxLatency = c->max_latency;
+    }
+
+    if (initInfo->cmafEnabled)
+    {
+        if (0 == strncmp(c->chunkInfoType, "sidx_only", 9))
+        {
+            initInfo->segmentationInfo->chunkInfoType = E_CHUNKINFO_SIDX_ONLY;
+        }
+        else if (0 == strncmp(c->chunkInfoType, "cloc_only", 9))
+        {
+            initInfo->segmentationInfo->chunkInfoType = E_CHUNKINFO_CLOC_ONLY;
+        }
+        else if (0 == strncmp(c->chunkInfoType, "sidx_cloc", 9))
+        {
+            initInfo->segmentationInfo->chunkInfoType = E_CHUNKINFO_SIDX_AND_CLOC;
+        }
+        else
+        {
+            initInfo->segmentationInfo->chunkInfoType = E_NO_CHUNKINFO;
+            av_log(s, AV_LOG_INFO, "No chunk info type set or invalid set, then set to default value!\n");
+        }
+    }
+
+    if (0 == strncmp(c->proj_type, "ERP", 3))
+    {
+        initInfo->projType = E_SVIDEO_EQUIRECT;
+        initInfo->cubeMapInfo = NULL;
+    }
+    else if (0 == strncmp(c->proj_type, "Cube", 4))
+    {
+        initInfo->projType = E_SVIDEO_CUBEMAP;
+    }
+    else if (0 == strncmp(c->proj_type, "Planar", 6))
+    {
+        initInfo->projType = E_SVIDEO_PLANAR;
+    }
+
+    if (initInfo->projType == E_SVIDEO_CUBEMAP)
+    {
+        if (!(c->face_file))
+        {
+            av_log(s, AV_LOG_ERROR,
+                    "face_file should not be null when input source is from Cubemap projection! \n");
+            return AVERROR(EINVAL);
+        }
+
+        initInfo->cubeMapInfo = (InputCubeMapInfo*)malloc(sizeof(InputCubeMapInfo));
+        memset(initInfo->cubeMapInfo, 0, sizeof(InputCubeMapInfo));
+        FILE *fp = fopen(c->face_file, "r");
+        if (!fp)
+        {
+            av_log(s, AV_LOG_ERROR,
+                    "Failed to open cubemap face file !\n");
+            return AVERROR(ENOMEM);
+        }
+        char face_name[128] = { 0 };
+        char transform_name[128] = { 0 };
+        fscanf(fp, "%s %s", face_name, transform_name);
+        initInfo->cubeMapInfo->face0MapInfo.mappedStandardFaceId = convert_face_index(face_name);
+        initInfo->cubeMapInfo->face0MapInfo.transformType = convert_transform_type(transform_name);
+
+        memset(face_name, 0, 128);
+        memset(transform_name, 0, 128);
+        fscanf(fp, "%s %s", face_name, transform_name);
+        initInfo->cubeMapInfo->face1MapInfo.mappedStandardFaceId = convert_face_index(face_name);
+        initInfo->cubeMapInfo->face1MapInfo.transformType = convert_transform_type(transform_name);
+
+        memset(face_name, 0, 128);
+        memset(transform_name, 0, 128);
+        fscanf(fp, "%s %s", face_name, transform_name);
+        initInfo->cubeMapInfo->face2MapInfo.mappedStandardFaceId = convert_face_index(face_name);
+        initInfo->cubeMapInfo->face2MapInfo.transformType = convert_transform_type(transform_name);
+
+        memset(face_name, 0, 128);
+        memset(transform_name, 0, 128);
+        fscanf(fp, "%s %s", face_name, transform_name);
+        initInfo->cubeMapInfo->face3MapInfo.mappedStandardFaceId = convert_face_index(face_name);
+        initInfo->cubeMapInfo->face3MapInfo.transformType = convert_transform_type(transform_name);
+
+        memset(face_name, 0, 128);
+        memset(transform_name, 0, 128);
+        fscanf(fp, "%s %s", face_name, transform_name);
+        initInfo->cubeMapInfo->face4MapInfo.mappedStandardFaceId = convert_face_index(face_name);
+        initInfo->cubeMapInfo->face4MapInfo.transformType = convert_transform_type(transform_name);
+
+        memset(face_name, 0, 128);
+        memset(transform_name, 0, 128);
+        fscanf(fp, "%s %s", face_name, transform_name);
+        initInfo->cubeMapInfo->face5MapInfo.mappedStandardFaceId = convert_face_index(face_name);
+        initInfo->cubeMapInfo->face5MapInfo.transformType = convert_transform_type(transform_name);
+
+        fclose(fp);
+        fp = NULL;
+    }
+    memset(c->bufferedFrames, 0, 1024 * sizeof(BufferedFrame));
+    c->bufferedFramesNum = 0;
+    c->inStreamsNum = 0;
+    c->handler = NULL;
+
+    return 0;
+}
+
+static void omaf_free(AVFormatContext *s)
+{
+    OMAFContext *c = s->priv_data;
+
+    VROmafPackingClose(c->handler);
+
+    if (c->initInfo->bsBuffers)
+    {
+        for (int i = 0; i < (c->initInfo->bsNumVideo + c->initInfo->bsNumAudio); i++)
+        {
+            if (c->initInfo->bsBuffers[i].data)
+            {
+                free(c->initInfo->bsBuffers[i].data);
+                c->initInfo->bsBuffers[i].data = NULL;
+            }
+        }
+        free(c->initInfo->bsBuffers);
+        c->initInfo->bsBuffers = NULL;
+    }
+
+    if(c->initInfo->viewportInfo)
+    {
+        free(c->initInfo->viewportInfo);
+        c->initInfo->viewportInfo = NULL;
+    }
+
+    if(c->initInfo->segmentationInfo)
+    {
+        if (c->initInfo->segmentationInfo->dirName)
+        {
+            free(c->initInfo->segmentationInfo->dirName);
+            c->initInfo->segmentationInfo->dirName = NULL;
+        }
+
+        free(c->initInfo->segmentationInfo);
+        c->initInfo->segmentationInfo = NULL;
+    }
+
+    if (c->initInfo->cubeMapInfo)
+    {
+        free(c->initInfo->cubeMapInfo);
+        c->initInfo->cubeMapInfo = NULL;
+    }
+
+    if(c->initInfo)
+    {
+        free(c->initInfo);
+        c->initInfo = NULL;
+    }
+
+    return;
+}
+
+static int omaf_write_header(AVFormatContext *s)
+{
+    return 0;
+}
+
+static int omaf_write_packet(AVFormatContext *s, AVPacket *pkt)
+{
+    OMAFContext *c = s->priv_data;
+    int ret = 0;
+
+    if(!c->handler)
+    {
+        int i = pkt->stream_index;
+        AVStream *st = s->streams[i];
+
+        if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts == 0))
+        {
+            c->initInfo->bsBuffers[i].dataSize = pkt->side_data->size;
+
+            c->initInfo->bsBuffers[i].data = (uint8_t*)malloc(c->initInfo->bsBuffers[i].dataSize * sizeof(uint8_t));
+            if (!(c->initInfo->bsBuffers[i].data))
+            {
+                av_log(s, AV_LOG_ERROR, "Failed to malloc memory for holding bitstream header data \n");
+                return -1;
+            }
+            memcpy(c->initInfo->bsBuffers[i].data, pkt->side_data->data, c->initInfo->bsBuffers[i].dataSize);
+
+        }
+        else if ((st->codecpar->codec_id == AV_CODEC_ID_AAC) && !c->first_audio_input)
+        {
+            c->initInfo->bsBuffers[i].dataSize = pkt->size;
+
+            c->initInfo->bsBuffers[i].data = (uint8_t*)malloc(c->initInfo->bsBuffers[i].dataSize * sizeof(uint8_t));
+            if (!(c->initInfo->bsBuffers[i].data))
+            {
+                av_log(s, AV_LOG_ERROR, "Failed to malloc memory for holding bitstream header data \n");
+                return -1;
+            }
+            memcpy(c->initInfo->bsBuffers[i].data, pkt->data, c->initInfo->bsBuffers[i].dataSize);
+        }
+
+        if (st->codecpar->codec_id == AV_CODEC_ID_H264)
+        {
+            c->initInfo->bsBuffers[i].codecId = CODEC_ID_H264;
+        }
+        else if (st->codecpar->codec_id == AV_CODEC_ID_HEVC)
+        {
+            c->initInfo->bsBuffers[i].codecId = CODEC_ID_H265;
+        }
+        else if (st->codecpar->codec_id == AV_CODEC_ID_AAC)
+        {
+            c->initInfo->bsBuffers[i].codecId = CODEC_ID_AAC;
+        }
+
+        c->initInfo->bsBuffers[i].bitRate = st->codecpar->bit_rate;
+        c->initInfo->bsBuffers[i].frameRate.num = st->avg_frame_rate.num;
+        c->initInfo->bsBuffers[i].frameRate.den = st->avg_frame_rate.den;
+        c->initInfo->bsBuffers[i].mediaType = -1;
+        switch(st->codecpar->codec_type)
+        {
+            case AVMEDIA_TYPE_VIDEO:
+                c->initInfo->bsBuffers[i].mediaType = VIDEOTYPE;
+                break;
+            case AVMEDIA_TYPE_AUDIO:
+                c->initInfo->bsBuffers[i].mediaType = AUDIOTYPE;
+                c->initInfo->bsBuffers[i].audioObjType = st->codecpar->profile ;
+                c->initInfo->bsBuffers[i].sampleRate = st->codecpar->sample_rate;
+                c->initInfo->bsBuffers[i].channelNum = st->codecpar->channels;
+                break;
+            case AVMEDIA_TYPE_SUBTITLE:
+                c->initInfo->bsBuffers[i].mediaType = SUBTITLETYPE;
+                break;
+            default:
+                break;
+        }
+
+        if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts == 0))
+        {
+            c->inStreamsNum++;
+        }
+        else if ((st->codecpar->codec_id == AV_CODEC_ID_AAC) && !c->first_audio_input)
+        {
+            c->inStreamsNum++;
+            c->first_audio_input = true;
+        }
+
+        FrameBSInfo* frameInfo = (FrameBSInfo*)malloc(sizeof(FrameBSInfo));
+        memset(frameInfo, 0, sizeof(FrameBSInfo));
+        if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts == 0))
+        {
+            frameInfo->dataSize = pkt->size - pkt->side_data->size;
+        }
+        else if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts != 0))
+        {
+            frameInfo->dataSize = pkt->size;
+        }
+        else if (st->codecpar->codec_id == AV_CODEC_ID_AAC)
+        {
+            frameInfo->dataSize = pkt->size;
+        }
+
+        frameInfo->data = (uint8_t*)malloc(frameInfo->dataSize * sizeof(uint8_t));
+        if (!(frameInfo->data))
+        {
+            av_log(s, AV_LOG_ERROR, "Failed to malloc memory for buffered frame data \n");
+            return -1;
+        }
+
+        if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts == 0))
+        {
+            memcpy(frameInfo->data, pkt->data + pkt->side_data->size, frameInfo->dataSize);
+            frameInfo->isKeyFrame = (pkt->flags & AV_PKT_FLAG_KEY);
+        }
+        else if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts != 0))
+        {
+            memcpy(frameInfo->data, pkt->data, frameInfo->dataSize);
+            frameInfo->isKeyFrame = (pkt->flags & AV_PKT_FLAG_KEY);
+        }
+        else if (st->codecpar->codec_id == AV_CODEC_ID_AAC)
+        {
+            memcpy(frameInfo->data, pkt->data, frameInfo->dataSize);
+            frameInfo->isKeyFrame = true;
+        }
+        frameInfo->pts = pkt->pts;
+
+        c->bufferedFrames[c->bufferedFramesNum].streamIdx = pkt->stream_index;
+        c->bufferedFrames[c->bufferedFramesNum].frameBSInfo = frameInfo;
+        c->bufferedFramesNum++;
+
+        if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts == 0))
+        {
+            free(pkt->side_data->data);
+            pkt->side_data->data = NULL;
+            pkt->side_data->size = 0;
+            free(pkt->side_data);
+            pkt->side_data = NULL;
+            pkt->side_data_elems = 0;
+        }
+
+        if (c->inStreamsNum == (c->initInfo->bsNumVideo + c->initInfo->bsNumAudio))
+        {
+            c->handler = VROmafPackingInit(c->initInfo);
+            if (!(c->handler))
+            {
+                av_log(s, AV_LOG_ERROR, "Failed to create VR Omaf Packing handler \n");
+                return -1;
+            }
+            c->frameNum++;
+        }
+    }
+    else
+    {
+        if (c->bufferedFramesNum > 0)
+        {
+            for (int i = 0; i < c->bufferedFramesNum; i++)
+            {
+                ret = VROmafPackingWriteSegment(c->handler, c->bufferedFrames[i].streamIdx, c->bufferedFrames[i].frameBSInfo);
+                if (ret != 0)
+                {
+                    av_log(s, AV_LOG_ERROR, "Failed to write segment.\n" );
+                    return ret;
+                }
+
+                free(c->bufferedFrames[i].frameBSInfo->data);
+                c->bufferedFrames[i].frameBSInfo->data = NULL;
+                c->bufferedFrames[i].frameBSInfo->dataSize = 0;
+                free(c->bufferedFrames[i].frameBSInfo);
+                c->bufferedFrames[i].frameBSInfo = NULL;
+            }
+            c->bufferedFramesNum = 0;
+            c->frameNum++;
+        }
+
+        FrameBSInfo* frameInfo = (FrameBSInfo*)malloc(sizeof(FrameBSInfo));
+
+        frameInfo->data = pkt->data;
+        frameInfo->dataSize = pkt->size;
+
+        frameInfo->isKeyFrame = (pkt->flags & AV_PKT_FLAG_KEY);
+
+        frameInfo->pts = pkt->pts;
+
+        ret = VROmafPackingWriteSegment(c->handler, pkt->stream_index, frameInfo);
+        if(ret !=0 )
+        {
+            av_log(s, AV_LOG_ERROR, "Failed to write segment.\n" );
+        }
+
+        free(frameInfo);
+        frameInfo = NULL;
+        c->frameNum++;
+    }
+
+    return ret;
+}
+
+static int omaf_write_trailer(AVFormatContext *s)
+{
+    OMAFContext *c = s->priv_data;
+    int ret = 0;
+
+    ret = VROmafPackingEndStreams(c->handler);
+    if(ret)
+    {
+        av_log(s, AV_LOG_ERROR, "Failed to write end mpd \n" );
+        return ret;
+    }
+
+    return 0;
+}
+
+#define OFFSET(x) offsetof(OMAFContext, x)
+#define E AV_OPT_FLAG_ENCODING_PARAM
+static const AVOption options[] = {
+    { "packing_proj_type", "input source projection type, ERP or Cubemap", OFFSET(proj_type), AV_OPT_TYPE_STRING, { .str = "ERP" }, 0, 0, E },
+    { "cubemap_face_file", "configure input cubemap face relation to face layout defined in OMAF for cube-3x2", OFFSET(face_file), AV_OPT_TYPE_STRING, { 0 }, 0, 0, E },
+    { "viewport_w", "set viewport width", OFFSET(viewport_w), AV_OPT_TYPE_INT, { .i64 = 1024 }, 0, INT_MAX, E },
+    { "viewport_h", "set viewport height", OFFSET(viewport_h), AV_OPT_TYPE_INT, { .i64 = 1024 }, 0, INT_MAX, E },
+    { "viewport_yaw", "set viewport yaw angle, which is the angle around y axis", OFFSET(viewport_yaw), AV_OPT_TYPE_FLOAT, { .dbl = 90 }, 0, 180, E },
+    { "viewport_pitch", "set viewport pitch angle, which is the angle around x axis", OFFSET(viewport_pitch), AV_OPT_TYPE_FLOAT, { .dbl = 0 }, 0, 100, E },
+    { "viewport_fov_hor", "set horizontal angle of field of view (FOV)", OFFSET(viewport_fov_hor), AV_OPT_TYPE_FLOAT, { .dbl = 80 }, 0, 180, E },
+    { "viewport_fov_ver", "set vertical angle of field of view (FOV)", OFFSET(viewport_fov_ver), AV_OPT_TYPE_FLOAT, { .dbl = 80 }, 0, 100, E },
+    { "window_size", "number of segments kept in the manifest", OFFSET(window_size), AV_OPT_TYPE_INT, { .i64 = 5 }, 0, INT_MAX, E },
+    { "extra_window_size", "number of segments kept outside of the manifest before removing from disk", OFFSET(extra_window_size), AV_OPT_TYPE_INT, { .i64 = 15 }, 0, INT_MAX, E },
+    { "split_tile", "need split the stream to tiles if input is tile-based hevc stream", OFFSET(split_tile), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 2, E },
+    { "seg_duration", "segment duration (in seconds, fractional value can be set)", OFFSET(seg_duration), AV_OPT_TYPE_DURATION, { .i64 = 5000000 }, 0, INT_MAX, E },
+    { "remove_at_exit", "remove all segments when finished", OFFSET(remove_at_exit), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "use_template", "Use SegmentTemplate instead of SegmentList", OFFSET(use_template), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, E },
+    { "use_timeline", "Use SegmentTimeline in SegmentTemplate", OFFSET(use_timeline), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, E },
+    { "utc_timing_url", "URL of the page that will return the UTC timestamp in ISO format", OFFSET(utc_timing_url), AV_OPT_TYPE_STRING, { 0 }, 0, 0, E },
+    { "is_live", "Enable/Disable streaming mode of output. Each frame will be moof fragment", OFFSET(is_live), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "base_url", "MPD BaseURL", OFFSET(base_url), AV_OPT_TYPE_STRING, { 0 }, 0, 0, E },
+    { "out_name", "name prefix for all dash output files", OFFSET(out_name), AV_OPT_TYPE_STRING, {.str = "dash-stream"}, 0, 0, E },
+    { "need_buffered_frames", "needed buffered frames number before packing starts", OFFSET(need_buffered_frames), AV_OPT_TYPE_INT, { .i64 = 15 }, 0, INT_MAX, E },
+    { "extractors_per_thread", "extractor tracks per segmentation thread", OFFSET(extractors_per_thread), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, E },
+    { "has_extractor", "Enable/Disable OMAF extractor tracks", OFFSET(has_extractor), AV_OPT_TYPE_INT, { .i64 = 1 }, 0, INT_MAX, E },
+    { "packing_plugin_path", "OMAF Packing plugin path", OFFSET(packingPluginPath), AV_OPT_TYPE_STRING, {.str = "/usr/local/lib"}, 0, 0, E },
+    { "packing_plugin_name", "OMAF Packing plugin name", OFFSET(packingPluginName), AV_OPT_TYPE_STRING, {.str = "HighResPlusFullLowResPacking"}, 0, 0, E },
+    { "video_plugin_path", "Video stream process plugin path", OFFSET(videoPluginPath), AV_OPT_TYPE_STRING, {.str = "/usr/local/lib"}, 0, 0, E },
+    { "video_plugin_name", "Video stream process plugin name", OFFSET(videoPluginName), AV_OPT_TYPE_STRING, {.str = "HevcVideoStreamProcess"}, 0, 0, E },
+    { "audio_plugin_path", "Audio stream process plugin path", OFFSET(audioPluginPath), AV_OPT_TYPE_STRING, {.str = "NULL"}, 0, 0, E },
+    { "audio_plugin_name", "Audio stream process plugin name", OFFSET(audioPluginName), AV_OPT_TYPE_STRING, {.str = "NULL"}, 0, 0, E },
+    { "fixed_extractors_res", "whether extractor track needs the fixed resolution", OFFSET(fixedPackedPicRes), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "cmaf_enabled", "whether to enable CMAF segments", OFFSET(cmafEnabled), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "chunk_info_type", "which chunk info type (sidx_only/cloc_only/sidx_and_cloc) is enabled", OFFSET(chunkInfoType), AV_OPT_TYPE_STRING, { .str = "none" }, 0, 0, E },
+    { "chunk_dur", "CMAF chunk duration in millisecond", OFFSET(chunkDur), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, E },
+    { "seg_writer_path", "Segment writer plugin path", OFFSET(segWriterPluginPath), AV_OPT_TYPE_STRING, {.str = "/usr/local/lib"}, 0, 0, E },
+    { "seg_writer_name", "Segment writer plugin name", OFFSET(segWriterPluginName), AV_OPT_TYPE_STRING, {.str = "SegmentWriter"}, 0, 0, E },
+    { "mpd_writer_path", "MPD file writer plugin path", OFFSET(mpdWriterPluginPath), AV_OPT_TYPE_STRING, {.str = "/usr/local/lib"}, 0, 0, E },
+    { "mpd_writer_name", "MPD file writer plugin name", OFFSET(mpdWriterPluginName), AV_OPT_TYPE_STRING, {.str = "MPDWriter"}, 0, 0, E },
+    { "target_latency", "Target end to end latency in live streaming in millisecond", OFFSET(target_latency), AV_OPT_TYPE_INT, { .i64 = 3500 }, 0, INT_MAX, E },
+    { "min_latency", "Minimum end to end latency in live streaming in millisecond", OFFSET(min_latency), AV_OPT_TYPE_INT, { .i64 = 2000 }, 0, INT_MAX, E },
+    { "max_latency", "Maximum end to end latency in live streaming in millisecond", OFFSET(max_latency), AV_OPT_TYPE_INT, { .i64 = 10000 }, 0, INT_MAX, E },
+    { "need_external_log", "whether external log callback is needed", OFFSET(need_external_log), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "min_log_level", "Minimal log level of output [0: INFO, 1: WARNING, 2: ERROR, 3: FATAL]", OFFSET(min_log_level), AV_OPT_TYPE_INT, { .i64 = 2 }, 0, 3, E },
+    { NULL },
+};
+
+static const AVClass omaf_class = {
+    .class_name = "OMAF Compliance muxer",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+AVOutputFormat ff_omaf_packing_muxer = {
+    .name           = "omaf_packing",
+    .long_name      = "VR OMAF Compliance Muxer",
+    .extensions     = "mpd",
+    .priv_data_size = sizeof(OMAFContext),
+    .audio_codec    = AV_CODEC_ID_AAC,
+    .video_codec    = AV_CODEC_ID_HEVC,
+    .flags          = AVFMT_GLOBALHEADER | AVFMT_NOFILE | AVFMT_TS_NEGATIVE,
+    .init           = omaf_init,
+    .write_header   = omaf_write_header,
+    .write_packet   = omaf_write_packet,
+    .write_trailer  = omaf_write_trailer,
+    .deinit         = omaf_free,
+    .priv_class     = &omaf_class,
+};
+
+
diff -Nur FFmpeg/libavformat/tests/.gitignore FFmpeg_patched/libavformat/tests/.gitignore
--- FFmpeg/libavformat/tests/.gitignore	2022-06-29 07:15:48.707919028 +0000
+++ FFmpeg_patched/libavformat/tests/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,7 +0,0 @@
-/fifo_muxer
-/movenc
-/noproxy
-/rtmpdh
-/seek
-/srtp
-/url
diff -Nur FFmpeg/libavformat/tiled_dash_dec.c FFmpeg_patched/libavformat/tiled_dash_dec.c
--- FFmpeg/libavformat/tiled_dash_dec.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavformat/tiled_dash_dec.c	2022-06-29 07:16:09.583918780 +0000
@@ -0,0 +1,408 @@
+/*
+ * Intel tile Dash Demuxer
+ *
+ * Copyright (c) 2018 Intel Cooperation
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+#include "libavutil/time.h"
+
+#include "libavutil/avassert.h"
+#include "libavutil/avutil.h"
+#include "libavutil/avstring.h"
+#include "libavutil/intreadwrite.h"
+#include "libavutil/mathematics.h"
+#include "libavutil/opt.h"
+#include "libavutil/rational.h"
+#include "libavutil/time_internal.h"
+
+#include "libavcodec/avcodec.h"
+#include "avformat.h"
+#include "internal.h"
+#include "avio_internal.h"
+#include "tiled_dash_dec.h"
+
+uint64_t frameCnt = 0;
+
+int tiled_dash_ViewPort_update(AVFormatContext *s, bool isVertical, double move)
+{
+    int ret = 0;
+    TiledDASHDecContext *c = s->priv_data;
+    if(isVertical)
+    {
+        double pitch = move + c->lastPose.pitch;
+        if(pitch > 90)
+        {
+            pitch = 90;
+        }
+        else if(pitch < -90)
+        {
+            pitch = -90;
+        }
+
+        c->pose.pitch = pitch;
+    }
+    else
+    {
+        double yaw = move + c->lastPose.yaw;
+        if(yaw > 180)
+        {
+            yaw -= 360;
+        }
+        else if(yaw < -180)
+        {
+            yaw += 360;
+        }
+        c->pose.yaw = yaw;
+    }
+
+    c->lastPose.yaw = c->pose.yaw;
+    c->lastPose.pitch = c->pose.pitch;
+
+    ret = OmafAccess_ChangeViewport(c->hdl, &(c->pose));
+    return ret;
+}
+
+static int tiled_dash_read_packet(AVFormatContext *s, AVPacket *pkt)
+{
+    int ret = 0;
+    TiledDASHDecContext *c = s->priv_data;
+    frameCnt++;
+    // TODO: read packet for one stream once??
+    for (int streamId = 0; streamId < c->mInfo.stream_count; streamId++)
+    {
+    //int streamId = 0;
+    //frameCnt++;
+
+        DashStreamInfo stInfo = c->mInfo.stream_info[streamId];
+
+        DashPacket dashPkt[5];
+        memset(dashPkt, 0, 5 * sizeof(DashPacket));
+        int dashPktNum = 0;
+
+        if (stInfo.stream_type == MediaType_Video)
+        {
+            ret = OmafAccess_GetPacket(c->hdl, streamId, &(dashPkt[0]), &dashPktNum, &(pkt->pts), c->needHeaders, c->mClearBuf);
+            if(ret != ERROR_NONE){
+                //av_log(s, AV_LOG_ERROR, "OmafAccess_GetPacket get null packet\    n" );
+                //av_packet_unref(pkt);
+            }
+
+            if ((frameCnt % 50) == 0)
+            {
+                HeadPose newPose;
+                newPose.yaw = 45;
+                newPose.pitch = 90;
+                OmafAccess_ChangeViewport(c->hdl, &newPose);
+            }
+            else if ((frameCnt % 75) == 0)
+            {
+                OmafAccess_ChangeViewport(c->hdl, &(c->pose));
+            }
+
+            if(dashPktNum && dashPkt[0].buf && dashPkt[0].size)
+            {
+                int size = dashPkt[0].size;
+                if (av_new_packet(pkt, size) < 0)
+                    return AVERROR(ENOMEM);
+
+                memcpy(pkt->data, dashPkt[0].buf, size);
+                pkt->size = size;
+
+                free(dashPkt[0].buf);
+                dashPkt[0].buf = NULL;
+                if (dashPkt[0].rwpk != NULL)
+                {
+                    if (dashPkt[0].rwpk->rectRegionPacking != NULL)
+                    {
+                        free(dashPkt[0].rwpk->rectRegionPacking);
+                        dashPkt[0].rwpk->rectRegionPacking = NULL;
+                    }
+                    free(dashPkt[0].rwpk);
+                    dashPkt[0].rwpk = NULL;
+                }
+                if (dashPkt[0].qtyResolution)
+                {
+                    free(dashPkt[0].qtyResolution);
+                    dashPkt[0].qtyResolution = NULL;
+                }
+                if(c->needHeaders){c->needHeaders = false;}
+            }
+
+            for (int pktIdx = 1; pktIdx < dashPktNum; pktIdx++)
+            {
+                if (dashPkt[pktIdx].buf && dashPkt[pktIdx].size)
+                {
+                    free(dashPkt[pktIdx].buf);
+                    dashPkt[pktIdx].buf = NULL;
+
+                    if (dashPkt[pktIdx].rwpk != NULL)
+                    {
+                        if (dashPkt[pktIdx].rwpk->rectRegionPacking != NULL)
+                        {
+                            free(dashPkt[pktIdx].rwpk->rectRegionPacking);
+                            dashPkt[pktIdx].rwpk->rectRegionPacking = NULL;
+                        }
+                        free(dashPkt[pktIdx].rwpk);
+                        dashPkt[pktIdx].rwpk = NULL;
+                    }
+                    if (dashPkt[pktIdx].qtyResolution)
+                    {
+                        free(dashPkt[pktIdx].qtyResolution);
+                        dashPkt[pktIdx].qtyResolution = NULL;
+                    }
+                }
+            }
+        }
+        else if (stInfo.stream_type == MediaType_Audio)
+        {
+            uint64_t audio_pts = 0;
+            ret = OmafAccess_GetPacket(c->hdl, streamId, &(dashPkt[0]), &dashPktNum, &(audio_pts), c->needHeaders, c->mClearBuf);
+            if(ret == ERROR_NULL_PACKET)
+            {
+                av_log(s, AV_LOG_INFO, "OmafAccess_GetPacket get null packet\n" );
+            }
+
+            if(dashPktNum && dashPkt[0].buf && dashPkt[0].size)
+            {
+                FILE *audioFP = fopen("dumpedAAC.aac", "ab+");
+                if (!audioFP)
+                {
+                    av_log(s, AV_LOG_ERROR, "Failed to open dumpedAAC.m4a !\n" );
+                }
+                fwrite(dashPkt[0].buf, 1, dashPkt[0].size, audioFP);
+                fclose(audioFP);
+                audioFP = NULL;
+            }
+        }
+    }
+    return ret;
+}
+
+static int SetupHeadSetInfo(HeadSetInfo *clientInfo)
+{
+    if(!clientInfo)
+    {
+        return -1;
+    }
+
+    clientInfo->pose = (HeadPose*)malloc(sizeof(HeadPose));
+    clientInfo->pose->yaw = -90;
+    clientInfo->pose->pitch = 0;
+    clientInfo->viewPort_hFOV = 80;
+    clientInfo->viewPort_vFOV = 80;
+    clientInfo->viewPort_Width = 960;
+    clientInfo->viewPort_Height = 960;
+
+    return 0;
+}
+
+static int tiled_dash_read_header(AVFormatContext *s)
+{
+    int ret = 0;
+    TiledDASHDecContext *c = s->priv_data;
+    AVIOContext *pb = s->pb;
+
+    c->mClearBuf = false;
+    c->needHeaders = true;
+    c->client = (DashStreamingClient *)malloc(sizeof(DashStreamingClient));
+    memset(c->client, 0, sizeof(DashStreamingClient));
+    memset(&c->client->omaf_params.proxy, 0, sizeof(OmafHttpProxy));
+    memset(&c->client->omaf_params.predictor_params, 0, sizeof(OmafPredictorParams));
+    c->client->omaf_params.max_decode_width = 2560;
+    c->client->omaf_params.max_decode_height = 2560;
+    c->client->source_type = MultiResSource;//DefaultSource;
+    c->client->media_url = s->filename;
+    c->client->enable_extractor = c->enable_extractor;
+    if(!c->cache_path)
+    {
+        c->client->cache_path = "./cache";
+    }
+    else
+    {
+        char* cache_folder = "/cache";
+        c->client->cache_path = malloc(strlen(c->cache_path) + strlen(cache_folder));
+        strcpy(c->client->cache_path, c->cache_path);
+        strcpy(c->client->cache_path + strlen(c->cache_path), cache_folder);
+    }
+
+    c->hdl = OmafAccess_Init(c->client);
+
+    ret = SetupHeadSetInfo(&(c->HSInfo));
+    ret = OmafAccess_SetupHeadSetInfo(c->hdl, &(c->HSInfo));
+
+    ret = OmafAccess_OpenMedia(c->hdl, c->client, false, "", "");
+    ret = OmafAccess_StartStreaming(c->hdl);
+
+    c->lastPose.yaw = c->HSInfo.pose->yaw;
+    c->lastPose.pitch = c->HSInfo.pose->pitch;
+
+    ret = OmafAccess_GetMediaInfo(c->hdl, &(c->mInfo));
+    printf("Media streams cnt is %d\n", c->mInfo.stream_count);
+    bool hasAudio = false;
+    for(int i = 0 ; i < c->mInfo.stream_count ; i++)
+    {
+        DashStreamInfo stInfo = c->mInfo.stream_info[i];
+        if (stInfo.stream_type == MediaType_Audio)
+        {
+            hasAudio = true;
+            break;
+        }
+    }
+
+    for(int i = 0 ; i < c->mInfo.stream_count ; i++)
+    {
+        AVStream *st = avformat_new_stream(s, NULL);
+        if (!st) {
+            return AVERROR(ENOMEM);
+        }
+        DashStreamInfo stInfo = c->mInfo.stream_info[i];
+
+        st->id = i;
+        //codec_parameters_reset(st->codecpar);
+
+        if(stInfo.stream_type == MediaType_Video)
+        {
+            st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;
+            if (hasAudio)
+            {
+                c->n_videos = c->mInfo.stream_count - 1;
+            }
+            else
+            {
+                c->n_videos = c->mInfo.stream_count;
+            }
+            st->codecpar->codec_id = AV_CODEC_ID_HEVC;
+        }
+        else if(stInfo.stream_type == MediaType_Audio)
+        {
+            st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;
+            c->n_audios = 1;
+            st->codecpar->codec_id = AV_CODEC_ID_AAC;
+        }
+
+        //st->codecpar->codec_id = AV_CODEC_ID_HEVC;
+
+        st->codecpar->width = stInfo.width;
+        st->codecpar->height = stInfo.height;
+        st->codecpar->bit_rate = stInfo.bit_rate;
+        st->codecpar->codec_tag = avio_rl32(pb);
+
+        //st->codecpar->extradata = ;
+        //st->codecpar->extradata_size = ;
+        st->codecpar->bits_per_coded_sample = avio_rb16(pb);
+
+        //st->need_parsing = AVSTREAM_PARSE_FULL_RAW;
+
+        st->internal->avctx->framerate.num = stInfo.framerate_num;
+        st->internal->avctx->framerate.den = stInfo.framerate_den;
+        //st->internal->avctx->framerate = stInfo.framerate_num / stInfo.framerate_den;
+        //st->time_base.num = stInfo.framerate_num;
+        //st->time_base.den = stInfo.framerate_den;
+        avpriv_set_pts_info(st, st->pts_wrap_bits, st->time_base.num, st->time_base.den);
+    }
+
+    av_usleep(5000000);
+
+    return ret;
+}
+
+static int tiled_dash_close(AVFormatContext *s)
+{
+    TiledDASHDecContext *c = s->priv_data;
+
+    OmafAccess_CloseMedia(c->hdl);
+
+    OmafAccess_Close(c->hdl);
+
+    if(c->HSInfo.pose)
+    {
+        free(c->HSInfo.pose);
+        c->HSInfo.pose = NULL;
+    }
+
+    if(c->client)
+    {
+        free(c->client);
+        c->client = NULL;
+    }
+
+    return 0;
+}
+
+static int tiled_dash_read_seek(AVFormatContext *s, int stream_index, int64_t timestamp, int flags)
+{
+    TiledDASHDecContext *c = s->priv_data;
+
+    OmafAccess_SeekMedia(c->hdl, time);
+
+    return 0;
+}
+
+static int tiled_dash_probe(AVProbeData *p)
+{
+    if (!av_stristr(p->buf, "<MPD"))
+        return 0;
+
+    if (av_stristr(p->buf, "urn:mpeg:dash:schema:mpd:2011") ||
+        av_stristr(p->buf, "urn:mpeg:dash:srd:2014") ){
+        return AVPROBE_SCORE_MAX;
+    }
+    if (av_stristr(p->buf, "urn:mpeg:dash:profile:isoff-live:2011")) {
+        return AVPROBE_SCORE_MAX;
+    }
+
+    return 0;
+}
+
+#define OFFSET(x) offsetof(TiledDASHDecContext, x)
+#define FLAGS AV_OPT_FLAG_DECODING_PARAM
+static const AVOption dash_options[] = {
+    {"allowed_extensions", "List of file extensions that dash is allowed to access",
+        OFFSET(allowed_extensions), AV_OPT_TYPE_STRING,
+        {.str = "mpd"},
+        INT_MIN, INT_MAX, FLAGS},
+    {"cache_path", "the specific path of cache folder, default is /home",
+        OFFSET(cache_path), AV_OPT_TYPE_STRING,
+        {.str = NULL},
+        INT_MIN, INT_MAX, FLAGS},
+    {"enable_extractor", "whether to enable extractor track in OMAF Dash Access engine",
+        OFFSET(enable_extractor), AV_OPT_TYPE_INT,
+        {.i64 = 1},
+        INT_MIN, INT_MAX, FLAGS},
+    {NULL}
+};
+
+static const AVClass tiled_dash_dec_class = {
+    .class_name = "Tiled Dash Demuxer",
+    .item_name  = av_default_item_name,
+    .option     = dash_options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+AVInputFormat ff_tile_dash_demuxer = {
+    .name           = "tiled_dash_demuxer",
+    .long_name      = "Demuxer for Dynamic Adaptive Streaming over HTTP",
+    .priv_class     = &tiled_dash_dec_class,
+    .priv_data_size = sizeof(TiledDASHDecContext),
+    .read_probe     = tiled_dash_probe,
+    .read_header    = tiled_dash_read_header,
+    .read_packet    = tiled_dash_read_packet,
+    .read_close     = tiled_dash_close,
+    .read_seek      = tiled_dash_read_seek,
+    .flags          = AVFMT_NO_BYTE_SEEK,
+};
diff -Nur FFmpeg/libavformat/tiled_dash_dec.h FFmpeg_patched/libavformat/tiled_dash_dec.h
--- FFmpeg/libavformat/tiled_dash_dec.h	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavformat/tiled_dash_dec.h	2022-06-29 07:16:09.551918780 +0000
@@ -0,0 +1,65 @@
+/*
+ * Intel tile Dash muxer
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef TILE_DASH_DEC_H
+#define TILE_DASH_DEC_H
+
+#include <stdbool.h>
+
+#include "libavutil/avassert.h"
+#include "libavutil/avutil.h"
+#include "libavutil/avstring.h"
+#include "libavutil/intreadwrite.h"
+#include "libavutil/mathematics.h"
+#include "libavutil/opt.h"
+#include "libavutil/rational.h"
+#include "libavutil/time_internal.h"
+
+#include "avformat.h"
+#include "avio_internal.h"
+
+#include "OmafDashAccessApi.h"
+
+typedef struct{
+    const AVClass *class;
+    char allowed_extensions[256];
+    char* cache_path;
+
+    int n_videos;
+
+    int n_audios;
+
+    DashStreamingClient *client;
+    DashMediaInfo       mInfo;
+    Handler             hdl;
+    HeadSetInfo         HSInfo;
+    HeadPose            pose;
+    HeadPose            lastPose;
+    bool                mClearBuf;
+    bool                needHeaders;
+    int                 enable_extractor;
+}TiledDASHDecContext;
+
+int tiled_dash_ViewPort_update(AVFormatContext *s, bool isVertical, double move);
+
+#endif
+
diff -Nur FFmpeg/libavformat/tiled_dash_enc.c FFmpeg_patched/libavformat/tiled_dash_enc.c
--- FFmpeg/libavformat/tiled_dash_enc.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavformat/tiled_dash_enc.c	2022-06-29 07:16:09.571918780 +0000
@@ -0,0 +1,359 @@
+/*
+ * Intel tile Dash muxer
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <unistd.h>
+#include <sys/stat.h>
+
+#include "tiled_dash_parse.h"
+
+static int dash_init(AVFormatContext *s)
+{
+    GPAC_DASHContext *c = s->priv_data;
+    int ret = 0, i;
+    char *ptr;
+    char basename[1024];
+    int mode;
+    int mode_u, mode_g, mode_o;
+
+    av_strlcpy(c->dirname, s->url, sizeof(c->dirname));
+    ptr = strrchr(c->dirname, '/');
+    if (ptr) {
+        av_strlcpy(basename, &ptr[1], sizeof(basename));
+        ptr[1] = '\0';
+    } else {
+        c->dirname[0] = '\0';
+        av_strlcpy(basename, s->url, sizeof(basename));
+    }
+
+    //av_strlcpy(c->base_url, "", sizeof(c->base_url));
+    ptr = strrchr(basename, '.');
+    if (ptr)
+        *ptr = '\0';
+
+    c->streams = av_mallocz(sizeof(*c->streams) * s->nb_streams);
+    if (!c->streams)
+        return AVERROR(ENOMEM);
+
+    c->nb_streams = s->nb_streams;
+    for (i = 0; i < s->nb_streams; i++) {
+        DashOutStream *os = &c->streams[i];
+        AVStream *st = s->streams[i];
+        os->stream_index = i + 1;
+        os->bit_rate = s->streams[i]->codecpar->bit_rate;
+        os->frame_rate = (double)st->avg_frame_rate.num / (double)st->avg_frame_rate.den;
+        if (!os->bit_rate) {
+            int level = s->strict_std_compliance >= FF_COMPLIANCE_STRICT ?
+                        AV_LOG_ERROR : AV_LOG_WARNING;
+            av_log(s, level, "No bit rate set for stream %d\n", i);
+            if (s->strict_std_compliance >= FF_COMPLIANCE_STRICT)
+                return AVERROR(EINVAL);
+        }
+
+        //ff_dash_fill_tmpl_params(os->initfile, sizeof(os->initfile), c->init_seg_name, i, 0, os->bit_rate, 0);
+        snprintf(os->out_name, sizeof(os->out_name), "%s%d", c->out_name, os->stream_index);
+        snprintf(os->dir_name, sizeof(os->dir_name), "%s", c->dirname);
+
+        mode_u = 7;
+        mode_g = 7;
+        mode_o = 7;
+        mode = mode_u * 64 + mode_g * 8 + mode_o;
+        if (access(&(os->dir_name[0]), 0) == 0)
+        {
+            av_log(s, AV_LOG_DEBUG, "Folder %s has existed\n", os->dir_name);
+            if (access(&(os->dir_name[0]), mode) != 0)
+            {
+                if (chmod(&(os->dir_name[0]), mode) != 0)
+                {
+                    av_log(s, AV_LOG_ERROR, "Failed to change write mode for folder %s\n", os->dir_name);
+                    return AVERROR(EINVAL);
+                }
+            }
+        }
+        else
+        {
+            av_log(s, AV_LOG_DEBUG, "Create folder %s\n", os->dir_name);
+            if (mkdir(&(os->dir_name[0]), mode) != 0)
+            {
+                av_log(s, AV_LOG_ERROR, "Failed to create folder %s\n", os->dir_name);
+                return AVERROR(EINVAL);
+            }
+        }
+
+        //snprintf(os->stream_name, sizeof(os->stream_name), "%s%s", c->dirname, c->out_name);
+
+        av_log(s, AV_LOG_VERBOSE, "stream %d output filename prefix: %s%s\n", i, os->dir_name, os->out_name);
+
+        os->initialized = 0;
+        //os->packets_written = 0;
+        //os->total_pkt_size = 0;
+        os->vstream_idx = i;
+        os->fmt_ctx = s;
+        os->codec_ctx = s->streams[i]->codecpar;
+        os->bit_rate = s->streams[i]->codecpar->bit_rate;
+        os->split_tile = c->split_tile;
+        os->timescale = st->time_base;
+
+        if(NULL != s->streams[i]->codecpar->extradata){
+            ret = dash_probe_extra_data(os, s->streams[i]->codecpar->extradata, 
+                                           s->streams[i]->codecpar->extradata_size);
+            if(ret != 0){
+                av_freep(&c->streams);
+                return ret;
+            }
+                
+            ret = dash_init_output_stream(c, os);
+                
+            if(!ret) os->initialized = 1;
+        }
+        
+        switch(st->codecpar->codec_type) {
+        case AVMEDIA_TYPE_VIDEO:
+            c->has_video = 1;
+            break;
+        case AVMEDIA_TYPE_AUDIO:
+            c->has_audio = 1;
+            break;
+        default:
+            break;
+        }
+    }
+
+    if (!c->has_video && c->seg_duration <= 0) {
+        av_log(s, AV_LOG_WARNING, "no video stream and no seg duration set\n");
+        return AVERROR(EINVAL);
+    }
+    return 0;
+}
+
+static void dash_free(AVFormatContext *s)
+{
+    GPAC_DASHContext *c = s->priv_data;
+    int i;
+
+    if (!c->streams)
+        return;
+    for (i = 0; i < s->nb_streams; i++) {
+        DashOutStream *os = &c->streams[i];
+        dash_free_output_stream(os);
+    }
+    av_freep(&c->streams);
+}
+
+static int dash_write_header(AVFormatContext *s)
+{
+    //GPAC_DASHContext *c = s->priv_data;
+    //int i, ret = 0;
+    //for (i = 0; i < s->nb_streams; i++) {
+    //    DashOutStream *os = &c->streams[i];
+        //TOBE: write header for each out stream. 
+    //}
+    return 0;//ret;
+}
+
+static int dash_write_packet(AVFormatContext *s, AVPacket *pkt)
+{
+    GPAC_DASHContext *c = s->priv_data;
+    AVStream *st = s->streams[pkt->stream_index];
+    DashOutStream *os = &c->streams[pkt->stream_index];
+    //int64_t seg_end_duration, elapsed_duration;
+    int ret = 0;
+
+    if(!os->initialized){
+        //if(!s->streams[pkt->stream_index]->codecpar->extradata) return 0;
+        
+        ret = dash_probe_extra_data(os, pkt->data, pkt->size);
+        //ret = dash_probe_extra_data(os, s->streams[pkt->stream_index]->codecpar->extradata, 
+        //                       s->streams[pkt->stream_index]->codecpar->extradata_size);
+        
+        if(ret != 0) return ret;
+        
+        ret = dash_init_output_stream(c, os);
+        if(ret != 0){
+            av_log(s, AV_LOG_ERROR, "Output stream initialized failed: %d\n", pkt->stream_index );
+            return ret;
+        }
+        os->initialized = 1;
+    }
+    
+    ///write mpd in streaming mode
+    if( c->streaming ){
+        ret = dash_update_mpd(c, 0);
+        if(ret != 0){
+            av_log(s, AV_LOG_ERROR, "Failed to update mpd in streaming mode\n" );
+            return ret;
+        }
+    }
+
+    // Fill in a heuristic guess of the packet duration, if none is available.
+    // The mp4 muxer will do something similar (for the last packet in a fragment)
+    // if nothing is set (setting it for the other packets doesn't hurt).
+    // By setting a nonzero duration here, we can be sure that the mp4 muxer won't
+    // invoke its heuristic (this doesn't have to be identical to that algorithm),
+    // so that we know the exact timestamps of fragments.
+    if (!pkt->duration && os->last_dts != AV_NOPTS_VALUE)
+        pkt->duration = pkt->dts - os->last_dts;
+    os->last_dts = pkt->dts;
+
+    // If forcing the stream to start at 0, the mp4 muxer will set the start
+    // timestamps to 0. Do the same here, to avoid mismatches in duration/timestamps.
+    if (os->first_pts == AV_NOPTS_VALUE &&
+        s->avoid_negative_ts == AVFMT_AVOID_NEG_TS_MAKE_ZERO) {
+        pkt->pts -= pkt->dts;
+        pkt->dts  = 0;
+    }
+
+    if (os->first_pts == AV_NOPTS_VALUE)
+        os->first_pts = pkt->pts;
+
+    if (!c->availability_start_time[0])
+        format_date_now(c->availability_start_time,
+                        sizeof(c->availability_start_time));
+    
+    if (!os->availability_time_offset && pkt->duration) {
+        int64_t frame_duration = av_rescale_q(pkt->duration, st->time_base,
+                                              AV_TIME_BASE_Q);
+         os->availability_time_offset = ((double) c->seg_duration -
+                                         frame_duration) / AV_TIME_BASE;
+    }
+
+    ret = dash_write_segment(c, os, pkt );
+    if(ret){
+        av_log(s, AV_LOG_ERROR, "Failed to write segment for stream %d\n", pkt->stream_index );
+        return ret;
+    }
+
+    return ret;
+}
+
+static int dash_write_trailer(AVFormatContext *s)
+{
+    GPAC_DASHContext *c = s->priv_data;
+    int ret = 0;
+    DashOutStream *os = NULL;
+    
+    for (int i = 0; i < s->nb_streams; i++) {
+        os = &c->streams[i];
+        os->total_frames = os->nb_frames;
+        av_log(s, AV_LOG_DEBUG, "Total_frames %d \n", os->total_frames);
+        if (os->total_frames % os->frame_per_fragment != 0)
+        {
+            dash_end_output_stream(os);
+        }
+    }
+
+    if (c->streaming)
+    {
+        ret = dash_update_mpd(c, 1);
+        if(ret ){
+            av_log(s, AV_LOG_ERROR, "Failed to write mpd \n" );
+            return ret;
+        }
+    }
+    else
+    {
+        dash_write_mpd(c, 1);
+    } 
+    /*
+    if (s->nb_streams > 0) {
+        DashOutStream *os = &c->streams[0];
+        // If no segments have been written so far, try to do a crude
+        // guess of the segment duration
+        if (!c->last_duration)
+            c->last_duration = av_rescale_q(os->last_pts - os->start_pts,
+                                            s->streams[0]->time_base,
+                                            AV_TIME_BASE_Q);
+        c->total_duration = av_rescale_q(os->last_pts - os->first_pts,
+                                         s->streams[0]->time_base,
+                                         AV_TIME_BASE_Q);
+    }
+    //dash_flush(s, 1, -1);
+    */
+    return 0;
+}
+
+/*
+static int dash_check_bitstream(struct AVFormatContext *s, const AVPacket *avpkt)
+{
+    GPAC_DASHContext *c = s->priv_data;
+    DashOutStream *os = &c->streams[avpkt->stream_index];
+    AVFormatContext *oc = s->ctx;
+    if (oc->oformat->check_bitstream) {
+        int ret;
+        AVPacket pkt = *avpkt;
+        pkt.stream_index = 0;
+        ret = oc->oformat->check_bitstream(oc, &pkt);
+        if (ret == 1) {
+            AVStream *st = s->streams[avpkt->stream_index];
+            AVStream *ost = oc->streams[0];
+            //st->internal->bsfcs = ost->internal->bsfcs;
+            //st->internal->nb_bsfcs = ost->internal->nb_bsfcs;
+            //ost->internal->bsfcs = NULL;
+            //ost->internal->nb_bsfcs = 0;
+        }
+        return ret;
+    }
+    return 1;
+}
+*/
+#define OFFSET(x) offsetof(GPAC_DASHContext, x)
+#define E AV_OPT_FLAG_ENCODING_PARAM
+static const AVOption options[] = {
+    { "adaptation_sets", "Adaptation sets. Syntax: id=0,streams=0,1,2 id=1,streams=3,4 and so on", OFFSET(adaptation_sets), AV_OPT_TYPE_STRING, { 0 }, 0, 0, AV_OPT_FLAG_ENCODING_PARAM },
+    { "window_size", "number of segments kept in the manifest", OFFSET(window_size), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, E },
+    { "extra_window_size", "number of segments kept outside of the manifest before removing from disk", OFFSET(extra_window_size), AV_OPT_TYPE_INT, { .i64 = 5 }, 0, INT_MAX, E },
+    { "split_tile", "need split the stream to tiles if input is tile-based hevc stream", OFFSET(split_tile), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 2, E },
+    { "seg_duration", "segment duration (in seconds, fractional value can be set)", OFFSET(seg_duration), AV_OPT_TYPE_DURATION, { .i64 = 5000000 }, 0, INT_MAX, E },
+    { "remove_at_exit", "remove all segments when finished", OFFSET(remove_at_exit), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "use_template", "Use SegmentTemplate instead of SegmentList", OFFSET(use_template), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, E },
+    { "use_timeline", "Use SegmentTimeline in SegmentTemplate", OFFSET(use_timeline), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, E },
+    { "utc_timing_url", "URL of the page that will return the UTC timestamp in ISO format", OFFSET(utc_timing_url), AV_OPT_TYPE_STRING, { 0 }, 0, 0, E },
+    { "streaming", "Enable/Disable streaming mode of output. Each frame will be moof fragment", OFFSET(streaming), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "base_url", "MPD BaseURL", OFFSET(base_url), AV_OPT_TYPE_STRING, { 0 }, 0, 0, E },
+    { "out_name", "name prefix for all dash output files", OFFSET(out_name), AV_OPT_TYPE_STRING, {.str = "dash-stream"}, 0, 0, E },
+    { NULL },
+};
+
+static const AVClass dash_class = {
+    .class_name = "libgpac dash muxer",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+AVOutputFormat ff_tile_dash_muxer = {
+    .name           = "tile_dash",
+    .long_name      = "libgpac-based tiled DASH Muxer",
+    .extensions     = "mpd",
+    .priv_data_size = sizeof(GPAC_DASHContext),
+    .audio_codec    = AV_CODEC_ID_AAC,
+    .video_codec    = AV_CODEC_ID_HEVC,
+    .flags          = AVFMT_GLOBALHEADER | AVFMT_NOFILE | AVFMT_TS_NEGATIVE,
+    .init           = dash_init,
+    .write_header   = dash_write_header,
+    .write_packet   = dash_write_packet,
+    .write_trailer  = dash_write_trailer,
+    .deinit         = dash_free,
+ //   .check_bitstream = dash_check_bitstream,
+    .priv_class     = &dash_class,
+};
+
+
diff -Nur FFmpeg/libavformat/tiled_dash_parse.c FFmpeg_patched/libavformat/tiled_dash_parse.c
--- FFmpeg/libavformat/tiled_dash_parse.c	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavformat/tiled_dash_parse.c	2022-06-29 07:16:09.539918781 +0000
@@ -0,0 +1,1624 @@
+/*
+ * Intel tile Dash muxer
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <stdio.h>
+
+#include "tiled_dash_parse.h"
+
+void format_date_now(char *buf, int size)
+{
+    time_t t = time(NULL);
+    struct tm *ptm, tmbuf;
+    ptm = gmtime_r(&t, &tmbuf);
+    if (ptm) {
+        if (!strftime(buf, size, "%Y-%m-%dT%H:%M:%SZ", ptm))
+            buf[0] = '\0';
+    }
+}
+
+/**
+ * A function which takes FFmpeg H264 extradata (SPS/PPS) and bring them ready to be pushed to the MP4 muxer.
+ * @param extradata
+ * @param extradata_size
+ * @param dstcfg
+ * @returns GF_OK is the extradata was parsed and is valid, other values otherwise.
+ */
+static GF_Err dc_avc_import_ffextradata(const u8 *extradata, const u64 extradata_size, GF_AVCConfig *dstcfg)
+{
+#ifdef GPAC_DISABLE_AV_PARSERS
+	return GF_OK;
+#else
+	u8 nal_size;
+	AVCState avc;
+	GF_BitStream *bs;
+	if (!extradata || (extradata_size < sizeof(u32)))
+		return GF_BAD_PARAM;
+	bs = gf_bs_new((const char *) extradata, extradata_size, GF_BITSTREAM_READ);
+	if (!bs)
+		return GF_BAD_PARAM;
+	if (gf_bs_read_u32(bs) != 0x00000001) {
+		gf_bs_del(bs);
+		return GF_BAD_PARAM;
+	}
+
+	//SPS
+	{
+		s32 idx;
+		char *buffer = NULL;
+		const u64 nal_start = 4;
+		nal_size = gf_media_nalu_next_start_code_bs(bs);
+		if (nal_start + nal_size > extradata_size) {
+			gf_bs_del(bs);
+			return GF_BAD_PARAM;
+		}
+		buffer = (char*)gf_malloc(nal_size);
+		gf_bs_read_data(bs, buffer, nal_size);
+		gf_bs_seek(bs, nal_start);
+		if ((gf_bs_read_u8(bs) & 0x1F) != GF_AVC_NALU_SEQ_PARAM) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		}
+
+		idx = gf_media_avc_read_sps(buffer, nal_size, &avc, 0, NULL);
+		if (idx < 0) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		}
+
+		dstcfg->configurationVersion = 1;
+		dstcfg->profile_compatibility = avc.sps[idx].prof_compat;
+		dstcfg->AVCProfileIndication = avc.sps[idx].profile_idc;
+		dstcfg->AVCLevelIndication = avc.sps[idx].level_idc;
+		dstcfg->chroma_format = avc.sps[idx].chroma_format;
+		dstcfg->luma_bit_depth = 8 + avc.sps[idx].luma_bit_depth_m8;
+		dstcfg->chroma_bit_depth = 8 + avc.sps[idx].chroma_bit_depth_m8;
+
+		{
+			GF_AVCConfigSlot *slc = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));
+			slc->size = nal_size;
+			slc->id = idx;
+			slc->data = buffer;
+			gf_list_add(dstcfg->sequenceParameterSets, slc);
+		}
+	}
+
+	//PPS
+	{
+		s32 idx;
+		char *buffer = NULL;
+		const u64 nal_start = 4 + nal_size + 4;
+		gf_bs_seek(bs, nal_start);
+		nal_size = gf_media_nalu_next_start_code_bs(bs);
+		if (nal_start + nal_size > extradata_size) {
+			gf_bs_del(bs);
+			return GF_BAD_PARAM;
+		}
+		buffer = (char*)gf_malloc(nal_size);
+		gf_bs_read_data(bs, buffer, nal_size);
+		gf_bs_seek(bs, nal_start);
+		if ((gf_bs_read_u8(bs) & 0x1F) != GF_AVC_NALU_PIC_PARAM) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		}
+
+		idx = gf_media_avc_read_pps(buffer, nal_size, &avc);
+		if (idx < 0) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		}
+
+		{
+			GF_AVCConfigSlot *slc = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));
+			slc->size = nal_size;
+			slc->id = idx;
+			slc->data = buffer;
+			gf_list_add(dstcfg->pictureParameterSets, slc);
+		}
+	}
+
+	gf_bs_del(bs);
+	return GF_OK;
+#endif
+}
+
+/**
+ * A function which takes FFmpeg H265 extradata (SPS/PPS) and bring them ready to be pushed to the MP4 muxer.
+ * @param extradata
+ * @param extradata_size
+ * @param dstcfg
+ * @returns GF_OK is the extradata was parsed and is valid, other values otherwise.
+ */
+static GF_Err dc_hevc_import_ffextradata(const u8 *extradata, const u64 extradata_size, HEVCState* hevc, GF_HEVCConfig *dst_cfg)
+{
+#ifdef GPAC_DISABLE_AV_PARSERS
+    return GF_OK;
+#else
+    //HEVCState hevc;
+    GF_HEVCParamArray *vpss = NULL, *spss = NULL, *ppss = NULL, *seis = NULL;
+    GF_BitStream *bs;
+    char *buffer = NULL;
+    u32 buffer_size = 0;
+    if (!extradata || (extradata_size < sizeof(u32)))
+  	return GF_BAD_PARAM;
+    bs = gf_bs_new((const char *) extradata, extradata_size, GF_BITSTREAM_READ);
+    if (!bs)
+ 	return GF_BAD_PARAM;
+    
+    if( NULL == dst_cfg->param_array ) dst_cfg->param_array = gf_list_new();
+    
+    memset(hevc, 0, sizeof(HEVCState));
+    hevc->sps_active_idx = -1;
+
+    while (gf_bs_available(bs)) {
+ 	s32 idx;
+	GF_AVCConfigSlot *slc;
+	u8 nal_unit_type, temporal_id, layer_id;
+	u64 nal_start, start_code;
+	u32 nal_size;
+
+	start_code = gf_bs_read_u32(bs);
+	if (start_code>>8 == 0x000001) {
+            nal_start = gf_bs_get_position(bs) - 1;
+	    gf_bs_seek(bs, nal_start);
+	    start_code = 1;
+	}
+	if (start_code != 0x00000001) {
+	    gf_bs_del(bs);
+	    if (buffer) gf_free(buffer);
+		if (vpss && spss && ppss) return GF_OK;
+		return GF_BAD_PARAM;
+	    }
+	    nal_start = gf_bs_get_position(bs);
+	    nal_size = gf_media_nalu_next_start_code_bs(bs);
+	    if (nal_start + nal_size > extradata_size) {
+		gf_bs_del(bs);
+		return GF_BAD_PARAM;
+	    }
+
+	    if (nal_size > buffer_size) {
+		buffer = (char*)gf_realloc(buffer, nal_size);
+		buffer_size = nal_size;
+	    }
+	    gf_bs_read_data(bs, buffer, nal_size);
+
+	    gf_media_hevc_parse_nalu(buffer, nal_size, hevc, &nal_unit_type, &temporal_id, &layer_id);
+	    if (layer_id) {
+		gf_bs_del(bs);
+		gf_free(buffer);
+		return GF_BAD_PARAM;
+	    }
+
+	    switch (nal_unit_type) {
+	    case GF_HEVC_NALU_VID_PARAM:
+		idx = gf_media_hevc_read_vps(buffer, nal_size , hevc);
+		if (idx < 0) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		}
+
+		assert(hevc.vps[idx].state == 1); //we don't expect multiple VPS
+		if (hevc->vps[idx].state == 1) {
+		    hevc->vps[idx].state = 2;
+		    hevc->vps[idx].crc = gf_crc_32(buffer, nal_size);
+
+                    dst_cfg->avgFrameRate = hevc->vps[idx].rates[0].avg_pic_rate;
+     		    dst_cfg->constantFrameRate = hevc->vps[idx].rates[0].constand_pic_rate_idc;
+		    dst_cfg->numTemporalLayers = hevc->vps[idx].max_sub_layers;
+		    dst_cfg->temporalIdNested = hevc->vps[idx].temporal_id_nesting;
+
+		    if (!vpss) {
+		 	GF_SAFEALLOC(vpss, GF_HEVCParamArray);
+			if (vpss) {
+			    vpss->nalus = gf_list_new();
+			    gf_list_add(dst_cfg->param_array, vpss);
+			    vpss->array_completeness = 1;
+			    vpss->type = GF_HEVC_NALU_VID_PARAM;
+			}
+		    }
+
+		    slc = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));
+		    if (slc) {
+			slc->size = nal_size;
+			slc->id = idx;
+			slc->data = (char*)gf_malloc(sizeof(char)*slc->size);
+			if (slc->data)
+		     	    memcpy(slc->data, buffer, sizeof(char)*slc->size);
+			if (vpss)
+			    gf_list_add(vpss->nalus, slc);
+		    }
+		}
+			break;
+		case GF_HEVC_NALU_SEQ_PARAM:
+		    idx = gf_media_hevc_read_sps(buffer, nal_size, hevc);
+		    if (idx < 0) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		    }
+
+		    assert(!(hevc->sps[idx].state & AVC_SPS_DECLARED)); //we don't expect multiple SPS
+		    if ((hevc->sps[idx].state & AVC_SPS_PARSED) && !(hevc->sps[idx].state & AVC_SPS_DECLARED)) {
+			hevc->sps[idx].state |= AVC_SPS_DECLARED;
+			hevc->sps[idx].crc = gf_crc_32(buffer, nal_size);
+		    }
+
+		    dst_cfg->configurationVersion = 1;
+		    dst_cfg->profile_space = hevc->sps[idx].ptl.profile_space;
+		    dst_cfg->tier_flag = hevc->sps[idx].ptl.tier_flag;
+		    dst_cfg->profile_idc = hevc->sps[idx].ptl.profile_idc;
+		    dst_cfg->general_profile_compatibility_flags = hevc->sps[idx].ptl.profile_compatibility_flag;
+		    dst_cfg->progressive_source_flag = hevc->sps[idx].ptl.general_progressive_source_flag;
+		    dst_cfg->interlaced_source_flag = hevc->sps[idx].ptl.general_interlaced_source_flag;
+		    dst_cfg->non_packed_constraint_flag = hevc->sps[idx].ptl.general_non_packed_constraint_flag;
+		    dst_cfg->frame_only_constraint_flag = hevc->sps[idx].ptl.general_frame_only_constraint_flag;
+
+		    dst_cfg->constraint_indicator_flags = hevc->sps[idx].ptl.general_reserved_44bits;
+		    dst_cfg->level_idc = hevc->sps[idx].ptl.level_idc;
+
+                    dst_cfg->chromaFormat = hevc->sps[idx].chroma_format_idc;
+		    dst_cfg->luma_bit_depth = hevc->sps[idx].bit_depth_luma;
+		    dst_cfg->chroma_bit_depth = hevc->sps[idx].bit_depth_chroma;
+
+		    if (!spss) {
+		 	GF_SAFEALLOC(spss, GF_HEVCParamArray);
+			if (spss) {
+		   	    spss->nalus = gf_list_new();
+			    gf_list_add(dst_cfg->param_array, spss);
+			    spss->array_completeness = 1;
+			    spss->type = GF_HEVC_NALU_SEQ_PARAM;
+			}
+		    }
+
+                    slc = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));
+		    if (slc) {
+			slc->size = nal_size;
+			slc->id = idx;
+			slc->data = (char*)gf_malloc(sizeof(char)*slc->size);
+			if (slc->data)
+		   	    memcpy(slc->data, buffer, sizeof(char)*slc->size);
+			    if (spss)
+				gf_list_add(spss->nalus, slc);
+		    }
+		    break;
+		case GF_HEVC_NALU_PIC_PARAM:
+		    idx = gf_media_hevc_read_pps(buffer, nal_size, hevc);
+		    if (idx < 0) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		    }
+
+		    assert(hevc->pps[idx].state == 1); //we don't expect multiple PPS
+		    if (hevc->pps[idx].state == 1) {
+			hevc->pps[idx].state = 2;
+			hevc->pps[idx].crc = gf_crc_32(buffer, nal_size);
+
+			if (!ppss) {
+		   	    GF_SAFEALLOC(ppss, GF_HEVCParamArray);
+			    if (ppss) {
+				ppss->nalus = gf_list_new();
+				gf_list_add(dst_cfg->param_array, ppss);
+				ppss->array_completeness = 1;
+				ppss->type = GF_HEVC_NALU_PIC_PARAM;
+			    }
+			}
+
+			slc = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));
+			if (slc) {
+			    slc->size = nal_size;
+			    slc->id = idx;
+			    slc->data = (char*)gf_malloc(sizeof(char)*slc->size);
+			    if (slc->data)
+				memcpy(slc->data, buffer, sizeof(char)*slc->size);
+    			        if (ppss)
+				    gf_list_add(ppss->nalus, slc);
+		        }
+		    }
+			break;
+		case GF_HEVC_NALU_SEI_PREFIX:
+		    if (!seis) {
+			GF_SAFEALLOC(seis, GF_HEVCParamArray);
+			if (seis) {
+			    seis->nalus = gf_list_new();
+			    seis->array_completeness = 0;
+			    seis->type = GF_HEVC_NALU_SEI_PREFIX;
+			}
+		    }
+		    slc = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));
+		    if (slc) {
+			slc->size = nal_size;
+			slc->data = (char*)gf_malloc(sizeof(char)*slc->size);
+			if (slc->data)
+		  	    memcpy(slc->data, buffer, sizeof(char)*slc->size);
+			if (seis)
+			     gf_list_add(seis->nalus, slc);
+		    }
+		    break;
+		default:
+		    break;
+	    }
+    }
+
+    gf_bs_del(bs);
+    if (buffer) gf_free(buffer);
+
+    return GF_OK;
+#endif
+}
+
+static int hevc_get_tile_info(HEVCState *hevc, u32 *tile_x, u32 *tile_y, u32 *tile_width, u32 *tile_height)
+{
+	HEVCSliceInfo *si = &hevc->s_info;
+	u32 i, tbX, tbY, PicWidthInCtbsY, PicHeightInCtbsY, tileX, tileY, oX, oY, val;
+
+        if( (0==si->sps->max_CU_width)||
+            (0==si->pps->num_tile_columns)||
+            (0==si->pps->num_tile_rows) ){
+            av_log(NULL, AV_LOG_ERROR, "si->slice_segment_address=%d, hevc_get_tile_info: si->sps->max_CU_width=%d, si->pps->num_tile_columns =%d, si->pps->num_tile_rows =%d \n", 
+                    si->slice_segment_address,
+                    si->sps->max_CU_width,
+                    si->pps->num_tile_columns,
+                    si->pps->num_tile_rows);
+            return -1;
+        }
+	PicWidthInCtbsY = si->sps->width / si->sps->max_CU_width;
+	if (PicWidthInCtbsY * si->sps->max_CU_width < si->sps->width) PicWidthInCtbsY++;
+	PicHeightInCtbsY = si->sps->height / si->sps->max_CU_width;
+	if (PicHeightInCtbsY * si->sps->max_CU_width < si->sps->height) PicHeightInCtbsY++;
+
+	tbX = si->slice_segment_address % PicWidthInCtbsY;
+	tbY = si->slice_segment_address / PicWidthInCtbsY;
+
+	tileX = tileY = 0;
+	oX = oY = 0;
+	for (i=0; i < si->pps->num_tile_columns; i++) {
+		if (si->pps->uniform_spacing_flag) {
+			val = (i+1)*PicWidthInCtbsY / si->pps->num_tile_columns - (i)*PicWidthInCtbsY / si->pps->num_tile_columns;
+		} else {
+			if (i<si->pps->num_tile_columns-1) {
+				val = si->pps->column_width[i];
+			} else {
+				val = (PicWidthInCtbsY - si->pps->column_width[i-1]);
+			}
+		}
+		*tile_x = oX;
+		*tile_width = val;
+
+		if (oX >= tbX) break;
+		oX += val;
+		tileX++;
+	}
+	for (i=0; i<si->pps->num_tile_rows; i++) {
+		if (si->pps->uniform_spacing_flag) {
+			val = (i+1)*PicHeightInCtbsY / si->pps->num_tile_rows - (i)*PicHeightInCtbsY / si->pps->num_tile_rows;
+		} else {
+			if (i<si->pps->num_tile_rows-1) {
+				val = si->pps->row_height[i];
+			} else {
+				val = (PicHeightInCtbsY - si->pps->row_height[i-1]);
+			}
+		}
+		*tile_y = oY;
+		*tile_height = val;
+
+		if (oY >= tbY) break;
+		oY += val;
+		tileY++;
+	}
+	*tile_x = *tile_x * si->sps->max_CU_width;
+	*tile_y = *tile_y * si->sps->max_CU_width;
+	*tile_width = *tile_width * si->sps->max_CU_width;
+	*tile_height = *tile_height * si->sps->max_CU_width;
+
+	if (*tile_x + *tile_width > si->sps->width)
+		*tile_width = si->sps->width - *tile_x;
+	if (*tile_y + *tile_height > si->sps->height)
+		*tile_height = si->sps->height - *tile_y;
+
+	return tileX + tileY * si->pps->num_tile_columns;
+}
+
+static int hevc_get_tile_rect(HEVCState hevc, int idx, u32 *tile_x, u32 *tile_y, u32 *tile_width, u32 *tile_height)
+{
+           
+    u32 i, tbX, tbY, PicWidthInCtbsY, PicHeightInCtbsY, tileX, tileY, oX, oY, val;
+
+    HEVC_SPS sps = hevc.sps[0];
+    HEVC_PPS pps = hevc.pps[0];
+    if( (0==sps.max_CU_width)||
+        (0==pps.num_tile_columns)||
+        (0==pps.num_tile_rows) ){
+            av_log(NULL, AV_LOG_ERROR, "hevc_get_tile_rect: sps->max_CU_width=%d, pps->num_tile_columns =%d, pps->num_tile_rows =%d \n", 
+                    sps.max_CU_width,
+                    pps.num_tile_columns,
+                    pps.num_tile_rows);
+            return -1;
+    }
+    
+    PicWidthInCtbsY = sps.width / sps.max_CU_width;
+    if (PicWidthInCtbsY * sps.max_CU_width < sps.width) PicWidthInCtbsY++;
+
+    PicHeightInCtbsY = sps.height / sps.max_CU_width;
+    if (PicHeightInCtbsY * sps.max_CU_width < sps.height) PicHeightInCtbsY++;
+
+    tbX = idx % pps.num_tile_columns;
+    tbY = idx / pps.num_tile_columns;
+
+    tileX = tileY = 0;
+    oX = oY = 0;
+    for (i=0; i < pps.num_tile_columns; i++) {
+        if (pps.uniform_spacing_flag) {
+	    val = (i+1)*PicWidthInCtbsY / pps.num_tile_columns - (i)*PicWidthInCtbsY / pps.num_tile_columns;
+	} else {
+	    if (i<pps.num_tile_columns-1) {
+		val = pps.column_width[i];
+	    } else {
+		val = (PicWidthInCtbsY - pps.column_width[i-1]);
+	    }
+        }
+	*tile_x = oX;
+	*tile_width = val;
+
+	if (oX >= (tbX * (PicWidthInCtbsY / pps.num_tile_columns))) break;
+	oX += val;
+	tileX++;
+    }
+    for (i=0; i<pps.num_tile_rows; i++) {
+        if (pps.uniform_spacing_flag) {
+            val = (i+1)*PicHeightInCtbsY / pps.num_tile_rows - (i)*PicHeightInCtbsY / pps.num_tile_rows;
+	} else {
+            if (i<pps.num_tile_rows-1) {
+	        val = pps.row_height[i];
+	    } else {
+		val = (PicHeightInCtbsY - pps.row_height[i-1]);
+	    }
+	}
+	*tile_y = oY;
+	*tile_height = val;
+
+	if (oY >= (tbY * (PicHeightInCtbsY / pps.num_tile_rows))) break;
+	oY += val;
+	tileY++;
+    }
+    
+    *tile_x = *tile_x * sps.max_CU_width;
+    *tile_y = *tile_y * sps.max_CU_width;
+    *tile_width = *tile_width * sps.max_CU_width;
+    *tile_height = *tile_height * sps.max_CU_width;
+
+    if (*tile_x + *tile_width > sps.width)
+	*tile_width = sps.width - *tile_x;
+    if (*tile_y + *tile_height > sps.height)
+	*tile_height = sps.height - *tile_y;
+
+    return tileX + tileY * pps.num_tile_columns;
+}
+
+static GF_Err dc_gpac_video_write_config(DashOutStream* os, int idx, u32 *di, u32 track) 
+{
+    GF_Err ret;
+    VideoOutput* video_output_file = os->video_out[idx];
+    
+    if (os->codec_ctx->codec_id == AV_CODEC_ID_H264){
+	ret = gf_isom_avc_config_new(video_output_file->isof, track, &os->avc_cfg, NULL, NULL, di);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_avc_config_new\n", gf_error_to_string(ret));
+		return ret;
+	}
+
+        //inband SPS/PPS
+	ret = gf_isom_avc_set_inband_config(video_output_file->isof, track, 1);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_avc_set_inband_config\n", gf_error_to_string(ret));
+		return ret;
+	}
+    } else if (os->codec_ctx->codec_id == AV_CODEC_ID_HEVC) { //FIXME CODEC_ID_HEVC would break on old releases
+	ret = gf_isom_hevc_config_new(video_output_file->isof, track, &os->hevc_cfg, NULL, NULL, di);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_hevc_config_new\n", gf_error_to_string(ret));
+		return ret;
+	}
+
+        //inband SPS/PPS
+	//ret = gf_isom_hevc_set_inband_config(video_output_file->isof, track, 1);
+	//if (ret != GF_OK) {
+	 //   av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_hevc_set_inband_config\n", gf_error_to_string(ret));
+	 //   return ret;
+	//}
+    }
+
+    return GF_OK;
+}
+
+static int dc_gpac_video_moov_create_tile(DashOutStream* os, int idx)
+{
+    GF_Err ret;
+    u32 TrackNum;
+    VideoOutput* video_output_file = os->video_out[idx];
+    char filename[1024]; 
+    snprintf(filename, sizeof(filename), "%s%s", 
+                 os->dir_name, 
+                 os->video_out[idx]->seg_init_name);
+    
+    if( idx == 0 ) return -1;
+    
+    video_output_file->isof = gf_isom_open(filename, GF_ISOM_OPEN_WRITE, NULL);
+    
+    ret = gf_isom_clone_movie( os->video_out[0]->isof, 
+                               video_output_file->isof, 
+                               GF_FALSE, GF_FALSE, GF_TRUE, 
+                               GF_FALSE );
+    if (ret) return -1;
+
+
+    /*because of movie fragments MOOF based offset, ISOM <4 is forbidden*/
+    gf_isom_set_brand_info(video_output_file->isof, GF_ISOM_BRAND_ISO5, 1);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISOM, 0);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISO1, 0);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISO2, 0);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISO3, 0);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_MP41, 0);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_MP42, 0);
+
+    gf_isom_remove_root_od(video_output_file->isof);
+    
+    ret = gf_isom_clone_track(os->video_out[0]->isof, idx+1, video_output_file->isof, GF_FALSE, &TrackNum);
+    if (ret) return -1;
+    
+    video_output_file->iso_track_ID = gf_isom_get_track_id(video_output_file->isof, TrackNum);
+    video_output_file->iso_track = TrackNum;
+    
+    ret = gf_isom_setup_track_fragment( video_output_file->isof, gf_isom_get_track_id(video_output_file->isof, TrackNum), 0, 0, 0, 0, 0, 0);
+
+    if (ret) return -1;
+  //"hvt1.1.6.L186.80"
+    gf_isom_set_brand_info(video_output_file->isof, GF_ISOM_BRAND_ISO5, 1);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_DASH, 1);
+    
+    ret = gf_isom_finalize_for_fragment(video_output_file->isof, 1);
+    
+    return 0;
+}
+
+static void hevc_add_trif(GF_ISOFile *file, u32 track, u32 id, Bool full_picture, u32 independent, Bool filtering_disable, u32 tx, u32 ty, u32 tw, u32 th, Bool is_default)
+{
+	char data[11];
+	u32 di, data_size=7;
+	GF_BitStream *bs;
+	//write TRIF sample group description
+	bs = gf_bs_new((const char*)data, 11, GF_BITSTREAM_WRITE);
+	gf_bs_write_u16(bs, id);	//groupID
+	gf_bs_write_int(bs, 1, 1); //tile Region flag always true for us
+	gf_bs_write_int(bs, independent, 2); //independentIDC: set to 1 (motion-constrained tiles but not all tiles RAP)
+	gf_bs_write_int(bs, full_picture, 1);//full picture: false since we don't do L-HEVC tiles
+	gf_bs_write_int(bs, filtering_disable, 1); //filtering disabled: set to 1 (always true on our bitstreams for now) - Check xPS to be sure ...
+	gf_bs_write_int(bs, 0, 1);//has dependency list: false since we don't do L-HEVC tiles
+	gf_bs_write_int(bs, 0, 2); //reserved
+	if (!full_picture) {
+		gf_bs_write_u16(bs, tx);
+		gf_bs_write_u16(bs, ty);
+		data_size+=4;
+	}
+	gf_bs_write_u16(bs, tw);
+	gf_bs_write_u16(bs, th);
+	gf_bs_del(bs);
+
+	gf_isom_add_sample_group_info(file, track, GF_ISOM_SAMPLE_GROUP_TRIF, data, data_size, is_default, &di);
+}
+
+static int dc_gpac_video_moov_create_root(DashOutStream* os)
+{
+	GF_Err ret;
+	u32 di=1, track;
+        u32 width, height;
+	s32 translation_x, translation_y;
+	s16 layer;
+
+        VideoOutput* video_output_file = os->video_out[0];
+        char filename[1024]; 
+        snprintf(filename, sizeof(filename), "%s%s", 
+                 os->dir_name, 
+                 os->video_out[0]->seg_init_name);
+	//TODO: For the moment it is fixed
+	//u32 sample_dur = video_output_file->codec_ctx->time_base.den;
+
+	//int64_t profile = 0;
+	//av_opt_get_int(video_output_file->codec_ctx->priv_data, "level", AV_OPT_SEARCH_CHILDREN, &profile);
+
+	video_output_file->isof = gf_isom_open(filename, GF_ISOM_OPEN_WRITE, NULL);
+	if (!video_output_file->isof) {
+		av_log(NULL, AV_LOG_ERROR, "Cannot open iso file %s\n", filename);
+		return -1;
+	}
+	//gf_isom_store_movie_config(video_output_file->isof, 0);
+
+	track = gf_isom_new_track(video_output_file->isof, 0, GF_ISOM_MEDIA_VISUAL, (int)(os->frame_rate + 0.5));
+        video_output_file->iso_track = track;
+	video_output_file->iso_track_ID = gf_isom_get_track_id(video_output_file->isof, track);
+
+	if (!video_output_file->frame_dur)
+		video_output_file->frame_dur = os->timescale.num / os->timescale.den;
+
+	if (!track) {
+		av_log(NULL, AV_LOG_ERROR, "Cannot create new track\n");
+		return -1;
+	}
+
+	ret = gf_isom_set_track_enabled(video_output_file->isof, track, 1);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_set_track_enabled\n", gf_error_to_string(ret));
+		return -1;
+	}
+
+	ret = dc_gpac_video_write_config(os, 0, &di, track);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: dc_gpac_video_write_config\n", gf_error_to_string(ret));
+		return -1;
+	}
+        gf_isom_set_nalu_extract_mode(video_output_file->isof, track, GF_ISOM_NALU_EXTRACT_INSPECT);
+	gf_isom_set_visual_info(video_output_file->isof, track, di, os->codec_ctx->width, os->codec_ctx->height);
+	gf_isom_set_sync_table(video_output_file->isof, track);
+
+        /*because of movie fragments MOOF based offset, ISOM <4 is forbidden*/
+        gf_isom_set_brand_info(video_output_file->isof, GF_ISOM_BRAND_ISO5, 1);
+        gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISOM, 0);
+        gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISO1, 0);
+        gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISO2, 0);
+        gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISO3, 0);
+        gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_MP41, 0);
+        gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_MP42, 0);
+
+        gf_isom_remove_root_od(video_output_file->isof);
+        
+        ret = gf_isom_setup_track_fragment( video_output_file->isof, 
+                                            track, 1, 
+                                            video_output_file->use_source_timing ? (u32) video_output_file->frame_dur : 1, 
+                                            0, 0, 0, 0);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_setup_track_fragment\n", gf_error_to_string(ret));
+		return -1;
+	}
+        
+        for( int i=1; i<os->nb_tiles+1; i++){
+            ret = gf_isom_clone_track(video_output_file->isof, track, video_output_file->isof, GF_FALSE, &os->video_out[i]->iso_track );
+            if (ret) return ret;
+            os->video_out[i]->iso_track_ID = gf_isom_get_track_id(video_output_file->isof, os->video_out[i]->iso_track);
+        }
+        
+	for( int i=1; i<os->nb_tiles+1; i++){
+            width = 0; 
+            height = 0;
+	    translation_x = 0;
+            translation_y = 0;
+	    layer = 0;
+            
+            
+            gf_isom_hevc_set_tile_config(video_output_file->isof, os->video_out[i]->iso_track, 1, NULL, GF_FALSE);
+
+	    // setup track references from tile track to base
+            gf_isom_set_track_reference( video_output_file->isof, 
+                                         os->video_out[i]->iso_track,                                         
+                                         GF_ISOM_REF_TBAS, 
+                                         video_output_file->iso_track_ID);
+            if(ret != GF_OK){
+                   av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_set_track_reference failed\n", gf_error_to_string(ret));
+            }
+            
+            if (! gf_isom_has_track_reference(os->video_out[0]->isof, os->video_out[0]->iso_track, GF_ISOM_REF_SABT, os->video_out[i]->dash_track_ID)) {
+                ret = gf_isom_set_track_reference( os->video_out[0]->isof, 
+                                                  os->video_out[0]->iso_track, 
+                                                  GF_ISOM_REF_SABT, 
+                                                  os->video_out[i]->dash_track_ID);
+                if(ret != GF_OK){
+                   av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_set_track_reference failed\n", gf_error_to_string(ret));
+               }
+	    }
+           
+            hevc_add_trif( video_output_file->isof, 
+                           os->video_out[i]->iso_track, 
+                           os->video_out[i]->iso_track_ID, 
+                           GF_FALSE, 
+                           (os->video_out[i]->tile.all_intra) ? 2 : 1, 
+                           GF_TRUE, 
+                           os->video_out[i]->tile.tx, 
+                           os->video_out[i]->tile.ty, 
+                           os->video_out[i]->tile.tw,
+                           os->video_out[i]->tile.th, 
+                           GF_TRUE);
+            
+	    gf_isom_set_visual_info( video_output_file->isof, 
+                                     os->video_out[i]->iso_track, 
+                                     1, 
+                                     os->video_out[i]->tile.tw, 
+                                     os->video_out[i]->tile.th);
+
+	    gf_isom_get_track_layout_info( video_output_file->isof, 
+                                           track, 
+                                           &width, &height, 
+                                           &translation_x, &translation_y, 
+                                           &layer);
+	    gf_isom_set_track_layout_info( video_output_file->isof, 
+                                           os->video_out[i]->iso_track, 
+                                           width<<16, height<<16, 
+                                           translation_x, translation_y, 
+                                           layer);
+ 
+            ret = gf_isom_setup_track_fragment( video_output_file->isof, 
+                                                os->video_out[i]->iso_track, 1, 
+                                                video_output_file->use_source_timing ? (u32) video_output_file->frame_dur : 1, 
+                                                0, 0, 0, 0);
+	    if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_setup_track_fragment\n", gf_error_to_string(ret));
+		return -1;
+	    }
+        }
+        
+        
+
+	ret = gf_isom_finalize_for_fragment(video_output_file->isof, track);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_finalize_for_fragment\n", gf_error_to_string(ret));
+		return -1;
+	}
+
+	/*ret = gf_media_get_rfc_6381_codec_name(video_output_file->isof, track, video_output_file->video_data_conf->codec6381, GF_FALSE, GF_FALSE);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_finalize_for_fragment\n", gf_error_to_string(ret));
+		return -1;
+	}*/
+        
+	return 0;
+}
+
+static int dc_gpac_video_moov_create(DashOutStream* os, int idx)
+{
+	GF_Err ret;
+	u32 di=1, track;
+
+        VideoOutput* video_output_file = os->video_out[idx];
+        char filename[1024]; 
+        snprintf(filename, sizeof(filename), "%s%s", 
+                 os->dir_name, 
+                 os->video_out[idx]->seg_init_name );
+        
+        //TODO: For the moment it is fixed
+	//u32 sample_dur = video_output_file->codec_ctx->time_base.den;
+
+	//int64_t profile = 0;
+	//av_opt_get_int(video_output_file->codec_ctx->priv_data, "level", AV_OPT_SEARCH_CHILDREN, &profile);
+
+	video_output_file->isof = gf_isom_open(filename, GF_ISOM_OPEN_WRITE, NULL);
+	if (!video_output_file->isof) {
+		av_log(NULL, AV_LOG_ERROR, "Cannot open iso file %s\n", filename);
+		return -1;
+	}
+	//gf_isom_store_movie_config(video_output_file->isof, 0);
+	track = gf_isom_new_track(video_output_file->isof, 0, GF_ISOM_MEDIA_VISUAL, (int)(os->frame_rate + 0.5));
+	video_output_file->iso_track_ID = gf_isom_get_track_id(video_output_file->isof, track);
+
+	//video_output_file->timescale = os->timescale.den;
+	if (!video_output_file->frame_dur)
+		video_output_file->frame_dur = os->timescale.num / os->timescale.den;
+
+	if (!track) {
+		av_log(NULL, AV_LOG_ERROR, "Cannot create new track\n");
+		return -1;
+	}
+
+	ret = gf_isom_set_track_enabled(video_output_file->isof, track, 1);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_set_track_enabled\n", gf_error_to_string(ret));
+		return -1;
+	}
+
+	ret = dc_gpac_video_write_config(os, idx, &di, track);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: dc_gpac_video_write_config\n", gf_error_to_string(ret));
+		return -1;
+	}
+        
+	gf_isom_set_visual_info(video_output_file->isof, track, di, os->codec_ctx->width, os->codec_ctx->height);
+	gf_isom_set_sync_table(video_output_file->isof, track);
+
+	ret = gf_isom_setup_track_fragment(video_output_file->isof, track, 1, video_output_file->use_source_timing ? (u32) video_output_file->frame_dur : 1, 0, 0, 0, 0);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_setup_track_fragment\n", gf_error_to_string(ret));
+		return -1;
+	}
+
+	ret = gf_isom_finalize_for_fragment(video_output_file->isof, track);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_finalize_for_fragment\n", gf_error_to_string(ret));
+		return -1;
+	}
+
+	/*ret = gf_media_get_rfc_6381_codec_name(video_output_file->isof, track, video_output_file->video_data_conf->codec6381, GF_FALSE, GF_FALSE);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_finalize_for_fragment\n", gf_error_to_string(ret));
+		return -1;
+	}*/
+
+	return 0;
+}
+
+static int dc_gpac_video_isom_open_seg(DashOutStream* os, int idx)
+{
+	GF_Err ret;
+        VideoOutput* video_output_file = os->video_out[idx];
+	ret = gf_isom_start_segment(video_output_file->isof, os->video_out[idx]->seg_media_name, 1);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_start_segment\n", gf_error_to_string(ret));
+		return -1;
+	}
+	av_log(NULL, AV_LOG_ERROR, "[DashCast] Opening new segment %s at UTC "LLU" ms\n", os->video_out[idx]->seg_media_name, gf_net_get_utc() );
+	return 0;
+}
+
+static int dc_gpac_video_isom_write(DashOutStream* os, int idx)
+{
+	GF_Err ret;
+	VideoOutput* video_output_file = os->video_out[idx];
+
+	u32 sc_size = 0;
+	u32 nalu_size = 0;
+
+	u32 buf_len = video_output_file->encoded_frame_size;
+	u8 *buf_ptr = video_output_file->vbuf;
+
+	GF_BitStream *out_bs = gf_bs_new(NULL, 2 * buf_len, GF_BITSTREAM_WRITE);
+        nalu_size = gf_media_nalu_next_start_code(buf_ptr, buf_len, &sc_size);
+	if (0 != nalu_size) {
+		gf_bs_write_u32(out_bs, nalu_size);
+		gf_bs_write_data(out_bs, (const char*) buf_ptr, nalu_size);
+	}
+	
+        buf_ptr += (nalu_size + sc_size);
+	buf_len -= (nalu_size + sc_size);
+	
+	while (buf_len) {
+		nalu_size = gf_media_nalu_next_start_code(buf_ptr, buf_len, &sc_size);
+		if (nalu_size != 0) {
+			gf_bs_write_u32(out_bs, nalu_size );
+			gf_bs_write_data(out_bs, (const char*) buf_ptr, nalu_size );
+		}
+
+		buf_ptr += nalu_size;
+
+		if (!sc_size || (buf_len < nalu_size + sc_size))
+			break;
+		buf_len -= nalu_size + sc_size;
+		buf_ptr += sc_size;
+	}
+	gf_bs_get_content(out_bs, &video_output_file->sample->data, &video_output_file->sample->dataLength);
+	//video_output_file->sample->data = //(char *) (video_output_file->vbuf + nalu_size + sc_size);
+	//video_output_file->sample->dataLength = //video_output_file->encoded_frame_size - (sc_size + nalu_size);
+
+	video_output_file->sample->DTS = os->video_out[idx]->cur_pts;
+	video_output_file->sample->CTS_Offset = (s32) (os->video_out[idx]->cur_pts - video_output_file->sample->DTS);
+	video_output_file->sample->IsRAP = os->video_out[idx]->cur_keyframe;
+	av_log(NULL, AV_LOG_DEBUG, "%d, Isom Write: RAP %d , DTS "LLD" CTS offset %d \n",  
+                    video_output_file->iso_track_ID,  
+                    video_output_file->sample->IsRAP,  
+                    video_output_file->sample->DTS,  
+                    video_output_file->sample->CTS_Offset); 
+	ret = gf_isom_fragment_add_sample( video_output_file->isof, 
+                                           video_output_file->iso_track_ID, 
+                                           video_output_file->sample, 1, 
+                                           video_output_file->use_source_timing ? (u32) video_output_file->frame_dur : 1, 
+                                           0, 0, 0);
+	if (ret != GF_OK) {
+		gf_bs_del(out_bs);
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_fragment_add_sample\n", gf_error_to_string(ret));
+		return -1;
+	}
+              
+        video_output_file->sample_count++;
+	//free data but keep sample structure alive
+	gf_free(video_output_file->sample->data);
+	video_output_file->sample->data = NULL;
+	video_output_file->sample->dataLength = 0;
+
+	gf_bs_del(out_bs);
+	return 0;
+}
+
+static int get_tile_output(DashOutStream* os, int x, int y, int w, int h)
+{
+    for(int i = 1; i < os->nb_tiles+1; i++){
+        if( (os->video_out[i]->tile.tx == x)&&
+            (os->video_out[i]->tile.ty == y)&&
+            (os->video_out[i]->tile.tw == w)&&
+            (os->video_out[i]->tile.th == h))
+            return i;
+    }
+    return 0;
+}
+
+static int dc_gpac_video_isom_tile_write(DashOutStream* os, AVPacket *pkt)
+{
+    int ret = 0;
+    GF_Err e = GF_OK;
+    u8 nal_type = 0;
+    u8 temporal_id, layer_id;
+    int cur_tile, tx, ty, tw, th, idx;
+    int nalu_size = 0;
+    int sc_size = 0;
+    int buf_len = pkt->size;
+    char *buf_ptr = pkt->data;
+    HEVCState hevc = os->hevc_state;
+
+    av_log(NULL, AV_LOG_DEBUG, "pkt->data=%p, pkt->size=%d,\n", buf_ptr, buf_len);
+    GF_BitStream *out_bs = NULL;  
+    GF_BitStream *bs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);
+    
+    nalu_size = gf_media_nalu_next_start_code(buf_ptr, buf_len, &sc_size);
+    if (nalu_size)
+    {
+        av_log(NULL, AV_LOG_ERROR, "The NALU size before first start code should be zero. \n");
+    } 
+    if (sc_size) {
+        buf_ptr += (nalu_size + sc_size);
+        buf_len -= (nalu_size + sc_size);
+    }
+    idx = 0;
+    while (buf_len) {
+        sc_size = 0;
+        if(NULL==out_bs) out_bs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);
+        nalu_size = gf_media_nalu_next_start_code(buf_ptr, buf_len, &sc_size);
+        av_log(NULL, AV_LOG_DEBUG, "buf_ptr=%p, buf_len=%d, nalu_size=%d, sc_size=%d\n", buf_ptr, buf_len, nalu_size, sc_size);
+        if (nalu_size) {
+            ret = gf_media_hevc_parse_nalu(buf_ptr, nalu_size, &hevc, &nal_type, &temporal_id, &layer_id);
+
+	    //error parsing NAL, set nal to fallback to regular import
+	    if (ret<0) nal_type = -1;
+
+	    switch (nal_type) {
+                case GF_HEVC_NALU_VID_PARAM:
+                case GF_HEVC_NALU_SEQ_PARAM:
+                case GF_HEVC_NALU_PIC_PARAM:
+                     break;
+                case GF_HEVC_NALU_SLICE_TRAIL_N:
+		case GF_HEVC_NALU_SLICE_TRAIL_R:
+		case GF_HEVC_NALU_SLICE_TSA_N:
+		case GF_HEVC_NALU_SLICE_TSA_R:
+		case GF_HEVC_NALU_SLICE_STSA_N:
+		case GF_HEVC_NALU_SLICE_STSA_R:
+		case GF_HEVC_NALU_SLICE_BLA_W_LP:
+		case GF_HEVC_NALU_SLICE_BLA_W_DLP:
+		case GF_HEVC_NALU_SLICE_BLA_N_LP:
+		case GF_HEVC_NALU_SLICE_IDR_W_DLP:
+		case GF_HEVC_NALU_SLICE_IDR_N_LP:
+		case GF_HEVC_NALU_SLICE_CRA:
+		case GF_HEVC_NALU_SLICE_RADL_R:
+		case GF_HEVC_NALU_SLICE_RADL_N:
+		case GF_HEVC_NALU_SLICE_RASL_R:
+		case GF_HEVC_NALU_SLICE_RASL_N:
+		    tx = ty = tw = th = 0;
+		    cur_tile = hevc_get_tile_info( &hevc, &tx, &ty, &tw, &th);
+		    if (cur_tile>=os->nb_tiles) {
+			av_log(NULL, AV_LOG_ERROR, "[HEVC Tiles] Tile index %d is greater than number of tiles %d in PPS\n", cur_tile, os->nb_tiles);
+			e = GF_NON_COMPLIANT_BITSTREAM;
+		    }
+		    if (e)
+			continue;
+                    idx = get_tile_output(os, tx, ty, tw, th);
+
+                    if (hevc.s_info.slice_type != GF_HEVC_SLICE_TYPE_I) {
+                        os->video_out[idx]->cur_keyframe = 0;
+		    }else{
+                        os->video_out[idx]->cur_keyframe = 1;
+                    }
+                    
+                    os->video_out[idx]->encoded_frame_size = nalu_size + sc_size;
+                    os->video_out[idx]->cur_pts = pkt->pts;
+                    gf_bs_write_u32(out_bs, nalu_size );
+		    gf_bs_write_data(out_bs, (const char*) buf_ptr, nalu_size );
+                        
+                    gf_bs_get_content(out_bs, &os->video_out[idx]->sample->data, &os->video_out[idx]->sample->dataLength);
+          	    os->video_out[idx]->sample->DTS = os->video_out[idx]->cur_pts;
+	            os->video_out[idx]->sample->CTS_Offset = (s32) (os->video_out[idx]->cur_pts - os->video_out[idx]->sample->DTS);
+	            os->video_out[idx]->sample->IsRAP = os->video_out[idx]->cur_keyframe;
+                    gf_bs_del(out_bs);
+                    out_bs = NULL;
+                    break;
+                default:
+                    os->video_out[0]->encoded_frame_size = nalu_size + sc_size;
+                    os->video_out[0]->cur_pts = pkt->pts;
+                    gf_bs_write_u32(bs, nalu_size );
+		    gf_bs_write_data(bs, (const char*) buf_ptr, nalu_size );
+                    
+                    break;
+            }
+            buf_ptr = buf_ptr + (nalu_size + sc_size);
+            buf_len = buf_len - (nalu_size + sc_size);
+
+        }
+
+    }
+    
+    gf_bs_get_content(bs, &os->video_out[0]->sample->data, &os->video_out[0]->sample->dataLength);
+    gf_bs_del(bs);
+    
+    for(int i=0; i<os->nb_tiles+1; i++){
+        ret = gf_isom_fragment_add_sample( os->video_out[i]->isof, 
+                                           os->video_out[i]->iso_track_ID, 
+                                           os->video_out[i]->sample, 1, 
+                                           os->video_out[i]->use_source_timing ? (u32) os->video_out[i]->frame_dur : 1, 
+                                           0, 0, 0);
+        if(ret != GF_OK){
+             av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_fragment_add_sample tiles=%d\n", gf_error_to_string(ret), i);
+        }
+        
+        if(i > 0 ){
+           /*if (! gf_isom_has_track_reference(os->video_out[0]->isof, os->video_out[0]->iso_track, GF_ISOM_REF_SABT, os->video_out[i]->dash_track_ID)) {
+               ret = gf_isom_set_track_reference(os->video_out[0]->isof, os->video_out[0]->iso_track, GF_ISOM_REF_SABT, os->video_out[i]->dash_track_ID);
+               if(ret != GF_OK){
+                   av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_set_track_reference failed\n", gf_error_to_string(ret));
+               }
+	    }*/
+            e = gf_isom_copy_sample_info(os->video_out[i]->isof, 1, os->video_out[0]->isof, 1, os->video_out[i]->sample_count+1);
+	    if (ret != GF_OK){
+                   av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_copy_sample_info failed\n", gf_error_to_string(ret));
+               }
+        }
+        os->video_out[i]->sample_count++;
+	//free data but keep sample structure alive
+        gf_free(os->video_out[i]->sample->data);
+        os->video_out[i]->sample->data = NULL;
+        os->video_out[i]->sample->dataLength = 0;
+    }
+    
+    return 0;
+}
+
+static int dc_gpac_video_isom_close_seg(DashOutStream* os, int idx)
+{
+    u64 seg_size;
+    VideoOutput* video_output_file = os->video_out[idx];
+    GF_Err ret = gf_isom_close_segment(video_output_file->isof, 0, 0, 0, 0, 0, 0, GF_TRUE, GF_FALSE, video_output_file->seg_marker, NULL, NULL, &seg_size);
+    if (ret != GF_OK) {
+	av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_close_segment\n", gf_error_to_string(ret));
+	return -1;
+    }
+    av_log(NULL, AV_LOG_DEBUG, "[DashCast] Rep %s Closing segment %s at UTC "LLU" ms - size "LLU" bytes\n", video_output_file->rep_id, gf_isom_get_segment_name(video_output_file->isof), gf_net_get_utc(), seg_size );
+
+    return 0;
+}
+
+static int gpac_video_isom_close(DashOutStream* os, int idx)
+{
+    GF_Err ret;
+    VideoOutput* video_output_file = os->video_out[idx];
+    //dc_gpac_video_isom_close_seg(os, idx);
+    os->video_out[idx]->iso_created = 0;
+    video_output_file->sample_count = 0;
+    ret = gf_isom_close(video_output_file->isof);
+    if (ret != GF_OK) {
+	av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_close\n", gf_error_to_string(ret));
+	return -1;
+    }
+     
+    return 0;
+}
+
+static int gpac_video_isom_open(DashOutStream* os, int idx)
+{
+    GF_Err ret;
+    
+    if( idx == 0 ){
+        ret = dc_gpac_video_moov_create_root(os);
+    }else{
+        ret = dc_gpac_video_moov_create_tile(os, idx);
+    }
+    if(ret != GF_OK){
+        
+        av_log(NULL, AV_LOG_VERBOSE, "failed to init_video_ouput::dc_gpac_video_moov_create\n");
+        return -1;
+    }
+    
+    /*
+    ret = dc_gpac_video_isom_open_seg(os, idx);
+    if(ret != GF_OK){
+        av_log(NULL, AV_LOG_VERBOSE, "failed to init_video_ouput::dc_gpac_video_isom_open_seg\n");
+        return -1;
+    }*/
+    
+     return 0;
+}
+
+int dash_probe_extra_data(DashOutStream* os, char* buf, int size)
+{
+    GF_Err ret;
+    
+    if( NULL == buf || 0 == size){
+        av_log(NULL, AV_LOG_ERROR, "extra data buffer is NULL or size = 0; cannot proceed\n");
+        return -1;
+    }
+    
+    if( os->codec_ctx)
+    switch( os->codec_ctx->codec_id ){
+        case AV_CODEC_ID_HEVC:
+            ret = dc_hevc_import_ffextradata(buf, size, &os->hevc_state, &os->hevc_cfg);
+            break;
+        case AV_CODEC_ID_H264:
+            ret = dc_avc_import_ffextradata(buf, size, &os->avc_cfg);
+            break;
+        default:
+           break;
+    }
+    
+    if(ret != GF_OK){
+        av_log(NULL, AV_LOG_ERROR, "import_ffextradata; cannot proceed\n");
+        return -1;
+    }
+            
+    return 0;
+}
+
+static void get_timescale(DashOutStream* os, int *timescale)
+{
+    int fps_1000 = (int)(os->frame_rate * 1000 + 0.5);
+
+    if (fps_1000 == 29970)
+    {
+        *timescale = 30000;
+    }
+    else if (fps_1000 == 23976)
+    {
+        *timescale = 24000;
+    }
+    else if (fps_1000 == 59940)
+    {
+        *timescale = 60000;
+    }
+    else
+    {
+        *timescale = fps_1000;
+    }
+}
+static int init_video_ouput_tile(DashOutStream* os, int idx)
+{
+    //GF_Err ret;
+    int val;
+    
+    os->video_out[idx] = av_malloc(sizeof(VideoOutput));
+    
+#ifndef GPAC_DISABLE_ISOM
+    os->video_out[idx]->sample = gf_isom_sample_new();
+    os->video_out[idx]->isof = NULL;
+#endif
+    os->video_out[idx]->dash_track_ID = idx + 1;
+    os->video_out[idx]->iso_track_ID = 1;
+    /* Variables that encoder needs to encode data */
+    os->video_out[idx]->bit_rate = os->bit_rate / os->nb_tiles; 
+
+    os->video_out[idx]->seg_marker = 0;
+    //gdr;
+    os->video_out[idx]->use_source_timing = 0;
+    os->video_out[idx]->nb_segments = 0;
+    os->video_out[idx]->frame_dur = os->frame_dur;
+    os->video_out[idx]->encoded_frame_size = 0;
+    os->video_out[idx]->segment_index = 0;
+    os->video_out[idx]->sample_count = 0;
+    os->video_out[idx]->iso_created = 0;
+    get_timescale(os, &(os->video_out[idx]->timescale));
+    val = hevc_get_tile_rect(os->hevc_state,
+                             idx - 1,
+                             &(os->video_out[idx]->tile.tx),
+                             &(os->video_out[idx]->tile.ty),
+                             &(os->video_out[idx]->tile.tw),
+                             &(os->video_out[idx]->tile.th));
+    if(val < 0 || val > os->nb_tiles ){
+        av_log(NULL, AV_LOG_ERROR, "init_video_ouput_tile: %d; hevc_get_tile_rect failed\n", idx );
+        return -1;
+    }
+    
+    os->video_out[idx]->tile.data_offset = 0;
+    os->video_out[idx]->tile.nb_nalus_in_sample = 0;
+    os->video_out[idx]->tile.all_intra = 0;
+            
+    os->video_out[idx]->dependency_id = os->stream_index;
+    snprintf(os->video_out[idx]->rep_id, sizeof(os->video_out[idx]->rep_id), 
+            "%s_%d", os->video_out[0]->rep_id, idx );
+    snprintf(os->video_out[idx]->seg_init_name, sizeof(os->video_out[idx]->seg_init_name), 
+            "%s_track%d_init.mp4", os->out_name, os->video_out[idx]->dash_track_ID );
+    snprintf(os->video_out[idx]->seg_media_name_tmpl, sizeof(os->video_out[idx]->seg_media_name_tmpl), 
+            "%s_track%d_$Number$.m4s", os->out_name, os->video_out[idx]->dash_track_ID);
+    snprintf(os->video_out[idx]->seg_media_name, sizeof(os->video_out[idx]->seg_media_name), 
+            "%s%s_track%d_%d.m4s", os->dir_name, os->out_name, os->video_out[idx]->dash_track_ID, os->video_out[idx]->segment_index+1);
+    av_log(NULL, AV_LOG_VERBOSE, "main stream init mp4 name: %s; segment name templ: %s\n", 
+            os->video_out[idx]->seg_init_name, os->video_out[idx]->seg_media_name_tmpl);
+
+    return 0;
+}
+
+static int init_video_ouput(DashOutStream* os)
+{
+    //GF_Err ret;
+    
+    os->video_out[0] = malloc(sizeof(VideoOutput));
+    
+#ifndef GPAC_DISABLE_ISOM
+    os->video_out[0]->sample = gf_isom_sample_new();
+    os->video_out[0]->isof = NULL;
+#endif
+    
+    os->video_out[0]->dash_track_ID = 1;
+    os->video_out[0]->iso_track_ID = 1;
+    /* Variables that encoder needs to encode data */
+    
+    os->video_out[0]->seg_marker = 0;
+    //gdr;
+    os->video_out[0]->use_source_timing = 0;
+    os->video_out[0]->nb_segments = 0;
+    os->video_out[0]->segment_index = 0;
+    os->video_out[0]->frame_dur = os->frame_dur;
+    os->video_out[0]->encoded_frame_size = 0;
+    os->video_out[0]->iso_created = 0;
+    get_timescale(os, &(os->video_out[0]->timescale));
+
+    snprintf(os->video_out[0]->rep_id, sizeof(os->video_out[0]->rep_id), "%d", os->stream_index );
+    snprintf(os->video_out[0]->seg_init_name, sizeof(os->video_out[0]->seg_init_name), "%s_set1_init.mp4", os->out_name );
+    snprintf(os->video_out[0]->seg_media_name_tmpl, sizeof(os->video_out[0]->seg_media_name_tmpl), "%s_track1_$Number$.m4s", os->out_name);
+    snprintf(os->video_out[0]->seg_media_name, sizeof(os->video_out[0]->seg_media_name), "%s%s_track1_%d.m4s", os->dir_name, os->out_name, os->video_out[0]->segment_index+1);
+    av_log(NULL, AV_LOG_VERBOSE, "main stream init mp4 name: %s; segment name templ: %s\n", os->video_out[0]->seg_init_name, os->video_out[0]->seg_media_name);
+    
+    return 0;
+}
+
+void dash_end_output_stream(DashOutStream* os)
+{
+    for(int i=0; i<os->nb_tiles + 1; i++){
+        gf_isom_flush_fragments(os->video_out[i]->isof, GF_TRUE);
+        gpac_video_isom_close(os, i);
+    }
+}
+
+void dash_free_output_stream(DashOutStream* os)
+{
+    //if(NULL != os){
+    //    av_freep(os);
+    //    os = NULL;
+    //}    
+}
+
+int dash_init_output_stream(GPAC_DASHContext* ctx, DashOutStream* os)
+{
+    int ret = 0;
+    int sps_id = 0;
+
+    os->availability_time_offset = 0;
+    os->seg_dur = ctx->seg_duration / 1000;    //ms
+    os->frag_dur = ctx->seg_duration / 1000;  //ms
+    os->frame_dur = (int64_t)(1000 / os->frame_rate); //ms
+    if (ctx->window_size) {
+        os->minimum_update_period = (os->seg_dur * ctx->window_size) / 1000;
+    } else {
+        os->minimum_update_period = os->seg_dur / 1000;
+    }
+        
+    os->frame_per_segment= os->seg_dur / os->frame_dur;
+    os->frame_per_fragment = os->frag_dur / os->frame_dur;
+    os->first_dts_in_fragment = 0;
+    os->fragment_started = 0;
+    os->segment_started = 0;
+    os->last_pts = AV_NOPTS_VALUE;
+    os->last_dts = AV_NOPTS_VALUE;
+    os->first_pts = AV_NOPTS_VALUE;
+    os->start_pts = AV_NOPTS_VALUE;
+    
+    os->nb_tiles = 0;
+    
+    ret = init_video_ouput(os);
+    if(ret){
+        av_log(NULL, AV_LOG_ERROR, "failed to initial stream = %d, main output\n", os->vstream_idx );
+        dash_free_output_stream(os);
+    }
+    
+    sps_id = os->hevc_state.sps_active_idx;
+    os->max_width = os->hevc_state.sps[sps_id].width;
+    os->max_height = os->hevc_state.sps[sps_id].height;
+    if(os->hevc_state.pps[0].tiles_enabled_flag && os->split_tile){
+        os->nb_tiles = os->hevc_state.pps[0].num_tile_columns
+                    * os->hevc_state.pps[0].num_tile_rows;
+
+        for(int i = 1; i < os->nb_tiles+1; i++)
+        {
+            ret = init_video_ouput_tile(os, i);
+            if(ret){
+                dash_free_output_stream(os);
+                av_log(NULL, AV_LOG_ERROR, "failed to initial stream = %d, output tile =%d\n", os->vstream_idx, i);
+                break;
+            }
+        }
+    }
+    
+    return ret;
+}
+
+int dash_write_segment(GPAC_DASHContext* ctx, DashOutStream* os, AVPacket *pkt)
+{
+    int ret =0;
+    int i;
+    int start_idx = 0;
+    char filename[1024];
+    int fragment_idx = 0;
+ 
+    if(os->nb_frames % os->frame_per_segment == 0){
+        for(i=0; i<os->nb_tiles+1; i++){
+            if(0 == os->video_out[i]->iso_created){
+                gpac_video_isom_open(os, i); 
+                os->video_out[i]->iso_created = 1;
+            }
+            ret = dc_gpac_video_isom_open_seg(os, i);
+            if(ret != GF_OK){
+               av_log(NULL, AV_LOG_VERBOSE, "failed to init_video_ouput::dc_gpac_video_isom_open_seg\n");
+               return -1;
+            }
+                      
+        }
+        os->segment_started = 1;
+    }
+    
+    if(os->nb_frames % os->frame_per_fragment == 0){
+        for(i=0; i<os->nb_tiles+1; i++){
+            fragment_idx = i * (os->nb_tiles + 1) + 1;            
+            gf_isom_set_next_moof_number(os->video_out[i]->isof, fragment_idx);
+            gf_isom_start_fragment(os->video_out[i]->isof, 1);
+            gf_isom_set_traf_base_media_decode_time(os->video_out[i]->isof, os->video_out[i]->iso_track_ID, os->first_dts_in_fragment);
+        }
+        os->first_dts_in_fragment += os->frame_per_fragment;
+        os->fragment_started = 1;
+    }
+    
+    if(os->hevc_state.pps[0].tiles_enabled_flag && os->split_tile){
+        ret = dc_gpac_video_isom_tile_write(os, pkt);
+        if(ret)
+            av_log(NULL, AV_LOG_ERROR, "failed to write_segment:dc_gpac_video_isom_tile_write\n");
+    }else{
+        os->video_out[0]->encoded_frame_size = pkt->size;
+        os->video_out[0]->cur_pts = pkt->pts;
+	os->video_out[0]->cur_keyframe = (pkt->flags & AV_PKT_FLAG_KEY) ? 1 : 0;
+        
+        os->video_out[0]->vbuf = pkt->data;
+        os->video_out[0]->vbuf_size = pkt->size;
+        
+        ret = dc_gpac_video_isom_write(os, 0);
+        if(ret)
+            av_log(NULL, AV_LOG_ERROR, "failed to write_segment:dc_gpac_video_isom_write\n");
+    }
+    
+    av_log(NULL, AV_LOG_DEBUG, "frame_per_fragment=%d, os->nb_frames=%d, os->nb_frames MOD os->frame_per_fragment=%d \n",
+                                os->frame_per_fragment, os->nb_frames, 
+                                os->nb_frames%os->frame_per_fragment);
+    /// reach the segment duration, close current segment and init an new one.
+    if(os->nb_frames%os->frame_per_fragment == os->frame_per_fragment - 1){
+        for(i=0; i<os->nb_tiles+1; i++){
+            gf_isom_flush_fragments(os->video_out[i]->isof, GF_TRUE);
+        }
+        os->fragment_started = 0;
+    }
+    
+    av_log(NULL, AV_LOG_DEBUG, "frame_per_segment=%d, os->nb_frames%d, os->nb_frames MOD os->frame_per_segment=%d \n",
+                                os->frame_per_segment, os->nb_frames, 
+                                os->nb_frames%os->frame_per_segment);
+    if(os->nb_frames%os->frame_per_segment == os->frame_per_fragment - 1){
+        for(i=0; i<os->nb_tiles+1; i++){
+            gpac_video_isom_close(os, i);
+            os->video_out[i]->nb_segments++;
+            os->video_out[i]->segment_index++;
+            snprintf(os->video_out[i]->seg_media_name, sizeof(os->video_out[i]->seg_media_name), "%s%s_track%d_%d.m4s", 
+                os->dir_name, os->out_name, os->video_out[i]->dash_track_ID, os->video_out[i]->segment_index+1);
+        }
+        os->segment_started = 0;
+        
+        
+        if (ctx->streaming) {
+            for(i=0; i<os->nb_tiles+1; i++){
+                av_log(NULL, AV_LOG_DEBUG, "$$$$ windows_size=%d, extra_window_size %d, video_out[%d]->nb_segments=%d, segment_index=%d\n", 
+                                                    ctx->window_size, ctx->extra_window_size, i, os->video_out[i]->nb_segments,
+                                                    os->video_out[i]->segment_index);
+                int remove_cnt = os->video_out[i]->nb_segments - ctx->window_size - ctx->extra_window_size;
+                if (remove_cnt > 0)
+                {
+                        
+                    snprintf(filename, sizeof(filename), "%s%s_track%d_%d.m4s", 
+                                  os->dir_name, os->out_name, os->video_out[i]->dash_track_ID, remove_cnt);
+                    remove(filename);
+                    av_log(NULL, AV_LOG_DEBUG, "remove file %s\n", filename);
+                           
+                }
+            }
+        }
+    }
+    os->nb_frames++;
+    
+    return 0;
+}
+
+void dash_write_mpd(GPAC_DASHContext *ctx, int is_final)
+{
+	u32 sec;
+	time_t gtime;
+	struct tm *t;
+	FILE *f;
+        char mpd_name[1024];
+	char name[GF_MAX_PATH];
+        int duration = 0;
+        int hour, minute, second, msecond;
+        char presentation_duration[1024];
+        int start_number = 1;
+        DashOutStream *os = &ctx->streams[0];
+
+	snprintf(name, sizeof(name), "%s%s.mpd", ctx->dirname, ctx->out_name);
+        snprintf(mpd_name, sizeof(mpd_name), "%s.mpd", ctx->out_name);
+
+	f = gf_fopen(name, "w");
+	//TODO: if (!f) ...
+
+	//	time_t t = time(NULL);
+	//	time_t t2 = t + 2;
+	//	t += (2 * (cmddata->seg_dur / 1000.0));
+	//	tm = *gmtime(&t2);
+	//	snprintf(availability_start_time, "%d-%d-%dT%d:%d:%dZ", tm.tm_year + 1900,
+	//			tm.tm_mon + 1, tm.tm_mday, tm.tm_hour, tm.tm_min, tm.tm_sec);
+	//	fprintf(stdout, "%s \n", availability_start_time);
+
+	fprintf(f, "<?xml version=\"1.0\"?>\n");
+    fprintf(f, "<MPD xmlns=\"urn:mpeg:dash:schema:mpd:2011\"  minBufferTime=\"PT%fS\" maxSegmentDuration=\"PT%fS\"", (double)(os->seg_dur/1000), (double)(os->seg_dur/1000));
+    fprintf(f, " profiles=\"%s\"", ctx->streaming ? "urn:mpeg:dash:profile:isoff-live:2011" : "rn:mpeg:dash:profile:isoff-on-demand:2011");
+        fprintf(f, " type=\"%s\"", is_final ? "static" : "dynamic");
+
+    if (ctx->streaming)
+    {
+        start_number = 0;
+    }
+    if (is_final && ctx->streaming) {
+        ctx->streaming = 0;
+        os->total_frames = os->total_frames % os->frame_per_fragment;
+    }
+
+    if (is_final)
+    {
+        duration = (int)(os->total_frames * 1000 / os->frame_rate + 0.5);
+        hour = duration / 3600000;
+        duration = duration % 3600000;
+        minute = duration / 60000;
+        duration = duration % 60000;
+        second = duration / 1000;
+        msecond = duration % 1000;
+        snprintf(presentation_duration, sizeof(presentation_duration), "PT%02dH%02dM%02d.%03dS", hour, minute, second, msecond);
+        fprintf(f, " mediaPresentationDuration=\"%s\"", presentation_duration);
+    } else {
+        gf_net_get_ntp(&sec, NULL);
+        gtime = sec - GF_NTP_SEC_1900_TO_1970;
+        t = gmtime(&gtime);
+        if (os->video_out[0]->segment_index == 0) {
+            snprintf(os->available_start_time, sizeof(os->available_start_time), "%d-%d-%dT%d:%d:%dZ", 1900+t->tm_year,
+                    t->tm_mon+1, t->tm_mday, t->tm_hour, t->tm_min, t->tm_sec);
+        }
+        fprintf(f, " availabilityStartTime=\"%s\"", os->available_start_time);
+        fprintf(f, " timeShiftBufferDepth=\"PT5M\"");
+        if (os->minimum_update_period > 0)
+    	    fprintf(f, " minimumUpdatePeriod=\"PT%dS\"", os->minimum_update_period);
+
+        fprintf(f, " publishTime=\"%d-%02d-%02dT%02d:%02d:%02dZ\"", 1900+t->tm_year, t->tm_mon+1, t->tm_mday, t->tm_hour, t->tm_min, t->tm_sec);
+    }
+	fprintf(f, ">\n");
+
+	fprintf(f,
+	        " <ProgramInformation moreInformationURL=\"http://gpac.io\">\n"
+	        "  <Title>%s</Title>\n"
+	        " </ProgramInformation>\n", mpd_name);
+
+        if (ctx->base_url) {
+	    if (strcmp(ctx->base_url, "") != 0) {
+	        fprintf(f, " <BaseURL>%s</BaseURL>\n", ctx->base_url);
+	    }
+        }
+        if (!ctx->streaming)
+        {
+            fprintf(f, " <Period duration=\"%s\">\n", presentation_duration);
+        }
+        else
+        {
+	    fprintf(f, " <Period start=\"PT0H0M0.000S\" id=\"P1\">\n");
+        }
+        
+
+        for (int stream_idx = 0; stream_idx < ctx->nb_streams; stream_idx++)
+        {
+            os = &ctx->streams[stream_idx];
+	    fprintf(f, "  <AdaptationSet segmentAlignment=\"true\" maxWidth=\"%d\" maxHeight=\"%d\" bitstreamSwitching=\"false\">\n",
+                        os->max_width, os->max_height);
+            fprintf(f, "   <EssentialProperty schemeIdUri=\"urn:mpeg:dash:srd:2014\" value=\"1,0,0,0,0\"/>\n");
+            fprintf(f,
+	        "   <SegmentTemplate initialization=\"%s\"/>\n",
+	        os->video_out[0]->seg_init_name);
+            fprintf(f, "   <Representation id=\"%s\" mimeType=\"video/mp4\" codecs=\"%s\" "
+                        "width=\"%d\" height=\"%d\" frameRate=\"%d/%d\" sar=\"1:1\" startWithSAP=\"1\" bandwidth=\"%d\">\n",
+                        os->video_out[0]->rep_id,
+                        "hvc2.1.6.L186.80",
+                        os->max_width, os->max_height, os->timescale.den,
+                        os->timescale.num, os->bit_rate);
+            fprintf(f, "    <SegmentTemplate timescale=\"%d\" duration=\"%d\" media=\"%s\""
+                        " startNumber=\"%d\"/>\n",
+                        os->video_out[0]->timescale, (os->seg_dur * os->video_out[0]->timescale) / 1000, os->video_out[0]->seg_media_name_tmpl, start_number);
+            fprintf(f, "   </Representation>\n");
+            fprintf(f, "  </AdaptationSet>\n");
+
+	    for (int tile_idx = 1; tile_idx < os->nb_tiles + 1; tile_idx++) {
+		fprintf(f, "  <AdaptationSet segmentAlignment=\"true\" maxWidth=\"%d\" maxHeight=\"%d\" bitstreamSwitching=\"false\">\n",
+                            os->video_out[tile_idx]->tile.tw, os->video_out[tile_idx]->tile.th);
+                fprintf(f, "   <SupplementalProperty schemeIdUri=\"urn:mpeg:dash:srd:2014\" value=\"1,%d,%d,%d,%d\"/>\n",
+                            os->video_out[tile_idx]->tile.tx, os->video_out[tile_idx]->tile.ty,
+                            os->video_out[tile_idx]->tile.tw, os->video_out[tile_idx]->tile.th);
+		fprintf(f, "   <Representation id=\"%s\" mimeType=\"video/mp4\" codecs=\"%s\" "
+		        "width=\"%d\" height=\"%d\" frameRate=\"%d/%d\" sar=\"1:1\" startWithSAP=\"1\" bandwidth=\"%d\" dependencyId=\"%d\">\n",
+		        os->video_out[tile_idx]->rep_id, "hvc2.1.6.L186.80",
+		        os->video_out[tile_idx]->tile.tw, os->video_out[tile_idx]->tile.th, os->timescale.den, os->timescale.num,
+		        os->video_out[tile_idx]->bit_rate, os->video_out[tile_idx]->dependency_id);
+                fprintf(f, "    <SegmentTemplate timescale=\"%d\" duration=\"%d\" media=\"%s\""
+                            " startNumber=\"%d\"/>\n",
+                            os->video_out[tile_idx]->timescale, (os->seg_dur * os->video_out[tile_idx]->timescale) / 1000, os->video_out[tile_idx]->seg_media_name_tmpl, start_number);
+                fprintf(f, "   </Representation>\n");
+                fprintf(f, "  </AdaptationSet>\n");
+	    }
+
+        }
+
+	fprintf(f, " </Period>\n");
+
+	fprintf(f, "</MPD>\n");
+
+	gf_fclose(f);
+}
+int dash_update_mpd(GPAC_DASHContext* dash_ctx, int is_final)
+{
+    DashOutStream *os = &dash_ctx->streams[0];
+    if (dash_ctx->window_size) {
+        if (os->video_out[0]->segment_index % dash_ctx->window_size == 0)
+        {
+            dash_write_mpd(dash_ctx, is_final);
+            return 0;
+        }
+    }
+    else {
+        if (os->nb_frames % os->frame_per_fragment == 0)
+        {
+            dash_write_mpd(dash_ctx, is_final);
+            return 0;
+        }
+    }
+
+    if (is_final) {
+        dash_write_mpd(dash_ctx, is_final);
+        return 0;
+    }
+
+    return 0;
+}
diff -Nur FFmpeg/libavformat/tiled_dash_parse.h FFmpeg_patched/libavformat/tiled_dash_parse.h
--- FFmpeg/libavformat/tiled_dash_parse.h	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/libavformat/tiled_dash_parse.h	2022-06-29 07:16:09.555918780 +0000
@@ -0,0 +1,168 @@
+/*
+ * Intel tile Dash muxer
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef TILE_DASH_PARSE_H
+#define TILE_DASH_PARSE_H
+
+#include "libavutil/avassert.h"
+#include "libavutil/avutil.h"
+#include "libavutil/avstring.h"
+#include "libavutil/intreadwrite.h"
+#include "libavutil/mathematics.h"
+#include "libavutil/opt.h"
+#include "libavutil/rational.h"
+#include "libavutil/time_internal.h"
+
+#include "avformat.h"
+#include "avio_internal.h"
+
+#include "gpac/constants.h"
+#include "gpac/internal/mpd.h"
+#include "gpac/media_tools.h"
+#include "gpac/isomedia.h"
+//#include "gpac/isom_tools.h"
+#include "gpac/internal/media_dev.h"
+
+#define MAX_TILE 1024
+
+typedef struct
+{
+	u32 tx, ty, tw, th;
+	u32 data_offset;
+	u32 nb_nalus_in_sample;
+	Bool all_intra;
+} HEVCTileImport;
+
+typedef struct {
+
+#ifndef GPAC_DISABLE_ISOM
+	GF_ISOFile        *isof;
+	GF_ISOSample      *sample;
+#endif
+	u32               iso_track_ID;
+        u32               iso_track;
+        int               dash_track_ID;
+	/* Variables that encoder needs to encode data */
+	uint8_t           *vbuf;
+	int               vbuf_size;
+        int               encoded_frame_size;
+        int64_t           cur_pts;
+        int               cur_keyframe;
+	u32               seg_marker;
+	int               gdr;
+        u32               nb_segments;
+        int               segment_index;
+        int64_t           frame_dur;
+	char              rep_id[64];
+        int               dependency_id;
+        HEVCTileImport    tile;
+        int               bit_rate;
+        char              seg_init_name[1024];
+        char              seg_media_name[1024];
+        char              seg_media_name_tmpl[1024];
+        int               timescale;
+        int               use_source_timing;
+        int               sample_count;
+        int               iso_created;
+} VideoOutput;
+
+typedef struct DashOutStream {
+    AVFormatContext       *fmt_ctx;
+    AVCodecParameters     *codec_ctx;
+    HEVCState             hevc_state;
+    GF_HEVCConfig         hevc_cfg;
+    GF_AVCConfig          avc_cfg;
+    int                   initialized;
+    int                   stream_index;
+    //int                   packets_written;
+    //int                   total_pkt_size;
+    int                   total_frames;
+    int                   nb_frames;
+    int                   bit_rate;
+    VideoOutput           *video_out[MAX_TILE];
+    int                   nb_tiles;
+    int                   max_width;
+    int                   max_height;
+    double                frame_rate;
+    
+    int64_t               last_pts;
+    int64_t               last_dts;
+    int64_t               first_pts;
+    int64_t               start_pts;
+    int64_t               first_dts_in_fragment;
+    double                availability_time_offset;
+    int                   frame_per_fragment;
+    int                   frame_per_segment;
+    Bool                  fragment_started;
+    Bool                  segment_started;
+    int                   seg_dur;
+    int                   frag_dur;
+    int                   minimum_update_period;
+    int64_t               frame_dur;
+    AVRational            timescale;
+    int                   vstream_idx;
+    int                   split_tile;
+    char                  out_name[256];
+    char                  dir_name[1024];
+    char                  available_start_time[1024];
+
+} DashOutStream;
+
+typedef struct {
+    const AVClass  *class;  /* Class for private options. */
+    char           *adaptation_sets;
+    int            nb_as;
+    int            window_size;
+    int            extra_window_size;
+    int64_t        seg_duration;
+    int            remove_at_exit;
+    int            use_template;
+    int            use_timeline;
+    DashOutStream  *streams;
+    int            nb_streams;
+    int64_t        last_duration;
+    int64_t        total_duration;
+    char           availability_start_time[100];
+    char           dirname[1024];
+    const char     *out_name;
+    const char     *base_url;
+    const char     *utc_timing_url;
+    int            master_playlist_created;
+    AVIOContext    *mpd_out;
+    int            streaming;
+    int            index_correction;
+    int            split_tile;
+    int            has_video;
+    int            has_audio;
+} GPAC_DASHContext;
+
+
+void format_date_now(char *buf, int size);
+int dash_init_output_stream(GPAC_DASHContext* ctx, DashOutStream* os);
+void dash_end_output_stream(DashOutStream* os);
+int dash_probe_extra_data(DashOutStream* os, char* buf, int size);
+int dash_update_mpd(GPAC_DASHContext* dash_ctx, int is_final);
+int dash_write_segment( GPAC_DASHContext* ctx, DashOutStream* os, AVPacket *pkt );
+void dash_free_output_stream(DashOutStream* os);
+void dash_write_mpd(GPAC_DASHContext *ctx, int is_final);
+#endif
+
diff -Nur FFmpeg/libavresample/tests/.gitignore FFmpeg_patched/libavresample/tests/.gitignore
--- FFmpeg/libavresample/tests/.gitignore	2022-06-29 07:15:48.715919028 +0000
+++ FFmpeg_patched/libavresample/tests/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1 +0,0 @@
-/avresample
diff -Nur FFmpeg/libavutil/.gitignore FFmpeg_patched/libavutil/.gitignore
--- FFmpeg/libavutil/.gitignore	2022-06-29 07:15:48.719919028 +0000
+++ FFmpeg_patched/libavutil/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,2 +0,0 @@
-/avconfig.h
-/ffversion.h
diff -Nur FFmpeg/libavutil/tests/.gitignore FFmpeg_patched/libavutil/tests/.gitignore
--- FFmpeg/libavutil/tests/.gitignore	2022-06-29 07:15:48.739919028 +0000
+++ FFmpeg_patched/libavutil/tests/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,51 +0,0 @@
-/adler32
-/aes
-/aes_ctr
-/atomic
-/audio_fifo
-/avstring
-/base64
-/blowfish
-/bprint
-/camellia
-/cast5
-/color_utils
-/cpu
-/cpu_init
-/crc
-/des
-/dict
-/display
-/error
-/encryption_info
-/eval
-/fifo
-/file
-/hash
-/hmac
-/hwdevice
-/imgutils
-/integer
-/lfg
-/lls
-/log
-/lzo
-/md5
-/murmur3
-/opt
-/parseutils
-/pca
-/pixdesc
-/pixelutils
-/pixfmt_best
-/random_seed
-/rational
-/ripemd
-/sha
-/sha512
-/softfloat
-/tea
-/tree
-/twofish
-/utf8
-/xtea
diff -Nur FFmpeg/libswresample/tests/.gitignore FFmpeg_patched/libswresample/tests/.gitignore
--- FFmpeg/libswresample/tests/.gitignore	2022-06-29 07:15:48.747919028 +0000
+++ FFmpeg_patched/libswresample/tests/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1 +0,0 @@
-/swresample
diff -Nur FFmpeg/libswscale/tests/.gitignore FFmpeg_patched/libswscale/tests/.gitignore
--- FFmpeg/libswscale/tests/.gitignore	2022-06-29 07:15:48.755919028 +0000
+++ FFmpeg_patched/libswscale/tests/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,3 +0,0 @@
-/colorspace
-/pixdesc_query
-/swscale
diff -Nur FFmpeg/run_cubification.sh FFmpeg_patched/run_cubification.sh
--- FFmpeg/run_cubification.sh	1970-01-01 00:00:00.000000000 +0000
+++ FFmpeg_patched/run_cubification.sh	2022-06-29 07:16:09.771918778 +0000
@@ -0,0 +1,15 @@
+#!/bin/bash
+
+export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH
+export LD_LIBRARY_PATH=/usr/local/lib64:$LD_LIBRARY_PATH
+
+#cp ../../cubification_mdf/map_ERP3840x1920_Cubemap2880x1920/Dewarp_genx.isa ./
+#cp ../../cubification_mdf/map_ERP3840x1920_Cubemap2880x1920/xCooridnate.bin ./
+#cp ../../cubification_mdf/map_ERP3840x1920_Cubemap2880x1920/yCooridnate.bin ./
+#./ffmpeg -hwaccel vaapi -hwaccel_output_format vaapi -i h265_3840x1920.h265 -vf erp2cubmap_mdf,hwdownload,format=nv12 -pix_fmt yuv420p -input_type 1 -rc 1 -c:v distributed_encoder -s 2880x1920 -g 15 -tile_row 6 -tile_column 9 -la_depth 2 -config_file config_high.xml -b 15M -map 0:v -y cubification_4k.h265
+
+cp ../../tools/bin/map_ERP7680x3840_Cubemap5760x3840/Dewarp_genx.isa ./
+cp ../../tools/bin/map_ERP7680x3840_Cubemap5760x3840/xCooridnate.bin ./
+cp ../../tools/bin/map_ERP7680x3840_Cubemap5760x3840/yCooridnate.bin ./
+./ffmpeg -hwaccel vaapi -hwaccel_output_format vaapi -i h265_7680x3840.h265 -vf erp2cubmap_mdf,hwdownload,format=nv12 -pix_fmt yuv420p -input_type 1 -rc 1 -c:v distributed_encoder -s 5760x3840 -g 25 -tile_row 6 -tile_column 9 -la_depth 2 -config_file config_high.xml -b 30M -map 0:v -y cubification_8k.h265
+
diff -Nur FFmpeg/tests/.gitignore FFmpeg_patched/tests/.gitignore
--- FFmpeg/tests/.gitignore	2022-06-29 07:15:48.755919028 +0000
+++ FFmpeg_patched/tests/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,11 +0,0 @@
-/audiogen
-/audiomatch
-/base64
-/data/
-/pixfmts.mak
-/rotozoom
-/test_copy.ffmeta
-/tiny_psnr
-/tiny_ssim
-/videogen
-/vsynth1/
diff -Nur FFmpeg/tests/api/.gitignore FFmpeg_patched/tests/api/.gitignore
--- FFmpeg/tests/api/.gitignore	2022-06-29 07:15:48.755919028 +0000
+++ FFmpeg_patched/tests/api/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1 +0,0 @@
-/*-test
diff -Nur FFmpeg/tests/checkasm/.gitignore FFmpeg_patched/tests/checkasm/.gitignore
--- FFmpeg/tests/checkasm/.gitignore	2022-06-29 07:15:48.759919028 +0000
+++ FFmpeg_patched/tests/checkasm/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1 +0,0 @@
-/checkasm
diff -Nur FFmpeg/tests/dnn/.gitignore FFmpeg_patched/tests/dnn/.gitignore
--- FFmpeg/tests/dnn/.gitignore	2022-06-29 07:15:48.759919028 +0000
+++ FFmpeg_patched/tests/dnn/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,6 +0,0 @@
-/dnn-layer-conv2d-test
-/dnn-layer-depth2space-test
-/dnn-layer-maximum-test
-/dnn-layer-pad-test
-/dnn-layer-mathbinary-test
-/dnn-layer-mathunary-test
diff -Nur FFmpeg/tools/.gitignore FFmpeg_patched/tools/.gitignore
--- FFmpeg/tools/.gitignore	2022-06-29 07:15:48.907919026 +0000
+++ FFmpeg_patched/tools/.gitignore	1970-01-01 00:00:00.000000000 +0000
@@ -1,19 +0,0 @@
-/aviocat
-/ffbisect
-/bisect.need
-/crypto_bench
-/cws2fws
-/fourcc2pixfmt
-/ffescape
-/ffeval
-/ffhash
-/graph2dot
-/ismindex
-/pktdumper
-/probetest
-/qt-faststart
-/sidxindex
-/trasher
-/seek_print
-/uncoded_frame
-/zmqsend
