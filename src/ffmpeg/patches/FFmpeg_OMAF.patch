diff -urN FFmpeg/configure FFmpeg-patched/configure
--- FFmpeg/configure	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/configure	2020-09-27 13:35:13.977526503 +0800
@@ -252,6 +252,7 @@
   --enable-libopencv       enable video filtering via libopencv [no]
   --enable-libopenh264     enable H.264 encoding via OpenH264 [no]
   --enable-libopenjpeg     enable JPEG 2000 de/encoding via OpenJPEG [no]
+  --enable-libopenhevc     enable HEVC decoding via OpenHEVC [no]
   --enable-libopenmpt      enable decoding tracked files via libopenmpt [no]
   --enable-libopus         enable Opus de/encoding via libopus [no]
   --enable-libpulse        enable Pulseaudio input via libpulse [no]
@@ -293,6 +294,16 @@
   --enable-libxcb-shape    enable X11 grabbing shape rendering [autodetect]
   --enable-libxvid         enable Xvid encoding via xvidcore,
                            native MPEG-4/Xvid encoder exists [no]
+  --enable-libsvthevc             enable HEVC encodig via SVT [no]
+  --enable-libDistributedEncoder  enable Distributed Encoder [no]
+  --enable-hevctile               enable HEVC tile encodig via SVT or x265 [no]
+  --enable-libstitch              enable HEVC tile stitch library [no]
+  --enable-libgpac                enable DASH mux with libgpac [no]
+  --enable-libVROmafPacking       enable OMAF Compliance packing muxer [no]
+  --enable-libVRDashStreaming     enable VR DASH streaming and demuxer library [no]
+  --enable-libOmafDashAccess      enable OMAF Compliance DASH streaming and demuxer library [no]
+  --enable-libtransform360        enable Transform360 to transform projection from ERP to cubemap [no]
+  --enable-libxcam                enable image processing via xcam [no]
   --enable-libxml2         enable XML parsing using the C library libxml2, needed
                            for dash demuxing support [no]
   --enable-libzimg         enable z.lib, needed for zscale filter [no]
@@ -1721,6 +1732,7 @@
     libdavs2
     librubberband
     libvidstab
+    libsvthevc
     libx264
     libx265
     libxavs
@@ -1783,6 +1795,13 @@
     libjack
     libklvanc
     libkvazaar
+    libgpac
+    libstitch
+    libDistributedEncoder
+    libtransform360
+    libVRDashStreaming
+    libOmafDashAccess
+    libVROmafPacking
     libmodplug
     libmp3lame
     libmysofa
@@ -1791,6 +1810,7 @@
     libopenjpeg
     libopenmpt
     libopus
+    libopenhevc
     libpulse
     librabbitmq
     librav1e
@@ -1812,6 +1832,7 @@
     libvpx
     libwavpack
     libwebp
+    libxcam
     libxml2
     libzimg
     libzmq
@@ -3194,8 +3215,13 @@
 chromaprint_muxer_deps="chromaprint"
 h264_videotoolbox_encoder_deps="pthreads"
 h264_videotoolbox_encoder_select="videotoolbox_encoder"
+hevc_svt_encoder_deps="libsvthevc"
+distributed_encoder_deps="libDistributedEncoder"
+hevc_tile_encoder_deps="libsvthevc libstitch"
 hevc_videotoolbox_encoder_deps="pthreads"
 hevc_videotoolbox_encoder_select="videotoolbox_encoder"
+libopenhevc_decoder_deps="libopenhevc"
+libsvt_hevc_encoder_deps="libsvthevc"
 libaom_av1_decoder_deps="libaom"
 libaom_av1_encoder_deps="libaom"
 libaom_av1_encoder_select="extract_extradata_bsf"
@@ -3343,9 +3369,14 @@
 spx_muxer_select="ogg_muxer"
 swf_demuxer_suggest="zlib"
 tak_demuxer_select="tak_parser"
+tile_dash_muxer_select="libgpac"
+tile_dash_demuxer_select="libOmafDashAccess"
+omaf_packing_muxer_select="libVROmafPacking"
 truehd_demuxer_select="mlp_parser"
 tg2_muxer_select="mov_muxer"
 tgp_muxer_select="mov_muxer"
+tile_dash_demuxer_select="libOmafDashAccess"
+omaf_packing_muxer_select="libVROmafPacking"
 vobsub_demuxer_select="mpegps_demuxer"
 w64_demuxer_select="wav_demuxer"
 w64_muxer_select="wav_muxer"
@@ -3559,6 +3590,7 @@
 overlay_qsv_filter_deps="libmfx"
 overlay_qsv_filter_select="qsvvpp"
 overlay_vulkan_filter_deps="vulkan libglslang"
+xcam_filter_deps="libxcam"
 owdenoise_filter_deps="gpl"
 pad_opencl_filter_deps="opencl"
 pan_filter_deps="swresample"
@@ -3613,6 +3645,8 @@
 tinterlace_filter_deps="gpl"
 tinterlace_merge_test_deps="tinterlace_filter"
 tinterlace_pad_test_deps="tinterlace_filter"
+transform360_filter_deps="libtransform360"
+transform360_filter_select="libtransform360"
 tonemap_filter_deps="const_nan"
 tonemap_vaapi_filter_deps="vaapi VAProcFilterParameterBufferHDRToneMapping"
 tonemap_opencl_filter_deps="opencl const_nan"
@@ -6314,6 +6348,13 @@
 enabled libgsm            && { for gsm_hdr in "gsm.h" "gsm/gsm.h"; do
                                    check_lib libgsm "${gsm_hdr}" gsm_create -lgsm && break;
                                done || die "ERROR: libgsm not found"; }
+enabled libgpac           && require_pkg_config libgpac gpac gpac/dash.h gf_dash_new
+enabled libVROmafPacking  && require_pkg_config libVROmafPacking VROmafPacking VROmafPackingAPI.h VROmafPackingInit
+enabled libVRDashStreaming && require_pkg_config libVRDashStreaming VRDashStreaming VRDashStreamingAPI.h DashStreaming_Init
+enabled libOmafDashAccess && require_pkg_config libOmafDashAccess OmafDashAccess OmafDashAccessApi.h OmafAccess_Init
+enabled libxcam           && { check_pkg_config libxcam "libxcam >= 1.4.0" "capi/xcam_handle.h" xcam_create_handle ||
+                               die "ERROR: libxcam must be installed and version must be >= 1.4.0"; }
+
 enabled libilbc           && require libilbc ilbc.h WebRtcIlbcfix_InitDecode -lilbc $pthreads_extralibs
 enabled libklvanc         && require libklvanc libklvanc/vanc.h klvanc_context_create -lklvanc
 enabled libkvazaar        && require_pkg_config libkvazaar "kvazaar >= 0.8.1" kvazaar.h kvz_api_get
@@ -6344,6 +6385,7 @@
                                  require libopencv opencv2/core/core_c.h cvCreateImageHeader -lopencv_core -lopencv_imgproc; } ||
                                require_pkg_config libopencv opencv opencv/cxcore.h cvCreateImageHeader; }
 enabled libopenh264       && require_pkg_config libopenh264 openh264 wels/codec_api.h WelsGetCodecVersion
+enabled libopenhevc       && require libopenhevc libopenhevc/openhevc.h  oh_decode -lopenhevc -lm
 enabled libopenjpeg       && { check_pkg_config libopenjpeg "libopenjp2 >= 2.1.0" openjpeg.h opj_version ||
                                { require_pkg_config libopenjpeg "libopenjp2 >= 2.1.0" openjpeg.h opj_version -DOPJ_STATIC && add_cppflags -DOPJ_STATIC; } }
 enabled libopenmpt        && require_pkg_config libopenmpt "libopenmpt >= 0.2.6557" libopenmpt/libopenmpt.h openmpt_module_create -lstdc++ && append libopenmpt_extralibs "-lstdc++"
@@ -6369,6 +6411,10 @@
 enabled libssh            && require_pkg_config libssh libssh libssh/sftp.h sftp_init
 enabled libspeex          && require_pkg_config libspeex speex speex/speex.h speex_decoder_init
 enabled libsrt            && require_pkg_config libsrt "srt >= 1.3.0" srt/srt.h srt_socket
+enabled libsvthevc        && require_pkg_config libsvthevc SvtHevcEnc EbApi.h EbInitHandle
+enabled libDistributedEncoder && require_pkg_config libDistributedEncoder DistributedEncoder DistributedEncoderAPI.h DistributedEncoder_Init
+enabled libtransform360   && require_pkg_config libtranform360 Transform360 VideoFrameTransformHandler.h VideoFrameTransform_new
+enabled libstitch         && require_pkg_config libstitch stitch genTiledstreamAPI.h genTiledStream_Init
 enabled libtensorflow     && require libtensorflow tensorflow/c/c_api.h TF_Version -ltensorflow
 enabled libtesseract      && require_pkg_config libtesseract tesseract tesseract/capi.h TessBaseAPICreate
 enabled libtheora         && require libtheora theora/theoraenc.h th_info_init -ltheoraenc -ltheoradec -logg
diff -urN FFmpeg/doc/filters.texi FFmpeg-patched/doc/filters.texi
--- FFmpeg/doc/filters.texi	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/doc/filters.texi	2020-09-27 13:35:13.073526575 +0800
@@ -25732,3 +25732,79 @@
 @end table

 @c man end MULTIMEDIA SOURCES
+
+@section xcam
+Image processing supported through libXCam.
+
+To enable compilation of @var{xcam} filter you need to configure FFmpeg with
+@code{--enable-libxcam}.
+
+libXCam supports automotive surround view stitching, 360 video stitching,
+digital video stabilization, noise reduction and so on. For more information
+about libxcam see @url{https://github.com/intel/libxcam}.
+
+@subsection Options
+
+@table @option
+
+@item inputs
+The number of inputs. Default is @code{1}. 3dnr, waveletnr, fisheye, defog
+and dvs handlers support one input, stitch and stitchcl handlers support
+dynamic inputs.
+
+@item w
+Output video width. Default is @code{0}.
+If the value is 0, the corresponding input width is used for the output.
+
+@item h
+Output video height. Default is @code{0}.
+If the value is 0, the corresponding input height is used for the output.
+
+@item fmt
+Pixel format. Default is @code{auto}.
+
+@table @samp
+@item auto
+Negotiate pixel format automatically, selects the input pixel format as the
+processing format.
+@item nv12
+NV12 format. All handlers support NV12 format.
+@item yuv420
+YUV420 format. Currently, only @b{soft} stitching supports YUV420 format.
+@end table
+
+@item name
+Handler name. Default is @code{stitch}.
+
+@table @samp
+@item 3dnr
+3D denoising
+@item waveletnr
+Wavelet denoising
+@item fisheye
+Fisheye calibration
+@item defog
+Fog removal
+@item dvs
+Digital video stabilizer
+@item stitch
+Soft/GLES/Vulkan stitching, supports automotive surround view stitching and
+360 video stitching.
+@item stitchcl
+OpenCL stitching, supports automotive surround view stitching and 360 video
+stitching.
+@end table
+
+@item allocoutbuf
+Whether or not to allocate output buffer. Default is @code{1}.
+
+@item params
+Private parameters for each handler. Currently, only @b{stitch} and
+@b{stitchcl} handlers have private parameters.
+
+@end table
+
+@subsection Examples
+
+For more detailed examples see @url{https://github.com/intel/libxcam/wiki/Tests#1-ffmpeg-xcam}.
+
diff -urN FFmpeg/fftools/ffmpeg.c FFmpeg-patched/fftools/ffmpeg.c
--- FFmpeg/fftools/ffmpeg.c	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/fftools/ffmpeg.c	2020-09-27 13:35:13.078526574 +0800
@@ -1314,6 +1314,7 @@
             if (ost->logfile && enc->stats_out) {
                 fprintf(ost->logfile, "%s", enc->stats_out);
             }
+            break;
         }
         ost->sync_opts++;
         /*
@@ -1508,6 +1509,7 @@
             }
 
             av_frame_unref(filtered_frame);
+            break;
         }
     }
 
diff -urN FFmpeg/fftools/ffplay.c FFmpeg-patched/fftools/ffplay.c
--- FFmpeg/fftools/ffplay.c	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/fftools/ffplay.c	2020-09-27 13:35:13.078526574 +0800
@@ -3355,15 +3355,22 @@
                 seek_chapter(cur_stream, -1);
                 break;
             case SDLK_LEFT:
-                incr = seek_interval ? -seek_interval : -10.0;
-                goto do_seek;
+                {
+                    incr = seek_interval ? -seek_interval : -10.0;
+                    goto do_seek;
+                }
             case SDLK_RIGHT:
-                incr = seek_interval ? seek_interval : 10.0;
-                goto do_seek;
+                {
+                    incr = seek_interval ? seek_interval : 10.0;
+                    goto do_seek;
+                }
             case SDLK_UP:
-                incr = 60.0;
-                goto do_seek;
+                {
+                    incr = 60.0;
+                    goto do_seek;
+                }
             case SDLK_DOWN:
+                {
                 incr = -60.0;
             do_seek:
                     if (seek_by_bytes) {
@@ -3390,6 +3397,7 @@
                         stream_seek(cur_stream, (int64_t)(pos * AV_TIME_BASE), (int64_t)(incr * AV_TIME_BASE), 0);
                     }
                 break;
+                }
             default:
                 break;
             }
diff -urN FFmpeg/libavcodec/allcodecs.c FFmpeg-patched/libavcodec/allcodecs.c
--- FFmpeg/libavcodec/allcodecs.c	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavcodec/allcodecs.c	2020-09-27 13:35:13.111526572 +0800
@@ -146,7 +146,10 @@
 extern AVCodec ff_h264_rkmpp_decoder;
 extern AVCodec ff_hap_encoder;
 extern AVCodec ff_hap_decoder;
+extern AVCodec ff_hevc_bypassvideo_decoder;
+extern AVCodec ff_h264_bypassvideo_decoder;
 extern AVCodec ff_hevc_decoder;
+extern AVCodec ff_libopenhevc_decoder;
 extern AVCodec ff_hevc_qsv_decoder;
 extern AVCodec ff_hevc_rkmpp_decoder;
 extern AVCodec ff_hevc_v4l2m2m_decoder;
@@ -781,6 +784,9 @@
 extern AVCodec ff_hevc_mf_encoder;
 extern AVCodec ff_hevc_nvenc_encoder;
 extern AVCodec ff_hevc_qsv_encoder;
+extern AVCodec ff_libsvt_hevc_encoder;
+extern AVCodec ff_distributed_encoder;
+extern AVCodec ff_hevc_tile_encoder;
 extern AVCodec ff_hevc_v4l2m2m_encoder;
 extern AVCodec ff_hevc_vaapi_encoder;
 extern AVCodec ff_hevc_videotoolbox_encoder;
diff -urN FFmpeg/libavcodec/bypass_decoder.h FFmpeg-patched/libavcodec/bypass_decoder.h
--- FFmpeg/libavcodec/bypass_decoder.h	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavcodec/bypass_decoder.h	2020-09-27 13:35:13.176526567 +0800
@@ -0,0 +1,63 @@
+/*
+ * Raw Video Decoder
+ * Copyright (c) 2001 Fabrice Bellard
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * Raw Video Decoder
+ */
+
+#include "avcodec.h"
+#include "bswapdsp.h"
+#include "get_bits.h"
+#include "raw.h"
+#include "internal.h"
+#include "libavutil/avassert.h"
+#include "libavutil/buffer.h"
+#include "libavutil/common.h"
+#include "libavutil/intreadwrite.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/opt.h"
+
+typedef struct ByPassVideoContext {
+    int frame_size;  /* size of the frame in bytes */
+    int flip;
+    int is_1_2_4_8_bpp; // 1, 2, 4 and 8 bpp in avi/mov, 1 and 8 bpp in nut
+    int is_mono;
+    int is_pal8;
+    int is_nut_mono;
+    int is_nut_pal8;
+    int is_yuv2;
+    int is_lt_16bpp; // 16bpp pixfmt and bits_per_coded_sample < 16
+    int tff;
+    // user options
+    int frameWidth;
+    int frameHeight;
+} ByPassVideoContext;
+
+#define OFFSET(x) offsetof(ByPassVideoContext, x)
+#define VE (AV_OPT_FLAG_DECODING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    {"W", "input bitstream width", OFFSET(frameWidth), AV_OPT_TYPE_INT, {.i64 = 0}, 0, INT_MAX, VE},
+    {"H", "input bitstream height", OFFSET(frameHeight), AV_OPT_TYPE_INT, {.i64 = 0}, 0, INT_MAX, VE},
+    {NULL}
+};
+
+
diff -urN FFmpeg/libavcodec/bypass_h264_decoder.c FFmpeg-patched/libavcodec/bypass_h264_decoder.c
--- FFmpeg/libavcodec/bypass_h264_decoder.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavcodec/bypass_h264_decoder.c	2020-09-27 13:35:13.176526567 +0800
@@ -0,0 +1,150 @@
+/*
+ * Raw Video Decoder
+ * Copyright (c) 2001 Fabrice Bellard
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * Raw Video Decoder
+ */
+
+#include "bypass_decoder.h"
+
+static const AVClass bypassdec_class = {
+    .class_name = "bypassdec",
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static av_cold int h264_bypass_init_decoder(AVCodecContext *avctx)
+{
+    ByPassVideoContext *context = avctx->priv_data;
+    const AVPixFmtDescriptor *desc;
+
+    if (   avctx->codec_tag == MKTAG('r','a','w',' ')
+        || avctx->codec_tag == MKTAG('N','O','1','6'))
+        avctx->pix_fmt = avpriv_find_pix_fmt(avpriv_pix_fmt_bps_mov,
+                                      avctx->bits_per_coded_sample);
+    else if (avctx->codec_tag == MKTAG('W', 'R', 'A', 'W'))
+        avctx->pix_fmt = avpriv_find_pix_fmt(avpriv_pix_fmt_bps_avi,
+                                      avctx->bits_per_coded_sample);
+    else if (avctx->codec_tag && (avctx->codec_tag & 0xFFFFFF) != MKTAG('B','I','T', 0))
+        avctx->pix_fmt = avpriv_find_pix_fmt(ff_raw_pix_fmt_tags, avctx->codec_tag);
+    else if (avctx->pix_fmt == AV_PIX_FMT_NONE && avctx->bits_per_coded_sample)
+        avctx->pix_fmt = avpriv_find_pix_fmt(avpriv_pix_fmt_bps_avi,
+                                      avctx->bits_per_coded_sample);
+
+    return 0;
+}
+
+static int h264_bypass_decode(AVCodecContext *avctx, void *data, int *got_frame,
+                      AVPacket *avpkt)
+{
+    const AVPixFmtDescriptor *desc;
+    ByPassVideoContext *context       = avctx->priv_data;
+    const uint8_t *buf             = avpkt->data;
+    int buf_size                   = avpkt->size;
+    int linesize_align             = 4;
+    int stride;
+    int res, len;
+    int need_copy;
+
+    AVFrame   *frame   = data;
+
+    avctx->width = context->frameWidth;
+    avctx->height = context->frameHeight;
+
+    if (avctx->width <= 0) {
+        av_log(avctx, AV_LOG_ERROR, "width is not set\n");
+        return AVERROR_INVALIDDATA;
+    }
+    if (avctx->height <= 0) {
+        av_log(avctx, AV_LOG_ERROR, "height is not set\n");
+        return AVERROR_INVALIDDATA;
+    }
+
+    if (context->is_nut_mono)
+        stride = avctx->width / 8 + (avctx->width & 7 ? 1 : 0);
+    else if (context->is_nut_pal8)
+        stride = avctx->width;
+    else
+        stride = avpkt->size / avctx->height;
+
+    av_log(avctx, AV_LOG_DEBUG, "PACKET SIZE: %d, STRIDE: %d\n", avpkt->size, stride);
+
+    avctx->pix_fmt = AV_PIX_FMT_YUV420P;
+
+    need_copy = !avpkt->buf || context->is_1_2_4_8_bpp || context->is_yuv2 || context->is_lt_16bpp;
+
+    frame->pict_type        = AV_PICTURE_TYPE_I;
+    frame->key_frame        = 1;
+
+    res = ff_decode_frame_props(avctx, frame);
+    if (res < 0)
+        return res;
+
+    frame->pkt_pos      = avctx->internal->last_pkt_props->pos;
+    frame->pkt_duration = avctx->internal->last_pkt_props->duration;
+
+    if (context->tff >= 0) {
+        frame->interlaced_frame = 1;
+        frame->top_field_first  = context->tff;
+    }
+
+    if ((res = av_image_check_size(avctx->width, avctx->height, 0, avctx)) < 0)
+        return res;
+
+    if (need_copy)
+        frame->buf[0] = av_buffer_alloc(FFMAX(context->frame_size, buf_size));
+    else
+        frame->buf[0] = av_buffer_ref(avpkt->buf);
+    if (!frame->buf[0])
+        return AVERROR(ENOMEM);
+
+    if (need_copy) {
+        memcpy(frame->buf[0]->data, buf, buf_size);
+        buf = frame->buf[0]->data;
+    }
+
+    frame->data[0] = buf;
+    frame->linesize[0] = buf_size;
+
+    *got_frame = 1;
+    return buf_size;
+}
+
+static av_cold int h264_bypass_close_decoder(AVCodecContext *avctx)
+{
+    ByPassVideoContext *context = avctx->priv_data;
+
+    return 0;
+}
+
+AVCodec ff_h264_bypassvideo_decoder = {
+    .name           = "h264bypassdec",
+    .long_name      = NULL_IF_CONFIG_SMALL("bypass video decoder"),
+    .type           = AVMEDIA_TYPE_VIDEO,
+    .id             = AV_CODEC_ID_H264BYPASSVIDEO,
+    .priv_data_size = sizeof(ByPassVideoContext),
+    .init           = h264_bypass_init_decoder,
+    .close          = h264_bypass_close_decoder,
+    .decode         = h264_bypass_decode,
+    .priv_class     = &bypassdec_class,
+    .capabilities   = AV_CODEC_CAP_PARAM_CHANGE,
+};
diff -urN FFmpeg/libavcodec/bypass_hevc_decoder.c FFmpeg-patched/libavcodec/bypass_hevc_decoder.c
--- FFmpeg/libavcodec/bypass_hevc_decoder.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavcodec/bypass_hevc_decoder.c	2020-09-27 13:35:13.176526567 +0800
@@ -0,0 +1,150 @@
+/*
+ * Raw Video Decoder
+ * Copyright (c) 2001 Fabrice Bellard
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * Raw Video Decoder
+ */
+
+#include "bypass_decoder.h"
+
+static const AVClass bypassdec_class = {
+    .class_name = "bypassdec",
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static av_cold int hevc_bypass_init_decoder(AVCodecContext *avctx)
+{
+    ByPassVideoContext *context = avctx->priv_data;
+    const AVPixFmtDescriptor *desc;
+
+    if (   avctx->codec_tag == MKTAG('r','a','w',' ')
+        || avctx->codec_tag == MKTAG('N','O','1','6'))
+        avctx->pix_fmt = avpriv_find_pix_fmt(avpriv_pix_fmt_bps_mov,
+                                      avctx->bits_per_coded_sample);
+    else if (avctx->codec_tag == MKTAG('W', 'R', 'A', 'W'))
+        avctx->pix_fmt = avpriv_find_pix_fmt(avpriv_pix_fmt_bps_avi,
+                                      avctx->bits_per_coded_sample);
+    else if (avctx->codec_tag && (avctx->codec_tag & 0xFFFFFF) != MKTAG('B','I','T', 0))
+        avctx->pix_fmt = avpriv_find_pix_fmt(ff_raw_pix_fmt_tags, avctx->codec_tag);
+    else if (avctx->pix_fmt == AV_PIX_FMT_NONE && avctx->bits_per_coded_sample)
+        avctx->pix_fmt = avpriv_find_pix_fmt(avpriv_pix_fmt_bps_avi,
+                                      avctx->bits_per_coded_sample);
+
+    return 0;
+}
+
+static int hevc_bypass_decode(AVCodecContext *avctx, void *data, int *got_frame,
+                      AVPacket *avpkt)
+{
+    const AVPixFmtDescriptor *desc;
+    ByPassVideoContext *context       = avctx->priv_data;
+    const uint8_t *buf             = avpkt->data;
+    int buf_size                   = avpkt->size;
+    int linesize_align             = 4;
+    int stride;
+    int res, len;
+    int need_copy;
+
+    AVFrame   *frame   = data;
+
+    avctx->width = context->frameWidth;
+    avctx->height = context->frameHeight;
+
+    if (avctx->width <= 0) {
+        av_log(avctx, AV_LOG_ERROR, "width is not set\n");
+        return AVERROR_INVALIDDATA;
+    }
+    if (avctx->height <= 0) {
+        av_log(avctx, AV_LOG_ERROR, "height is not set\n");
+        return AVERROR_INVALIDDATA;
+    }
+
+    if (context->is_nut_mono)
+        stride = avctx->width / 8 + (avctx->width & 7 ? 1 : 0);
+    else if (context->is_nut_pal8)
+        stride = avctx->width;
+    else
+        stride = avpkt->size / avctx->height;
+
+    av_log(avctx, AV_LOG_DEBUG, "PACKET SIZE: %d, STRIDE: %d\n", avpkt->size, stride);
+
+    avctx->pix_fmt = AV_PIX_FMT_YUV420P;
+
+    need_copy = !avpkt->buf || context->is_1_2_4_8_bpp || context->is_yuv2 || context->is_lt_16bpp;
+
+    frame->pict_type        = AV_PICTURE_TYPE_I;
+    frame->key_frame        = 1;
+
+    res = ff_decode_frame_props(avctx, frame);
+    if (res < 0)
+        return res;
+
+    frame->pkt_pos      = avctx->internal->last_pkt_props->pos;
+    frame->pkt_duration = avctx->internal->last_pkt_props->duration;
+
+    if (context->tff >= 0) {
+        frame->interlaced_frame = 1;
+        frame->top_field_first  = context->tff;
+    }
+
+    if ((res = av_image_check_size(avctx->width, avctx->height, 0, avctx)) < 0)
+        return res;
+
+    if (need_copy)
+        frame->buf[0] = av_buffer_alloc(FFMAX(context->frame_size, buf_size));
+    else
+        frame->buf[0] = av_buffer_ref(avpkt->buf);
+    if (!frame->buf[0])
+        return AVERROR(ENOMEM);
+
+    if (need_copy) {
+        memcpy(frame->buf[0]->data, buf, buf_size);
+        buf = frame->buf[0]->data;
+    }
+
+    frame->data[0] = buf;
+    frame->linesize[0] = buf_size;
+
+    *got_frame = 1;
+    return buf_size;
+}
+
+static av_cold int hevc_bypass_close_decoder(AVCodecContext *avctx)
+{
+    ByPassVideoContext *context = avctx->priv_data;
+
+    return 0;
+}
+
+AVCodec ff_hevc_bypassvideo_decoder = {
+    .name           = "hevcbypassdec",
+    .long_name      = NULL_IF_CONFIG_SMALL("bypass video decoder"),
+    .type           = AVMEDIA_TYPE_VIDEO,
+    .id             = AV_CODEC_ID_HEVCBYPASSVIDEO,
+    .priv_data_size = sizeof(ByPassVideoContext),
+    .init           = hevc_bypass_init_decoder,
+    .close          = hevc_bypass_close_decoder,
+    .decode         = hevc_bypass_decode,
+    .priv_class     = &bypassdec_class,
+    .capabilities   = AV_CODEC_CAP_PARAM_CHANGE,
+};
diff -urN FFmpeg/libavcodec/codec_desc.c FFmpeg-patched/libavcodec/codec_desc.c
--- FFmpeg/libavcodec/codec_desc.c	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavcodec/codec_desc.c	2020-09-27 13:35:13.183526566 +0800
@@ -130,6 +130,20 @@
         .props     = AV_CODEC_PROP_INTRA_ONLY | AV_CODEC_PROP_LOSSLESS,
     },
     {
+        .id        = AV_CODEC_ID_HEVCBYPASSVIDEO,
+        .type      = AVMEDIA_TYPE_VIDEO,
+        .name      = "hevcbypassdec",
+        .long_name = NULL_IF_CONFIG_SMALL("hevc bypass video decoder"),
+        .props     = AV_CODEC_PROP_INTRA_ONLY | AV_CODEC_PROP_LOSSLESS,
+    },
+    {
+        .id        = AV_CODEC_ID_H264BYPASSVIDEO,
+        .type      = AVMEDIA_TYPE_VIDEO,
+        .name      = "h264bypassdec",
+        .long_name = NULL_IF_CONFIG_SMALL("h264 bypass video decoder"),
+        .props     = AV_CODEC_PROP_INTRA_ONLY | AV_CODEC_PROP_LOSSLESS,
+    },
+    {
         .id        = AV_CODEC_ID_MSMPEG4V1,
         .type      = AVMEDIA_TYPE_VIDEO,
         .name      = "msmpeg4v1",
diff -urN FFmpeg/libavcodec/codec_id.h FFmpeg-patched/libavcodec/codec_id.h
--- FFmpeg/libavcodec/codec_id.h	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavcodec/codec_id.h	2020-09-27 13:35:13.390526550 +0800
@@ -60,6 +60,8 @@
     AV_CODEC_ID_JPEGLS,
     AV_CODEC_ID_MPEG4,
     AV_CODEC_ID_RAWVIDEO,
+    AV_CODEC_ID_HEVCBYPASSVIDEO,
+    AV_CODEC_ID_H264BYPASSVIDEO,
     AV_CODEC_ID_MSMPEG4V1,
     AV_CODEC_ID_MSMPEG4V2,
     AV_CODEC_ID_MSMPEG4V3,
diff -urN FFmpeg/libavcodec/distributed_encoder.c FFmpeg-patched/libavcodec/distributed_encoder.c
--- FFmpeg/libavcodec/distributed_encoder.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavcodec/distributed_encoder.c	2020-09-27 13:35:13.193526565 +0800
@@ -0,0 +1,712 @@
+/*
+* Scalable Video Technology for distributed encoder library plugin
+*
+* Copyright (c) 2019 Intel Corporation
+*
+* This file is part of FFmpeg.
+*
+* FFmpeg is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* FFmpeg is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+#include <sys/time.h>
+#include <time.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <unistd.h>
+
+#include "DistributedEncoderAPI.h"
+#include "error_code.h"
+#include "common_data.h"
+
+#include "libavutil/common.h"
+#include "libavutil/frame.h"
+#include "libavutil/opt.h"
+
+#include "internal.h"
+#include "avcodec.h"
+
+static bool glog_initialized = false;
+static int min_loglevel = 2;
+
+static void de_log_callback(LogLevel log_level, const char* file_name, uint64_t line_num, const char* fmt, ...)
+{
+    va_list vl;
+    va_start(vl, fmt);
+
+    switch (log_level)
+    {
+        case LOG_INFO:
+        {
+            if(min_loglevel == 0)
+            {
+                av_vlog(NULL, AV_LOG_INFO, fmt, vl);
+            }
+            break;
+        }
+        case LOG_WARNING:
+        {
+            if(min_loglevel <= 1)
+            {
+                av_vlog(NULL, AV_LOG_WARNING, fmt, vl);
+            }
+            break;
+        }
+        case LOG_ERROR:
+        {
+            if(min_loglevel <= 2)
+            {
+                av_vlog(NULL, AV_LOG_ERROR, fmt, vl);
+            }
+            break;
+        }
+        case LOG_FATAL:
+        {
+            if(min_loglevel <= 3)
+            {
+                av_vlog(NULL, AV_LOG_FATAL, fmt, vl);
+            }
+            break;
+        }
+        default:
+        {
+            av_log(NULL, AV_LOG_ERROR, "Invalid log level !");
+            break;
+        }
+    }
+    va_end(vl);
+}
+
+typedef struct DEContext {
+    const AVClass *class;
+
+    DistributedEncoderParam  encode_params;
+    DEHandle                 handle;
+    const char*              configFile;
+    InputStreamType          input_type;
+    int                      inputCodec;
+    bool                     send_end;
+    bool                     eos_flag;
+
+    // User options.
+    int                      vui_info;
+    int                      hierarchical_level;
+    int                      la_depth;
+    int                      enc_mode;
+    int                      rc_mode;
+    int                      scd;
+    int                      tune;
+    int                      qp;
+    int                      hdr;
+    int                      asm_type;
+    int                      forced_idr;
+    int                      aud;
+    int                      profile;
+    int                      tier;
+    int                      level;
+    int                      gop_pred_structure;
+    int                      base_layer_switch_mode;
+    int                      tile_row;
+    int                      tile_column;
+    uint64_t                 frame_number;
+    bool                     in_parallel;
+    bool                     external_log_flag;
+    int                      min_log_level;
+    const char*              proj_type;
+} DEContext;
+
+static int set_enc_params(AVCodecContext *avctx, DistributedEncoderParam *DEparams)
+{
+    DEContext *deCxt = avctx->priv_data;
+
+    memset(DEparams, 0, sizeof(DistributedEncoderParam));
+    EncoderParam params;
+    memset(&params, 0, sizeof(EncoderParam));
+    params.bit_depth = 8;
+    params.format = PixelColor_YUV420;
+    params.vui_info = deCxt->vui_info;
+    params.hierarchical_level = deCxt->hierarchical_level;
+    if(avctx->gop_size > 0) {
+        params.intra_period = avctx->gop_size - 1;
+    }
+    params.la_depth = deCxt->la_depth;
+    params.enc_mode = deCxt->enc_mode;
+    params.rc_mode = deCxt->rc_mode;
+    params.scd = deCxt->scd;
+    params.tune = deCxt->tune;
+    params.qp = deCxt->qp;
+    params.profile = deCxt->profile;
+    params.pred_structure = deCxt->gop_pred_structure;
+    params.base_layer_switch_mode = deCxt->base_layer_switch_mode;
+    params.bit_rate = avctx->bit_rate;
+    params.intra_refresh_type = 1;
+    params.tier = deCxt->tier;
+    params.level = deCxt->level;
+    params.aud = deCxt->aud;
+    params.asm_type = deCxt->asm_type;
+    if(avctx->framerate.num > 0 && avctx->framerate.den > 0) {
+        params.framerate_num = avctx->framerate.num;
+        params.framerate_den = avctx->framerate.den * avctx->ticks_per_frame;
+    }
+    else
+    {
+        params.framerate_num = avctx->time_base.den;
+        params.framerate_den = avctx->time_base.num * avctx->ticks_per_frame;
+    }
+
+    params.deblocking_enable = 0;
+    params.sao_enable = 0;
+    // tile related setting
+    params.tile_columnCnt = deCxt->tile_column;
+    params.tile_rowCnt = deCxt->tile_row;
+    params.target_socket = -1;
+    params.native_mode = false;
+    params.MCTS_enable = (params.tile_columnCnt * params.tile_rowCnt) > 1 ? 1 : 0;
+
+    if(deCxt->in_parallel && params.MCTS_enable)
+        params.in_parallel = true;
+    else
+        params.in_parallel = false;
+
+    memcpy(&(DEparams->encoderParams), &params, sizeof(EncoderParam));
+
+    DEparams->type = ResourceBalanced;
+
+    StreamInfo sInfo;
+    memset(&sInfo, 0, sizeof(StreamInfo));
+    sInfo.frameWidth = avctx->width;
+    sInfo.frameHeight = avctx->height;
+    sInfo.tileUniformSpacing = true;
+    sInfo.tileColumn = deCxt->tile_column;
+    sInfo.tileRow = deCxt->tile_row;
+    if(sInfo.frameWidth % sInfo.tileColumn)
+    {
+        av_log(avctx, AV_LOG_ERROR,
+                "Frame Width can't be divided by tile column number \n");
+        return -1;
+    }
+    if(((sInfo.frameWidth/sInfo.tileColumn)%64) && (sInfo.tileColumn != 1))
+    {
+        av_log(avctx, AV_LOG_ERROR,
+                "Tile width can't be divided by 64 \n");
+        return -1;
+    }
+    if(sInfo.frameHeight % sInfo.tileRow)
+    {
+        av_log(avctx, AV_LOG_ERROR,
+                "Frame Height can't be divided by tile row number \n");
+        return -1;
+    }
+    if(((sInfo.frameHeight/sInfo.tileRow)%64) && (sInfo.tileRow != 1))
+    {
+        av_log(avctx, AV_LOG_ERROR,
+                "Tile height can't be divided by 64 \n");
+        return -1;
+    }
+
+    sInfo.tileOverlapped = 0;
+    sInfo.overlapWidth = 0;
+    sInfo.overlapHeight = 0;
+    sInfo.streamType = deCxt->input_type;
+    memcpy(&(DEparams->streamInfo), &sInfo, sizeof(StreamInfo));
+
+    ProjectionInfo          projInfo;
+    memset(&projInfo, 0, sizeof(ProjectionInfo));
+    projInfo.enable = true;
+    if(0 == strncmp(deCxt->proj_type, "ERP", 3))
+    {
+        projInfo.type = E_EQUIRECT_PROJECTION;
+    }
+    else if (0 == strncmp(deCxt->proj_type, "Cube", 4))
+    {
+        projInfo.type = E_CUBEMAP_PROJECTION;
+    }
+    else if (0 == strncmp(deCxt->proj_type, "Planar", 6))
+    {
+        projInfo.enable = false;
+    }
+    else
+    {
+        av_log(avctx, AV_LOG_ERROR,
+                "Invalid input source projection type %s \n", deCxt->proj_type);
+        return -1;
+    }
+    memcpy(&(DEparams->suppleEnhanceInfo.projInfo), &projInfo, sizeof(ProjectionInfo));
+
+    CodecAppOption codecOption;
+    memset(&codecOption, 0, sizeof(CodecAppOption));
+
+    if(deCxt->input_type == encoded)
+    {
+        if(deCxt->inputCodec == 0) //HEVC
+        {
+            codecOption.decOption.decType = DecoderType_openHEVC;
+            ohOption *oh = (ohOption*)malloc(sizeof(ohOption));
+            if(!oh)
+                return AVERROR(EINVAL);
+            oh->threadCount = 16;
+            oh->threadType = 4;
+            codecOption.decOption.decSetting = (void*)oh;
+        }
+        else if(deCxt->inputCodec == 1) //AVC
+        {
+            codecOption.decOption.decType = DecoderType_ffmpeg;
+            ffmpegOption * fo = (ffmpegOption*)malloc(sizeof(ffmpegOption));
+            if(!fo)
+            {
+                return AVERROR(EINVAL);
+            }
+            fo->codecID = CodecID_H264;
+            codecOption.decOption.decSetting = (void*)fo;
+        }
+        else
+            return AVERROR(EINVAL);
+    }
+
+    if(params.in_parallel)
+        codecOption.encOption.encType = EncoderType_Multiple_SVTHEVC;
+    else
+        codecOption.encOption.encType = EncoderType_SVTHEVC;
+
+    DEparams->glogInitialized = glog_initialized;
+    codecOption.minLogLevel = deCxt->min_log_level;
+    min_loglevel = deCxt->min_log_level;
+    if(deCxt->external_log_flag)
+    {
+        codecOption.logFunction = (void*)(de_log_callback);
+    }
+    else
+    {
+        codecOption.logFunction = NULL;
+    }
+
+    memcpy(&(DEparams->codecOption), &codecOption, sizeof(CodecAppOption));
+
+    return 0;
+}
+
+static av_cold int de_init(AVCodecContext *avctx)
+{
+    DEContext   *deCxt = avctx->priv_data;
+
+    deCxt->eos_flag = false;
+    deCxt->send_end = false;
+    deCxt->frame_number = 0;
+
+    int ret = set_enc_params(avctx, &(deCxt->encode_params));
+    if(ret)
+        return ret;
+
+    ret = DistributedEncoder_ParseConfigFile(deCxt->configFile, &(deCxt->encode_params));
+    if (ret != DE_STATUS_SUCCESS)
+    {
+        return AVERROR(EINVAL);
+    }
+
+    deCxt->handle = DistributedEncoder_Init(&(deCxt->encode_params));
+    if(!deCxt->handle)
+    {
+        return AVERROR(EINVAL);
+    }
+    else
+    {
+        glog_initialized = true;
+    }
+
+    return 0;
+}
+
+static int prepare_input_frame(AVCodecContext *avctx, bool isEncoded, InputFrame** inputFrame, const AVFrame *frame)
+{
+    DEContext  *deCxt = avctx->priv_data;
+    DistributedEncoderParam enc_params = deCxt->encode_params;
+    InputFrame* inFrame = *inputFrame;
+    int data_num = isEncoded ? 1 : 3;
+
+    for(int i = 0; i < data_num; i++)
+    {
+        int factor = i == 0 ? 1 : 2;
+        int copy_size = deCxt->input_type == encoded ? frame->linesize[i] : (frame->linesize[i] * enc_params.streamInfo.frameHeight / factor);
+
+        if(isEncoded)
+        {
+            inFrame->data[i] = (char*)malloc(sizeof(char*) * copy_size);
+            memcpy(inFrame->data[i], frame->data[i], copy_size);
+        }
+        else
+        {
+            inFrame->data[i] = frame->data[i];
+        }
+        inFrame->copysize[i] = copy_size;
+        inFrame->stride[i] = frame->linesize[i];
+    }
+
+    *inputFrame = inFrame;
+    return 0;
+}
+
+static int de_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+{
+    DEContext  *deCxt = avctx->priv_data;
+    DistributedEncoderParam enc_params = deCxt->encode_params;
+
+    if (!frame) {
+        InputFrame* lastFrame = (InputFrame*)malloc(sizeof(InputFrame));
+        if(!lastFrame)
+            return AVERROR(EINVAL);
+        memset(lastFrame, 0, sizeof(InputFrame));
+        lastFrame->data[0] = NULL;
+        lastFrame->stride[0] = 0;
+        lastFrame->width = enc_params.streamInfo.frameWidth;
+        lastFrame->height = enc_params.streamInfo.frameHeight;
+        lastFrame->format = enc_params.encoderParams.format;
+        lastFrame->picType = PictureType_NONE;
+        DistributedEncoder_Process(deCxt->handle, lastFrame);
+        free(lastFrame);
+        deCxt->send_end = true;
+        av_log(avctx, AV_LOG_DEBUG, "Finish sending frames!!!\n");
+        return 0;
+    }
+
+    InputFrame* inFrame = (InputFrame*)malloc(sizeof(InputFrame));
+    if(!inFrame)
+        return AVERROR(EINVAL);
+    memset(inFrame, 0 , sizeof(InputFrame));
+
+    if(deCxt->input_type != encoded && deCxt->input_type != raw)
+    {
+        free(inFrame);
+        return AVERROR(EINVAL);
+    }
+
+    bool isEncoded = (deCxt->input_type == encoded);
+    bool useSharedMem = (deCxt->input_type == raw);
+
+    prepare_input_frame(avctx, isEncoded, &inFrame, frame);
+
+    inFrame->useSharedMem = useSharedMem;
+    inFrame->width = enc_params.streamInfo.frameWidth;
+    inFrame->height =enc_params.streamInfo.frameHeight ;
+    inFrame->format = enc_params.encoderParams.format;
+    switch (frame->pict_type) {
+    case AV_PICTURE_TYPE_I:
+        inFrame->picType = PictureType_I;
+        break;
+    case AV_PICTURE_TYPE_P:
+        inFrame->picType = PictureType_P;
+        break;
+    case AV_PICTURE_TYPE_B:
+        inFrame->picType = PictureType_B;
+        break;
+    default:
+        inFrame->picType = PictureType_NONE;
+        break;
+    }
+    DistributedEncoder_Process(deCxt->handle, inFrame);
+    if(inFrame)
+        free(inFrame);
+    return 0;
+}
+
+static int de_receive_packet(AVCodecContext *avctx, AVPacket *pkt)
+{
+    DEContext  *deCxt = avctx->priv_data;
+    int ret = 0;
+
+    if (deCxt->eos_flag)
+    {
+        av_log(avctx, AV_LOG_ERROR, "EOS reached!!\n");
+        return AVERROR_EOF;
+    }
+
+    char *data = NULL;
+    uint64_t size = 0;
+    int64_t pts = 0, dts = 0;
+    bool eos = false;
+
+    DistributedEncoder_GetPacket(deCxt->handle, &data, &size, &pts, &dts, &eos);
+    if(!data && !size && !eos && !deCxt->send_end)
+    {
+        return AVERROR(EAGAIN);
+        // *got_packet = 0;
+        // return 0;
+    }
+
+    if(!data && !size && deCxt->send_end)
+    {
+        while(!data)
+        {
+            DistributedEncoder_GetPacket(deCxt->handle, &data, &size, &pts, &dts, &eos);
+            usleep(5000);
+        }
+    }
+
+    if ((ret = ff_alloc_packet2(avctx, pkt, size, 0)) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to allocate output packet.\n");
+        free(data);
+        data = NULL;
+        return ret;
+    }
+
+    if(!data && !size)
+    {
+        return AVERROR(EAGAIN);
+    }
+    memcpy(pkt->data, data, size);
+
+    pkt->size = size;
+    pkt->pts  = pts;
+    pkt->dts = dts;
+    int gop = deCxt->encode_params.encoderParams.intra_period + 1;
+    if(pkt->pts % gop == 0)
+    {
+        pkt->flags |= AV_PKT_FLAG_KEY;
+    }
+
+    if (deCxt->frame_number == 0)
+    {
+        Headers* header = (Headers*)malloc(sizeof(Headers));
+        if(!header)
+        {
+             av_log(avctx, AV_LOG_ERROR, "Failed to create header for output .\n");
+             return AVERROR(ENOMEM);
+        }
+
+        ret = DistributedEncoder_GetParam(deCxt->handle, Param_Header, &header);
+
+        if(ret == DE_STATUS_SUCCESS)
+        {
+            pkt->side_data = (AVPacketSideData*)malloc(sizeof(AVPacketSideData));
+            if(!pkt->side_data)
+            {
+                free(header);
+                return AVERROR(EINVAL);
+            }
+            pkt->side_data->size = header->headerSize;
+            pkt->side_data->data = av_malloc(pkt->side_data->size + AV_INPUT_BUFFER_PADDING_SIZE);
+            if (!(pkt->side_data->data))
+            {
+                av_log(avctx, AV_LOG_ERROR,
+                    "Cannot allocate HEVC header of size %d. \n", pkt->side_data->size);
+                free(header);
+                return AVERROR(ENOMEM);
+            }
+            memcpy(pkt->side_data->data, header->headerData, pkt->side_data->size);
+
+            free(header);
+            header = NULL;
+
+            pkt->side_data->type = AV_PKT_DATA_NEW_EXTRADATA;
+            pkt->side_data_elems = 1;
+        }
+        else
+        {
+            av_log(avctx, AV_LOG_ERROR, "Failed to get bitstream header.\n");
+        }
+    }
+
+    //*got_packet = 1;
+
+    deCxt->frame_number++;
+
+    if (eos)
+    {
+        deCxt->eos_flag = true;
+    }
+
+    if(data)
+    {
+        free(data);
+        data = NULL;
+    }
+
+    return 0;
+}
+
+static int de_encode_frame(AVCodecContext *avctx, AVPacket *pkt, const AVFrame *pic, int *got_packet)
+{
+    int ret = 0;
+
+    DEContext   *deCxt = avctx->priv_data;
+    if(deCxt->eos_flag == true)
+    {
+        *got_packet = 0;
+        return 0;
+    }
+
+    ret = de_send_frame(avctx, pic);
+
+    //ret = de_receive_packet(avctx, pkt, got_packet);
+
+    if(!(*got_packet))
+    {
+        usleep(900000);
+    }
+
+    return ret;
+}
+
+static av_cold int de_close(AVCodecContext *avctx)
+{
+    DEContext *deCxt = avctx->priv_data;
+
+    if (deCxt) {
+        if (deCxt->handle) {
+            DistributedEncoder_Destroy(deCxt->handle);
+            deCxt->handle = NULL;
+        }
+        deCxt = NULL;
+    }
+
+    return 0;
+}
+
+#define OFFSET(x) offsetof(DEContext, x)
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+static const AVOption options[] = {
+    { "config_file", "configure file path for workers information", OFFSET(configFile),
+      AV_OPT_TYPE_STRING, { 0 }, 0, 0, VE },
+
+    { "proj_type", "input source projection type, ERP or Cubemap", OFFSET(proj_type),
+      AV_OPT_TYPE_STRING, { .str = "ERP" }, 0, 0, VE },
+
+    { "input_type", "input stream type, 0 - encoded, 1 - raw, default is 0", OFFSET(input_type),
+      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 0xff, VE},
+
+    { "input_codec", "input bitstream type, only work when input type is 0-encoded, 0 - HEVC, 1 - AVC, default is 0", OFFSET(inputCodec),
+      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 0xff, VE},
+
+    { "vui", "Enable vui info", OFFSET(vui_info),
+      AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, VE },
+
+    { "aud", "Include AUD", OFFSET(aud),
+      AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VE },
+
+    { "hielevel", "Hierarchical prediction levels setting", OFFSET(hierarchical_level),
+      AV_OPT_TYPE_INT, { .i64 = 3 }, 0, 3, VE , "hielevel"},
+        { "flat",   NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 0 },  INT_MIN, INT_MAX, VE, "hielevel" },
+        { "2level", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 1 },  INT_MIN, INT_MAX, VE, "hielevel" },
+        { "3level", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 2 },  INT_MIN, INT_MAX, VE, "hielevel" },
+        { "4level", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 3 },  INT_MIN, INT_MAX, VE, "hielevel" },
+
+    { "la_depth", "Look ahead distance [0, 256]", OFFSET(la_depth),
+      AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 256, VE },
+
+    { "preset", "Encoding preset [0, 12] (e,g, for subjective quality tuning mode and >=4k resolution), [0, 10] (for >= 1080p resolution), [0, 9] (for all resolution and modes)",
+      OFFSET(enc_mode), AV_OPT_TYPE_INT, { .i64 = 9 }, 0, 12, VE },
+
+    { "profile", "Profile setting, Main Still Picture Profile not supported", OFFSET(profile),
+      AV_OPT_TYPE_INT, { .i64 = FF_PROFILE_HEVC_MAIN_10 }, FF_PROFILE_HEVC_MAIN, FF_PROFILE_HEVC_REXT, VE, "profile"},
+
+    { "tier", "Set tier (general_tier_flag)", OFFSET(tier),
+      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE, "tier" },
+        { "main", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 0 }, 0, 0, VE, "tier" },
+        { "high", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 1 }, 0, 0, VE, "tier" },
+
+    { "level", "Set level (level_idc)", OFFSET(level),
+      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 0xff, VE, "level" },
+
+    { "rc", "Bit rate control mode", OFFSET(rc_mode),
+      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE , "rc"},
+        { "cqp", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 0 },  INT_MIN, INT_MAX, VE, "rc" },
+        { "vbr", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = 1 },  INT_MIN, INT_MAX, VE, "rc" },
+
+    { "qp", "QP value for intra frames", OFFSET(qp),
+      AV_OPT_TYPE_INT, { .i64 = 32 }, 0, 51, VE },
+
+    { "sc_detection", "Scene change detection", OFFSET(scd),
+      AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VE },
+
+    { "tune", "Quality tuning mode", OFFSET(tune), AV_OPT_TYPE_INT, { .i64 = 1 }, 0, 2, VE, "tune" },
+        { "sq", "Visually optimized mode", 0,
+          AV_OPT_TYPE_CONST, { .i64 = 0 },  INT_MIN, INT_MAX, VE, "tune" },
+        { "oq",  "PSNR / SSIM optimized mode",  0,
+          AV_OPT_TYPE_CONST, { .i64 = 1 },  INT_MIN, INT_MAX, VE, "tune" },
+        { "vmaf", "VMAF optimized mode", 0,
+          AV_OPT_TYPE_CONST, { .i64 = 2 },  INT_MIN, INT_MAX, VE, "tune" },
+
+    { "pred_struct", "Prediction structure used to construct GOP", OFFSET(gop_pred_structure),
+      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 2, VE, "pred_struct" },
+        { "IPPP", "P is low delay P", 0, AV_OPT_TYPE_CONST, { .i64 = 0 }, INT_MIN, INT_MAX, VE, "pred_struct" },
+        { "Ibbb", "b is low delay B", 1, AV_OPT_TYPE_CONST, { .i64 = 1 }, INT_MIN, INT_MAX, VE, "pred_struct" },
+        { "IBBB", "B is normal bi-directional B", 2, AV_OPT_TYPE_CONST, { .i64 = 2 }, INT_MIN, INT_MAX, VE, "pred_struct" },
+
+    { "bl_mode", "Random Access Prediction Structure type setting", OFFSET(base_layer_switch_mode),
+      AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VE },
+
+    { "forced-idr", "If forcing keyframes, force them as IDR frames.", OFFSET(forced_idr),
+      AV_OPT_TYPE_BOOL,   { .i64 = 0 }, -1, 1, VE },
+
+    { "hdr", "High dynamic range input", OFFSET(hdr),
+      AV_OPT_TYPE_BOOL,   { .i64 = 0 }, 0, 1, VE },
+
+    { "asm_type", "Assembly instruction set type [0: C Only, 1: Auto]", OFFSET(asm_type),
+      AV_OPT_TYPE_BOOL,   { .i64 = 1 }, 0, 1, VE },
+
+    { "tile_column", "Tile column count number, default is 1", OFFSET(tile_column),
+      AV_OPT_TYPE_INT, { .i64 = 1 }, 0, 256, VE },
+
+    { "tile_row", "Tile row count number, default is 1", OFFSET(tile_row),
+      AV_OPT_TYPE_INT, { .i64 = 1 }, 0, 256, VE },
+
+    { "in_parallel", "Multiple encoders running in parallel [0: Off, 1: On]", OFFSET(in_parallel),
+      AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VE },
+
+    { "external_log_flag", "whether external log callback is needed", OFFSET(external_log_flag),
+      AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VE },
+
+    { "min_log_level", "Minimal log level of output [0: INFO, 1: WARNING, 2: ERROR, 3: FATAL]", OFFSET(min_log_level),
+      AV_OPT_TYPE_INT, { .i64 = 2 }, 0, 3, VE },
+
+    {NULL},
+};
+
+static const AVClass class = {
+    .class_name = "distributed_encoder",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVCodecDefault de_defaults[] = {
+    { "b",         "7M"    },
+    { "flags",     "+cgop" },
+    { "qmin",      "10"    },
+    { "qmax",      "48"    },
+    { "g",         "-2"    },
+    { NULL },
+};
+
+AVCodec ff_distributed_encoder = {
+    .name           = "distributed_encoder",
+    .long_name      = NULL_IF_CONFIG_SMALL("distributed HEVC encoder"),
+    .priv_data_size = sizeof(DEContext),
+    .type           = AVMEDIA_TYPE_VIDEO,
+    .id             = AV_CODEC_ID_HEVC,
+    .init           = de_init,
+    .send_frame     = de_send_frame,
+    .receive_packet = de_receive_packet,
+    .close          = de_close,
+    .capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AUTO_THREADS,
+    .pix_fmts       = (const enum AVPixelFormat[]){ AV_PIX_FMT_YUV420P,
+                                                    AV_PIX_FMT_YUV420P10,
+                                                    AV_PIX_FMT_YUV422P,
+                                                    AV_PIX_FMT_YUV420P10,
+                                                    AV_PIX_FMT_YUV444P,
+                                                    AV_PIX_FMT_YUV444P10,
+                                                    AV_PIX_FMT_NONE },
+    .priv_class     = &class,
+    .defaults       = de_defaults,
+    .caps_internal  = FF_CODEC_CAP_INIT_CLEANUP,
+    .wrapper_name   = "distributed_encoder",
+};
diff -urN FFmpeg/libavcodec/encode.c FFmpeg-patched/libavcodec/encode.c
--- FFmpeg/libavcodec/encode.c	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavcodec/encode.c	2020-09-27 13:35:13.203526565 +0800
@@ -430,12 +430,13 @@
         int ret;
         if (avctx->internal->draining && !(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))
             return AVERROR_EOF;
-        ret = avctx->codec->receive_packet(avctx, avpkt);
-        if (!ret)
-            // Encoders must always return ref-counted buffers.
-            // Side-data only packets have no data and can be not ref-counted.
-            av_assert0(!avpkt->data || avpkt->buf);
-        return ret;
+        // ret = avctx->codec->receive_packet(avctx, avpkt);
+        // if (!ret)
+        //     // Encoders must always return ref-counted buffers.
+        //     // Side-data only packets have no data and can be not ref-counted.
+        //     av_assert0(!avpkt->data || avpkt->buf);
+        // return ret;
+        return ret = avctx->codec->receive_packet(avctx, avpkt);
     }

     // Emulation via old API.
diff -urN FFmpeg/libavcodec/h264_parser.c FFmpeg-patched/libavcodec/h264_parser.c
--- FFmpeg/libavcodec/h264_parser.c	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavcodec/h264_parser.c	2020-09-27 13:35:13.224526563 +0800
@@ -703,7 +703,7 @@
 }
 
 AVCodecParser ff_h264_parser = {
-    .codec_ids      = { AV_CODEC_ID_H264 },
+    .codec_ids      = { AV_CODEC_ID_H264, AV_CODEC_ID_H264BYPASSVIDEO },
     .priv_data_size = sizeof(H264ParseContext),
     .parser_init    = init,
     .parser_parse   = h264_parse,
diff -urN FFmpeg/libavcodec/hevc_parser.c FFmpeg-patched/libavcodec/hevc_parser.c
--- FFmpeg/libavcodec/hevc_parser.c	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavcodec/hevc_parser.c	2020-09-27 13:35:13.232526562 +0800
@@ -381,7 +381,7 @@
 }
 
 AVCodecParser ff_hevc_parser = {
-    .codec_ids      = { AV_CODEC_ID_HEVC },
+    .codec_ids      = { AV_CODEC_ID_HEVC , AV_CODEC_ID_HEVCBYPASSVIDEO},
     .priv_data_size = sizeof(HEVCParserContext),
     .parser_parse   = hevc_parse,
     .parser_close   = hevc_parser_close,
diff -urN FFmpeg/libavcodec/libopenhevc.c FFmpeg-patched/libavcodec/libopenhevc.c
--- FFmpeg/libavcodec/libopenhevc.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavcodec/libopenhevc.c	2020-09-27 13:35:13.433526546 +0800
@@ -0,0 +1,178 @@
+/*
+ * OpenHEVC video Decoder
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <libopenhevc/openhevc.h>
+#include "avcodec.h"
+#include "internal.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/opt.h"
+#include "libavutil/common.h"
+#include "libavutil/internal.h"
+
+//#define DEBUG
+typedef struct OpenHevcContext{
+	const AVClass *class;
+	OHHandle handle;
+#ifdef DEBUG
+	FILE *fout;
+#endif
+	int thread_count;
+	int thread_type;
+	int temporal_layer_id;
+	int quality_layer_id;
+}OpenHevcContext;
+static av_cold int openhevc_close(AVCodecContext *ctx)
+{
+	OpenHevcContext *c = ctx->priv_data;
+	if(c->handle){
+		oh_close(c->handle);
+		c->handle = NULL;
+	}
+#ifdef DEBUG
+	if(c->fout){
+		fclose(c->fout);
+	}
+#endif
+	return 0;
+}
+static av_cold int openhevc_init(AVCodecContext *ctx)
+{
+	OpenHevcContext *c = ctx->priv_data;
+	c->handle = oh_init(c->thread_count, c->thread_type);
+	if(!c->handle){
+		av_log(ctx,AV_LOG_ERROR,"oh_init failed\n");
+		return AVERROR_EXTERNAL;
+	}
+	size_t extra_size_alloc;
+	extra_size_alloc = ctx->extradata_size > 0 ? (ctx->extradata_size +AV_INPUT_BUFFER_PADDING_SIZE) : 0;
+	if(extra_size_alloc){
+		oh_extradata_cpy(c->handle, ctx->extradata, extra_size_alloc);
+	}
+	oh_disable_cropping(c->handle, !!(ctx->flags2 & AV_CODEC_FLAG2_IGNORE_CROP));
+	oh_start(c->handle);
+	oh_select_temporal_layer(c->handle,c->temporal_layer_id);
+	oh_select_active_layer(c->handle,c->quality_layer_id);
+	oh_select_view_layer(c->handle,c->quality_layer_id);
+#ifdef DEBUG
+	c->fout = fopen("output.yuv","wb");
+	if(!c->fout){
+		printf("open file failed !\n");
+		return -1;
+	}
+#endif
+	return 0;
+}
+
+static int openhevc_decode(AVCodecContext *ctx, void *data, int *got_frame, AVPacket *avpkt)
+{
+	OpenHevcContext *c = ctx->priv_data;
+	AVFrame *picture = data;
+	int ret;
+	OHFrame openHevcFrame;
+
+	ret = oh_decode(c->handle, avpkt->data, avpkt->size, avpkt->pts);
+	if(ret<0){
+		av_log(ctx, AV_LOG_ERROR, "failed to decode frame\n");
+		return AVERROR_EXTERNAL;
+	}
+	if(ret){
+		uint8_t *data_ptr_array[4] = {NULL};
+		int stride_array[4] = {0};
+
+		oh_output_update(c->handle, 1, &openHevcFrame);
+		oh_frameinfo_update(c->handle, &openHevcFrame.frame_par);
+
+		if(av_image_check_size(openHevcFrame.frame_par.width, openHevcFrame.frame_par.height, 0, ctx))
+			return AVERROR_INVALIDDATA;
+		ctx->pix_fmt = AV_PIX_FMT_YUV420P;
+		ff_set_dimensions(ctx, openHevcFrame.frame_par.width, openHevcFrame.frame_par.height);
+
+		if((ret=ff_get_buffer(ctx, picture, 0))<0)
+			return ret;
+		picture->sample_aspect_ratio.num = openHevcFrame.frame_par.sample_aspect_ratio.num;
+		picture->sample_aspect_ratio.den = openHevcFrame.frame_par.sample_aspect_ratio.den;
+
+		data_ptr_array[0] = (uint8_t *)openHevcFrame.data_y_p;
+		data_ptr_array[1] = (uint8_t *)openHevcFrame.data_cb_p;
+		data_ptr_array[2] = (uint8_t *)openHevcFrame.data_cr_p;
+
+		stride_array[0] = openHevcFrame.frame_par.linesize_y;
+		stride_array[1] = openHevcFrame.frame_par.linesize_cb;
+		stride_array[2] = openHevcFrame.frame_par.linesize_cr;
+#ifdef DEBUG
+		if (c->fout) {
+		    int format = openHevcFrame.frame_par.chromat_format == OH_YUV420 ? 1 : 0;
+                    fwrite( (uint8_t *)openHevcFrame.data_y_p ,  sizeof(uint8_t) , openHevcFrame.frame_par.linesize_y  * openHevcFrame.frame_par.height,  c->fout);
+                    fwrite( (uint8_t *)openHevcFrame.data_cb_p , sizeof(uint8_t) , openHevcFrame.frame_par.linesize_cb * openHevcFrame.frame_par.height >> format, c->fout);
+                    fwrite( (uint8_t *)openHevcFrame.data_cr_p , sizeof(uint8_t) , openHevcFrame.frame_par.linesize_cr * openHevcFrame.frame_par.height >> format, c->fout);
+                                }
+#endif
+//		av_image_copy(picture->data, picture->linesize, (uint8_t **)data_ptr_array, stride_array, ctx->pix_fmt, picture->width, picture->height);
+		picture->data[0] = data_ptr_array[0];
+		picture->data[1] = data_ptr_array[1];
+		picture->data[2] = data_ptr_array[2];
+		picture->linesize[0] = stride_array[0];
+		picture->linesize[1] = stride_array[1];
+		picture->linesize[2] = stride_array[2];
+		picture->format = ctx->pix_fmt;
+
+		picture->pts = avpkt->pts;
+	        picture->pkt_dts = avpkt->dts;
+		picture->pkt_duration = avpkt->duration;
+
+		*got_frame = 1;
+	}
+	return avpkt->size;
+
+}
+static void openhevc_flush(AVCodecContext *avctx)
+{
+	OpenHevcContext *c = avctx->priv_data;
+	oh_flush(c->handle);
+}
+#define OFFSET(x) offsetof(OpenHevcContext, x)
+#define VE (AV_OPT_FLAG_DECODING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+	{"thread_count", "for how many threads to be executed, 1 is for default", OFFSET(thread_count), AV_OPT_TYPE_INT, {.i64 = 1}, 0, INT_MAX, VE},
+	{"thread_type", "which multithreads methods to use, 1 is for default", OFFSET(thread_type), AV_OPT_TYPE_INT, {.i64 = 1}, 0, INT_MAX, VE},
+	{"temporal_layer_id","temporal layer id,7 is for default",OFFSET(temporal_layer_id),AV_OPT_TYPE_INT,{.i64 = 7}, 0 , INT_MAX, VE},
+	{"quality_layer_id","quality layer id,0 is for default",OFFSET(quality_layer_id),AV_OPT_TYPE_INT,{.i64 = 0}, 0 , INT_MAX, VE},
+	{NULL},
+};
+static const AVClass openhevc_class = {
+	.class_name = "libopenhevc",
+	.item_name = av_default_item_name,
+	.option = options,
+	.version = LIBAVUTIL_VERSION_INT,
+};
+AVCodec ff_libopenhevc_decoder = {
+	.name = "libopenhevc",
+	.long_name = NULL_IF_CONFIG_SMALL("libopenhevc HEVC decoder"),
+	.type = AVMEDIA_TYPE_VIDEO,
+	.id = AV_CODEC_ID_HEVC,
+	.priv_data_size = sizeof(OpenHevcContext),
+	.priv_class = &openhevc_class,
+	.init = openhevc_init,
+	.flush = openhevc_flush,
+	.close = openhevc_close,
+	.decode = openhevc_decode,
+	.capabilities = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_DR1,
+	.caps_internal = FF_CODEC_CAP_SETS_PKT_DTS | FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP,
+};
diff -urN FFmpeg/libavcodec/libsvt_hevc.c FFmpeg-patched/libavcodec/libsvt_hevc.c
--- FFmpeg/libavcodec/libsvt_hevc.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavcodec/libsvt_hevc.c	2020-09-27 13:35:13.262526560 +0800
@@ -0,0 +1,341 @@
+/*
+* Scalable Video Technology for HEVC encoder library plugin
+*
+* Copyright (c) 2018 Intel Corporation
+*
+* This program is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with this program; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+
+
+#include "EbErrorCodes.h"
+#include "EbTime.h"
+#include "EbApi.h"
+
+#include "libavutil/common.h"
+#include "libavutil/frame.h"
+#include "libavutil/opt.h"
+
+#include "internal.h"
+#include "avcodec.h"
+
+typedef struct SvtEncoder {
+    EB_H265_ENC_CONFIGURATION           enc_params;
+    EB_COMPONENTTYPE                    *svt_handle;
+    EB_BUFFERHEADERTYPE                 *in_buf;
+    EB_BUFFERHEADERTYPE                 *out_buf;
+    int                                  raw_size;
+} SvtEncoder;
+
+typedef struct SvtParams {
+    int vui_info;
+    int hierarchical_level;
+    int intra_period;
+    int la_depth;
+    int intra_ref_type;
+    int enc_mode;
+    int rc_mode;
+    int scd;
+    int tune;
+	int qp;
+    int profile;
+    int base_layer_switch_mode;
+}SvtParams;
+
+typedef struct SvtContext {
+    AVClass     *class;
+    SvtEncoder  *svt_enc;
+    SvtParams   svt_param;
+    int         eos_flag;
+} SvtContext;
+
+static void free_buffer(SvtEncoder *svt_enc)
+{
+    if (svt_enc->in_buf) {
+        EB_H265_ENC_INPUT *in_data = (EB_H265_ENC_INPUT* )svt_enc->in_buf->pBuffer;
+        if (in_data) {
+            av_freep(&in_data);
+        }
+        av_freep(&svt_enc->in_buf);
+    }
+    av_freep(&svt_enc->out_buf);
+}
+
+static EB_ERRORTYPE alloc_buffer(EB_H265_ENC_CONFIGURATION *config, SvtEncoder *svt_enc)
+{
+    EB_ERRORTYPE       ret       = EB_ErrorNone;
+
+    const int    pack_mode_10bit   = (config->encoderBitDepth > 8) && (config->compressedTenBitFormat == 0) ? 1 : 0;
+    const size_t luma_size_8bit    = config->sourceWidth * config->sourceHeight * (1 << pack_mode_10bit);
+    const size_t luma_size_10bit   = (config->encoderBitDepth > 8 && pack_mode_10bit == 0) ? luma_size_8bit : 0;
+
+    svt_enc->raw_size = (luma_size_8bit + luma_size_10bit) * 3 / 2;
+
+    // allocate buffer for in and out
+    svt_enc->in_buf           = av_mallocz(sizeof(EB_BUFFERHEADERTYPE));
+    svt_enc->out_buf          = av_mallocz(sizeof(EB_BUFFERHEADERTYPE));
+    if (!svt_enc->in_buf || !svt_enc->out_buf)
+        goto failed;
+
+    svt_enc->in_buf->pBuffer  = av_mallocz(sizeof(EB_H265_ENC_INPUT));
+    if (!svt_enc->in_buf->pBuffer)
+        goto failed;
+
+    svt_enc->in_buf->nSize        = sizeof(EB_BUFFERHEADERTYPE);
+    svt_enc->in_buf->pAppPrivate  = NULL;
+    svt_enc->out_buf->nSize       = sizeof(EB_BUFFERHEADERTYPE);
+    svt_enc->out_buf->nAllocLen   = svt_enc->raw_size;
+    svt_enc->out_buf->pAppPrivate = NULL;
+
+    return ret;
+
+failed:
+    free_buffer(svt_enc);
+    return AVERROR(ENOMEM);
+}
+
+static int error_mapping(int val)
+{
+    if (val == EB_ErrorInsufficientResources)
+        return AVERROR(ENOMEM);
+    if ((val == EB_ErrorUndefined) || (val == EB_ErrorInvalidComponent) ||
+        (val == EB_ErrorBadParameter))
+        return AVERROR(EINVAL);
+    return AVERROR_EXTERNAL;
+}
+
+static EB_ERRORTYPE config_enc_params(EB_H265_ENC_CONFIGURATION  *param, AVCodecContext *avctx)
+{
+    SvtContext *q       = avctx->priv_data;
+    SvtEncoder *svt_enc = q->svt_enc;
+    EB_ERRORTYPE    ret = EB_ErrorNone;
+    int         tenBits = 0;
+
+    param->sourceWidth     = avctx->width;
+    param->sourceHeight    = avctx->height;
+
+    if (avctx->pix_fmt == AV_PIX_FMT_YUV420P10LE) {
+        av_log(avctx, AV_LOG_DEBUG , "Encoder 10 bits depth input\n");
+        param->compressedTenBitFormat = 0;
+        tenBits = 1;
+    }
+
+    // Update param from options
+    param->hierarchicalLevels     = q->svt_param.hierarchical_level;
+    param->encMode                = q->svt_param.enc_mode;
+    param->intraRefreshType       = q->svt_param.intra_ref_type;
+    param->profile                = q->svt_param.profile;
+    param->rateControlMode        = q->svt_param.rc_mode;
+    param->sceneChangeDetection   = q->svt_param.scd;
+    param->tune                   = q->svt_param.tune;
+    param->baseLayerSwitchMode    = q->svt_param.base_layer_switch_mode;
+	param->qp                     = q->svt_param.qp;
+	param->intraPeriodLength      = q->svt_param.intra_period;
+
+    param->targetBitRate          = avctx->bit_rate;
+    param->frameRateNumerator     = avctx->time_base.den;
+    param->frameRateDenominator   = avctx->time_base.num * avctx->ticks_per_frame;
+
+    if (q->svt_param.vui_info)
+        param->videoUsabilityInfo = q->svt_param.vui_info;
+    if (q->svt_param.la_depth != -1)
+        param->lookAheadDistance  = q->svt_param.la_depth;
+
+    if (tenBits == 1) {
+        param->encoderBitDepth        = 10;
+        param->profile                = 2;
+    }
+
+    ret = alloc_buffer(param, svt_enc);
+
+    return ret;
+}
+
+static void read_in_data(EB_H265_ENC_CONFIGURATION *config, const AVFrame* frame, EB_BUFFERHEADERTYPE *headerPtr)
+{
+
+    unsigned int is16bit = config->encoderBitDepth > 8;
+    unsigned long long lumaReadSize = (unsigned long long)config->sourceWidth * config->sourceHeight<< is16bit;
+    EB_H265_ENC_INPUT *in_data = (EB_H265_ENC_INPUT*)headerPtr->pBuffer;
+
+    // support yuv420p and yuv420p010
+    in_data->luma = frame->data[0];
+    in_data->cb   = frame->data[1];
+    in_data->cr   = frame->data[2];
+	
+	// stride info
+	in_data->yStride  = frame->linesize[0] >> is16bit;
+	in_data->cbStride = frame->linesize[1] >> is16bit;
+	in_data->crStride = frame->linesize[2] >> is16bit;
+
+    headerPtr->nFilledLen   += lumaReadSize * 3/2u;
+}
+
+static av_cold int eb_enc_init(AVCodecContext *avctx)
+{
+    SvtContext   *q = avctx->priv_data;
+    SvtEncoder   *svt_enc = NULL;
+    EB_ERRORTYPE ret = EB_ErrorNone;
+
+    q->svt_enc  = av_mallocz(sizeof(*q->svt_enc));
+    if (!q->svt_enc)
+        return AVERROR(ENOMEM);
+    svt_enc = q->svt_enc;
+
+    q->eos_flag = 0;
+
+    ret = EbInitHandle(&svt_enc->svt_handle, q, &svt_enc->enc_params);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    ret = config_enc_params(&svt_enc->enc_params, avctx);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    ret = EbH265EncSetParameter(svt_enc->svt_handle, &svt_enc->enc_params);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    ret = EbInitEncoder(svt_enc->svt_handle);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+    return ret;
+
+failed_init:
+    return error_mapping(ret);
+}
+
+static int eb_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+{
+    SvtContext           *q = avctx->priv_data;
+    SvtEncoder           *svt_enc = q->svt_enc;
+    EB_BUFFERHEADERTYPE  *headerPtr = svt_enc->in_buf;
+    int                  ret = 0;
+
+    if (!frame) {
+        EB_BUFFERHEADERTYPE headerPtrLast;
+        headerPtrLast.nAllocLen = 0;
+        headerPtrLast.nFilledLen = 0;
+        headerPtrLast.nTickCount = 0;
+        headerPtrLast.pAppPrivate = NULL;
+        //headerPtrLast.nOffset = 0;
+        //headerPtrLast.nTimeStamp = 0;
+        headerPtrLast.nFlags = EB_BUFFERFLAG_EOS;
+        headerPtrLast.pBuffer = NULL;
+        EbH265EncSendPicture(svt_enc->svt_handle, &headerPtrLast);
+        q->eos_flag = 1;
+        av_log(avctx, AV_LOG_DEBUG, "Finish sending frames!!!\n");
+        return ret;
+    }
+
+    read_in_data(&svt_enc->enc_params, frame, headerPtr);
+
+    //headerPtr->nOffset    = 0;
+    headerPtr->nFlags     = 0;
+    //headerPtr->nFlags     = 0;
+    //headerPtr->nTimeStamp = 0;
+    headerPtr->pAppPrivate = NULL;
+    headerPtr->pts         = frame->pts;
+    EbH265EncSendPicture(svt_enc->svt_handle, headerPtr);
+
+    return ret;
+}
+
+static int eb_receive_packet(AVCodecContext *avctx, AVPacket *pkt)
+{
+    SvtContext  *q = avctx->priv_data;
+    SvtEncoder  *svt_enc = q->svt_enc;
+    EB_BUFFERHEADERTYPE   *headerPtr = svt_enc->out_buf;
+    EB_ERRORTYPE          stream_status = EB_ErrorNone;
+    int ret = 0;
+
+    if ((ret = ff_alloc_packet2(avctx, pkt, svt_enc->raw_size, 0)) < 0)
+        return ret;
+    headerPtr->pBuffer = pkt->data;
+    stream_status = EbH265GetPacket(svt_enc->svt_handle, headerPtr, q->eos_flag);
+    if ((stream_status == EB_NoErrorEmptyQueue))
+        return AVERROR(EAGAIN);
+
+    pkt->size = headerPtr->nFilledLen;
+    ret = (headerPtr->nFlags & EB_BUFFERFLAG_EOS) ? AVERROR_EOF : 0;
+    return ret;
+}
+
+static av_cold int eb_enc_close(AVCodecContext *avctx)
+{
+    SvtContext *q = avctx->priv_data;
+    SvtEncoder   *svt_enc = q->svt_enc;
+
+    EbDeinitEncoder(svt_enc->svt_handle);
+    EbDeinitHandle(svt_enc->svt_handle);
+
+    free_buffer(svt_enc);
+    av_freep(&svt_enc);
+
+    return 0;
+}
+
+#define OFFSET(x) offsetof(SvtContext, x)
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+static const AVOption options[] = {
+    {"vui", "Enable vui info", OFFSET(svt_param.vui_info), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },
+    {"hielevel", "Hierarchical Prediction Levels [0,3]", OFFSET(svt_param.hierarchical_level), AV_OPT_TYPE_INT, { .i64 = 3 }, 0, 3, VE },
+    {"la_depth", "Look Ahead Distance [0,256]", OFFSET(svt_param.la_depth), AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 256, VE },
+    {"intra_ref_type", "Intra Refresh Type 0: No intra refresh1: CRA (Open GOP) 2: IDR", OFFSET(svt_param.intra_ref_type), AV_OPT_TYPE_INT, { .i64 = 1 }, 1, 2, VE },
+    {"enc_p", "Encoding preset [0,12] (for tune 0 and >=4k resolution), [0,10] (for >= 1080p resolution), [0,9] (for all resolution and modes)", OFFSET(svt_param.enc_mode), AV_OPT_TYPE_INT, { .i64 = 9 }, 0, 12, VE },
+    {"profile", "Profile now support[1,2],Main Still Picture Profile not supported", OFFSET(svt_param.profile), AV_OPT_TYPE_INT, { .i64 = 2 }, 1, 2, VE },
+    {"rc", "RC mode 0: CQP 1: VBR", OFFSET(svt_param.rc_mode), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },
+	{"q", "QP value for intra frames", OFFSET(svt_param.qp), AV_OPT_TYPE_INT, { .i64 = 32 }, 0, 51, VE },
+	{"ip", "distance between intra frames", OFFSET(svt_param.intra_period), AV_OPT_TYPE_INT, { .i64 = -2 }, -2, 255, VE },
+    {"scd", "scene change detection", OFFSET(svt_param.scd), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },
+    {"tune", "tune mode: SQ/OQ[0,1]", OFFSET(svt_param.tune), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },
+    {"bl_mode", "Random Access Prediction Structure Type", OFFSET(svt_param.base_layer_switch_mode), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE },
+    {NULL},
+};
+
+static const AVClass class = {
+    .class_name = "hevc_svt encoder",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVCodecDefault eb_enc_defaults[] = {
+    { "b",         "7M"    },
+    { "refs",      "0"     },
+    { "g",         "90"   },
+    { "flags",     "+cgop" },
+    { NULL },
+};
+
+AVCodec ff_hevc_svt_encoder = {
+    .name           = "libsvt_hevc",
+    .long_name      = NULL_IF_CONFIG_SMALL("SVT-HEVC(Scalable Video Technology for HEVC) encoder"),
+    .priv_data_size = sizeof(SvtContext),
+    .type           = AVMEDIA_TYPE_VIDEO,
+    .id             = AV_CODEC_ID_HEVC,
+    .init           = eb_enc_init,
+    .send_frame     = eb_send_frame,
+    .receive_packet = eb_receive_packet,
+    .close          = eb_enc_close,
+    .capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AUTO_THREADS,
+    .pix_fmts       = (const enum AVPixelFormat[]){ AV_PIX_FMT_YUV420P,
+                                                    AV_PIX_FMT_YUV420P10,
+                                                    AV_PIX_FMT_NONE },
+    .priv_class     = &class,
+    .defaults       = eb_enc_defaults,
+    .caps_internal  = FF_CODEC_CAP_INIT_CLEANUP,
+    .wrapper_name   = "libsvt_hevc",
+};
+
diff -urN FFmpeg/libavcodec/Makefile FFmpeg-patched/libavcodec/Makefile
--- FFmpeg/libavcodec/Makefile	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavcodec/Makefile	2020-09-27 13:35:13.080526574 +0800
@@ -96,6 +96,7 @@
 OBJS-$(CONFIG_H264PRED)                += h264pred.o
 OBJS-$(CONFIG_H264QPEL)                += h264qpel.o
 OBJS-$(CONFIG_HEVCPARSE)               += hevc_parse.o h2645_parse.o hevc_ps.o hevc_sei.o hevc_data.o
+OBJS-$(CONFIG_LIBOPENHEVC_DECODER)	   += libopenhevc.o
 OBJS-$(CONFIG_HPELDSP)                 += hpeldsp.o
 OBJS-$(CONFIG_HUFFMAN)                 += huffman.o
 OBJS-$(CONFIG_HUFFYUVDSP)              += huffyuvdsp.o
@@ -387,6 +388,10 @@
 OBJS-$(CONFIG_HEVC_MF_ENCODER)         += mfenc.o mf_utils.o
 OBJS-$(CONFIG_HEVC_NVENC_ENCODER)      += nvenc_hevc.o
 OBJS-$(CONFIG_NVENC_HEVC_ENCODER)      += nvenc_hevc.o
+OBJS-$(CONFIG_LIBSVT_HEVC_ENCODER)     += libsvt_hevc.o
+OBJS-$(CONFIG_DISTRIBUTED_ENCODER)     += distributed_encoder.o
+OBJS-$(CONFIG_HEVC_TILE_ENCODER)       += tile_encoder.o \
+                                          tile_encode_svt_impl.o
 OBJS-$(CONFIG_HEVC_QSV_DECODER)        += qsvdec_h2645.o
 OBJS-$(CONFIG_HEVC_QSV_ENCODER)        += qsvenc_hevc.o hevc_ps_enc.o       \
                                           hevc_data.o
@@ -568,6 +573,8 @@
 OBJS-$(CONFIG_RA_288_DECODER)          += ra288.o celp_filters.o
 OBJS-$(CONFIG_RALF_DECODER)            += ralf.o
 OBJS-$(CONFIG_RASC_DECODER)            += rasc.o
+OBJS-$(CONFIG_HEVC_BYPASSVIDEO_DECODER) += bypass_hevc_decoder.o
+OBJS-$(CONFIG_H264_BYPASSVIDEO_DECODER) += bypass_h264_decoder.o
 OBJS-$(CONFIG_RAWVIDEO_DECODER)        += rawdec.o
 OBJS-$(CONFIG_RAWVIDEO_ENCODER)        += rawenc.o
 OBJS-$(CONFIG_REALTEXT_DECODER)        += realtextdec.o ass.o
diff -urN FFmpeg/libavcodec/tile_encoder.c FFmpeg-patched/libavcodec/tile_encoder.c
--- FFmpeg/libavcodec/tile_encoder.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavcodec/tile_encoder.c	2020-09-27 13:35:13.371526551 +0800
@@ -0,0 +1,586 @@
+/*
+ * Intel tile encoder
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <stdint.h>
+#include <string.h>
+
+#include "libavutil/attributes.h"
+#include "libavutil/avassert.h"
+#include "libavutil/dict.h"
+#include "libavutil/error.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/internal.h"
+#include "libavutil/log.h"
+#include "libavutil/mem.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/opt.h"
+
+#include "tile_encoder.h"
+
+//pthread_mutex_t mutex;
+//pthread_cond_t cond;
+
+typedef struct TileEncoderContext {
+    const AVClass *class;
+    EncoderWrapper api;
+    enum ENC_LIB   enc_lib;
+    enum TILE_MODE tile_mode;
+
+    //for average size tile, the input just give the layout, such as 3x3, 4x4
+    int            tiles_gw;
+    int            tiles_gh;
+
+    //for fix size tile, the last one of colum or row is not the fixed value
+    int            fix_tiles_w;
+    int            fix_tiles_h;
+    char          *params;
+} TileEncoderContext;
+
+// Support fix size tile
+static int assign_tiles_fix( TileEncoderContext* ctx )
+{
+    EncoderWrapper* wrapper = &(ctx->api);
+
+    int *tiles_col_width, *tiles_row_height;
+    tiles_col_width = (int *)malloc(ctx->tiles_gw * sizeof(int));
+    tiles_row_height = (int *)malloc(ctx->tiles_gh * sizeof(int));
+    for (int i=0;i<ctx->tiles_gw - 1;i++)tiles_col_width[i]=ctx->fix_tiles_w;
+    for (int i=0;i<ctx->tiles_gh - 1;i++)tiles_row_height[i]=ctx->fix_tiles_h;
+
+    wrapper->tile_num = ctx->tiles_gw * ctx->tiles_gh;
+    wrapper->tile_w = ctx->tiles_gw;
+    wrapper->tile_h = ctx->tiles_gh;
+
+    for(int i = 0; i < ctx->tiles_gh; i++)
+    {
+        for(int j = 0; j < ctx->tiles_gw; j++)
+        {
+            int idx = i * ctx->tiles_gw + j;
+            wrapper->tile_info[idx].left    = (j == 0) ? 0 : wrapper->tile_info[idx - 1].left + tiles_col_width[j-1];
+            wrapper->tile_info[idx].top     = (i == 0) ? 0 : wrapper->tile_info[(i-1)*ctx->tiles_gw + j].top + tiles_row_height[i-1];
+            wrapper->tile_info[idx].tHeight = (i == ctx->tiles_gh - 1) ? wrapper->height - wrapper->tile_info[idx].top : tiles_row_height[i];
+            wrapper->tile_info[idx].tWidth  = (j == ctx->tiles_gw - 1) ? wrapper->width - wrapper->tile_info[idx].left : tiles_col_width[j];
+        }
+    }
+
+    if(tiles_col_width)
+    {
+        free(tiles_col_width);
+        tiles_col_width = NULL;
+    }
+    if(tiles_row_height)
+    {
+        free(tiles_row_height);
+        tiles_row_height = NULL;
+    }
+
+    return 0;
+}
+static int assign_tiles_avg( TileEncoderContext* ctx )
+{
+    EncoderWrapper* wrapper = &(ctx->api);
+
+    wrapper->tile_num = ctx->tiles_gw * ctx->tiles_gh;
+    wrapper->tile_w = ctx->tiles_gw;
+    wrapper->tile_h = ctx->tiles_gh;
+
+#define LCU_SIZE 64
+
+    // Width and Height should be divisible by LCU_SIZE
+    int width_in_lcu = wrapper->width / LCU_SIZE;
+    int height_in_lcu = wrapper->height / LCU_SIZE;
+
+    // (6.5.1) in Rec. ITU-T H.265 v5 (02/2018)
+    int *tiles_col_width, *tiles_row_height;
+    tiles_col_width = (int *)malloc(ctx->tiles_gw * sizeof(int));
+    tiles_row_height = (int *)malloc(ctx->tiles_gh * sizeof(int));
+    for( int i=0; i<ctx->tiles_gw; i++)
+    {
+        tiles_col_width[i] = (i+1) * width_in_lcu / ctx->tiles_gw - i * width_in_lcu / ctx->tiles_gw;
+    }
+    for( int i=0; i<ctx->tiles_gh; i++)
+    {
+        tiles_row_height[i] = (i+1) * height_in_lcu / ctx->tiles_gh - i * height_in_lcu / ctx->tiles_gh;
+
+    }
+
+    for(int i = 0; i < ctx->tiles_gh; i++)
+    {
+        for(int j = 0; j < ctx->tiles_gw; j++)
+        {
+            int idx = i * ctx->tiles_gw + j;
+            wrapper->tile_info[idx].left    = (j == 0) ? 0 : wrapper->tile_info[idx - 1].left + tiles_col_width[j-1] * LCU_SIZE;
+            wrapper->tile_info[idx].top     = (i == 0) ? 0 : wrapper->tile_info[(i-1)*ctx->tiles_gw + j].top + tiles_row_height[i-1] * LCU_SIZE;
+            wrapper->tile_info[idx].tHeight = tiles_row_height[i] * LCU_SIZE;
+            wrapper->tile_info[idx].tWidth  = tiles_col_width[j] * LCU_SIZE;
+        }
+    }
+
+    if(tiles_col_width)
+    {
+        free(tiles_col_width);
+        tiles_col_width = NULL;
+    }
+    if(tiles_row_height)
+    {
+        free(tiles_row_height);
+        tiles_row_height = NULL;
+    }
+
+    return 0;
+}
+
+/// assign bit rate for each tile.
+int get_tile_bitrate(EncoderWrapper* wrapper, int idx)
+{
+    int bit_rate = wrapper->avctx->bit_rate;
+    double percent = 0.0;
+    
+    if( 0==bit_rate ) bit_rate = wrapper->avctx->bit_rate_tolerance;
+    
+    ///FIXME if there is more suitable way to calculate bit rate for each tile
+    percent = (double)( wrapper->tile_info[idx].tHeight * wrapper->tile_info[idx].tWidth ) / (double)(wrapper->width * wrapper->height);
+    
+    return (int) (bit_rate * percent);
+    
+ }
+
+int get_tile_maxrate(EncoderWrapper* wrapper, int idx)
+{
+    int max_rate = wrapper->avctx->rc_max_rate;
+    
+    ///FIXME if there is more suitable way to calculate bit rate for each tile
+    double percent = (double)( wrapper->tile_info[idx].tHeight * wrapper->tile_info[idx].tWidth ) / (double)(wrapper->width * wrapper->height);
+    
+    return (int) (max_rate * percent);
+
+}
+
+int bFifoReady( EncoderWrapper* wrapper )
+{
+    int eos = 0;
+    int ready = 0;
+    for(int i=0; i<wrapper->tile_num; i++){
+        if( wrapper->tile_info[i].outpkt_fifo ){
+            if( av_fifo_size(wrapper->tile_info[i].outpkt_fifo) ){
+                ready++;
+            }else{
+                if(wrapper->tile_info[i].eos) eos++;
+            }
+        }
+    }
+    if( ready == wrapper->tile_num ) return 1;
+    if( eos == wrapper->tile_num ) return AVERROR_EOF;
+
+    return 0;
+}
+int bs_tile_stitching(EncoderWrapper* wrapper, AVPacket* outPkt)
+{
+    int ret = 0;
+    AVPacket pkt[MAX_TILES];
+    int bReady = bFifoReady(wrapper);
+    int totalsize=0;
+    uint8_t* dst = NULL;
+    if( AVERROR_EOF == bReady ) return AVERROR_EOF;
+    
+    if( 1 == bReady ){
+        for(int i=0; i<wrapper->tile_num; i++){
+            av_fifo_generic_read( wrapper->tile_info[i].outpkt_fifo, &pkt[i],  sizeof(AVPacket),  NULL);
+#ifdef FILE_DEBUG
+            wrapper->tile_info[i].nSpkt += 1;
+            av_log(wrapper->avctx, AV_LOG_DEBUG, "######tile id=%d, getpkt=%d, stitched packet=%d#########\n", i, wrapper->tile_info[i].nGetpkt, wrapper->tile_info[i].nSpkt);
+            av_log(wrapper->avctx, AV_LOG_DEBUG, "**********tile id = %d, packet size = %d, packet addr=%p!!!\n", i,pkt[i].size, pkt[i].data);
+#endif
+            totalsize += pkt[i].size;
+        }
+
+        // Sometimes the size of output is larger than size of input,
+        // so we alloc 2 times larger size packet.
+        ret = ff_alloc_packet2(wrapper->avctx, outPkt, 2*totalsize, 2*totalsize);
+        if( ret < 0) return -1;
+
+        dst = outPkt->data;
+
+        // call stitching library
+        wrapper->paramTiledStream.pOutputTiledBitstream = dst;
+
+        for (int i = 0; i < wrapper->paramTiledStream.tilesHeightCount; i++)
+        {
+            for (int j = 0; j < wrapper->paramTiledStream.tilesWidthCount; j++)
+            {
+                param_oneStream_info *ptempinput = wrapper->paramTiledStream.pTiledBitstream[i*wrapper->paramTiledStream.tilesWidthCount + j];
+                ptempinput->pTiledBitstreamBuffer = pkt[i*wrapper->paramTiledStream.tilesWidthCount + j].data;
+                ptempinput->inputBufferLen = pkt[i*wrapper->paramTiledStream.tilesWidthCount + j].size;
+            }
+        }
+
+        wrapper->paramTiledStream.inputBistreamsLen = totalsize;
+        genTiledStream_process(&(wrapper->paramTiledStream), wrapper->pGen);
+        dst += wrapper->paramTiledStream.outputiledbistreamlen;
+        outPkt->size = wrapper->paramTiledStream.outputiledbistreamlen;
+/*
+#ifdef FILE_DEBUG
+        for(int i=0; i<wrapper->tile_num; i++){
+            memcpy(dst, pkt[i].data, pkt[i].size);
+            dst += pkt[i].size;
+            fwrite(pkt[i].data, 1, pkt[i].size, wrapper->tile_info[i].file);
+        }
+#endif
+*/
+        // Send vps+sps+pps info
+        AVCodecContext* avctx = wrapper->avctx;
+        if(avctx->extradata_size == 0)
+        {
+            unsigned char *headerAddr;
+            avctx->extradata_size = genTiledStream_getParam(wrapper->pGen, ID_GEN_TILED_BITSTREAMS_HEADER, &headerAddr);
+            avctx->extradata = av_malloc(avctx->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);
+            if (!avctx->extradata) {
+                av_log(avctx, AV_LOG_ERROR,
+                       "Cannot allocate HEVC header of size %d.\n", avctx->extradata_size);
+                return AVERROR(ENOMEM);
+            }
+            memcpy(avctx->extradata, headerAddr, avctx->extradata_size);
+        }
+
+        switch (wrapper->paramTiledStream.sliceType) {
+        case SLICE_IDR:
+        case SLICE_I:
+            avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;
+            break;
+        case SLICE_P:
+            avctx->coded_frame->pict_type = AV_PICTURE_TYPE_P;
+            break;
+        case SLICE_B:
+            avctx->coded_frame->pict_type = AV_PICTURE_TYPE_B;
+            break;
+        }
+
+        //outPkt->pts = paramTiledStream.pts;
+
+        ///unref the packet read from fifo
+        for(int i=0; i<wrapper->tile_num; i++){
+            av_packet_unref(&pkt[i]);
+            free(pkt[i].data);
+        }
+
+        return 0;
+    }
+    return -1;
+}
+
+int get_tile_frame_copy(EncoderWrapper* wrapper, int tile_idx, const AVFrame *pic, AVFrame** tile_pic )
+{
+    int ret = 0;
+    uint8_t* src = NULL;
+    uint8_t* dst = NULL;
+    int factor = 1;
+    AVFrame* frame = NULL;
+    
+    if( NULL == *tile_pic ){
+        *tile_pic = av_frame_alloc();
+        if (!*tile_pic) {
+            av_freep(*tile_pic);
+            return AVERROR(ENOMEM);
+        }
+    }
+    
+    frame = *tile_pic;
+    frame->height = wrapper->tile_info[tile_idx].tHeight;
+    frame->width  = wrapper->tile_info[tile_idx].tWidth;
+
+    frame->format = pic->format;
+
+    if (!frame->data[0]) {
+        ret = av_frame_get_buffer(frame, 32);
+        if (ret < 0){
+            av_freep(*tile_pic);
+            return ret;
+        }
+    }
+
+    ///current copy is based on YUV420p format
+    for( int planner=0; planner<3; planner++ ){
+        if( planner > 0 ){
+            factor = 2;
+        }
+        src = pic->data[planner] + pic->linesize[planner]*(wrapper->tile_info[tile_idx].top / factor) + wrapper->tile_info[tile_idx].left / factor;
+        dst = frame->data[planner];
+        for( int i=0; i<frame->height/factor; i++ ){
+            src += pic->linesize[planner];
+            dst += frame->linesize[planner];
+            memcpy( dst, src, frame->width / factor );
+        }
+    }
+
+    return ret;
+}
+
+int get_tile_frame_nocopy(EncoderWrapper* wrapper, int tile_idx, const AVFrame *pic, AVFrame** tile_pic )
+{
+    AVFrame* frame = NULL;
+    int factor = 1;
+    
+    if( NULL == *tile_pic ){
+        *tile_pic = av_frame_alloc();
+        if (!*tile_pic) {
+            av_freep(*tile_pic);
+            return AVERROR(ENOMEM);
+        }
+    }
+    
+    frame = *tile_pic;
+    frame->height = wrapper->tile_info[tile_idx].tHeight;
+    frame->width = wrapper->tile_info[tile_idx].tWidth;
+    frame->format = pic->format;
+
+    for( int i=0; i<4; i++ ){
+        if( i > 0 ){
+            factor = 2;
+        }
+        frame->data[i] = pic->data[i] + pic->linesize[i]*(wrapper->tile_info[tile_idx].top / factor) + wrapper->tile_info[tile_idx].left / factor;
+        frame->linesize[i] = pic->linesize[i];
+    }
+
+    return 0;
+}
+
+static av_cold int tile_encode_close(AVCodecContext *avctx)
+{
+    TileEncoderContext *ctx = avctx->priv_data;
+    EncoderWrapper *wrapper = &(ctx->api);
+    AVFifoBuffer* fifo = NULL;
+
+    if(wrapper->pGen)
+    {
+        genTiledStream_unInit(wrapper->pGen);
+    }
+
+    if (wrapper->paramTiledStream.pTiledBitstream)
+    {
+        for (int i = 0; i < wrapper->paramTiledStream.tilesHeightCount; i++)
+        {
+            for (int j = 0; j < wrapper->paramTiledStream.tilesWidthCount; j++)
+            {
+                free(wrapper->paramTiledStream.pTiledBitstream[i*wrapper->paramTiledStream.tilesWidthCount + j]);
+                wrapper->paramTiledStream.pTiledBitstream[i*wrapper->paramTiledStream.tilesWidthCount + j] = NULL;
+            }
+        }
+        free(wrapper->paramTiledStream.pTiledBitstream);
+        wrapper->paramTiledStream.pTiledBitstream = NULL;
+    }
+    if(avctx->extradata)
+    {
+        free(avctx->extradata);
+        avctx->extradata = NULL;
+    }
+
+    if(wrapper->tid)
+    {
+        free(wrapper->tid);
+        wrapper->tid = NULL;
+    }
+    if(wrapper->tile_enc_info)
+    {
+        free(wrapper->tile_enc_info);
+        wrapper->tile_enc_info = NULL;
+    }
+
+    if( NULL != ctx->api.enc_close )
+        ctx->api.enc_close(&(ctx->api));
+
+    for( int i=0; i < ctx->api.tile_num; i++ ){
+
+#ifdef FILE_DEBUG
+        if(ctx->api.tile_info[i].file) fclose(ctx->api.tile_info[i].file);
+#endif
+
+        fifo = ctx->api.tile_info[i].outpkt_fifo;
+        while ( fifo && av_fifo_size(fifo)) {
+            AVPacket pkt;
+            av_fifo_generic_read(fifo, &pkt,  sizeof(pkt),  NULL);
+            free(pkt.data);
+            av_packet_unref(&pkt);
+        }
+        av_fifo_free(fifo);
+        fifo = NULL;
+    }
+    return 0;
+}
+
+static av_cold int tile_encode_init(AVCodecContext *avctx)
+{
+    TileEncoderContext *ctx = avctx->priv_data;
+    EncoderWrapper* wrapper = &(ctx->api);
+    int ret = 0;
+    char filename[256];
+
+    wrapper->width = avctx->coded_width;
+    wrapper->height = avctx->coded_height;
+
+    wrapper->avctx = avctx;
+    switch(ctx->tile_mode){
+        case FIX_SIZE:
+            wrapper->uniform_split = false;
+            assign_tiles_fix( ctx );
+            break;
+        case AVG_SIZE:
+            wrapper->uniform_split = true;
+            assign_tiles_avg( ctx );
+            break;
+        default:
+            break;
+    }
+
+
+    switch(ctx->enc_lib){
+        case ENC_X265:
+            wrapper->enc_close = libx265_enc_close;
+            wrapper->enc_frame = libx265_enc_frame;
+            wrapper->enc_init  = libx265_enc_init;
+            break;
+        case ENC_SVT:
+            wrapper->enc_close = svt_enc_close;
+            wrapper->enc_frame = svt_enc_frame;
+            wrapper->enc_init  = svt_enc_init;
+            break;
+        default:
+            break;
+    }
+
+    pthread_mutex_init(&(wrapper->mutex), NULL);
+    pthread_cond_init(&(wrapper->cond), NULL);
+    wrapper->tid = malloc(wrapper->tile_num * sizeof(pthread_t));
+    wrapper->tile_enc_info = malloc(wrapper->tile_num * sizeof(TileEncoderInfo));
+    for(int i=0; i<wrapper->tile_num; i++){
+        wrapper->tile_info[i].tBitrate = get_tile_bitrate(wrapper, i);
+        wrapper->tile_info[i].tMaxrate = get_tile_maxrate(wrapper, i);
+        wrapper->tile_info[i].eos = 0;
+        wrapper->tile_info[i].outpkt_fifo = av_fifo_alloc( FIFO_SIZE * sizeof(AVPacket));
+#ifdef FILE_DEBUG
+        wrapper->tile_info[i].nGetpkt = 0;
+        wrapper->tile_info[i].nSpkt = 0;
+        sprintf(filename, "out_%d.265", i);
+        wrapper->tile_info[i].file = fopen(filename, "wb+");
+#endif
+        wrapper->tile_enc_info[i].ctx      = wrapper;
+        wrapper->tile_enc_info[i].tile_idx = i;
+
+        ret = pthread_create(&wrapper->tid[i], NULL, svt_enc_tile, &(wrapper->tile_enc_info[i]));
+        if(0 != ret)
+        {
+            av_log(avctx, AV_LOG_ERROR, "Cannot create thread!\n");
+            return ret;
+        }
+    }
+
+    if( NULL != ctx->api.enc_init ){
+        ret = wrapper->enc_init(wrapper);
+        if( 0 != ret ) return ret;
+    }
+
+    wrapper->paramTiledStream.tilesHeightCount = wrapper->tile_h;
+    wrapper->paramTiledStream.tilesWidthCount  = wrapper->tile_w;
+    wrapper->paramTiledStream.tilesUniformSpacing = wrapper->uniform_split;
+    wrapper->paramTiledStream.frameWidth = wrapper->width;
+    wrapper->paramTiledStream.frameHeight = wrapper->height;
+    wrapper->paramTiledStream.pTiledBitstream = (param_oneStream_info**)malloc(wrapper->tile_h * wrapper->tile_w * sizeof(param_oneStream_info *));
+    if (!wrapper->paramTiledStream.pTiledBitstream)
+    {
+        printf("memory alloc failed!");
+        return 1;
+    }
+
+    for (int i = 0; i < wrapper->paramTiledStream.tilesHeightCount; i++)
+    {
+        for (int j = 0; j < wrapper->paramTiledStream.tilesWidthCount; j++)
+        {
+            wrapper->paramTiledStream.pTiledBitstream[i*wrapper->paramTiledStream.tilesWidthCount + j] = (param_oneStream_info*)malloc(sizeof(param_oneStream_info));
+        }
+    }
+
+    wrapper->pGen = genTiledStream_Init(&(wrapper->paramTiledStream));
+    if (!wrapper->pGen)
+    {
+        printf("the initialize failed\n");
+        return 1;
+    }
+
+    return 0;
+}
+
+static int tile_encode_frame(AVCodecContext *avctx, AVPacket *pkt,
+                                const AVFrame *pic, int *got_packet)
+{
+    TileEncoderContext *ctx = avctx->priv_data;
+    if( NULL != ctx->api.enc_frame )
+        ctx->api.enc_frame(&(ctx->api), pkt, pic, got_packet);
+
+    return 0;
+}
+
+#define OFFSET(x) offsetof(TileEncoderContext, x)
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+static const AVOption options[] = {
+    { "enc", "what's the encoder for each tile. so far, x265=1, svt=2.", OFFSET(enc_lib), AV_OPT_TYPE_INT, { .i64 = 2 }, 0, 3, VE },
+    { "tile_mode", "specify how to divide the tiles of the picture: 1 fixed size tiles; 2. grid layout, 3x3, 4x4.", OFFSET(tile_mode), AV_OPT_TYPE_INT, { .i64 = 2 }, 0, 3, VE },
+    { "tiles_gw", "horizontal grid number of tiles; available when tile is divided via grid layout .", OFFSET(tiles_gw), AV_OPT_TYPE_INT, { .i64 = 1 }, 0, INT_MAX, VE },
+    { "tiles_gh", "vertical grid number of tiles; available when tile is divided via grid layout .", OFFSET(tiles_gh), AV_OPT_TYPE_INT, { .i64 = 1 }, 0, INT_MAX, VE },
+    { "tiles_fixw", "horizontal width of tiles; available when tile is divided via fixed size.", OFFSET(fix_tiles_w), AV_OPT_TYPE_INT, { .i64 = 512 }, 0, INT_MAX, VE },
+    { "tiles_fixh", "vertical height of tiles; available when tile is divided via fixed size.", OFFSET(fix_tiles_h), AV_OPT_TYPE_INT, { .i64 = 512 }, 0, INT_MAX, VE },
+    { "params", "Set parameters as a comma-separated list of key=value pairs.", OFFSET(params), AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VE },
+    { NULL },
+};
+
+static const AVClass class = {
+    .class_name = "hevc_tile_encoder",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVCodecDefault defaults[] = {
+    { "b", "0" },
+    { NULL },
+};
+
+AVCodec ff_hevc_tile_encoder = {
+    .name             = "hevc_tile_encoder",
+    .long_name        = NULL_IF_CONFIG_SMALL("distribute tile H.265 / HEVC"),
+    .type             = AVMEDIA_TYPE_VIDEO,
+    .id               = AV_CODEC_ID_HEVC,
+    .capabilities     = AV_CODEC_CAP_DELAY,
+    .pix_fmts         = (const enum AVPixelFormat[]){ AV_PIX_FMT_YUV420P,
+                                                    AV_PIX_FMT_YUV420P10,
+                                                    AV_PIX_FMT_NONE },
+
+    .priv_class       = &class,
+    .priv_data_size   = sizeof(TileEncoderContext),
+    .defaults         = defaults,
+
+    .init             = tile_encode_init,
+    .encode2          = tile_encode_frame,
+    .close            = tile_encode_close,
+
+    .caps_internal    = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP,
+
+    .wrapper_name     = "hevc_tile_encoder",
+};
diff -urN FFmpeg/libavcodec/tile_encoder.h FFmpeg-patched/libavcodec/tile_encoder.h
--- FFmpeg/libavcodec/tile_encoder.h	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavcodec/tile_encoder.h	2020-09-27 13:35:13.371526551 +0800
@@ -0,0 +1,125 @@
+/*
+ * Intel tile encoder
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef TILE_ENCODER_H
+#define TILE_ENCODER_H
+#define FILE_DEBUG
+
+#include "libavutil/fifo.h"
+
+#include "avcodec.h"
+#include "internal.h"
+#include <stdio.h>
+#include <pthread.h>
+#include <unistd.h>
+#include <stdbool.h>
+
+#include "genTiledstreamAPI.h"
+
+#define MAX_TILES 256
+#define FIFO_SIZE 8024
+
+enum ENC_LIB{
+    ENC_NULL = 0,
+    ENC_X265 = 1,
+    ENC_SVT  = 2
+};
+
+enum TILE_MODE{
+    NULL_MODE = 0,
+    FIX_SIZE  = 1,
+    AVG_SIZE  = 2
+};
+typedef int (*ENC_CLOSE)(void*);
+typedef int (*ENC_INIT)(void*);
+typedef int (*ENC_FRAME)(void*, AVPacket*, const AVFrame*, int*);
+
+typedef struct TileInfo{
+        int            top;
+        int            left;
+        int            tWidth;
+        int            tHeight;
+        int            tBitrate;
+        int            tMaxrate;
+        AVFifoBuffer*  outpkt_fifo;
+        int            proc_idx;
+        int            eos;
+        void*          enc_ctx;
+        AVPacket*      internal_pkt;
+#ifdef FILE_DEBUG
+        int            nGetpkt;
+        int            nSpkt;
+        FILE*          file;
+#endif
+} TileInfo;
+
+typedef struct TileEncoderInfo{
+    void          *ctx;
+    int           tile_idx;
+}TileEncoderInfo;
+
+typedef struct EncoderWrapper{
+        AVCodecContext* avctx;
+
+        int             width;
+        int             height;
+        void*           enc_param;
+
+        bool            uniform_split;
+        int             tile_num;
+        int             tile_w;
+        int             tile_h;
+        TileInfo        tile_info[MAX_TILES];
+
+        ENC_CLOSE       enc_close;
+        ENC_INIT        enc_init;
+        ENC_FRAME       enc_frame;
+
+        TileEncoderInfo *tile_enc_info;
+        pthread_t       *tid;
+        int             initialized;
+
+        void            *pGen;
+        param_gen_tiledStream paramTiledStream;
+        pthread_mutex_t mutex;
+        pthread_cond_t cond;
+} EncoderWrapper;
+
+int get_tile_frame_copy(EncoderWrapper* wrapper, int tile_idx, const AVFrame *pic, AVFrame** tile_pic );
+int get_tile_frame_nocopy(EncoderWrapper* wrapper, int tile_idx, const AVFrame *pic, AVFrame** tile_pic );
+
+int bs_tile_stitching(EncoderWrapper* wrapper, AVPacket* outPkt);
+int get_tile_bitrate(EncoderWrapper* wrapper, int idx);
+int get_tile_maxrate(EncoderWrapper* wrapper, int idx);
+
+int libx265_enc_close(void* ctx);
+int libx265_enc_init(void* ctx);
+int libx265_enc_frame(void* ctx, AVPacket *pkt, const AVFrame *pic, int *got_packet);
+
+int svt_enc_close(void* ctx);
+int svt_enc_init(void* ctx);
+int svt_enc_frame(void* ctx, AVPacket *pkt, const AVFrame *pic, int *got_packet);
+int svt_enc_tile(TileEncoderInfo *tile_enc_info);
+int bFifoReady( EncoderWrapper* wrapper );
+
+#endif /* TILE_ENCODER_H */
+
diff -urN FFmpeg/libavcodec/tile_encode_svt_impl.c FFmpeg-patched/libavcodec/tile_encode_svt_impl.c
--- FFmpeg/libavcodec/tile_encode_svt_impl.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavcodec/tile_encode_svt_impl.c	2020-09-27 13:35:13.371526551 +0800
@@ -0,0 +1,488 @@
+/*
+ * Intel tile encoder
+ *
+ * Copyright (c) 2018 Intel Cooperation
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+#include <sys/time.h>
+#include <time.h>
+#include <stdio.h>
+#include <stdlib.h>
+
+#include <stdint.h>
+#include <string.h>
+
+#include "libavutil/attributes.h"
+#include "libavutil/avassert.h"
+#include "libavutil/dict.h"
+#include "libavutil/error.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/internal.h"
+#include "libavutil/log.h"
+#include "libavutil/mem.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/opt.h"
+#include "libavutil/common.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+
+#include "tile_encoder.h"
+#include "EbErrorCodes.h"
+#include "EbTime.h"
+#include "EbApi.h"
+
+#include <float.h>
+
+typedef struct SvtEncoder {
+    EB_H265_ENC_CONFIGURATION           enc_params;
+    EB_COMPONENTTYPE                    *svt_handle;
+    EB_BUFFERHEADERTYPE                 *in_buf;
+    EB_BUFFERHEADERTYPE                 *out_buf;
+    int                                  raw_size;
+} SvtEncoder;
+
+typedef struct SvtParams {
+    int vui_info;
+    int hierarchical_level;
+    int intra_period;
+    int la_depth;
+    int intra_ref_type;
+    int enc_mode;
+    int rc_mode;
+    int scd;
+    int tune;
+    int qp;
+    int profile;
+    int base_layer_switch_mode;
+    int bit_rate;
+    int intra_refresh_type;
+}SvtParams;
+
+typedef struct SvtContext {
+    SvtEncoder  *svt_enc;
+    SvtParams   svt_param;
+    int         eos_flag;
+    int         i;
+} SvtContext;
+
+static int error_mapping(int val)
+{
+    if (val == EB_ErrorInsufficientResources)
+        return AVERROR(ENOMEM);
+    if ((val == EB_ErrorUndefined) || (val == EB_ErrorInvalidComponent) ||
+        (val == EB_ErrorBadParameter))
+        return AVERROR(EINVAL);
+    return AVERROR_EXTERNAL;
+}
+
+static void free_buffer(SvtEncoder *svt_enc)
+{
+    if (svt_enc->in_buf) {
+        EB_H265_ENC_INPUT *in_data = (EB_H265_ENC_INPUT* )svt_enc->in_buf->pBuffer;
+        if (in_data) {
+            av_freep(&in_data);
+        }
+        av_freep(&svt_enc->in_buf);
+    }
+    av_freep(&svt_enc->out_buf);
+}
+
+static EB_ERRORTYPE alloc_buffer(EB_H265_ENC_CONFIGURATION *config, SvtEncoder *svt_enc)
+{
+    EB_ERRORTYPE       ret       = EB_ErrorNone;
+
+    const int    pack_mode_10bit   = (config->encoderBitDepth > 8) && (config->compressedTenBitFormat == 0) ? 1 : 0;
+    const size_t luma_size_8bit    = config->sourceWidth * config->sourceHeight * (1 << pack_mode_10bit);
+    const size_t luma_size_10bit   = (config->encoderBitDepth > 8 && pack_mode_10bit == 0) ? luma_size_8bit : 0;
+
+    svt_enc->raw_size = (luma_size_8bit + luma_size_10bit) * 3 / 2;
+
+    // allocate buffer for in and out
+    svt_enc->in_buf           = av_mallocz(sizeof(EB_BUFFERHEADERTYPE));
+    svt_enc->out_buf          = av_mallocz(sizeof(EB_BUFFERHEADERTYPE));
+    if (!svt_enc->in_buf || !svt_enc->out_buf)
+        goto failed;
+
+    svt_enc->in_buf->pBuffer  = av_mallocz(sizeof(EB_H265_ENC_INPUT));
+    if (!svt_enc->in_buf->pBuffer)
+        goto failed;
+
+    svt_enc->in_buf->nSize        = sizeof(EB_BUFFERHEADERTYPE);
+    svt_enc->in_buf->pAppPrivate  = NULL;
+    svt_enc->out_buf->nSize       = sizeof(EB_BUFFERHEADERTYPE);
+    svt_enc->out_buf->nAllocLen   = svt_enc->raw_size;
+    svt_enc->out_buf->pAppPrivate = NULL;
+
+    return ret;
+
+failed:
+    free_buffer(svt_enc);
+    return AVERROR(ENOMEM);
+
+
+}
+
+static EB_ERRORTYPE config_enc_params(EncoderWrapper* wrapper, int tile_idx, EB_H265_ENC_CONFIGURATION  *param )
+{
+    AVCodecContext *avctx = wrapper->avctx;
+    SvtContext *q       = (SvtContext *)wrapper->tile_info[tile_idx].enc_ctx;
+    SvtEncoder *svt_enc = q->svt_enc;
+    EB_ERRORTYPE    ret = EB_ErrorNone;
+    int         tenBits = 0;
+
+    param->sourceWidth     = wrapper->tile_info[tile_idx].tWidth;
+    param->sourceHeight    = wrapper->tile_info[tile_idx].tHeight;
+
+    if (avctx->pix_fmt == AV_PIX_FMT_YUV420P10LE) {
+        av_log(avctx, AV_LOG_DEBUG , "Encoder 10 bits depth input\n");
+        param->compressedTenBitFormat = 0;
+        tenBits = 1;
+    }
+
+    // Update param from options
+    param->hierarchicalLevels     = q->svt_param.hierarchical_level;
+    param->encMode                = q->svt_param.enc_mode;
+    param->intraRefreshType       = q->svt_param.intra_ref_type;
+    param->profile                = q->svt_param.profile;
+    param->rateControlMode        = q->svt_param.rc_mode;
+    param->sceneChangeDetection   = q->svt_param.scd;
+    param->tune                   = q->svt_param.tune;
+    param->baseLayerSwitchMode    = q->svt_param.base_layer_switch_mode;
+
+    param->targetBitRate          = q->svt_param.bit_rate;
+    param->frameRateNumerator     = avctx->time_base.den;
+    param->frameRateDenominator   = avctx->time_base.num * avctx->ticks_per_frame;
+    // Need to disable deblock filter to disable loop_filter_across_slices_enable_flag
+    param->disableDlfFlag         = 1;
+    param->enableSaoFlag          = 0;
+    // Make encoded bitstream has I/P frame only
+    param->intraPeriodLength      = q->svt_param.intra_period;
+    param->qp                     = q->svt_param.qp;
+    param->intraRefreshType       = q->svt_param.intra_refresh_type;
+
+    if (q->svt_param.vui_info)
+        param->videoUsabilityInfo = q->svt_param.vui_info;
+    if (q->svt_param.la_depth != -1)
+        param->lookAheadDistance  = q->svt_param.la_depth;
+
+    if (tenBits == 1) {
+        param->encoderBitDepth        = 10;
+        param->profile                = 2;
+    }
+
+    ret = alloc_buffer(param, svt_enc);
+
+    return ret;
+}
+
+static int eb_enc_init(EncoderWrapper* wrapper, int tile_idx)
+{
+    SvtContext* ctx = wrapper->tile_info[tile_idx].enc_ctx;
+
+    EB_ERRORTYPE ret = EB_ErrorNone;
+    SvtEncoder* svt_enc = NULL;
+
+    ctx->svt_enc  = av_mallocz(sizeof(*ctx->svt_enc));
+    if (!ctx->svt_enc)
+        return AVERROR(ENOMEM);
+
+    svt_enc = ctx->svt_enc;
+
+    ctx->eos_flag = 0;
+
+    ret = EbInitHandle(&svt_enc->svt_handle, ctx, &svt_enc->enc_params);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    ret = config_enc_params( wrapper, tile_idx, &svt_enc->enc_params);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    ret = EbH265EncSetParameter(svt_enc->svt_handle, &svt_enc->enc_params);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    ret = EbInitEncoder(svt_enc->svt_handle);
+    if (ret != EB_ErrorNone)
+        goto failed_init;
+
+    return ret;
+
+failed_init:
+    return error_mapping(ret);
+}
+
+static void read_in_data(EB_H265_ENC_CONFIGURATION *config, const AVFrame* frame, EB_BUFFERHEADERTYPE *headerPtr)
+{
+    unsigned int is16bit = config->encoderBitDepth > 8;
+    unsigned long long lumaReadSize = (unsigned long long)config->sourceWidth * config->sourceHeight<< is16bit;
+    EB_H265_ENC_INPUT *in_data = (EB_H265_ENC_INPUT*)headerPtr->pBuffer;
+
+    
+    // support yuv420p and yuv420p010
+    in_data->luma = frame->data[0];
+    in_data->cb   = frame->data[1];
+    in_data->cr   = frame->data[2];
+
+	// stride info
+    in_data->yStride  = frame->linesize[0] >> is16bit;
+    in_data->cbStride = frame->linesize[1] >> is16bit;
+    in_data->crStride = frame->linesize[2] >> is16bit;
+
+    headerPtr->nFilledLen   += lumaReadSize * 3/2u;
+
+}
+
+static int eb_send_frame(EncoderWrapper* wrapper, int tile_idx, const AVFrame *frame)
+{
+    SvtContext *q       = (SvtContext *)wrapper->tile_info[tile_idx].enc_ctx;
+    SvtEncoder           *svt_enc = q->svt_enc;
+    EB_BUFFERHEADERTYPE  *headerPtr = svt_enc->in_buf;
+    
+    AVFrame* tile_pic = NULL;
+    int                  ret = 0;
+    
+    if (!frame) {
+        EB_BUFFERHEADERTYPE headerPtrLast;
+        headerPtrLast.nAllocLen = 0;
+        headerPtrLast.nFilledLen = 0;
+        headerPtrLast.nTickCount = 0;
+        headerPtrLast.pAppPrivate = NULL;
+        //headerPtrLast.nOffset = 0;
+        //headerPtrLast.nTimeStamp = 0;
+        headerPtrLast.nFlags = EB_BUFFERFLAG_EOS;
+        headerPtrLast.pBuffer = NULL;
+        EbH265EncSendPicture(svt_enc->svt_handle, &headerPtrLast);
+        av_log(wrapper->avctx, AV_LOG_DEBUG, "========tile id = %d NULL frame!!!\n", tile_idx);
+        q->eos_flag = 1;
+        av_log(wrapper->avctx, AV_LOG_ERROR, "Finish sending frames!!!\n");
+        return ret;
+    }
+    get_tile_frame_nocopy(wrapper, tile_idx, frame, &tile_pic);
+    av_log(wrapper->avctx, AV_LOG_DEBUG, "------tile id = %d start frame address: y=%p, u=%p, v=%p!!!\n",
+                                          tile_idx, tile_pic->data[0], tile_pic->data[1], tile_pic->data[2]);
+
+    read_in_data(&svt_enc->enc_params, tile_pic, headerPtr);
+
+    //headerPtr->nOffset    = 0;
+    headerPtr->nFlags     = 0;
+    headerPtr->pAppPrivate = NULL;
+    headerPtr->pts        = frame->pts;
+    //headerPtr->nFlags     = 0;
+    //headerPtr->nTimeStamp = 0;
+    //headerPtr->pAppPrivate = NULL;
+    headerPtr->sliceType  = INVALID_SLICE;
+    q->i += 1;
+    av_log(wrapper->avctx, AV_LOG_DEBUG, "tile id = %d start to send frame, times = %d!!!\n", tile_idx, q->i);
+
+    EbH265EncSendPicture(svt_enc->svt_handle, headerPtr);
+
+    if(NULL!= tile_pic) av_frame_free(&tile_pic);
+    return ret;
+}
+
+static int eb_receive_packet(EncoderWrapper* wrapper, int tile_idx, AVPacket *pkt)
+{
+    SvtContext *q        = (SvtContext *)wrapper->tile_info[tile_idx].enc_ctx;
+    SvtEncoder  *svt_enc = q->svt_enc;
+    EB_BUFFERHEADERTYPE   *headerPtr = svt_enc->out_buf;
+    EB_ERRORTYPE          stream_status = EB_ErrorNone;
+
+    int ret = 0;
+
+    //if ((ret = ff_alloc_packet2(wrapper->avctx, pkt, svt_enc->raw_size, 0)) < 0){
+    //    av_log(wrapper->avctx, AV_LOG_ERROR, "tile id = %d ff_alloc_packet2 ret = %d!!!\n", tile_idx, ret);
+    //    return ret;
+    //}
+    pkt->data = malloc(svt_enc->raw_size);
+    pkt->size = svt_enc->raw_size;
+
+    headerPtr->pBuffer = pkt->data;
+    stream_status = EbH265GetPacket(svt_enc->svt_handle, headerPtr, q->eos_flag);
+    if ((stream_status == EB_NoErrorEmptyQueue)){
+        av_log(wrapper->avctx, AV_LOG_DEBUG, "tile id = %d stream_status == EB_NoErrorEmptyQueue!!!\n", tile_idx);
+        return AVERROR(EAGAIN);
+    }
+    pkt->size = headerPtr->nFilledLen;
+    pkt->pts = headerPtr->pts;
+    pkt->dts = headerPtr->dts;
+    ret = (headerPtr->nFlags & EB_BUFFERFLAG_EOS) ? AVERROR_EOF : 0;
+
+    av_log(wrapper->avctx, AV_LOG_DEBUG, "tile id = %d ret = %d!!!\n", tile_idx, ret);
+    return ret;
+}
+
+static av_cold int eb_enc_close(EncoderWrapper* wrapper, int tile_idx)
+{
+    SvtContext *q         = (SvtContext *)wrapper->tile_info[tile_idx].enc_ctx;
+    SvtEncoder *svt_enc   = q->svt_enc;
+
+    EbDeinitEncoder(svt_enc->svt_handle);
+    EbDeinitHandle(svt_enc->svt_handle);
+
+    free_buffer(svt_enc);
+    av_freep(&svt_enc);
+
+    return 0;
+}
+
+///encode each tile with SVT
+int svt_enc_close(void* ctx)
+{
+    EncoderWrapper* wrapper = (EncoderWrapper*)ctx;
+    SvtContext* svt_ctx = NULL;
+    
+    for(int i=0; i<wrapper->tile_num; i++){
+        svt_ctx = (SvtContext*)wrapper->tile_info[i].enc_ctx;
+        if( NULL != svt_ctx){
+            eb_enc_close(wrapper, i);
+            free(svt_ctx);
+        }
+        wrapper->tile_info[i].enc_ctx = NULL;
+    }
+    
+    return 0;
+}
+
+int svt_enc_init(void* ctx)
+{
+    EncoderWrapper* wrapper = (EncoderWrapper*)ctx;
+    SvtContext* svt_ctx = NULL;
+    int ret = 0;
+    
+    for(int i=0; i<wrapper->tile_num; i++){
+        svt_ctx = malloc(sizeof(SvtContext));
+        svt_ctx->svt_param.hierarchical_level = 3;
+        svt_ctx->svt_param.enc_mode = 9;
+        svt_ctx->svt_param.intra_ref_type = 1;
+        svt_ctx->svt_param.profile = 2;
+        svt_ctx->svt_param.rc_mode = 0;//0-CQP, 1-VBR
+        svt_ctx->svt_param.qp = 32;
+        svt_ctx->svt_param.scd = 0;
+        svt_ctx->svt_param.tune = 1;
+        svt_ctx->svt_param.intra_period = 5;
+        svt_ctx->svt_param.base_layer_switch_mode = 0;
+        svt_ctx->svt_param.vui_info = 0;
+        svt_ctx->svt_param.la_depth = -1;
+        svt_ctx->svt_param.bit_rate = wrapper->tile_info[i].tBitrate;
+        svt_ctx->i = 0;
+        svt_ctx->svt_param.intra_refresh_type = 1;//1-CRA, 2-IDR intra refresh
+        wrapper->tile_info[i].enc_ctx = svt_ctx;
+        ret = eb_enc_init(wrapper, i);
+        if( 0 != ret ) return ret;
+    }
+    wrapper->initialized = 1;
+    return 0;
+}
+
+int svt_enc_frame(void* ctx, AVPacket *pkt, const AVFrame *pic, int *got_packet)
+{
+    EncoderWrapper* wrapper = (EncoderWrapper*)ctx;
+    SvtContext *q = NULL;
+    
+    int ret = 0;
+
+    for(int i=0; i<wrapper->tile_num; i++){
+        q = (SvtContext *)wrapper->tile_info[i].enc_ctx;
+        if( wrapper->tile_info[i].eos ) continue;
+        
+        if(!q->eos_flag) eb_send_frame( wrapper, i, pic );
+    }
+
+    // Wake up all receive tile threads
+    if(!q->eos_flag)
+    {
+        pthread_cond_broadcast(&(wrapper->cond));
+    }
+    else
+    {
+        // Wait until all tiles are ready
+        while(0==bFifoReady(wrapper))
+        {
+            pthread_cond_broadcast(&(wrapper->cond));
+            usleep(10000);
+        }
+    }
+
+    //FIXME, suppose all encoder has the rhythm to get packet, so there is no buffer in the first time 
+
+    ret = bs_tile_stitching(wrapper, pkt);
+
+    if( AVERROR_EOF == ret ){
+        return AVERROR_EOF;
+    }
+    *got_packet = 1;
+    
+    if( -1 == ret ) *got_packet = 0;
+    
+    return 0;
+}
+
+int svt_enc_tile(TileEncoderInfo *tile_enc_info)
+{
+    int ret = 0;
+
+    EncoderWrapper *wrapper = (EncoderWrapper*)tile_enc_info->ctx;
+    int            tile_idx = tile_enc_info->tile_idx;
+
+    while(1)
+    {
+        if(wrapper->initialized)
+            break;
+    }
+
+    SvtContext          *q         = (SvtContext *)wrapper->tile_info[tile_idx].enc_ctx;
+    SvtEncoder          *svt_enc   = q->svt_enc;
+    EB_BUFFERHEADERTYPE *headerPtr = svt_enc->out_buf;
+
+    while(!wrapper->tile_info[tile_idx].eos)
+    {
+        // Wait until next frame is sent
+        if(!q->eos_flag)
+            pthread_cond_wait(&(wrapper->cond),&(wrapper->mutex));
+
+        AVPacket tile_pkts = {0};
+        ret = eb_receive_packet(wrapper, tile_idx, &tile_pkts);
+        av_log(wrapper->avctx, AV_LOG_DEBUG, "tile id = %d begin to eb_receive_packet!!!\n", tile_idx);
+        if( 0 == ret || AVERROR_EOF == ret ){
+            av_log(wrapper->avctx, AV_LOG_DEBUG, "**********tile id = %d eb_receive_packet got packet, packet size = %d, packet addr=%p!!!\n", tile_idx, tile_pkts.size, tile_pkts.data);
+            av_fifo_generic_write( wrapper->tile_info[tile_idx].outpkt_fifo, &tile_pkts, sizeof(AVPacket), NULL);
+#ifdef FILE_DEBUG
+            wrapper->tile_info[tile_idx].nGetpkt += 1;
+            //fwrite(tile_pkts.data, 1, tile_pkts.size, wrapper->tile_info[i].file);
+#endif
+            if( AVERROR_EOF == ret ){
+                av_log(wrapper->avctx, AV_LOG_ERROR, "tile id = %d EOS!!!\n", tile_idx);
+                wrapper->tile_info[tile_idx].eos = 1;
+            }
+        }else{
+            av_packet_unref(&tile_pkts);
+            free(tile_pkts.data);
+        }
+
+    }
+
+    // Wait until all tiles are done
+    while(AVERROR_EOF!=bFifoReady(wrapper))
+    {
+        pthread_cond_wait(&(wrapper->cond),&(wrapper->mutex));
+        usleep(10000);
+    }
+
+    return ret;
+}
diff -urN FFmpeg/libavcodec/tile_encode_x265_impl.c FFmpeg-patched/libavcodec/tile_encode_x265_impl.c
--- FFmpeg/libavcodec/tile_encode_x265_impl.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavcodec/tile_encode_x265_impl.c	2020-09-27 13:35:13.371526551 +0800
@@ -0,0 +1,477 @@
+/*
+ * Intel tile encoder
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+
+#include <stdint.h>
+#include <string.h>
+
+#include "libavutil/attributes.h"
+#include "libavutil/avassert.h"
+#include "libavutil/dict.h"
+#include "libavutil/error.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/internal.h"
+#include "libavutil/log.h"
+#include "libavutil/mem.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/opt.h"
+#include "libavutil/common.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+
+#include "tile_encoder.h"
+#include <x265.h>
+#include <float.h>
+
+typedef struct x265Context {
+    x265_encoder   *encoder;
+    x265_param     *params;
+    const x265_api *api;
+    
+    int            bit_rate;
+    int            rc_max_rate;
+    
+    float          crf;
+    int            forced_idr;
+    char           *preset;
+    char           *tune;
+    char           *profile;
+    char           *x265_opts;
+    
+} x265Context;
+
+///encode each tile with libx265
+static int is_keyframe(NalUnitType naltype)
+{
+    switch (naltype) {
+    case NAL_UNIT_CODED_SLICE_BLA_W_LP:
+    case NAL_UNIT_CODED_SLICE_BLA_W_RADL:
+    case NAL_UNIT_CODED_SLICE_BLA_N_LP:
+    case NAL_UNIT_CODED_SLICE_IDR_W_RADL:
+    case NAL_UNIT_CODED_SLICE_IDR_N_LP:
+    case NAL_UNIT_CODED_SLICE_CRA:
+        return 1;
+    default:
+        return 0;
+    }
+}
+
+static int x265_single_close( EncoderWrapper* wrapper, int tile_idx )
+{
+    x265Context* ctx = (x265Context*)wrapper->tile_info[tile_idx].enc_ctx;
+    
+    ctx->api->param_free(ctx->params);
+
+    if (ctx->encoder)
+        ctx->api->encoder_close(ctx->encoder);
+
+    return 0;
+}
+
+static int x265_single_init( EncoderWrapper* wrapper, int tile_idx )
+{
+    x265Context* ctx = wrapper->tile_info[tile_idx].enc_ctx;
+    AVCodecContext* avctx = wrapper->avctx;
+
+    ctx->api = x265_api_get(av_pix_fmt_desc_get(avctx->pix_fmt)->comp[0].depth);
+    if (!ctx->api)
+        ctx->api = x265_api_get(0);
+
+    ctx->params = ctx->api->param_alloc();
+    if (!ctx->params) {
+        av_log(avctx, AV_LOG_ERROR, "Could not allocate x265 param structure.\n");
+        return AVERROR(ENOMEM);
+    }
+
+    if (ctx->api->param_default_preset(ctx->params, ctx->preset, ctx->tune) < 0) {
+        int i;
+
+        av_log(avctx, AV_LOG_ERROR, "Error setting preset/tune %s/%s.\n", ctx->preset, ctx->tune);
+        av_log(avctx, AV_LOG_INFO, "Possible presets:");
+        for (i = 0; x265_preset_names[i]; i++)
+            av_log(avctx, AV_LOG_INFO, " %s", x265_preset_names[i]);
+
+        av_log(avctx, AV_LOG_INFO, "\n");
+        av_log(avctx, AV_LOG_INFO, "Possible tunes:");
+        for (i = 0; x265_tune_names[i]; i++)
+            av_log(avctx, AV_LOG_INFO, " %s", x265_tune_names[i]);
+
+        av_log(avctx, AV_LOG_INFO, "\n");
+
+        return AVERROR(EINVAL);
+    }
+
+    ctx->params->frameNumThreads = avctx->thread_count;
+    ctx->params->fpsNum          = avctx->time_base.den;
+    ctx->params->fpsDenom        = avctx->time_base.num * avctx->ticks_per_frame;
+    ctx->params->sourceWidth     = wrapper->tile_info[tile_idx].tWidth;
+    ctx->params->sourceHeight    = wrapper->tile_info[tile_idx].tHeight;
+    ctx->params->bEnablePsnr     = !!(avctx->flags & AV_CODEC_FLAG_PSNR);
+    ctx->params->bOpenGOP        = !(avctx->flags & AV_CODEC_FLAG_CLOSED_GOP);
+
+    /* Tune the CTU size based on input resolution. */
+    if (ctx->params->sourceWidth < 64 || ctx->params->sourceHeight < 64)
+        ctx->params->maxCUSize = 32;
+    if (ctx->params->sourceWidth < 32 || ctx->params->sourceHeight < 32)
+        ctx->params->maxCUSize = 16;
+    if (ctx->params->sourceWidth < 16 || ctx->params->sourceHeight < 16) {
+        av_log(avctx, AV_LOG_ERROR, "Image size is too small (%dx%d).\n",
+               ctx->params->sourceWidth, ctx->params->sourceHeight);
+        return AVERROR(EINVAL);
+    }
+
+    if ((avctx->color_primaries <= AVCOL_PRI_SMPTE432 &&
+         avctx->color_primaries != AVCOL_PRI_UNSPECIFIED) ||
+        (avctx->color_trc <= AVCOL_TRC_ARIB_STD_B67 &&
+         avctx->color_trc != AVCOL_TRC_UNSPECIFIED) ||
+        (avctx->colorspace <= AVCOL_SPC_ICTCP &&
+         avctx->colorspace != AVCOL_SPC_UNSPECIFIED)) {
+
+        ctx->params->vui.bEnableVideoSignalTypePresentFlag  = 1;
+        ctx->params->vui.bEnableColorDescriptionPresentFlag = 1;
+
+        // x265 validates the parameters internally
+        ctx->params->vui.colorPrimaries          = avctx->color_primaries;
+        ctx->params->vui.transferCharacteristics = avctx->color_trc;
+        ctx->params->vui.matrixCoeffs            = avctx->colorspace;
+    }
+
+    if (avctx->sample_aspect_ratio.num > 0 && avctx->sample_aspect_ratio.den > 0) {
+        char sar[12];
+        int sar_num, sar_den;
+
+        av_reduce(&sar_num, &sar_den,
+                  avctx->sample_aspect_ratio.num,
+                  avctx->sample_aspect_ratio.den, 65535);
+        snprintf(sar, sizeof(sar), "%d:%d", sar_num, sar_den);
+        if (ctx->api->param_parse(ctx->params, "sar", sar) == X265_PARAM_BAD_VALUE) {
+            av_log(avctx, AV_LOG_ERROR, "Invalid SAR: %d:%d.\n", sar_num, sar_den);
+            return AVERROR_INVALIDDATA;
+        }
+    }
+
+    switch (avctx->pix_fmt) {
+    case AV_PIX_FMT_YUV420P:
+    case AV_PIX_FMT_YUV420P10:
+    case AV_PIX_FMT_YUV420P12:
+        ctx->params->internalCsp = X265_CSP_I420;
+        break;
+    case AV_PIX_FMT_YUV422P:
+    case AV_PIX_FMT_YUV422P10:
+    case AV_PIX_FMT_YUV422P12:
+        ctx->params->internalCsp = X265_CSP_I422;
+        break;
+    case AV_PIX_FMT_GBRP:
+    case AV_PIX_FMT_GBRP10:
+    case AV_PIX_FMT_GBRP12:
+        ctx->params->vui.matrixCoeffs = AVCOL_SPC_RGB;
+        ctx->params->vui.bEnableVideoSignalTypePresentFlag  = 1;
+        ctx->params->vui.bEnableColorDescriptionPresentFlag = 1;
+    case AV_PIX_FMT_YUV444P:
+    case AV_PIX_FMT_YUV444P10:
+    case AV_PIX_FMT_YUV444P12:
+        ctx->params->internalCsp = X265_CSP_I444;
+        break;
+    case AV_PIX_FMT_GRAY8:
+    case AV_PIX_FMT_GRAY10:
+    case AV_PIX_FMT_GRAY12:
+        if (ctx->api->api_build_number < 85) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "libx265 version is %d, must be at least 85 for gray encoding.\n",
+                   ctx->api->api_build_number);
+            return AVERROR_INVALIDDATA;
+        }
+        ctx->params->internalCsp = X265_CSP_I400;
+        break;
+    }
+
+    if (ctx->crf >= 0) {
+        char crf[6];
+
+        snprintf(crf, sizeof(crf), "%2.2f", ctx->crf);
+        if (ctx->api->param_parse(ctx->params, "crf", crf) == X265_PARAM_BAD_VALUE) {
+            av_log(avctx, AV_LOG_ERROR, "Invalid crf: %2.2f.\n", ctx->crf);
+            return AVERROR(EINVAL);
+        }
+    } else if (ctx->bit_rate > 0) {
+        ctx->params->rc.bitrate         = ctx->bit_rate / 1000;
+        ctx->params->rc.rateControlMode = X265_RC_ABR;
+    }
+
+    ctx->params->rc.vbvBufferSize = ctx->bit_rate * 2 / 3000;
+    ctx->params->rc.vbvMaxBitrate = ctx->rc_max_rate    / 1000;
+
+    if (!(avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER))
+        ctx->params->bRepeatHeaders = 1;
+
+    if (ctx->x265_opts) {
+        AVDictionary *dict    = NULL;
+        AVDictionaryEntry *en = NULL;
+
+        if (!av_dict_parse_string(&dict, ctx->x265_opts, "=", ":", 0)) {
+            while ((en = av_dict_get(dict, "", en, AV_DICT_IGNORE_SUFFIX))) {
+                int parse_ret = ctx->api->param_parse(ctx->params, en->key, en->value);
+
+                switch (parse_ret) {
+                case X265_PARAM_BAD_NAME:
+                    av_log(avctx, AV_LOG_WARNING,
+                          "Unknown option: %s.\n", en->key);
+                    break;
+                case X265_PARAM_BAD_VALUE:
+                    av_log(avctx, AV_LOG_WARNING,
+                          "Invalid value for %s: %s.\n", en->key, en->value);
+                    break;
+                default:
+                    break;
+                }
+            }
+            av_dict_free(&dict);
+        }
+    }
+
+    if (ctx->params->rc.vbvBufferSize && avctx->rc_initial_buffer_occupancy > 1000 &&
+        ctx->params->rc.vbvBufferInit == 0.9) {
+        ctx->params->rc.vbvBufferInit = (float)avctx->rc_initial_buffer_occupancy / 1000;
+    }
+
+    if (ctx->profile) {
+        if (ctx->api->param_apply_profile(ctx->params, ctx->profile) < 0) {
+            int i;
+            av_log(avctx, AV_LOG_ERROR, "Invalid or incompatible profile set: %s.\n", ctx->profile);
+            av_log(avctx, AV_LOG_INFO, "Possible profiles:");
+            for (i = 0; x265_profile_names[i]; i++)
+                av_log(avctx, AV_LOG_INFO, " %s", x265_profile_names[i]);
+            av_log(avctx, AV_LOG_INFO, "\n");
+            return AVERROR(EINVAL);
+        }
+    }
+
+    ctx->encoder = ctx->api->encoder_open(ctx->params);
+    if (!ctx->encoder) {
+        av_log(avctx, AV_LOG_ERROR, "Cannot open libx265 encoder.\n");
+        x265_single_close(wrapper, tile_idx);
+        return AVERROR_INVALIDDATA;
+    }
+
+/*    if (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {
+        x265_nal *nal;
+        int nnal;
+
+        avctx->extradata_size = ctx->api->encoder_headers(ctx->encoder, &nal, &nnal);
+        if (avctx->extradata_size <= 0) {
+            av_log(avctx, AV_LOG_ERROR, "Cannot encode headers.\n");
+            libx265_encode_close(avctx);
+            return AVERROR_INVALIDDATA;
+        }
+
+        avctx->extradata = av_malloc(avctx->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);
+        if (!avctx->extradata) {
+            av_log(avctx, AV_LOG_ERROR,
+                   "Cannot allocate HEVC header of size %d.\n", avctx->extradata_size);
+            libx265_encode_close(avctx);
+            return AVERROR(ENOMEM);
+        }
+
+        memcpy(avctx->extradata, nal[0].payload, avctx->extradata_size);
+    }
+*/
+    return 0;
+}
+
+static int x265_single_frame( EncoderWrapper* wrapper, int tile_idx, AVPacket *pkt, const AVFrame *pic, int *got_packet  )
+{
+    x265Context* ctx = (x265Context*)wrapper->tile_info[tile_idx].enc_ctx;
+    AVCodecContext* avctx = wrapper->avctx;
+    AVFrame* tile_pic = NULL;
+    x265_picture x265pic;
+    x265_picture x265pic_out = { 0 };
+    x265_nal *nal;
+    uint8_t *dst;
+    int payload = 0;
+    int nnal;
+    int ret;
+    int i;
+
+    ctx->api->picture_init(ctx->params, &x265pic);
+
+    if (pic) {
+        get_tile_frame_nocopy(wrapper, tile_idx, pic, &tile_pic);
+
+        for (i = 0; i < 3; i++) {
+           x265pic.planes[i] = tile_pic->data[i];
+           x265pic.stride[i] = tile_pic->linesize[i];
+        }
+
+        x265pic.pts      = pic->pts;
+        x265pic.bitDepth = av_pix_fmt_desc_get(avctx->pix_fmt)->comp[0].depth;
+
+        x265pic.sliceType = pic->pict_type == AV_PICTURE_TYPE_I ?
+                                              (ctx->forced_idr ? X265_TYPE_IDR : X265_TYPE_I) :
+                            pic->pict_type == AV_PICTURE_TYPE_P ? X265_TYPE_P :
+                            pic->pict_type == AV_PICTURE_TYPE_B ? X265_TYPE_B :
+                            X265_TYPE_AUTO;
+    }
+
+    ret = ctx->api->encoder_encode(ctx->encoder, &nal, &nnal,
+                                   pic ? &x265pic : NULL, &x265pic_out);
+
+    if(NULL!= tile_pic) av_frame_free(&tile_pic);
+
+    if (ret < 0)
+        return AVERROR_EXTERNAL;
+
+    if (!nnal)
+        return 0;
+
+    ///FIXME, need to assign each NAL to a packet if stitching library can only process one NAL
+    for (i = 0; i < nnal; i++)
+        payload += nal[i].sizeBytes;
+
+    /*ret = ff_alloc_packet2(avctx, pkt, payload, payload);
+    if (ret < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Error getting output packet.\n");
+        return ret;
+    }*/
+    pkt->data = malloc(payload);
+    pkt->size = payload;
+    dst = pkt->data;
+
+    for (i = 0; i < nnal; i++) {
+        memcpy(dst, nal[i].payload, nal[i].sizeBytes);
+        dst += nal[i].sizeBytes;
+
+        if (is_keyframe(nal[i].type))
+            pkt->flags |= AV_PKT_FLAG_KEY;
+    }
+
+    pkt->pts = x265pic_out.pts;
+    pkt->dts = x265pic_out.dts;
+
+#if FF_API_CODED_FRAME
+FF_DISABLE_DEPRECATION_WARNINGS
+    switch (x265pic_out.sliceType) {
+    case X265_TYPE_IDR:
+    case X265_TYPE_I:
+        avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;
+        break;
+    case X265_TYPE_P:
+        avctx->coded_frame->pict_type = AV_PICTURE_TYPE_P;
+        break;
+    case X265_TYPE_B:
+        avctx->coded_frame->pict_type = AV_PICTURE_TYPE_B;
+        break;
+    }
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+
+#if X265_BUILD >= 130
+    if (x265pic_out.sliceType == X265_TYPE_B)
+#else
+    if (x265pic_out.frameData.sliceType == 'b')
+#endif
+        pkt->flags |= AV_PKT_FLAG_DISPOSABLE;
+
+    *got_packet = 1;
+
+    return 0;
+}
+
+int libx265_enc_close(void* ctx)
+{
+    EncoderWrapper* wrapper = (EncoderWrapper*)ctx;
+    x265Context* x265_ctx = NULL;
+
+    for(int i=0; i<wrapper->tile_num; i++){
+        x265_ctx = (x265Context*)wrapper->tile_info[i].enc_ctx;
+        if( NULL != x265_ctx){
+            x265_single_close(wrapper, i);
+            free(x265_ctx);
+        }
+        wrapper->tile_info[i].enc_ctx = NULL;
+    }
+
+    return 0;
+}
+
+int libx265_enc_init(void* ctx)
+{
+    EncoderWrapper* wrapper = (EncoderWrapper*)ctx;
+    x265Context* x265_ctx = NULL;
+
+    for(int i=0; i<wrapper->tile_num; i++){
+        x265_ctx = malloc(sizeof(x265Context));
+        x265_ctx->api         = NULL;
+        x265_ctx->encoder     = NULL;
+        x265_ctx->x265_opts   = wrapper->enc_param;
+        x265_ctx->preset      = "fast";
+        x265_ctx->tune        = "psnr";
+        x265_ctx->crf         = -1;
+        x265_ctx->profile     = "main";
+        x265_ctx->forced_idr  = 0;
+        x265_ctx->bit_rate    = wrapper->tile_info[i].tBitrate;
+        x265_ctx->rc_max_rate = wrapper->tile_info[i].tMaxrate;
+        wrapper->tile_info[i].enc_ctx = x265_ctx;
+        x265_single_init(wrapper, i);
+    }
+    return 0;
+}
+
+int libx265_enc_frame(void* ctx, AVPacket *pkt, const AVFrame *pic, int *got_packet)
+{
+    EncoderWrapper* wrapper = (EncoderWrapper*)ctx;
+    int ret = 0;
+    int       got_pkt = 0;
+    
+    for(int i=0; i<wrapper->tile_num; i++){
+        if( wrapper->tile_info[i].eos ) continue;
+        got_pkt = 0;
+        AVPacket tile_pkts = {0};
+
+        ret = x265_single_frame(wrapper, i, &tile_pkts, pic, &got_pkt);
+
+        if( got_pkt ){
+            av_log(wrapper->avctx, AV_LOG_DEBUG, "**********tile id = %d receive_packet got packet!!!\n", i);
+            av_fifo_generic_write( wrapper->tile_info[i].outpkt_fifo, &tile_pkts, sizeof(AVPacket), NULL);
+        }else{
+            av_packet_unref(&tile_pkts);
+            free(tile_pkts.data);
+        }
+        if( NULL==pic && !got_pkt ){
+            av_log(wrapper->avctx, AV_LOG_DEBUG, "tile id = %d EOS!!!\n", i);
+            wrapper->tile_info[i].eos = 1;
+        }
+    }
+    
+    //FIXME, suppose all encoder has the rhythm to get packet, so there is no buffer in the first time
+    ret = bs_tile_stitching(wrapper, pkt);
+    
+    if( AVERROR_EOF == ret ){
+        return AVERROR_EOF;
+    }
+    *got_packet = 1;
+
+    if( -1 == ret ) *got_packet = 0;
+
+    return 0;
+}
\ No newline at end of file
diff -urN FFmpeg/libavfilter/allfilters.c FFmpeg-patched/libavfilter/allfilters.c
--- FFmpeg/libavfilter/allfilters.c	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavfilter/allfilters.c	2020-09-27 13:35:13.453526545 +0800
@@ -406,6 +406,7 @@
 extern AVFilter ff_vf_tmix;
 extern AVFilter ff_vf_tonemap;
 extern AVFilter ff_vf_tonemap_opencl;
+extern AVFilter ff_vf_transform360;
 extern AVFilter ff_vf_tonemap_vaapi;
 extern AVFilter ff_vf_tpad;
 extern AVFilter ff_vf_transpose;
@@ -444,6 +445,7 @@
 extern AVFilter ff_vf_zmq;
 extern AVFilter ff_vf_zoompan;
 extern AVFilter ff_vf_zscale;
+extern AVFilter ff_vf_xcam;

 extern AVFilter ff_vsrc_allrgb;
 extern AVFilter ff_vsrc_allyuv;
diff -urN FFmpeg/libavfilter/Makefile FFmpeg-patched/libavfilter/Makefile
--- FFmpeg/libavfilter/Makefile	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavfilter/Makefile	2020-09-27 13:35:13.450526545 +0800
@@ -143,6 +143,7 @@
 OBJS-$(CONFIG_VIBRATO_FILTER)                += af_vibrato.o generate_wave_table.o
 OBJS-$(CONFIG_VOLUME_FILTER)                 += af_volume.o
 OBJS-$(CONFIG_VOLUMEDETECT_FILTER)           += af_volumedetect.o
+OBJS-$(CONFIG_XCAM_FILTER)                   += vf_xcam.o

 OBJS-$(CONFIG_AEVALSRC_FILTER)               += aeval.o
 OBJS-$(CONFIG_AFIRSRC_FILTER)                += asrc_afirsrc.o
@@ -426,6 +427,7 @@
 OBJS-$(CONFIG_TONEMAP_FILTER)                += vf_tonemap.o colorspace.o
 OBJS-$(CONFIG_TONEMAP_OPENCL_FILTER)         += vf_tonemap_opencl.o colorspace.o opencl.o \
                                                 opencl/tonemap.o opencl/colorspace_common.o
+OBJS-$(CONFIG_TRANSFORM360_FILTER)           += vf_transform360.o
 OBJS-$(CONFIG_TONEMAP_VAAPI_FILTER)          += vf_tonemap_vaapi.o vaapi_vpp.o
 OBJS-$(CONFIG_TPAD_FILTER)                   += vf_tpad.o
 OBJS-$(CONFIG_TRANSPOSE_FILTER)              += vf_transpose.o
diff -urN FFmpeg/libavfilter/vf_transform360.c FFmpeg-patched/libavfilter/vf_transform360.c
--- FFmpeg/libavfilter/vf_transform360.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavfilter/vf_transform360.c	2020-09-27 13:35:13.495526541 +0800
@@ -0,0 +1,483 @@
+/**
+ * Copyright (c) 2015-present, Facebook, Inc.
+ * All rights reserved.
+ *
+ * This source code is licensed under the license found in the
+ * LICENSE file in the root directory of this source tree.
+ */
+
+/**
+ * @file
+ * transform360 video filter
+ */
+
+#include "libavutil/avassert.h"
+#include "libavutil/avstring.h"
+#include "libavutil/eval.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/mem.h"
+#include "libavutil/parseutils.h"
+#include "avfilter.h"
+#include "internal.h"
+#include "video.h"
+#include <stdio.h>
+
+#include "transform360/VideoFrameTransformHandler.h"
+#include "transform360/VideoFrameTransformHelper.h"
+
+static const char *const var_names[] = {
+    "out_w",  "ow",
+    "out_h",  "oh",
+    NULL
+};
+
+enum var_name {
+    VAR_OUT_W, VAR_OW,
+    VAR_OUT_H, VAR_OH,
+    VARS_NB
+};
+
+/*
+   MMMMT
+   MMMMB
+   */
+
+typedef struct TransformContext {
+    const AVClass *class;
+    int w, h;
+    int out_map_planes;
+
+    AVDictionary *opts;
+    char *w_expr;               ///< width  expression string
+    char *h_expr;               ///< height expression string
+    char *size_str;
+    int cube_edge_length;
+    int max_cube_edge_length;
+    int max_output_h;
+    int max_output_w;
+    int input_layout;
+    int output_layout;
+    int input_stereo_format;
+    int output_stereo_format;
+    int vflip;
+    int planes;
+    float input_expand_coef;
+    float expand_coef;
+    int is_horizontal_offset;
+    float fixed_yaw;    ///< Yaw (asimuth) angle, degrees
+    float fixed_pitch;  ///< Pitch (elevation) angle, degrees
+    float fixed_roll;   ///< Roll (tilt) angle, degrees
+    float fixed_hfov;   ///< Horizontal field of view, degrees
+    float fixed_vfov;   ///< Vertical field of view, degrees
+    float fixed_cube_offcenter_x; // offcenter projection x
+    float fixed_cube_offcenter_y; // offcenter projection y
+    float fixed_cube_offcenter_z; // offcenter projection z
+
+    // openCV-based transform parameters
+    VideoFrameTransform* transform;
+    int interpolation_alg;
+    float width_scale_factor;
+    float height_scale_factor;
+    int enable_low_pass_filter;
+    float kernel_height_scale_factor;
+    float min_kernel_half_height;
+    float max_kernel_half_height;
+    int enable_multi_threading;
+    int num_vertical_segments;
+    int num_horizontal_segments;
+    int adjust_kernel;
+    float kernel_adjust_factor;
+
+} TransformContext;
+
+static inline void update_plane_sizes(
+    AVPixFmtDescriptor* desc,
+    int* in_w, int* in_h, int* out_w, int* out_h) {
+    *in_w = FF_CEIL_RSHIFT(*in_w, desc->log2_chroma_w);
+    *in_h = FF_CEIL_RSHIFT(*in_h, desc->log2_chroma_h);
+    *out_w = FF_CEIL_RSHIFT(*out_w, desc->log2_chroma_w);
+    *out_h = FF_CEIL_RSHIFT(*out_h, desc->log2_chroma_h);
+}
+
+static inline int generate_map(
+    TransformContext *s, AVFilterLink *inlink,
+    AVFilterLink *outlink, AVFrame *in) {
+    AVFilterContext *ctx = outlink->src;
+    int ret = 0;
+
+    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(outlink->format);
+    s->planes = av_pix_fmt_count_planes(outlink->format);
+    s->out_map_planes = 2;
+
+    FrameTransformContext frame_transform_ctx = (FrameTransformContext) {
+      .input_layout = s->input_layout,
+      .output_layout = s->output_layout,
+      .input_stereo_format = s->input_stereo_format,
+      .output_stereo_format = s->output_stereo_format,
+      .vflip = s->vflip,
+      .input_expand_coef = s->input_expand_coef,
+      .expand_coef = s->expand_coef,
+      .interpolation_alg = s->interpolation_alg,
+      .width_scale_factor = s->width_scale_factor,
+      .height_scale_factor = s->height_scale_factor,
+      .fixed_yaw = s->fixed_yaw,
+      .fixed_pitch = s->fixed_pitch,
+      .fixed_roll = s->fixed_roll,
+      .fixed_hfov = s->fixed_hfov,
+      .fixed_vfov = s->fixed_vfov,
+      .fixed_cube_offcenter_x = s->fixed_cube_offcenter_x,
+      .fixed_cube_offcenter_y = s->fixed_cube_offcenter_y,
+      .fixed_cube_offcenter_z = s->fixed_cube_offcenter_z,
+      .is_horizontal_offset = s->is_horizontal_offset,
+      .enable_low_pass_filter = s->enable_low_pass_filter,
+      .kernel_height_scale_factor = s->kernel_height_scale_factor,
+      .min_kernel_half_height = s->min_kernel_half_height,
+      .max_kernel_half_height = s->max_kernel_half_height,
+      .enable_multi_threading = s->enable_multi_threading,
+      .num_vertical_segments = s->num_vertical_segments,
+      .num_horizontal_segments = s->num_horizontal_segments,
+      .adjust_kernel = s->adjust_kernel,
+      .kernel_adjust_factor = s->kernel_adjust_factor};
+
+    s->transform = VideoFrameTransform_new(&frame_transform_ctx);
+    if (!s->transform) {
+      return AVERROR(ENOMEM);
+    }
+
+    int in_w, in_h, out_w, out_h;
+    for (int plane = 0; plane < s->out_map_planes; ++plane) {
+      out_w = outlink->w;
+      out_h = outlink->h;
+      in_w = inlink->w;
+      in_h = inlink->h;
+
+      if (plane == 1) {
+        update_plane_sizes(desc, &in_w, &in_h, &out_w, &out_h);
+      }
+
+      if (!VideoFrameTransform_generateMapForPlane(
+            s->transform, in_w, in_h, out_w, out_h, plane)) {
+        av_log(ctx, AV_LOG_INFO, "Failed to generate map for plane %d\n", plane);
+        return AVERROR(EINVAL);
+      }
+    }
+
+    return 0;
+}
+
+static int config_output(AVFilterLink *outlink) {
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = outlink->src->inputs[0];
+    TransformContext *s = ctx->priv;
+    double var_values[VARS_NB], res;
+    char *expr;
+    int ret;
+
+    var_values[VAR_OUT_W] = var_values[VAR_OW] = NAN;
+    var_values[VAR_OUT_H] = var_values[VAR_OH] = NAN;
+
+    if (s->input_stereo_format == STEREO_FORMAT_GUESS) {
+        int aspect_ratio = inlink->w / inlink->h;
+        if (aspect_ratio == 1)
+            s->input_stereo_format = STEREO_FORMAT_TB;
+        else if (aspect_ratio == 4)
+            s->input_stereo_format = STEREO_FORMAT_LR;
+        else
+            s->input_stereo_format = STEREO_FORMAT_MONO;
+    }
+
+    if (s->output_stereo_format == STEREO_FORMAT_GUESS) {
+        if (s->input_stereo_format == STEREO_FORMAT_MONO) {
+            s->output_stereo_format = STEREO_FORMAT_MONO;
+        } else {
+            s->output_stereo_format =
+                (s->output_layout == LAYOUT_CUBEMAP_23_OFFCENTER)
+                    ? STEREO_FORMAT_LR
+                    : STEREO_FORMAT_TB;
+        }
+    }
+
+    if (s->max_cube_edge_length > 0) {
+        if (s->input_stereo_format == STEREO_FORMAT_LR) {
+            s->cube_edge_length = inlink->w / 8;
+        } else {
+            s->cube_edge_length = inlink->w / 4;
+        }
+
+        // do not exceed the max length supplied
+        if (s->cube_edge_length > s->max_cube_edge_length) {
+            s->cube_edge_length = s->max_cube_edge_length;
+        }
+    }
+
+    // ensure cube edge length is a multiple of 16 by rounding down
+    // so that macroblocks do not cross cube edge boundaries
+    s->cube_edge_length = s->cube_edge_length - (s->cube_edge_length % 16);
+
+    if (s->cube_edge_length > 0) {
+         if (s->output_layout == LAYOUT_CUBEMAP_32) {
+            outlink->w = s->cube_edge_length * 3;
+            outlink->h = s->cube_edge_length * 2;
+
+        } else if (s->output_layout == LAYOUT_CUBEMAP_23_OFFCENTER) {
+            outlink->w = s->cube_edge_length * 2;
+            outlink->h = s->cube_edge_length * 3;
+        }
+    } else {
+        var_values[VAR_OUT_W] = var_values[VAR_OW] = NAN;
+        var_values[VAR_OUT_H] = var_values[VAR_OH] = NAN;
+
+        av_expr_parse_and_eval(&res, (expr = s->w_expr),
+                var_names, var_values,
+                NULL, NULL, NULL, NULL, NULL, 0, ctx);
+        s->w = var_values[VAR_OUT_W] = var_values[VAR_OW] = res;
+        if ((ret = av_expr_parse_and_eval(&res, (expr = s->h_expr),
+                        var_names, var_values,
+                        NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0) {
+            av_log(NULL, AV_LOG_ERROR,
+                    "Error when evaluating the expression '%s'.\n"
+                    "Maybe the expression for out_w:'%s' or for out_h:'%s' is self-referencing.\n",
+                    expr, s->w_expr, s->h_expr);
+            return ret;
+        }
+        s->h = var_values[VAR_OUT_H] = var_values[VAR_OH] = res;
+        /* evaluate again the width, as it may depend on the output height */
+        if ((ret = av_expr_parse_and_eval(&res, (expr = s->w_expr),
+                        var_names, var_values,
+                        NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0) {
+            av_log(NULL, AV_LOG_ERROR,
+                    "Error when evaluating the expression '%s'.\n"
+                    "Maybe the expression for out_w:'%s' or for out_h:'%s' is self-referencing.\n",
+                    expr, s->w_expr, s->h_expr);
+            return ret;
+        }
+        s->w = res;
+
+        outlink->w = s->w;
+        outlink->h = s->h;
+    }
+
+    if (s->output_stereo_format == STEREO_FORMAT_TB) {
+        outlink->h *= 2;
+        s->h *= 2;
+    } else if (s->output_stereo_format == STEREO_FORMAT_LR) {
+        outlink->w *= 2;
+        s->w *= 2;
+    }
+
+    av_log(ctx, AV_LOG_VERBOSE, "out_w:%d out_h:%d\n",
+            outlink->w, outlink->h);
+
+    return 0;
+}
+
+static av_cold int init_dict(AVFilterContext *ctx, AVDictionary **opts) {
+    TransformContext *s = ctx->priv;
+
+    if (s->size_str && (s->w_expr || s->h_expr)) {
+        av_log(ctx, AV_LOG_ERROR,
+                "Size and width/height expressions cannot be set at the same time.\n");
+        return AVERROR(EINVAL);
+    }
+
+    if (s->w_expr && !s->h_expr)
+        FFSWAP(char *, s->w_expr, s->size_str);
+
+    av_log(ctx, AV_LOG_VERBOSE, "w:%s h:%s\n",
+            s->w_expr, s->h_expr);
+
+    s->opts = *opts;
+    *opts = NULL;
+
+    return 0;
+}
+
+static av_cold void uninit(AVFilterContext *ctx) {
+    TransformContext *s = ctx->priv;
+
+    av_dict_free(&s->opts);
+    s->opts = NULL;
+
+    VideoFrameTransform_delete(s->transform);
+    s->transform = NULL;
+}
+
+static int filter_frame(AVFilterLink *inlink, AVFrame *in) {
+    AVFilterContext *ctx = inlink->dst;
+    TransformContext *s = ctx->priv;
+    AVFilterLink *outlink = ctx->outputs[0];
+    AVFrame *out;
+    av_log(ctx, AV_LOG_VERBOSE, "Frame\n");
+
+    // map not yet set
+    if (s->out_map_planes != 2) {
+      int result = generate_map(s, inlink, outlink, in);
+      if (result != 0) {
+          av_frame_free(&in);
+          return result;
+      }
+    }
+
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    av_log(ctx, AV_LOG_VERBOSE, "Got Frame %dx%d\n", outlink->w, outlink->h);
+
+    if (!out) {
+      av_frame_free(&in);
+      return AVERROR(ENOMEM);
+    }
+    av_frame_copy_props(out, in);
+    av_log(ctx, AV_LOG_VERBOSE, "Copied props \n");
+
+    uint8_t *in_data, *out_data;
+    int out_map_plane;
+    int in_w, in_h, out_w, out_h;
+    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(outlink->format);
+    for (int plane = 0; plane < s->planes; ++plane) {
+      in_data = in->data[plane];
+      av_assert1(in_data);
+      out_data = out->data[plane];
+      out_map_plane = (plane == 1 || plane == 2) ? 1 : 0;
+
+      out_w = outlink->w;
+      out_h = outlink->h;
+      in_w = inlink->w;
+      in_h = inlink->h;
+
+      if (plane >= 1) {
+        update_plane_sizes(desc, &in_w, &in_h, &out_w, &out_h);
+      }
+
+      if (!VideoFrameTransform_transformFramePlane(
+        s->transform,
+        in_data,
+        out_data,
+        in_w,
+        in_h,
+        in->linesize[plane],
+        out_w,
+        out_h,
+        out->linesize[plane],
+        out_map_plane,
+        plane)) {
+        return AVERROR(EINVAL);
+      }
+    }
+
+    av_frame_free(&in);
+    av_log(ctx, AV_LOG_VERBOSE, "Done freeing in \n");
+    return ff_filter_frame(outlink, out);
+}
+
+#define OFFSET(x) offsetof(TransformContext, x)
+#define FLAGS AV_OPT_FLAG_VIDEO_PARAM|AV_OPT_FLAG_FILTERING_PARAM
+
+static const AVOption transform360_options[] = {
+    { "w",             "Output video width",          OFFSET(w_expr),    AV_OPT_TYPE_STRING,        .flags = FLAGS },
+    { "width",         "Output video width",          OFFSET(w_expr),    AV_OPT_TYPE_STRING,        .flags = FLAGS },
+    { "h",             "Output video height",         OFFSET(h_expr),    AV_OPT_TYPE_STRING,        .flags = FLAGS },
+    { "height",        "Output video height",         OFFSET(h_expr),    AV_OPT_TYPE_STRING,        .flags = FLAGS },
+    { "size",          "set video size",              OFFSET(size_str), AV_OPT_TYPE_STRING, {.str = NULL}, 0, FLAGS },
+    { "s",             "set video size",              OFFSET(size_str), AV_OPT_TYPE_STRING, {.str = NULL}, 0, FLAGS },
+    { "is_horizontal_offset", "Whether to use offset on the horizontal plane only. It only affects yaw.", OFFSET(is_horizontal_offset), AV_OPT_TYPE_BOOL, {.i64 =   0},     0, 1,  .flags = FLAGS },
+    { "cube_edge_length", "Length of a cube edge (for cubic transform, overrides w and h, default 0 for off)",         OFFSET(cube_edge_length),    AV_OPT_TYPE_INT,  {.i64 = 0}, 0, 16384,  .flags = FLAGS },
+    { "max_cube_edge_length", "Max length of a cube edge (for cubic transform, overrides w, h, and cube_edge_length, default 0 for off)",   OFFSET(max_cube_edge_length),    AV_OPT_TYPE_INT,  {.i64 = 0}, 0, 16384,  .flags = FLAGS },
+    { "max_output_h", "Max height of the output video (for pyramid/cone transform, overrides pyramid_height, default 0 for off)",         OFFSET(max_output_h),    AV_OPT_TYPE_INT,  {.i64 = 0}, 0, 16384,  .flags = FLAGS },
+    { "max_output_w", "Max width of the output video (for pyramid/cone transform, overrides pyramid_height, default 0 for off)",         OFFSET(max_output_w),    AV_OPT_TYPE_INT,  {.i64 = 0}, 0, 16384,  .flags = FLAGS },
+    { "input_stereo_format", "Input video stereo format",         OFFSET(input_stereo_format),    AV_OPT_TYPE_INT,  {.i64 = STEREO_FORMAT_GUESS }, 0, STEREO_FORMAT_N - 1,  .flags = FLAGS, "stereo_format" },
+    { "output_stereo_format", "Output video stereo format",         OFFSET(output_stereo_format),    AV_OPT_TYPE_INT,  {.i64 = STEREO_FORMAT_GUESS }, 0, STEREO_FORMAT_N - 1,  .flags = FLAGS, "stereo_format" },
+    { "TB",      NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_TB },      0, 0, FLAGS, "stereo_format" },
+    { "LR",      NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_LR },      0, 0, FLAGS, "stereo_format" },
+    { "MONO",    NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_MONO },    0, 0, FLAGS, "stereo_format" },
+    { "GUESS",   NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_GUESS },   0, 0, FLAGS, "stereo_format" },
+    { "tb",      NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_TB },      0, 0, FLAGS, "stereo_format" },
+    { "lr",      NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_LR },      0, 0, FLAGS, "stereo_format" },
+    { "mono",    NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_MONO },    0, 0, FLAGS, "stereo_format" },
+    { "guess",   NULL, 0, AV_OPT_TYPE_CONST, {.i64 = STEREO_FORMAT_GUESS },   0, 0, FLAGS, "stereo_format" },
+    { "input_layout", "Input video layout format",          OFFSET(input_layout),     AV_OPT_TYPE_INT,  {.i64 = LAYOUT_EQUIRECT },   0, LAYOUT_N - 1,  .flags = FLAGS, "layout" },
+    { "output_layout", "Output video layout format",         OFFSET(output_layout),    AV_OPT_TYPE_INT,  {.i64 = LAYOUT_CUBEMAP_32 }, 0, LAYOUT_N - 1,  .flags = FLAGS, "layout" },
+    { "CUBEMAP_32",          NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_CUBEMAP_32 },          0, 0, FLAGS, "layout" },
+    { "CUBEMAP_23_OFFCENTER",NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_CUBEMAP_23_OFFCENTER },0, 0, FLAGS, "layout" },
+    { "EQUIRECT",NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_EQUIRECT },0, 0, FLAGS, "layout" },
+    { "BARREL",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_BARREL },  0, 0, FLAGS, "layout" },
+    { "EAC_32",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_EAC_32 },  0, 0, FLAGS, "layout" },
+    { "FLAT_FIXED",          NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_FLAT_FIXED },          0, 0, FLAGS, "layout" },
+    { "cubemap_32",          NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_CUBEMAP_32 },          0, 0, FLAGS, "layout" },
+    { "cubemap_23_offcenter",NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_CUBEMAP_23_OFFCENTER },0, 0, FLAGS, "layout" },
+    { "equirect",NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_EQUIRECT },0, 0, FLAGS, "layout" },
+    { "flat_fixed",          NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_FLAT_FIXED },          0, 0, FLAGS, "layout" },
+    { "barrel",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_BARREL },  0, 0, FLAGS, "layout" },
+    { "eac_32",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LAYOUT_EAC_32 },  0, 0, FLAGS, "layout" },
+    { "vflip", "Output video 2nd eye vertical flip (true, false)",         OFFSET(vflip),    AV_OPT_TYPE_INT, {.i64 = 0 }, 0, 1,     .flags = FLAGS, "vflip" },
+    { "false",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = 0 }, 0, 0, FLAGS, "vflip" },
+    { "true",   NULL, 0, AV_OPT_TYPE_CONST, {.i64 = 1 }, 0, 0, FLAGS, "vflip" },
+    { "input_expand_coef", "Expansion coeffiecient of the input",         OFFSET(input_expand_coef),    AV_OPT_TYPE_FLOAT,  {.dbl=1.01f}, 0, 10,  .flags = FLAGS },
+    { "expand_coef", "Expansion coeffiecient for each face in cubemap (default 1.01)",         OFFSET(expand_coef),    AV_OPT_TYPE_FLOAT,  {.dbl=1.01f}, 0, 10,  .flags = FLAGS },
+    { "yaw", "View orientation for flat_fixed projection, degrees",   OFFSET(fixed_yaw),          AV_OPT_TYPE_FLOAT,   {.dbl =   0.0}, -360, 360,  .flags = FLAGS },
+    { "pitch", "View orientation for flat_fixed projection, degrees", OFFSET(fixed_pitch),        AV_OPT_TYPE_FLOAT,   {.dbl =   0.0}, -180, 180,  .flags = FLAGS },
+    { "roll", "View orientation for flat_fixed projection, degrees",  OFFSET(fixed_roll),         AV_OPT_TYPE_FLOAT,   {.dbl =   0.0}, -180, 180,  .flags = FLAGS },
+    { "hfov", "Horizontal field of view for flat_fixed projection, degrees (default 120)",  OFFSET(fixed_hfov), AV_OPT_TYPE_FLOAT,   {.dbl = 120.0}, -360, 360,  .flags = FLAGS },
+    { "vfov", "Vertical field of view for flat_fixed projection, degrees (default 110)",     OFFSET(fixed_vfov), AV_OPT_TYPE_FLOAT,   {.dbl = 110.0}, -180, 180,  .flags = FLAGS },
+    { "cube_offcenter_x", "Offcenter cube displacement x",   OFFSET(fixed_cube_offcenter_x),          AV_OPT_TYPE_FLOAT,   {.dbl =   0.0}, -1, 1,  .flags = FLAGS },
+    { "cube_offcenter_y", "Offcenter cube displacement y",   OFFSET(fixed_cube_offcenter_y),          AV_OPT_TYPE_FLOAT,   {.dbl =   0.0}, -1, 1,  .flags = FLAGS },
+    { "cube_offcenter_z", "Offcenter cube displacement z",   OFFSET(fixed_cube_offcenter_z),          AV_OPT_TYPE_FLOAT,   {.dbl =   0.0}, -1, 1,  .flags = FLAGS },
+    { "NEAREST",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = NEAREST },  0, 0, FLAGS, "interpolation_alg" },
+    { "LINEAR",   NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LINEAR },   0, 0, FLAGS, "interpolation_alg" },
+    { "CUBIC",    NULL, 0, AV_OPT_TYPE_CONST, {.i64 = CUBIC },    0, 0, FLAGS, "interpolation_alg" },
+    { "LANCZOS4", NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LANCZOS4 }, 0, 0, FLAGS, "interpolation_alg" },
+    { "nearest",  NULL, 0, AV_OPT_TYPE_CONST, {.i64 = NEAREST },  0, 0, FLAGS, "interpolation_alg" },
+    { "linear",   NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LINEAR },   0, 0, FLAGS, "interpolation_alg" },
+    { "cubic",    NULL, 0, AV_OPT_TYPE_CONST, {.i64 = CUBIC },    0, 0, FLAGS, "interpolation_alg" },
+    { "lanczos4", NULL, 0, AV_OPT_TYPE_CONST, {.i64 = LANCZOS4 }, 0, 0, FLAGS, "interpolation_alg" },
+    { "interpolation_alg", "Interpolation algorithm", OFFSET(interpolation_alg), AV_OPT_TYPE_INT, {.i64 = 2}, 0, 4, .flags = FLAGS, "interpolation_alg"},
+    { "width_scale_factor", "Scale factor of width for antialiasing", OFFSET(width_scale_factor), AV_OPT_TYPE_FLOAT, {.dbl = 1.0}, 0, 10, .flags = FLAGS, "width_scale_factor" },
+    { "height_scale_factor", "Scale factor of height for antialiasing", OFFSET(height_scale_factor), AV_OPT_TYPE_FLOAT, {.dbl = 1.0}, 0, 10, .flags = FLAGS, "height_scale_factor" },
+    { "enable_low_pass_filter", "Enable low pass filter-based antialiasing", OFFSET(enable_low_pass_filter), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, .flags = FLAGS, "enable_low_pass_filter" },
+    { "enable_multi_threading", "Enable multi-threading to speed up low pass filter-based antialiasing", OFFSET(enable_multi_threading), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, .flags = FLAGS, "enable_multi_threading" },
+    { "num_vertical_segments" , "Number of vertical segments per frame plane", OFFSET(num_vertical_segments), AV_OPT_TYPE_INT, {.i64 = 5}, 2, 500, .flags = FLAGS, "num_vertical_segments" },
+    { "num_horizontal_segments" , "Number of horizontal segments per frame plane", OFFSET(num_horizontal_segments), AV_OPT_TYPE_INT, {.i64 = 1}, 1, 500, .flags = FLAGS, "num_horizontal_segments" },
+    { "kernel_height_scale_factor", "Factor to scale the calculated kernel height for low pass filtering", OFFSET(kernel_height_scale_factor), AV_OPT_TYPE_FLOAT, {.dbl = 1.0}, 0.1, 100.0, .flags = FLAGS, "kernel_height_scale_factor" },
+    { "min_kernel_half_height", "Half of the mininum kernel height", OFFSET(min_kernel_half_height), AV_OPT_TYPE_FLOAT, {.dbl = 1.0}, 0.5, 200, .flags = FLAGS, "min_kernel_half_height" },
+    { "max_kernel_half_height", "The maximum value of the kernel height", OFFSET(max_kernel_half_height), AV_OPT_TYPE_FLOAT, {.dbl = 10000.0}, 0.5, 100000, .flags = FLAGS, "max_kernel_half_height" },
+    { "adjust_kernel", "Enable adjustment of kernel", OFFSET(adjust_kernel), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, .flags = FLAGS, "adjust_kernel" },
+    { "kernel_adjust_factor", "Factor to further adjust the kernel size", OFFSET(kernel_adjust_factor), AV_OPT_TYPE_FLOAT, {.dbl = 1.0}, 0.1, 100.0, .flags = FLAGS, "kernel_adjust_factor" },
+    { NULL }
+};
+
+static const AVClass transform360_class = {
+    .class_name       = "transform360",
+    .item_name        = av_default_item_name,
+    .option           = transform360_options,
+    .version          = LIBAVUTIL_VERSION_INT,
+    .category         = AV_CLASS_CATEGORY_FILTER,
+};
+
+static const AVFilterPad avfilter_vf_transform_inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad avfilter_vf_transform_outputs[] = {
+    {
+        .name = "default",
+        .type = AVMEDIA_TYPE_VIDEO,
+        .config_props = config_output,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_transform360 = {
+    .name        = "transform360",
+    .description = NULL_IF_CONFIG_SMALL("Transforms equirectangular input video to the other format."),
+    .init_dict   = init_dict,
+    .uninit      = uninit,
+    .priv_size   = sizeof(TransformContext),
+    .priv_class  = &transform360_class,
+    .inputs      = avfilter_vf_transform_inputs,
+    .outputs     = avfilter_vf_transform_outputs,
+};
diff -urN FFmpeg/libavfilter/vf_xcam.c FFmpeg-patched/libavfilter/vf_xcam.c
--- FFmpeg/libavfilter/vf_xcam.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavfilter/vf_xcam.c	2020-09-27 13:35:13.516526540 +0800
@@ -0,0 +1,350 @@
+/*
+ * Copyright (c) 2020 Intel Corporation, all rights reserved.
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * libxcam wrapper functions
+ */
+
+#include <xcam/capi/xcam_handle.h>
+#include "libavutil/avstring.h"
+#include "libavutil/opt.h"
+#include "framesync.h"
+#include "internal.h"
+
+typedef struct XCamVideoFilterBuf {
+    XCamVideoBuffer buf;
+    AVFrame *frame;
+} XCamVideoFilterBuf;
+
+typedef struct XCAMContext {
+    const AVClass *class;
+
+    int nb_inputs;
+    int w;
+    int h;
+    char *fmt;
+    char *name;
+    int allocoutbuf;
+    char *params;
+
+    XCamHandle *handle;
+    uint32_t v4l2_fmt;
+
+    XCamVideoFilterBuf *inbufs[XCAM_MAX_INPUTS_NUM + 1];
+    FFFrameSync fs;
+} XCAMContext;
+
+static void xcambuf_ref(XCamVideoBuffer *buf) {
+    return;
+}
+
+static void xcambuf_unref(XCamVideoBuffer *buf) {
+    return;
+}
+
+static uint8_t *xcambuf_map(XCamVideoBuffer *buf) {
+    XCamVideoFilterBuf *avfilter_buf = (XCamVideoFilterBuf *)(buf);
+    return avfilter_buf->frame->data[0];
+}
+
+static void xcambuf_unmap(XCamVideoBuffer *buf) {
+    return;
+}
+
+static int xcambuf_get_fd(XCamVideoBuffer *buf) {
+    return 1;
+}
+
+static void fill_xcambuf_from_avframe(XCamVideoFilterBuf *buf, AVFrame *frame)
+{
+    buf->frame = frame;
+}
+
+static void fill_avframe_from_xcambuf(AVFrame *frame, XCamVideoBuffer *buf)
+{
+    XCamVideoBufferPlanarInfo planar;
+
+    uint8_t *start = xcam_video_buffer_map(buf);
+    if (!start)
+        return;
+
+    for (uint32_t idx = 0; idx < buf->info.components; idx++) {
+        uint8_t *src = start + buf->info.offsets[idx];
+        uint8_t *dest = frame->data[idx];
+        xcam_video_buffer_get_planar_info(&buf->info, &planar, idx);
+
+        for (uint32_t h = 0; h < planar.height; h++) {
+            memcpy(dest, src, frame->linesize[idx]);
+            src += buf->info.strides[idx];
+            dest += frame->linesize[idx];
+        }
+    }
+
+    xcam_video_buffer_unmap (buf);
+}
+
+static uint32_t avfmt_to_v4l2fmt(int avfmt) {
+    if (avfmt == AV_PIX_FMT_YUV420P)
+        return V4L2_PIX_FMT_YUV420;
+    return V4L2_PIX_FMT_NV12;
+}
+
+static int set_parameters(AVFilterContext *ctx, const AVFilterLink *inlink, const AVFilterLink *outlink)
+{
+    XCAMContext *s = inlink->dst->priv;
+
+    char params[XCAM_MAX_PARAMS_LENGTH] = { 0 };
+    snprintf(params, XCAM_MAX_PARAMS_LENGTH - 1, "inw=%d inh=%d outw=%d outh=%d fmt=%d allocoutbuf=%d %s",
+        inlink->w, inlink->h, outlink->w, outlink->h, s->v4l2_fmt, s->allocoutbuf, s->params);
+
+    if (xcam_handle_set_parameters(s->handle, params) != XCAM_RETURN_NO_ERROR) {
+        av_log(ctx, AV_LOG_ERROR, "xcam handler set parameters failed\n");
+        return AVERROR(EINVAL);
+    }
+
+    return 0;
+}
+
+static int
+init_xcambuf_info(XCAMContext *s, XCamVideoBuffer *buf, AVFrame *frame)
+{
+    XCamReturn ret = xcam_video_buffer_info_reset(
+        &buf->info, s->v4l2_fmt, frame->width, frame->height, frame->linesize[0], frame->height, 0);
+    if (ret != XCAM_RETURN_NO_ERROR)
+        return AVERROR(EINVAL);
+
+    for (int i = 0; frame->linesize[i]; i++) {
+        buf->info.offsets[i] = frame->data[i] - frame->data[0];
+        buf->info.strides[i] = frame->linesize[i];
+    }
+    buf->mem_type = XCAM_MEM_TYPE_CPU;
+
+    return 0;
+}
+
+static int xcam_execute(FFFrameSync *fs)
+{
+    AVFilterContext *ctx = fs->parent;
+    XCAMContext *s = fs->opaque;
+    AVFilterLink *outlink;
+    AVFrame *outframe, *frame;
+    XCamVideoBuffer *outbuf = NULL;
+
+    XCamVideoFilterBuf **inbufs = s->inbufs;
+    for (int i = 0; i < ctx->nb_inputs; i++) {
+        int error = ff_framesync_get_frame(&s->fs, i, &frame, 0);
+        if (error < 0)
+            return error;
+        if (init_xcambuf_info(s, &inbufs[i]->buf, frame) != 0)
+            return AVERROR(EINVAL);
+        fill_xcambuf_from_avframe(inbufs[i], frame);
+    }
+
+    if (xcam_handle_execute(s->handle, (XCamVideoBuffer **)inbufs, &outbuf) != XCAM_RETURN_NO_ERROR) {
+        av_log(ctx, AV_LOG_ERROR, "execute xcam handler failed\n");
+        return AVERROR(EINVAL);
+    }
+
+    outlink = ctx->outputs[0];
+    if (!(outframe = ff_get_video_buffer(outlink, outlink->w, outlink->h))) {
+        av_frame_free(&frame);
+        return AVERROR(ENOMEM);
+    }
+    av_frame_copy_props(outframe, frame);
+
+    fill_avframe_from_xcambuf(outframe, outbuf);
+    xcam_video_buffer_unref(outbuf);
+
+    return ff_filter_frame(outlink, outframe);
+}
+
+static int xcam_query_formats(AVFilterContext *ctx)
+{
+    XCAMContext *s = ctx->priv;
+    AVFilterFormats *formats = NULL;
+
+    static const enum AVPixelFormat nv12_fmts[] = {AV_PIX_FMT_NV12, AV_PIX_FMT_NONE};
+    static const enum AVPixelFormat yuv420_fmts[] = {AV_PIX_FMT_YUV420P, AV_PIX_FMT_NONE};
+    static const enum AVPixelFormat auto_fmts[] = {AV_PIX_FMT_NV12, AV_PIX_FMT_YUV420P, AV_PIX_FMT_NONE};
+
+    const enum AVPixelFormat *pix_fmts = NULL;
+    if (!av_strcasecmp(s->fmt, "nv12"))
+        pix_fmts = nv12_fmts;
+    else if (!av_strcasecmp(s->fmt, "yuv420"))
+        pix_fmts = yuv420_fmts;
+    else
+        pix_fmts = auto_fmts;
+
+    if (!(formats = ff_make_format_list(pix_fmts)))
+        return AVERROR(ENOMEM);
+
+    return ff_set_common_formats(ctx, formats);
+}
+
+static int xcam_config_output(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    XCAMContext *s = ctx->priv;
+    AVFilterLink *inlink = ctx->inputs[0];
+    int ret = 0;
+
+    s->v4l2_fmt = avfmt_to_v4l2fmt(inlink->format);
+    if (s->w && s->h) {
+        outlink->w = s->w;
+        outlink->h = s->h;
+    } else {
+        outlink->w = inlink->w;
+        outlink->h = inlink->h;
+    }
+
+    set_parameters(ctx, inlink, outlink);
+    if (xcam_handle_init(s->handle) != XCAM_RETURN_NO_ERROR) {
+        av_log(ctx, AV_LOG_ERROR, "init xcam handler failed\n");
+        return AVERROR(EINVAL);
+    }
+
+    if ((ret = ff_framesync_init(&s->fs, ctx, ctx->nb_inputs)) < 0)
+        return ret;
+    s->fs.opaque = s;
+    s->fs.on_event = xcam_execute;
+    for (int i = 0; i < ctx->nb_inputs; i++) {
+        FFFrameSyncIn *in = &s->fs.in[i];
+        in->time_base = ctx->inputs[i]->time_base;
+        in->sync      = 1;
+        in->before    = EXT_STOP;
+        in->after     = EXT_STOP;
+    }
+    ret = ff_framesync_configure(&s->fs);
+    outlink->time_base = s->fs.time_base;
+
+    return ret;
+}
+
+static av_cold int xcam_init(AVFilterContext *ctx)
+{
+    XCAMContext *s = ctx->priv;
+    int ret = 0;
+
+    s->handle = xcam_create_handle(s->name);
+    if (!s->handle) {
+        av_log(ctx, AV_LOG_ERROR, "create xcam handler failed\n");
+        return AVERROR(EINVAL);
+    }
+
+    for (int i = 0; i < s->nb_inputs; i++) {
+        s->inbufs[i] = av_mallocz_array(1, sizeof(*s->inbufs[i]));
+        if (!s->inbufs[i])
+            return AVERROR(ENOMEM);
+        s->inbufs[i]->buf.ref = xcambuf_ref;
+        s->inbufs[i]->buf.unref = xcambuf_unref;
+        s->inbufs[i]->buf.map = xcambuf_map;
+        s->inbufs[i]->buf.unmap = xcambuf_unmap;
+        s->inbufs[i]->buf.get_fd = xcambuf_get_fd;
+    }
+
+    for (int i = 0; i < s->nb_inputs; i++) {
+        AVFilterPad pad = { .type = AVMEDIA_TYPE_VIDEO };
+        pad.name = av_asprintf("input%d", i);
+        if (!pad.name)
+            return AVERROR(ENOMEM);
+
+        if ((ret = ff_insert_inpad(ctx, i, &pad)) < 0) {
+            av_freep(&pad.name);
+            return ret;
+        }
+    }
+
+    return 0;
+}
+
+static av_cold void xcam_uninit(AVFilterContext *ctx)
+{
+    XCAMContext *s = ctx->priv;
+
+    ff_framesync_uninit(&s->fs);
+    for (int i = 0; i < s->nb_inputs; i++) {
+        if (s->inbufs[i])
+            av_freep(&s->inbufs[i]);
+        if (ctx->input_pads)
+            av_freep(&ctx->input_pads[i].name);
+    }
+
+    xcam_destroy_handle(s->handle);
+    s->handle = NULL;
+}
+
+static int xcam_activate(AVFilterContext *ctx)
+{
+    XCAMContext *s = ctx->priv;
+    return ff_framesync_activate(&s->fs);
+}
+
+#define OFFSET(x) offsetof(XCAMContext, x)
+#define FLAGS AV_OPT_FLAG_VIDEO_PARAM|AV_OPT_FLAG_FILTERING_PARAM
+#define CONST_STRING(name, help, unit) \
+    { name, help, 0, AV_OPT_TYPE_CONST, { .str=name }, 0, 0, FLAGS, unit }
+
+static const AVOption xcam_options[] = {
+    { "inputs", "number of inputs", OFFSET(nb_inputs), AV_OPT_TYPE_INT, { .i64 = 1 }, 1, XCAM_MAX_INPUTS_NUM, FLAGS },
+    { "w",  "output width", OFFSET(w), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, FLAGS },
+    { "h", "output height", OFFSET(h), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, FLAGS },
+    { "fmt", "pixel format", OFFSET(fmt), AV_OPT_TYPE_STRING, { .str = "auto" }, 0, 0, FLAGS, "fmt" },
+        CONST_STRING("auto",   "automatic format negotiation", "fmt"),
+        CONST_STRING("nv12",   "NV12 format",                  "fmt"),
+        CONST_STRING("yuv420", "YUV420 format",                "fmt"),
+    { "name",   "handler name", OFFSET(name), AV_OPT_TYPE_STRING, { .str = "stitch" }, 0, 0, FLAGS, "name" },
+        CONST_STRING("3dnr",      "3d denoising",               "name"),
+        CONST_STRING("waveletnr", "wavelet denoising",          "name"),
+        CONST_STRING("fisheye",   "fisheye calibration",        "name"),
+        CONST_STRING("defog",     "fog removal",                "name"),
+        CONST_STRING("dvs",       "digital video stabilizer",   "name"),
+        CONST_STRING("stitch",    "soft/GLES/Vulkan stitching", "name"),
+        CONST_STRING("stitchcl",  "OpenCL stitching",           "name"),
+    { "allocoutbuf",  "alloc output buffer", OFFSET(allocoutbuf), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, FLAGS },
+    { "params", "private parameters for each handle, usage: params=help=1 field0=value0 field1=value1 ...",
+        OFFSET(params), AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, FLAGS },
+    { NULL }
+};
+
+AVFILTER_DEFINE_CLASS(xcam);
+
+static const AVFilterPad xcam_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = xcam_config_output
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_xcam = {
+    .name          = "xcam",
+    .description   = NULL_IF_CONFIG_SMALL("Apply image processing using libxcam"),
+    .priv_size     = sizeof(XCAMContext),
+    .priv_class    = &xcam_class,
+    .init          = xcam_init,
+    .query_formats = xcam_query_formats,
+    .outputs       = xcam_outputs,
+    .activate      = xcam_activate,
+    .uninit        = xcam_uninit,
+    .flags         = AVFILTER_FLAG_DYNAMIC_INPUTS
+};
+
diff -urN FFmpeg/libavformat/allformats.c FFmpeg-patched/libavformat/allformats.c
--- FFmpeg/libavformat/allformats.c	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavformat/allformats.c	2020-09-27 13:35:13.518526539 +0800
@@ -187,6 +187,8 @@
 extern AVOutputFormat ff_hds_muxer;
 extern AVInputFormat  ff_hevc_demuxer;
 extern AVOutputFormat ff_hevc_muxer;
+extern AVOutputFormat ff_omaf_packing_muxer;
+extern AVInputFormat  ff_tile_dash_demuxer;
 extern AVInputFormat  ff_hls_demuxer;
 extern AVOutputFormat ff_hls_muxer;
 extern AVInputFormat  ff_hnm_demuxer;
diff -urN FFmpeg/libavformat/flvdec.c FFmpeg-patched/libavformat/flvdec.c
--- FFmpeg/libavformat/flvdec.c	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavformat/flvdec.c	2020-09-27 13:35:13.527526539 +0800
@@ -318,6 +318,8 @@
         return vpar->codec_id == AV_CODEC_ID_VP6A;
     case FLV_CODECID_H264:
         return vpar->codec_id == AV_CODEC_ID_H264;
+    case FLV_CODECID_HEVC:
+        return vpar->codec_id == AV_CODEC_ID_HEVC;
     default:
         return vpar->codec_tag == flv_codecid;
     }
@@ -367,6 +369,11 @@
         par->codec_id = AV_CODEC_ID_MPEG4;
         ret = 3;
         break;
+    case FLV_CODECID_HEVC:
+        par->codec_id = AV_CODEC_ID_HEVC;
+        vstream->need_parsing = AVSTREAM_PARSE_NONE;
+        ret = 3; // not 4, reading packet type will consume one byte
+        break;
     default:
         avpriv_request_sample(s, "Video codec (%x)", flv_codecid);
         par->codec_tag = flv_codecid;
@@ -1222,6 +1229,7 @@
 
     if (st->codecpar->codec_id == AV_CODEC_ID_AAC ||
         st->codecpar->codec_id == AV_CODEC_ID_H264 ||
+        st->codecpar->codec_id == AV_CODEC_ID_HEVC ||
         st->codecpar->codec_id == AV_CODEC_ID_MPEG4) {
         int type = avio_r8(s->pb);
         size--;
@@ -1231,8 +1239,8 @@
             goto leave;
         }
 
-        if (st->codecpar->codec_id == AV_CODEC_ID_H264 || st->codecpar->codec_id == AV_CODEC_ID_MPEG4) {
-            // sign extension
+        if (st->codecpar->codec_id == AV_CODEC_ID_H264 || st->codecpar->codec_id == AV_CODEC_ID_HEVC
+                || st->codecpar->codec_id == AV_CODEC_ID_MPEG4) {// sign extension
             int32_t cts = (avio_rb24(s->pb) + 0xff800000) ^ 0xff800000;
             pts = dts + cts;
             if (cts < 0) { // dts might be wrong
@@ -1247,7 +1255,7 @@
             }
         }
         if (type == 0 && (!st->codecpar->extradata || st->codecpar->codec_id == AV_CODEC_ID_AAC ||
-            st->codecpar->codec_id == AV_CODEC_ID_H264)) {
+            st->codecpar->codec_id == AV_CODEC_ID_H264 || st->codecpar->codec_id == AV_CODEC_ID_HEVC)) {
             AVDictionaryEntry *t;
 
             if (st->codecpar->extradata) {
diff -urN FFmpeg/libavformat/flvenc.c FFmpeg-patched/libavformat/flvenc.c
--- FFmpeg/libavformat/flvenc.c	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavformat/flvenc.c	2020-09-27 13:35:13.527526539 +0800
@@ -29,6 +29,7 @@
 #include "avc.h"
 #include "avformat.h"
 #include "flv.h"
+#include "hevc.h"
 #include "internal.h"
 #include "metadata.h"
 #include "libavutil/opt.h"
@@ -46,6 +47,7 @@
     { AV_CODEC_ID_VP6,      FLV_CODECID_VP6 },
     { AV_CODEC_ID_VP6A,     FLV_CODECID_VP6A },
     { AV_CODEC_ID_H264,     FLV_CODECID_H264 },
+    { AV_CODEC_ID_HEVC,     FLV_CODECID_HEVC },
     { AV_CODEC_ID_NONE,     0 }
 };
 
@@ -491,7 +493,7 @@
     FLVContext *flv = s->priv_data;
 
     if (par->codec_id == AV_CODEC_ID_AAC || par->codec_id == AV_CODEC_ID_H264
-            || par->codec_id == AV_CODEC_ID_MPEG4) {
+            || par->codec_id == AV_CODEC_ID_HEVC || par->codec_id == AV_CODEC_ID_MPEG4) {
         int64_t pos;
         avio_w8(pb,
                 par->codec_type == AVMEDIA_TYPE_VIDEO ?
@@ -537,7 +539,11 @@
             avio_w8(pb, par->codec_tag | FLV_FRAME_KEY); // flags
             avio_w8(pb, 0); // AVC sequence header
             avio_wb24(pb, 0); // composition time
-            ff_isom_write_avcc(pb, par->extradata, par->extradata_size);
+            if (par->codec_id == AV_CODEC_ID_HEVC) {
+                ff_isom_write_hvcc(pb, par->extradata, par->extradata_size, 0);
+            } else {
+                ff_isom_write_avcc(pb, par->extradata, par->extradata_size);
+            }
         }
         data_size = avio_tell(pb) - pos;
         avio_seek(pb, -data_size - 10, SEEK_CUR);
@@ -844,7 +850,7 @@
             AVCodecParameters *par = s->streams[i]->codecpar;
             FLVStreamContext *sc = s->streams[i]->priv_data;
             if (par->codec_type == AVMEDIA_TYPE_VIDEO &&
-                    (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4))
+                    (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_HEVC || par->codec_id == AV_CODEC_ID_MPEG4))
                 put_avc_eos_tag(pb, sc->last_ts);
         }
     }
@@ -895,7 +901,7 @@
     if (par->codec_id == AV_CODEC_ID_VP6F || par->codec_id == AV_CODEC_ID_VP6A ||
         par->codec_id == AV_CODEC_ID_VP6  || par->codec_id == AV_CODEC_ID_AAC)
         flags_size = 2;
-    else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4)
+    else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_HEVC ||  par->codec_id == AV_CODEC_ID_MPEG4)
         flags_size = 5;
     else
         flags_size = 1;
@@ -913,6 +919,24 @@
         }
     }
 
+    if (par->codec_id == AV_CODEC_ID_HEVC) {
+        int side_size = 0;
+        uint8_t *side = av_packet_get_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA, &side_size);
+        if (side && side_size > 0 && (side_size != par->extradata_size || memcmp(side, par->extradata, side_size))) {
+            av_free(par->extradata);
+            par->extradata = av_mallocz(side_size + AV_INPUT_BUFFER_PADDING_SIZE);
+            if (!par->extradata) {
+                par->extradata_size = 0;
+                return AVERROR(ENOMEM);
+            }
+            memcpy(par->extradata, side, side_size);
+            par->extradata_size = side_size;
+            flv_write_codec_header(s, par, pkt->dts);
+        } else {
+            flv_write_codec_header(s, par, pkt->dts);
+        }
+    }
+
     if (flv->delay == AV_NOPTS_VALUE)
         flv->delay = -pkt->dts;
 
@@ -966,6 +990,10 @@
         if (par->extradata_size > 0 && *(uint8_t*)par->extradata != 1)
             if ((ret = ff_avc_parse_nal_units_buf(pkt->data, &data, &size)) < 0)
                 return ret;
+    } else if (par->codec_id == AV_CODEC_ID_HEVC) {
+        if (par->extradata_size > 0 && *(uint8_t*)par->extradata != 1)
+            if ((ret = ff_hevc_annexb2mp4_buf(pkt->data, &data, &size, 0, NULL)) < 0)
+                return ret;
     } else if (par->codec_id == AV_CODEC_ID_AAC && pkt->size > 2 &&
                (AV_RB16(pkt->data) & 0xfff0) == 0xfff0) {
         if (!s->streams[pkt->stream_index]->nb_frames) {
@@ -1036,9 +1064,9 @@
             else
                 avio_w8(pb, ((FFALIGN(par->width,  16) - par->width) << 4) |
                              (FFALIGN(par->height, 16) - par->height));
-        } else if (par->codec_id == AV_CODEC_ID_AAC)
+        } else if (par->codec_id == AV_CODEC_ID_AAC){
             avio_w8(pb, 1); // AAC raw
-        else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4) {
+        } else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_HEVC ||  par->codec_id == AV_CODEC_ID_MPEG4) {
             avio_w8(pb, 1); // AVC NALU
             avio_wb24(pb, pkt->pts - pkt->dts);
         }
diff -urN FFmpeg/libavformat/flv.h FFmpeg-patched/libavformat/flv.h
--- FFmpeg/libavformat/flv.h	2020-07-09 17:17:46.000000000 +0800
+++ FFmpeg-patched/libavformat/flv.h	2020-09-27 13:35:13.527526539 +0800
@@ -110,6 +110,7 @@
     FLV_CODECID_H264    = 7,
     FLV_CODECID_REALH263= 8,
     FLV_CODECID_MPEG4   = 9,
+    FLV_CODECID_HEVC    = 12,
 };

 enum {
diff -urN FFmpeg/libavformat/Makefile FFmpeg-patched/libavformat/Makefile
--- FFmpeg/libavformat/Makefile	2020-07-11 18:39:30.000000000 +0800
+++ FFmpeg-patched/libavformat/Makefile	2020-09-27 13:35:13.519526539 +0800
@@ -148,6 +148,8 @@
 OBJS-$(CONFIG_DATA_MUXER)                += rawenc.o
 OBJS-$(CONFIG_DASH_MUXER)                += dash.o dashenc.o hlsplaylist.o
 OBJS-$(CONFIG_DASH_DEMUXER)              += dash.o dashdec.o
+OBJS-$(CONFIG_TILE_DASH_DEMUXER)         += tiled_dash_dec.o
+OBJS-$(CONFIG_LIBVROMAFPACKING)          += omaf_packing_enc.o
 OBJS-$(CONFIG_DAUD_DEMUXER)              += dauddec.o
 OBJS-$(CONFIG_DAUD_MUXER)                += daudenc.o
 OBJS-$(CONFIG_DCSTR_DEMUXER)             += dcstr.o
diff -urN FFmpeg/libavformat/omaf_packing_enc.c FFmpeg-patched/libavformat/omaf_packing_enc.c
--- FFmpeg/libavformat/omaf_packing_enc.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavformat/omaf_packing_enc.c	2020-09-27 13:35:13.543526537 +0800
@@ -0,0 +1,730 @@
+/*
+ * Intel tile Dash muxer
+ *
+ * Copyright (c) 2018 Intel Cooperation
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <unistd.h>
+#include <sys/stat.h>
+
+#include "libavutil/avassert.h"
+#include "libavutil/avutil.h"
+#include "libavutil/avstring.h"
+#include "libavutil/intreadwrite.h"
+#include "libavutil/mathematics.h"
+#include "libavutil/opt.h"
+#include "libavutil/rational.h"
+#include "libavutil/time_internal.h"
+
+#include "avformat.h"
+#include "avio_internal.h"
+
+#include "360SCVPAPI.h"
+#include "VROmafPackingAPI.h"
+#include "common_data.h"
+
+static uint32_t min_loglevel = 2;
+
+typedef struct {
+    int         streamIdx;
+    FrameBSInfo *frameBSInfo;
+} BufferedFrame;
+
+typedef struct {
+    const AVClass  *class;  /* Class for private options. */
+    Handler        handler;
+    InitialInfo    *initInfo;
+    int            inStreamsNum;
+
+    const char     *proj_type;
+    const char     *face_file;
+    int            viewport_w;
+    int            viewport_h;
+    float          viewport_yaw;
+    float          viewport_pitch;
+    float          viewport_fov_hor;
+    float          viewport_fov_ver;
+    int            window_size;
+    int            extra_window_size;
+    int            has_extractor;
+    const char     *packingPluginPath;
+    const char     *packingPluginName;
+    bool           fixedPackedPicRes;
+    const char     *videoPluginPath;
+    const char     *videoPluginName;
+    const char     *audioPluginPath;
+    const char     *audioPluginName;
+    int            need_buffered_frames;
+    uint16_t       extractors_per_thread;
+    int64_t        seg_duration;
+    int            remove_at_exit;
+    int            use_template;
+    int            use_timeline;
+    char           dirname[1024];
+    const char     *out_name;
+    const char     *base_url;
+    const char     *utc_timing_url;
+    int            is_live;
+    int            split_tile;
+    int64_t        frameNum;
+    BufferedFrame  bufferedFrames[1024];
+    int            bufferedFramesNum;
+    bool           need_external_log;
+    int            min_log_level;
+    bool           first_audio_input;
+} OMAFContext;
+
+static uint8_t convert_face_index(char *face_name)
+{
+    if (0 == strncmp(face_name, "PY", 2))
+        return 0;
+    else if (0 == strncmp(face_name, "PX", 2))
+        return 1;
+    else if (0 == strncmp(face_name, "NY", 2))
+        return 2;
+    else if (0 == strncmp(face_name, "NZ", 2))
+        return 3;
+    else if (0 == strncmp(face_name, "NX", 2))
+        return 4;
+    else if (0 == strncmp(face_name, "PZ", 2))
+        return 5;
+    else
+        return 255;
+}
+
+static E_TransformType convert_transform_type(char *transform_name)
+{
+    if (0 == strncmp(transform_name, "NO_TRANSFORM", 12))
+        return NO_TRANSFORM;
+    else if (0 == strncmp(transform_name, "MIRRORING_HORIZONTALLY", 22))
+        return MIRRORING_HORIZONTALLY;
+    else if (0 == strncmp(transform_name, "ROTATION_180_ANTICLOCKWISE", 26))
+        return ROTATION_180_ANTICLOCKWISE;
+    else if (0 == strncmp(transform_name, "ROTATION_180_ANTICLOCKWISE_AFTER_MIRRORING_HOR", 46))
+        return ROTATION_180_ANTICLOCKWISE_AFTER_MIRRORING_HOR;
+    else if (0 == strncmp(transform_name, "ROTATION_90_ANTICLOCKWISE_BEFORE_MIRRORING_HOR", 46))
+        return ROTATION_90_ANTICLOCKWISE_BEFORE_MIRRORING_HOR;
+    else if (0 == strncmp(transform_name, "ROTATION_90_ANTICLOCKWISE", 25))
+        return ROTATION_90_ANTICLOCKWISE;
+    else if (0 == strncmp(transform_name, "ROTATION_270_ANTICLOCKWISE_BEFORE_MIRRORING_HOR", 47))
+        return ROTATION_270_ANTICLOCKWISE_BEFORE_MIRRORING_HOR;
+    else if (0 == strncmp(transform_name, "ROTATION_270_ANTICLOCKWISE", 26))
+        return ROTATION_270_ANTICLOCKWISE;
+    else
+        return NO_TRANSFORM;
+}
+
+static void ffmpeg_log_callback(LogLevel log_level, const char* file_name, uint64_t line_num, const char* fmt, ...)
+{
+    va_list vl;
+    va_start(vl, fmt);
+
+    switch (log_level)
+    {
+        case LOG_INFO:
+        {
+            if(min_loglevel == 0)
+            {
+                av_vlog(NULL, AV_LOG_INFO, fmt, vl);
+            }
+            break;
+        }
+        case LOG_WARNING:
+        {
+            if(min_loglevel <= 1)
+            {
+                av_vlog(NULL, AV_LOG_WARNING, fmt, vl);
+            }
+            break;
+        }
+        case LOG_ERROR:
+        {
+            if(min_loglevel <= 2)
+            {
+                av_vlog(NULL, AV_LOG_ERROR, fmt, vl);
+            }
+            break;
+        }
+        case LOG_FATAL:
+        {
+            if(min_loglevel <= 3)
+            {
+                av_vlog(NULL, AV_LOG_FATAL, fmt, vl);
+            }
+            break;
+        }
+        default:
+        {
+            av_log(NULL, AV_LOG_ERROR, "Invalid log level !");
+            break;
+        }
+    }
+    va_end(vl);
+}
+
+static int omaf_init(AVFormatContext *s)
+{
+    OMAFContext *c = s->priv_data;
+    int ret = 0;
+
+    c->frameNum = -1;
+
+    c->initInfo = (InitialInfo*)malloc(sizeof(InitialInfo));
+    if (!(c->initInfo))
+    {
+        av_log(s, AV_LOG_ERROR, "Failed to malloc memory for initial information \n");
+        return AVERROR(ENOMEM);
+    }
+    InitialInfo *initInfo = c->initInfo;
+    memset(initInfo, 0, sizeof(InitialInfo));
+
+    initInfo->bsNumVideo = 0;
+    initInfo->bsNumAudio = 0;
+    for (int i = 0; i < s->nb_streams; i++)
+    {
+        AVStream *st = s->streams[i];
+        switch(st->codecpar->codec_type)
+        {
+            case AVMEDIA_TYPE_VIDEO:
+                initInfo->bsNumVideo++;
+                break;
+            case AVMEDIA_TYPE_AUDIO:
+                initInfo->bsNumAudio++;
+                break;
+            default:
+                break;
+        }
+    }
+
+    if (initInfo->bsNumVideo > 2)
+    {
+        c->has_extractor = 0;
+    }
+
+    initInfo->videoProcessPluginPath = c->videoPluginPath;
+    initInfo->videoProcessPluginName = c->videoPluginName;
+
+    if (initInfo->bsNumAudio)
+    {
+        if ((0 == strncmp(c->audioPluginPath, "NULL", 4)) ||
+            (0 == strncmp(c->audioPluginName, "NULL", 4)))
+        {
+            av_log(s, AV_LOG_ERROR, "No audio stream process plugin is set but there is indeed audio stream input !\n");
+            return AVERROR_INVALIDDATA;
+        }
+
+        initInfo->audioProcessPluginPath = c->audioPluginPath;
+        initInfo->audioProcessPluginName = c->audioPluginName;
+    }
+
+    if (c->has_extractor)
+    {
+        initInfo->packingPluginPath = c->packingPluginPath;
+        if (initInfo->bsNumVideo == 1)
+        {
+            initInfo->packingPluginName = "SingleVideoPacking";
+        }
+        else if (initInfo->bsNumVideo == 2)
+        {
+            initInfo->packingPluginName = c->packingPluginName;
+        }
+        else
+        {
+            av_log(s, AV_LOG_ERROR, "Not correct video streams number for VR OMAF Packing \n");
+            return AVERROR(EINVAL);
+        }
+        initInfo->fixedPackedPicRes = c->fixedPackedPicRes;
+    }
+    else
+    {
+        initInfo->packingPluginPath = NULL;
+        initInfo->packingPluginName = NULL;
+        initInfo->fixedPackedPicRes = false;
+    }
+
+    min_loglevel = c->min_log_level;
+    if (c->need_external_log)
+    {
+        initInfo->logFunction = (void*)(ffmpeg_log_callback);
+    }
+    else
+    {
+        initInfo->logFunction = NULL;
+    }
+
+    initInfo->bsBuffers = (BSBuffer*)malloc(sizeof(BSBuffer) * (initInfo->bsNumVideo + initInfo->bsNumAudio));
+    if (!(initInfo->bsBuffers))
+    {
+        av_log(s, AV_LOG_ERROR, "Failed to malloc memory for video bitstream buffer \n");
+        return AVERROR(ENOMEM);
+    }
+
+    initInfo->viewportInfo = (ViewportInformation*)malloc(sizeof(ViewportInformation));
+    if (!(initInfo->viewportInfo))
+    {
+        av_log(s, AV_LOG_ERROR, "Failed to malloc memory for viewport information \n");
+        return AVERROR(ENOMEM);
+    }
+    memset(initInfo->viewportInfo, 0, sizeof(ViewportInformation));
+    initInfo->viewportInfo->viewportWidth = c->viewport_w;
+    initInfo->viewportInfo->viewportHeight = c->viewport_h;
+    initInfo->viewportInfo->viewportPitch = c->viewport_pitch;
+    initInfo->viewportInfo->viewportYaw = c->viewport_yaw;
+    initInfo->viewportInfo->horizontalFOVAngle = c->viewport_fov_hor;
+    initInfo->viewportInfo->verticalFOVAngle = c->viewport_fov_ver;
+    initInfo->viewportInfo->outGeoType = E_SVIDEO_VIEWPORT;
+    if (0 == strncmp(c->proj_type, "ERP", 3))
+    {
+        initInfo->viewportInfo->inGeoType = E_SVIDEO_EQUIRECT;
+    }
+    else if (0 == strncmp(c->proj_type, "Cube", 4))
+    {
+        initInfo->viewportInfo->inGeoType = E_SVIDEO_CUBEMAP;
+    }
+    else if (0 == strncmp(c->proj_type, "Planar", 6))
+    {
+        initInfo->viewportInfo->inGeoType = E_SVIDEO_PLANAR;
+    }
+
+    initInfo->segmentationInfo = (SegmentationInfo*)malloc(sizeof(SegmentationInfo));
+    if (!(initInfo->segmentationInfo))
+    {
+        av_log(s, AV_LOG_ERROR, "Failed to malloc memory for segmentation information \n");
+        return AVERROR(ENOMEM);
+    }
+    memset(initInfo->segmentationInfo, 0, sizeof(SegmentationInfo));
+    initInfo->segmentationInfo->windowSize = c->window_size;
+    initInfo->segmentationInfo->extraWindowSize = c->extra_window_size;
+    initInfo->segmentationInfo->needBufedFrames = c->need_buffered_frames;
+    initInfo->segmentationInfo->extractorTracksPerSegThread = c->extractors_per_thread;
+    initInfo->segmentationInfo->segDuration = c->seg_duration / 1000000;
+    initInfo->segmentationInfo->removeAtExit = c->remove_at_exit;
+    initInfo->segmentationInfo->useTemplate = c->use_template;
+    initInfo->segmentationInfo->useTimeline = c->use_timeline;
+
+    initInfo->segmentationInfo->dirName = (char*)malloc(1024 * sizeof(char));
+    av_strlcpy(initInfo->segmentationInfo->dirName, s->url, sizeof(c->dirname));
+    initInfo->segmentationInfo->outName = c->out_name;
+    initInfo->segmentationInfo->baseUrl = c->base_url;
+    initInfo->segmentationInfo->utcTimingUrl = c->utc_timing_url;
+    initInfo->segmentationInfo->isLive = c->is_live;
+    initInfo->segmentationInfo->splitTile = c->split_tile;
+    initInfo->segmentationInfo->hasMainAS = true;
+
+    if (0 == strncmp(c->proj_type, "ERP", 3))
+    {
+        initInfo->projType = E_SVIDEO_EQUIRECT;
+        initInfo->cubeMapInfo = NULL;
+    }
+    else if (0 == strncmp(c->proj_type, "Cube", 4))
+    {
+        initInfo->projType = E_SVIDEO_CUBEMAP;
+    }
+    else if (0 == strncmp(c->proj_type, "Planar", 6))
+    {
+        initInfo->projType = E_SVIDEO_PLANAR;
+    }
+
+    if (initInfo->projType == E_SVIDEO_CUBEMAP)
+    {
+        if (!(c->face_file))
+        {
+            av_log(s, AV_LOG_ERROR,
+                    "face_file should not be null when input source is from Cubemap projection! \n");
+            return AVERROR(EINVAL);
+        }
+
+        initInfo->cubeMapInfo = (InputCubeMapInfo*)malloc(sizeof(InputCubeMapInfo));
+        memset(initInfo->cubeMapInfo, 0, sizeof(InputCubeMapInfo));
+        FILE *fp = fopen(c->face_file, "r");
+        if (!fp)
+        {
+            av_log(s, AV_LOG_ERROR,
+                    "Failed to open cubemap face file !\n");
+            return AVERROR(ENOMEM);
+        }
+        char face_name[128] = { 0 };
+        char transform_name[128] = { 0 };
+        fscanf(fp, "%s %s", face_name, transform_name);
+        initInfo->cubeMapInfo->face0MapInfo.mappedStandardFaceId = convert_face_index(face_name);
+        initInfo->cubeMapInfo->face0MapInfo.transformType = convert_transform_type(transform_name);
+
+        memset(face_name, 0, 128);
+        memset(transform_name, 0, 128);
+        fscanf(fp, "%s %s", face_name, transform_name);
+        initInfo->cubeMapInfo->face1MapInfo.mappedStandardFaceId = convert_face_index(face_name);
+        initInfo->cubeMapInfo->face1MapInfo.transformType = convert_transform_type(transform_name);
+
+        memset(face_name, 0, 128);
+        memset(transform_name, 0, 128);
+        fscanf(fp, "%s %s", face_name, transform_name);
+        initInfo->cubeMapInfo->face2MapInfo.mappedStandardFaceId = convert_face_index(face_name);
+        initInfo->cubeMapInfo->face2MapInfo.transformType = convert_transform_type(transform_name);
+
+        memset(face_name, 0, 128);
+        memset(transform_name, 0, 128);
+        fscanf(fp, "%s %s", face_name, transform_name);
+        initInfo->cubeMapInfo->face3MapInfo.mappedStandardFaceId = convert_face_index(face_name);
+        initInfo->cubeMapInfo->face3MapInfo.transformType = convert_transform_type(transform_name);
+
+        memset(face_name, 0, 128);
+        memset(transform_name, 0, 128);
+        fscanf(fp, "%s %s", face_name, transform_name);
+        initInfo->cubeMapInfo->face4MapInfo.mappedStandardFaceId = convert_face_index(face_name);
+        initInfo->cubeMapInfo->face4MapInfo.transformType = convert_transform_type(transform_name);
+
+        memset(face_name, 0, 128);
+        memset(transform_name, 0, 128);
+        fscanf(fp, "%s %s", face_name, transform_name);
+        initInfo->cubeMapInfo->face5MapInfo.mappedStandardFaceId = convert_face_index(face_name);
+        initInfo->cubeMapInfo->face5MapInfo.transformType = convert_transform_type(transform_name);
+
+        fclose(fp);
+        fp = NULL;
+    }
+    memset(c->bufferedFrames, 0, 1024 * sizeof(BufferedFrame));
+    c->bufferedFramesNum = 0;
+    c->inStreamsNum = 0;
+    c->handler = NULL;
+
+    return 0;
+}
+
+static void omaf_free(AVFormatContext *s)
+{
+    OMAFContext *c = s->priv_data;
+
+    VROmafPackingClose(c->handler);
+
+    if (c->initInfo->bsBuffers)
+    {
+        for (int i = 0; i < (c->initInfo->bsNumVideo + c->initInfo->bsNumAudio); i++)
+        {
+            if (c->initInfo->bsBuffers[i].data)
+            {
+                free(c->initInfo->bsBuffers[i].data);
+                c->initInfo->bsBuffers[i].data = NULL;
+            }
+        }
+        free(c->initInfo->bsBuffers);
+        c->initInfo->bsBuffers = NULL;
+    }
+
+    if(c->initInfo->viewportInfo)
+    {
+        free(c->initInfo->viewportInfo);
+        c->initInfo->viewportInfo = NULL;
+    }
+
+    if(c->initInfo->segmentationInfo)
+    {
+        if (c->initInfo->segmentationInfo->dirName)
+        {
+            free(c->initInfo->segmentationInfo->dirName);
+            c->initInfo->segmentationInfo->dirName = NULL;
+        }
+
+        free(c->initInfo->segmentationInfo);
+        c->initInfo->segmentationInfo = NULL;
+    }
+
+    if (c->initInfo->cubeMapInfo)
+    {
+        free(c->initInfo->cubeMapInfo);
+        c->initInfo->cubeMapInfo = NULL;
+    }
+
+    if(c->initInfo)
+    {
+        free(c->initInfo);
+        c->initInfo = NULL;
+    }
+
+    return;
+}
+
+static int omaf_write_header(AVFormatContext *s)
+{
+    return 0;
+}
+
+static int omaf_write_packet(AVFormatContext *s, AVPacket *pkt)
+{
+    OMAFContext *c = s->priv_data;
+    int ret = 0;
+
+    if(!c->handler)
+    {
+        int i = pkt->stream_index;
+        AVStream *st = s->streams[i];
+
+        if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts == 0))
+        {
+            c->initInfo->bsBuffers[i].dataSize = pkt->side_data->size;
+
+            c->initInfo->bsBuffers[i].data = (uint8_t*)malloc(c->initInfo->bsBuffers[i].dataSize * sizeof(uint8_t));
+            if (!(c->initInfo->bsBuffers[i].data))
+            {
+                av_log(s, AV_LOG_ERROR, "Failed to malloc memory for holding bitstream header data \n");
+                return -1;
+            }
+            memcpy(c->initInfo->bsBuffers[i].data, pkt->side_data->data, c->initInfo->bsBuffers[i].dataSize);
+
+        }
+        else if ((st->codecpar->codec_id == AV_CODEC_ID_AAC) && !c->first_audio_input)
+        {
+            c->initInfo->bsBuffers[i].dataSize = pkt->size;
+
+            c->initInfo->bsBuffers[i].data = (uint8_t*)malloc(c->initInfo->bsBuffers[i].dataSize * sizeof(uint8_t));
+            if (!(c->initInfo->bsBuffers[i].data))
+            {
+                av_log(s, AV_LOG_ERROR, "Failed to malloc memory for holding bitstream header data \n");
+                return -1;
+            }
+            memcpy(c->initInfo->bsBuffers[i].data, pkt->data, c->initInfo->bsBuffers[i].dataSize);
+        }
+
+        if (st->codecpar->codec_id == AV_CODEC_ID_H264)
+        {
+            c->initInfo->bsBuffers[i].codecId = CODEC_ID_H264;
+        }
+        else if (st->codecpar->codec_id == AV_CODEC_ID_HEVC)
+        {
+            c->initInfo->bsBuffers[i].codecId = CODEC_ID_H265;
+        }
+        else if (st->codecpar->codec_id == AV_CODEC_ID_AAC)
+        {
+            c->initInfo->bsBuffers[i].codecId = CODEC_ID_AAC;
+        }
+
+        c->initInfo->bsBuffers[i].bitRate = st->codecpar->bit_rate;
+        c->initInfo->bsBuffers[i].frameRate.num = st->avg_frame_rate.num;
+        c->initInfo->bsBuffers[i].frameRate.den = st->avg_frame_rate.den;
+        c->initInfo->bsBuffers[i].mediaType = -1;
+        switch(st->codecpar->codec_type)
+        {
+            case AVMEDIA_TYPE_VIDEO:
+                c->initInfo->bsBuffers[i].mediaType = VIDEOTYPE;
+                break;
+            case AVMEDIA_TYPE_AUDIO:
+                c->initInfo->bsBuffers[i].mediaType = AUDIOTYPE;
+                c->initInfo->bsBuffers[i].audioObjType = st->codecpar->profile ;
+                c->initInfo->bsBuffers[i].sampleRate = st->codecpar->sample_rate;
+                c->initInfo->bsBuffers[i].channelNum = st->codecpar->channels;
+                break;
+            case AVMEDIA_TYPE_SUBTITLE:
+                c->initInfo->bsBuffers[i].mediaType = SUBTITLETYPE;
+                break;
+            default:
+                break;
+        }
+
+        if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts == 0))
+        {
+            c->inStreamsNum++;
+        }
+        else if ((st->codecpar->codec_id == AV_CODEC_ID_AAC) && !c->first_audio_input)
+        {
+            c->inStreamsNum++;
+            c->first_audio_input = true;
+        }
+
+        FrameBSInfo* frameInfo = (FrameBSInfo*)malloc(sizeof(FrameBSInfo));
+        memset(frameInfo, 0, sizeof(FrameBSInfo));
+        if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts == 0))
+        {
+            frameInfo->dataSize = pkt->size - pkt->side_data->size;
+        }
+        else if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts != 0))
+        {
+            frameInfo->dataSize = pkt->size;
+        }
+        else if (st->codecpar->codec_id == AV_CODEC_ID_AAC)
+        {
+            frameInfo->dataSize = pkt->size;
+        }
+
+        frameInfo->data = (uint8_t*)malloc(frameInfo->dataSize * sizeof(uint8_t));
+        if (!(frameInfo->data))
+        {
+            av_log(s, AV_LOG_ERROR, "Failed to malloc memory for buffered frame data \n");
+            return -1;
+        }
+        if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts == 0))
+        {
+            memcpy(frameInfo->data, pkt->data + pkt->side_data->size, frameInfo->dataSize);
+            frameInfo->isKeyFrame = (pkt->flags & AV_PKT_FLAG_KEY);
+        }
+        else if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts != 0))
+        {
+            memcpy(frameInfo->data, pkt->data, frameInfo->dataSize);
+            frameInfo->isKeyFrame = (pkt->flags & AV_PKT_FLAG_KEY);
+        }
+        else if (st->codecpar->codec_id == AV_CODEC_ID_AAC)
+        {
+            memcpy(frameInfo->data, pkt->data, frameInfo->dataSize);
+            frameInfo->isKeyFrame = true;
+        }
+        frameInfo->pts = pkt->pts;
+
+        c->bufferedFrames[c->bufferedFramesNum].streamIdx = pkt->stream_index;
+        c->bufferedFrames[c->bufferedFramesNum].frameBSInfo = frameInfo;
+        c->bufferedFramesNum++;
+
+        if (((st->codecpar->codec_id == AV_CODEC_ID_HEVC) || (st->codecpar->codec_id == AV_CODEC_ID_H264)) && (pkt->pts == 0))
+        {
+            free(pkt->side_data->data);
+            pkt->side_data->data = NULL;
+            pkt->side_data->size = 0;
+            free(pkt->side_data);
+            pkt->side_data = NULL;
+            pkt->side_data_elems = 0;
+        }
+
+        if (c->inStreamsNum == (c->initInfo->bsNumVideo + c->initInfo->bsNumAudio))
+        {
+            c->handler = VROmafPackingInit(c->initInfo);
+            if (!(c->handler))
+            {
+                av_log(s, AV_LOG_ERROR, "Failed to create VR Omaf Packing handler \n");
+                return -1;
+            }
+            c->frameNum++;
+        }
+    }
+    else
+    {
+        if (c->bufferedFramesNum > 0)
+        {
+            for (int i = 0; i < c->bufferedFramesNum; i++)
+            {
+                ret = VROmafPackingWriteSegment(c->handler, c->bufferedFrames[i].streamIdx, c->bufferedFrames[i].frameBSInfo);
+                if (ret != 0)
+                {
+                    av_log(s, AV_LOG_ERROR, "Failed to write segment.\n" );
+                    return ret;
+                }
+
+                free(c->bufferedFrames[i].frameBSInfo->data);
+                c->bufferedFrames[i].frameBSInfo->data = NULL;
+                c->bufferedFrames[i].frameBSInfo->dataSize = 0;
+                free(c->bufferedFrames[i].frameBSInfo);
+                c->bufferedFrames[i].frameBSInfo = NULL;
+            }
+            c->bufferedFramesNum = 0;
+            c->frameNum++;
+        }
+
+        FrameBSInfo* frameInfo = (FrameBSInfo*)malloc(sizeof(FrameBSInfo));
+
+        frameInfo->data = pkt->data;
+        frameInfo->dataSize = pkt->size;
+
+        frameInfo->isKeyFrame = (pkt->flags & AV_PKT_FLAG_KEY);
+
+        frameInfo->pts = pkt->pts;
+
+        ret = VROmafPackingWriteSegment(c->handler, pkt->stream_index, frameInfo);
+        if(ret !=0 )
+        {
+            av_log(s, AV_LOG_ERROR, "Failed to write segment.\n" );
+        }
+
+        free(frameInfo);
+        frameInfo = NULL;
+        c->frameNum++;
+    }
+
+    return ret;
+}
+
+static int omaf_write_trailer(AVFormatContext *s)
+{
+    OMAFContext *c = s->priv_data;
+    int ret = 0;
+
+    ret = VROmafPackingEndStreams(c->handler);
+    if(ret)
+    {
+        av_log(s, AV_LOG_ERROR, "Failed to write end mpd \n" );
+        return ret;
+    }
+
+    return 0;
+}
+
+#define OFFSET(x) offsetof(OMAFContext, x)
+#define E AV_OPT_FLAG_ENCODING_PARAM
+static const AVOption options[] = {
+    { "packing_proj_type", "input source projection type, ERP or Cubemap", OFFSET(proj_type), AV_OPT_TYPE_STRING, { .str = "ERP" }, 0, 0, E },
+    { "cubemap_face_file", "configure input cubemap face relation to face layout defined in OMAF for cube-3x2", OFFSET(face_file), AV_OPT_TYPE_STRING, { 0 }, 0, 0, E },
+    { "viewport_w", "set viewport width", OFFSET(viewport_w), AV_OPT_TYPE_INT, { .i64 = 1024 }, 0, INT_MAX, E },
+    { "viewport_h", "set viewport height", OFFSET(viewport_h), AV_OPT_TYPE_INT, { .i64 = 1024 }, 0, INT_MAX, E },
+    { "viewport_yaw", "set viewport yaw angle, which is the angle around y axis", OFFSET(viewport_yaw), AV_OPT_TYPE_FLOAT, { .dbl = 90 }, 0, 180, E },
+    { "viewport_pitch", "set viewport pitch angle, which is the angle around x axis", OFFSET(viewport_pitch), AV_OPT_TYPE_FLOAT, { .dbl = 0 }, 0, 100, E },
+    { "viewport_fov_hor", "set horizontal angle of field of view (FOV)", OFFSET(viewport_fov_hor), AV_OPT_TYPE_FLOAT, { .dbl = 80 }, 0, 180, E },
+    { "viewport_fov_ver", "set vertical angle of field of view (FOV)", OFFSET(viewport_fov_ver), AV_OPT_TYPE_FLOAT, { .dbl = 80 }, 0, 100, E },
+    { "window_size", "number of segments kept in the manifest", OFFSET(window_size), AV_OPT_TYPE_INT, { .i64 = 5 }, 0, INT_MAX, E },
+    { "extra_window_size", "number of segments kept outside of the manifest before removing from disk", OFFSET(extra_window_size), AV_OPT_TYPE_INT, { .i64 = 15 }, 0, INT_MAX, E },
+    { "split_tile", "need split the stream to tiles if input is tile-based hevc stream", OFFSET(split_tile), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 2, E },
+    { "seg_duration", "segment duration (in seconds, fractional value can be set)", OFFSET(seg_duration), AV_OPT_TYPE_DURATION, { .i64 = 5000000 }, 0, INT_MAX, E },
+    { "remove_at_exit", "remove all segments when finished", OFFSET(remove_at_exit), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "use_template", "Use SegmentTemplate instead of SegmentList", OFFSET(use_template), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, E },
+    { "use_timeline", "Use SegmentTimeline in SegmentTemplate", OFFSET(use_timeline), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, E },
+    { "utc_timing_url", "URL of the page that will return the UTC timestamp in ISO format", OFFSET(utc_timing_url), AV_OPT_TYPE_STRING, { 0 }, 0, 0, E },
+    { "is_live", "Enable/Disable streaming mode of output. Each frame will be moof fragment", OFFSET(is_live), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "base_url", "MPD BaseURL", OFFSET(base_url), AV_OPT_TYPE_STRING, { 0 }, 0, 0, E },
+    { "out_name", "name prefix for all dash output files", OFFSET(out_name), AV_OPT_TYPE_STRING, {.str = "dash-stream"}, 0, 0, E },
+    { "need_buffered_frames", "needed buffered frames number before packing starts", OFFSET(need_buffered_frames), AV_OPT_TYPE_INT, { .i64 = 15 }, 0, INT_MAX, E },
+    { "extractors_per_thread", "extractor tracks per segmentation thread", OFFSET(extractors_per_thread), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, E },
+    { "has_extractor", "Enable/Disable OMAF extractor tracks", OFFSET(has_extractor), AV_OPT_TYPE_INT, { .i64 = 1 }, 0, INT_MAX, E },
+    { "packing_plugin_path", "OMAF Packing plugin path", OFFSET(packingPluginPath), AV_OPT_TYPE_STRING, {.str = "/usr/local/lib"}, 0, 0, E },
+    { "packing_plugin_name", "OMAF Packing plugin name", OFFSET(packingPluginName), AV_OPT_TYPE_STRING, {.str = "HighResPlusFullLowResPacking"}, 0, 0, E },
+    { "video_plugin_path", "Video stream process plugin path", OFFSET(videoPluginPath), AV_OPT_TYPE_STRING, {.str = "/usr/local/lib"}, 0, 0, E },
+    { "video_plugin_name", "Video stream process plugin name", OFFSET(videoPluginName), AV_OPT_TYPE_STRING, {.str = "HevcVideoStreamProcess"}, 0, 0, E },
+    { "audio_plugin_path", "Audio stream process plugin path", OFFSET(audioPluginPath), AV_OPT_TYPE_STRING, {.str = "NULL"}, 0, 0, E },
+    { "audio_plugin_name", "Audio stream process plugin name", OFFSET(audioPluginName), AV_OPT_TYPE_STRING, {.str = "NULL"}, 0, 0, E },
+    { "fixed_extractors_res", "whether extractor track needs the fixed resolution", OFFSET(fixedPackedPicRes), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "need_external_log", "whether external log callback is needed", OFFSET(need_external_log), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "min_log_level", "Minimal log level of output [0: INFO, 1: WARNING, 2: ERROR, 3: FATAL]", OFFSET(min_log_level), AV_OPT_TYPE_INT, { .i64 = 2 }, 0, 3, E },
+    { NULL },
+};
+
+static const AVClass omaf_class = {
+    .class_name = "OMAF Compliance muxer",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+AVOutputFormat ff_omaf_packing_muxer = {
+    .name           = "omaf_packing",
+    .long_name      = "VR OMAF Compliance Muxer",
+    .extensions     = "mpd",
+    .priv_data_size = sizeof(OMAFContext),
+    .audio_codec    = AV_CODEC_ID_AAC,
+    .video_codec    = AV_CODEC_ID_HEVC,
+    .flags          = AVFMT_GLOBALHEADER | AVFMT_NOFILE | AVFMT_TS_NEGATIVE,
+    .init           = omaf_init,
+    .write_header   = omaf_write_header,
+    .write_packet   = omaf_write_packet,
+    .write_trailer  = omaf_write_trailer,
+    .deinit         = omaf_free,
+    .priv_class     = &omaf_class,
+};
diff -urN FFmpeg/libavformat/tiled_dash_dec.c FFmpeg-patched/libavformat/tiled_dash_dec.c
--- FFmpeg/libavformat/tiled_dash_dec.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavformat/tiled_dash_dec.c	2020-09-27 13:35:13.559526536 +0800
@@ -0,0 +1,408 @@
+/*
+ * Intel tile Dash Demuxer
+ *
+ * Copyright (c) 2018 Intel Cooperation
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+#include "libavutil/time.h"
+
+#include "libavutil/avassert.h"
+#include "libavutil/avutil.h"
+#include "libavutil/avstring.h"
+#include "libavutil/intreadwrite.h"
+#include "libavutil/mathematics.h"
+#include "libavutil/opt.h"
+#include "libavutil/rational.h"
+#include "libavutil/time_internal.h"
+
+#include "libavcodec/avcodec.h"
+#include "avformat.h"
+#include "internal.h"
+#include "avio_internal.h"
+#include "tiled_dash_dec.h"
+
+uint64_t frameCnt = 0;
+
+int tiled_dash_ViewPort_update(AVFormatContext *s, bool isVertical, double move)
+{
+    int ret = 0;
+    TiledDASHDecContext *c = s->priv_data;
+    if(isVertical)
+    {
+        double pitch = move + c->lastPose.pitch;
+        if(pitch > 90)
+        {
+            pitch = 90;
+        }
+        else if(pitch < -90)
+        {
+            pitch = -90;
+        }
+
+        c->pose.pitch = pitch;
+    }
+    else
+    {
+        double yaw = move + c->lastPose.yaw;
+        if(yaw > 180)
+        {
+            yaw -= 360;
+        }
+        else if(yaw < -180)
+        {
+            yaw += 360;
+        }
+        c->pose.yaw = yaw;
+    }
+
+    c->lastPose.yaw = c->pose.yaw;
+    c->lastPose.pitch = c->pose.pitch;
+
+    ret = OmafAccess_ChangeViewport(c->hdl, &(c->pose));
+    return ret;
+}
+
+static int tiled_dash_read_packet(AVFormatContext *s, AVPacket *pkt)
+{
+    int ret = 0;
+    TiledDASHDecContext *c = s->priv_data;
+    frameCnt++;
+    // TODO: read packet for one stream once??
+    for (int streamId = 0; streamId < c->mInfo.stream_count; streamId++)
+    {
+    //int streamId = 0;
+    //frameCnt++;
+
+        DashStreamInfo stInfo = c->mInfo.stream_info[streamId];
+
+        DashPacket dashPkt[5];
+        memset(dashPkt, 0, 5 * sizeof(DashPacket));
+        int dashPktNum = 0;
+
+        if (stInfo.stream_type == MediaType_Video)
+        {
+            ret = OmafAccess_GetPacket(c->hdl, streamId, &(dashPkt[0]), &dashPktNum, &(pkt->pts), c->needHeaders, c->mClearBuf);
+            if(ret != ERROR_NONE){
+                //av_log(s, AV_LOG_ERROR, "OmafAccess_GetPacket get null packet\    n" );
+                //av_packet_unref(pkt);
+            }
+
+            if ((frameCnt % 50) == 0)
+            {
+                HeadPose newPose;
+                newPose.yaw = 45;
+                newPose.pitch = 90;
+                OmafAccess_ChangeViewport(c->hdl, &newPose);
+            }
+            else if ((frameCnt % 75) == 0)
+            {
+                OmafAccess_ChangeViewport(c->hdl, &(c->pose));
+            }
+
+            if(dashPktNum && dashPkt[0].buf && dashPkt[0].size)
+            {
+                int size = dashPkt[0].size;
+                if (av_new_packet(pkt, size) < 0)
+                    return AVERROR(ENOMEM);
+
+                memcpy(pkt->data, dashPkt[0].buf, size);
+                pkt->size = size;
+
+                free(dashPkt[0].buf);
+                dashPkt[0].buf = NULL;
+                if (dashPkt[0].rwpk != NULL)
+                {
+                    if (dashPkt[0].rwpk->rectRegionPacking != NULL)
+                    {
+                        free(dashPkt[0].rwpk->rectRegionPacking);
+                        dashPkt[0].rwpk->rectRegionPacking = NULL;
+                    }
+                    free(dashPkt[0].rwpk);
+                    dashPkt[0].rwpk = NULL;
+                }
+                if (dashPkt[0].qtyResolution)
+                {
+                    free(dashPkt[0].qtyResolution);
+                    dashPkt[0].qtyResolution = NULL;
+                }
+                if(c->needHeaders){c->needHeaders = false;}
+            }
+
+            for (int pktIdx = 1; pktIdx < dashPktNum; pktIdx++)
+            {
+                if (dashPkt[pktIdx].buf && dashPkt[pktIdx].size)
+                {
+                    free(dashPkt[pktIdx].buf);
+                    dashPkt[pktIdx].buf = NULL;
+
+                    if (dashPkt[pktIdx].rwpk != NULL)
+                    {
+                        if (dashPkt[pktIdx].rwpk->rectRegionPacking != NULL)
+                        {
+                            free(dashPkt[pktIdx].rwpk->rectRegionPacking);
+                            dashPkt[pktIdx].rwpk->rectRegionPacking = NULL;
+                        }
+                        free(dashPkt[pktIdx].rwpk);
+                        dashPkt[pktIdx].rwpk = NULL;
+                    }
+                    if (dashPkt[pktIdx].qtyResolution)
+                    {
+                        free(dashPkt[pktIdx].qtyResolution);
+                        dashPkt[pktIdx].qtyResolution = NULL;
+                    }
+                }
+            }
+        }
+        else if (stInfo.stream_type == MediaType_Audio)
+        {
+            uint64_t audio_pts = 0;
+            ret = OmafAccess_GetPacket(c->hdl, streamId, &(dashPkt[0]), &dashPktNum, &(audio_pts), c->needHeaders, c->mClearBuf);
+            if(ret == ERROR_NULL_PACKET)
+            {
+                av_log(s, AV_LOG_INFO, "OmafAccess_GetPacket get null packet\n" );
+            }
+
+            if(dashPktNum && dashPkt[0].buf && dashPkt[0].size)
+            {
+                FILE *audioFP = fopen("dumpedAAC.aac", "ab+");
+                if (!audioFP)
+                {
+                    av_log(s, AV_LOG_ERROR, "Failed to open dumpedAAC.m4a !\n" );
+                }
+                fwrite(dashPkt[0].buf, 1, dashPkt[0].size, audioFP);
+                fclose(audioFP);
+                audioFP = NULL;
+            }
+        }
+    }
+    return ret;
+}
+
+static int SetupHeadSetInfo(HeadSetInfo *clientInfo)
+{
+    if(!clientInfo)
+    {
+        return -1;
+    }
+
+    clientInfo->pose = (HeadPose*)malloc(sizeof(HeadPose));
+    clientInfo->pose->yaw = -90;
+    clientInfo->pose->pitch = 0;
+    clientInfo->viewPort_hFOV = 80;
+    clientInfo->viewPort_vFOV = 80;
+    clientInfo->viewPort_Width = 960;
+    clientInfo->viewPort_Height = 960;
+
+    return 0;
+}
+
+static int tiled_dash_read_header(AVFormatContext *s)
+{
+    int ret = 0;
+    TiledDASHDecContext *c = s->priv_data;
+    AVIOContext *pb = s->pb;
+
+    c->mClearBuf = false;
+    c->needHeaders = true;
+    c->client = (DashStreamingClient *)malloc(sizeof(DashStreamingClient));
+    memset(c->client, 0, sizeof(DashStreamingClient));
+    memset(&c->client->omaf_params.proxy, 0, sizeof(OmafHttpProxy));
+    memset(&c->client->omaf_params.predictor_params, 0, sizeof(OmafPredictorParams));
+    c->client->omaf_params.max_decode_width = 2560;
+    c->client->omaf_params.max_decode_height = 2560;
+    c->client->source_type = MultiResSource;//DefaultSource;
+    c->client->media_url = s->filename;
+    c->client->enable_extractor = c->enable_extractor;
+    if(!c->cache_path)
+    {
+        c->client->cache_path = "./cache";
+    }
+    else
+    {
+        char* cache_folder = "/cache";
+        c->client->cache_path = malloc(strlen(c->cache_path) + strlen(cache_folder));
+        strcpy(c->client->cache_path, c->cache_path);
+        strcpy(c->client->cache_path + strlen(c->cache_path), cache_folder);
+    }
+
+    c->hdl = OmafAccess_Init(c->client);
+
+    ret = SetupHeadSetInfo(&(c->HSInfo));
+    ret = OmafAccess_SetupHeadSetInfo(c->hdl, &(c->HSInfo));
+
+    ret = OmafAccess_OpenMedia(c->hdl, c->client, false, "", "");
+    ret = OmafAccess_StartStreaming(c->hdl);
+
+    c->lastPose.yaw = c->HSInfo.pose->yaw;
+    c->lastPose.pitch = c->HSInfo.pose->pitch;
+
+    ret = OmafAccess_GetMediaInfo(c->hdl, &(c->mInfo));
+    printf("Media streams cnt is %d\n", c->mInfo.stream_count);
+    bool hasAudio = false;
+    for(int i = 0 ; i < c->mInfo.stream_count ; i++)
+    {
+        DashStreamInfo stInfo = c->mInfo.stream_info[i];
+        if (stInfo.stream_type == MediaType_Audio)
+        {
+            hasAudio = true;
+            break;
+        }
+    }
+
+    for(int i = 0 ; i < c->mInfo.stream_count ; i++)
+    {
+        AVStream *st = avformat_new_stream(s, NULL);
+        if (!st) {
+            return AVERROR(ENOMEM);
+        }
+        DashStreamInfo stInfo = c->mInfo.stream_info[i];
+
+        st->id = i;
+        //codec_parameters_reset(st->codecpar);
+
+        if(stInfo.stream_type == MediaType_Video)
+        {
+            st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;
+            if (hasAudio)
+            {
+                c->n_videos = c->mInfo.stream_count - 1;
+            }
+            else
+            {
+                c->n_videos = c->mInfo.stream_count;
+            }
+            st->codecpar->codec_id = AV_CODEC_ID_HEVC;
+        }
+        else if(stInfo.stream_type == MediaType_Audio)
+        {
+            st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;
+            c->n_audios = 1;
+            st->codecpar->codec_id = AV_CODEC_ID_AAC;
+        }
+
+        // st->codecpar->codec_id = AV_CODEC_ID_HEVC;
+
+        st->codecpar->width = stInfo.width;
+        st->codecpar->height = stInfo.height;
+        st->codecpar->bit_rate = stInfo.bit_rate;
+        st->codecpar->codec_tag = avio_rl32(pb);
+
+        //st->codecpar->extradata = ;
+        //st->codecpar->extradata_size = ;
+        st->codecpar->bits_per_coded_sample = avio_rb16(pb);
+
+        //st->need_parsing = AVSTREAM_PARSE_FULL_RAW;
+
+        st->internal->avctx->framerate.num = stInfo.framerate_num;
+        st->internal->avctx->framerate.den = stInfo.framerate_den;
+        //st->internal->avctx->framerate = stInfo.framerate_num / stInfo.framerate_den;
+        //st->time_base.num = stInfo.framerate_num;
+        //st->time_base.den = stInfo.framerate_den;
+        avpriv_set_pts_info(st, st->pts_wrap_bits, st->time_base.num, st->time_base.den);
+    }
+
+    av_usleep(5000000);
+
+    return ret;
+}
+
+static int tiled_dash_close(AVFormatContext *s)
+{
+    TiledDASHDecContext *c = s->priv_data;
+
+    OmafAccess_CloseMedia(c->hdl);
+
+    OmafAccess_Close(c->hdl);
+
+    if(c->HSInfo.pose)
+    {
+        free(c->HSInfo.pose);
+        c->HSInfo.pose = NULL;
+    }
+
+    if(c->client)
+    {
+        free(c->client);
+        c->client = NULL;
+    }
+
+    return 0;
+}
+
+static int tiled_dash_read_seek(AVFormatContext *s, int stream_index, int64_t timestamp, int flags)
+{
+    TiledDASHDecContext *c = s->priv_data;
+
+    OmafAccess_SeekMedia(c->hdl, time);
+
+    return 0;
+}
+
+static int tiled_dash_probe(AVProbeData *p)
+{
+    if (!av_stristr(p->buf, "<MPD"))
+        return 0;
+
+    if (av_stristr(p->buf, "urn:mpeg:dash:schema:mpd:2011") ||
+        av_stristr(p->buf, "urn:mpeg:dash:srd:2014") ){
+        return AVPROBE_SCORE_MAX;
+    }
+    if (av_stristr(p->buf, "urn:mpeg:dash:profile:isoff-live:2011")) {
+        return AVPROBE_SCORE_MAX;
+    }
+
+    return 0;
+}
+
+#define OFFSET(x) offsetof(TiledDASHDecContext, x)
+#define FLAGS AV_OPT_FLAG_DECODING_PARAM
+static const AVOption dash_options[] = {
+    {"allowed_extensions", "List of file extensions that dash is allowed to access",
+        OFFSET(allowed_extensions), AV_OPT_TYPE_STRING,
+        {.str = "mpd"},
+        INT_MIN, INT_MAX, FLAGS},
+    {"cache_path", "the specific path of cache folder, default is /home",
+        OFFSET(cache_path), AV_OPT_TYPE_STRING,
+        {.str = NULL},
+        INT_MIN, INT_MAX, FLAGS},
+    {"enable_extractor", "whether to enable extractor track in OMAF Dash Access engine",
+        OFFSET(enable_extractor), AV_OPT_TYPE_INT,
+        {.i64 = 1},
+        INT_MIN, INT_MAX, FLAGS},
+    {NULL}
+};
+
+static const AVClass tiled_dash_dec_class = {
+    .class_name = "Tiled Dash Demuxer",
+    .item_name  = av_default_item_name,
+    .option     = dash_options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+AVInputFormat ff_tile_dash_demuxer = {
+    .name           = "tiled_dash_demuxer",
+    .long_name      = "Demuxer for Dynamic Adaptive Streaming over HTTP",
+    .priv_class     = &tiled_dash_dec_class,
+    .priv_data_size = sizeof(TiledDASHDecContext),
+    .read_probe     = tiled_dash_probe,
+    .read_header    = tiled_dash_read_header,
+    .read_packet    = tiled_dash_read_packet,
+    .read_close     = tiled_dash_close,
+    .read_seek      = tiled_dash_read_seek,
+    .flags          = AVFMT_NO_BYTE_SEEK,
+};
diff -urN FFmpeg/libavformat/tiled_dash_dec.h FFmpeg-patched/libavformat/tiled_dash_dec.h
--- FFmpeg/libavformat/tiled_dash_dec.h	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavformat/tiled_dash_dec.h	2020-09-27 13:35:13.557526536 +0800
@@ -0,0 +1,65 @@
+/*
+ * Intel tile Dash muxer
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef TILE_DASH_DEC_H
+#define TILE_DASH_DEC_H
+
+#include <stdbool.h>
+
+#include "libavutil/avassert.h"
+#include "libavutil/avutil.h"
+#include "libavutil/avstring.h"
+#include "libavutil/intreadwrite.h"
+#include "libavutil/mathematics.h"
+#include "libavutil/opt.h"
+#include "libavutil/rational.h"
+#include "libavutil/time_internal.h"
+
+#include "avformat.h"
+#include "avio_internal.h"
+
+#include "OmafDashAccessApi.h"
+
+typedef struct{
+    const AVClass *class;
+    char allowed_extensions[256];
+    char* cache_path;
+
+    int n_videos;
+
+    int n_audios;
+
+    DashStreamingClient *client;
+    DashMediaInfo       mInfo;
+    Handler             hdl;
+    HeadSetInfo         HSInfo;
+    HeadPose            pose;
+    HeadPose            lastPose;
+    bool                mClearBuf;
+    bool                needHeaders;
+    int                 enable_extractor;
+}TiledDASHDecContext;
+
+int tiled_dash_ViewPort_update(AVFormatContext *s, bool isVertical, double move);
+
+#endif
+
diff -urN FFmpeg/libavformat/tiled_dash_enc.c FFmpeg-patched/libavformat/tiled_dash_enc.c
--- FFmpeg/libavformat/tiled_dash_enc.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavformat/tiled_dash_enc.c	2020-09-27 13:35:13.557526536 +0800
@@ -0,0 +1,359 @@
+/*
+ * Intel tile Dash muxer
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <unistd.h>
+#include <sys/stat.h>
+
+#include "tiled_dash_parse.h"
+
+static int dash_init(AVFormatContext *s)
+{
+    GPAC_DASHContext *c = s->priv_data;
+    int ret = 0, i;
+    char *ptr;
+    char basename[1024];
+    int mode;
+    int mode_u, mode_g, mode_o;
+
+    av_strlcpy(c->dirname, s->url, sizeof(c->dirname));
+    ptr = strrchr(c->dirname, '/');
+    if (ptr) {
+        av_strlcpy(basename, &ptr[1], sizeof(basename));
+        ptr[1] = '\0';
+    } else {
+        c->dirname[0] = '\0';
+        av_strlcpy(basename, s->url, sizeof(basename));
+    }
+
+    //av_strlcpy(c->base_url, "", sizeof(c->base_url));
+    ptr = strrchr(basename, '.');
+    if (ptr)
+        *ptr = '\0';
+
+    c->streams = av_mallocz(sizeof(*c->streams) * s->nb_streams);
+    if (!c->streams)
+        return AVERROR(ENOMEM);
+
+    c->nb_streams = s->nb_streams;
+    for (i = 0; i < s->nb_streams; i++) {
+        DashOutStream *os = &c->streams[i];
+        AVStream *st = s->streams[i];
+        os->stream_index = i + 1;
+        os->bit_rate = s->streams[i]->codecpar->bit_rate;
+        os->frame_rate = (double)st->avg_frame_rate.num / (double)st->avg_frame_rate.den;
+        if (!os->bit_rate) {
+            int level = s->strict_std_compliance >= FF_COMPLIANCE_STRICT ?
+                        AV_LOG_ERROR : AV_LOG_WARNING;
+            av_log(s, level, "No bit rate set for stream %d\n", i);
+            if (s->strict_std_compliance >= FF_COMPLIANCE_STRICT)
+                return AVERROR(EINVAL);
+        }
+
+        //ff_dash_fill_tmpl_params(os->initfile, sizeof(os->initfile), c->init_seg_name, i, 0, os->bit_rate, 0);
+        snprintf(os->out_name, sizeof(os->out_name), "%s%d", c->out_name, os->stream_index);
+        snprintf(os->dir_name, sizeof(os->dir_name), "%s", c->dirname);
+
+        mode_u = 7;
+        mode_g = 7;
+        mode_o = 7;
+        mode = mode_u * 64 + mode_g * 8 + mode_o;
+        if (access(&(os->dir_name[0]), 0) == 0)
+        {
+            av_log(s, AV_LOG_DEBUG, "Folder %s has existed\n", os->dir_name);
+            if (access(&(os->dir_name[0]), mode) != 0)
+            {
+                if (chmod(&(os->dir_name[0]), mode) != 0)
+                {
+                    av_log(s, AV_LOG_ERROR, "Failed to change write mode for folder %s\n", os->dir_name);
+                    return AVERROR(EINVAL);
+                }
+            }
+        }
+        else
+        {
+            av_log(s, AV_LOG_DEBUG, "Create folder %s\n", os->dir_name);
+            if (mkdir(&(os->dir_name[0]), mode) != 0)
+            {
+                av_log(s, AV_LOG_ERROR, "Failed to create folder %s\n", os->dir_name);
+                return AVERROR(EINVAL);
+            }
+        }
+
+        //snprintf(os->stream_name, sizeof(os->stream_name), "%s%s", c->dirname, c->out_name);
+
+        av_log(s, AV_LOG_VERBOSE, "stream %d output filename prefix: %s%s\n", i, os->dir_name, os->out_name);
+
+        os->initialized = 0;
+        //os->packets_written = 0;
+        //os->total_pkt_size = 0;
+        os->vstream_idx = i;
+        os->fmt_ctx = s;
+        os->codec_ctx = s->streams[i]->codecpar;
+        os->bit_rate = s->streams[i]->codecpar->bit_rate;
+        os->split_tile = c->split_tile;
+        os->timescale = st->time_base;
+
+        if(NULL != s->streams[i]->codecpar->extradata){
+            ret = dash_probe_extra_data(os, s->streams[i]->codecpar->extradata, 
+                                           s->streams[i]->codecpar->extradata_size);
+            if(ret != 0){
+                av_freep(&c->streams);
+                return ret;
+            }
+                
+            ret = dash_init_output_stream(c, os);
+                
+            if(!ret) os->initialized = 1;
+        }
+        
+        switch(st->codecpar->codec_type) {
+        case AVMEDIA_TYPE_VIDEO:
+            c->has_video = 1;
+            break;
+        case AVMEDIA_TYPE_AUDIO:
+            c->has_audio = 1;
+            break;
+        default:
+            break;
+        }
+    }
+
+    if (!c->has_video && c->seg_duration <= 0) {
+        av_log(s, AV_LOG_WARNING, "no video stream and no seg duration set\n");
+        return AVERROR(EINVAL);
+    }
+    return 0;
+}
+
+static void dash_free(AVFormatContext *s)
+{
+    GPAC_DASHContext *c = s->priv_data;
+    int i;
+
+    if (!c->streams)
+        return;
+    for (i = 0; i < s->nb_streams; i++) {
+        DashOutStream *os = &c->streams[i];
+        dash_free_output_stream(os);
+    }
+    av_freep(&c->streams);
+}
+
+static int dash_write_header(AVFormatContext *s)
+{
+    //GPAC_DASHContext *c = s->priv_data;
+    //int i, ret = 0;
+    //for (i = 0; i < s->nb_streams; i++) {
+    //    DashOutStream *os = &c->streams[i];
+        //TOBE: write header for each out stream. 
+    //}
+    return 0;//ret;
+}
+
+static int dash_write_packet(AVFormatContext *s, AVPacket *pkt)
+{
+    GPAC_DASHContext *c = s->priv_data;
+    AVStream *st = s->streams[pkt->stream_index];
+    DashOutStream *os = &c->streams[pkt->stream_index];
+    //int64_t seg_end_duration, elapsed_duration;
+    int ret = 0;
+
+    if(!os->initialized){
+        //if(!s->streams[pkt->stream_index]->codecpar->extradata) return 0;
+        
+        ret = dash_probe_extra_data(os, pkt->data, pkt->size);
+        //ret = dash_probe_extra_data(os, s->streams[pkt->stream_index]->codecpar->extradata, 
+        //                       s->streams[pkt->stream_index]->codecpar->extradata_size);
+        
+        if(ret != 0) return ret;
+        
+        ret = dash_init_output_stream(c, os);
+        if(ret != 0){
+            av_log(s, AV_LOG_ERROR, "Output stream initialized failed: %d\n", pkt->stream_index );
+            return ret;
+        }
+        os->initialized = 1;
+    }
+    
+    ///write mpd in streaming mode
+    if( c->streaming ){
+        ret = dash_update_mpd(c, 0);
+        if(ret != 0){
+            av_log(s, AV_LOG_ERROR, "Failed to update mpd in streaming mode\n" );
+            return ret;
+        }
+    }
+
+    // Fill in a heuristic guess of the packet duration, if none is available.
+    // The mp4 muxer will do something similar (for the last packet in a fragment)
+    // if nothing is set (setting it for the other packets doesn't hurt).
+    // By setting a nonzero duration here, we can be sure that the mp4 muxer won't
+    // invoke its heuristic (this doesn't have to be identical to that algorithm),
+    // so that we know the exact timestamps of fragments.
+    if (!pkt->duration && os->last_dts != AV_NOPTS_VALUE)
+        pkt->duration = pkt->dts - os->last_dts;
+    os->last_dts = pkt->dts;
+
+    // If forcing the stream to start at 0, the mp4 muxer will set the start
+    // timestamps to 0. Do the same here, to avoid mismatches in duration/timestamps.
+    if (os->first_pts == AV_NOPTS_VALUE &&
+        s->avoid_negative_ts == AVFMT_AVOID_NEG_TS_MAKE_ZERO) {
+        pkt->pts -= pkt->dts;
+        pkt->dts  = 0;
+    }
+
+    if (os->first_pts == AV_NOPTS_VALUE)
+        os->first_pts = pkt->pts;
+
+    if (!c->availability_start_time[0])
+        format_date_now(c->availability_start_time,
+                        sizeof(c->availability_start_time));
+    
+    if (!os->availability_time_offset && pkt->duration) {
+        int64_t frame_duration = av_rescale_q(pkt->duration, st->time_base,
+                                              AV_TIME_BASE_Q);
+         os->availability_time_offset = ((double) c->seg_duration -
+                                         frame_duration) / AV_TIME_BASE;
+    }
+
+    ret = dash_write_segment(c, os, pkt );
+    if(ret){
+        av_log(s, AV_LOG_ERROR, "Failed to write segment for stream %d\n", pkt->stream_index );
+        return ret;
+    }
+
+    return ret;
+}
+
+static int dash_write_trailer(AVFormatContext *s)
+{
+    GPAC_DASHContext *c = s->priv_data;
+    int ret = 0;
+    DashOutStream *os = NULL;
+    
+    for (int i = 0; i < s->nb_streams; i++) {
+        os = &c->streams[i];
+        os->total_frames = os->nb_frames;
+        av_log(s, AV_LOG_DEBUG, "Total_frames %d \n", os->total_frames);
+        if (os->total_frames % os->frame_per_fragment != 0)
+        {
+            dash_end_output_stream(os);
+        }
+    }
+
+    if (c->streaming)
+    {
+        ret = dash_update_mpd(c, 1);
+        if(ret ){
+            av_log(s, AV_LOG_ERROR, "Failed to write mpd \n" );
+            return ret;
+        }
+    }
+    else
+    {
+        dash_write_mpd(c, 1);
+    } 
+    /*
+    if (s->nb_streams > 0) {
+        DashOutStream *os = &c->streams[0];
+        // If no segments have been written so far, try to do a crude
+        // guess of the segment duration
+        if (!c->last_duration)
+            c->last_duration = av_rescale_q(os->last_pts - os->start_pts,
+                                            s->streams[0]->time_base,
+                                            AV_TIME_BASE_Q);
+        c->total_duration = av_rescale_q(os->last_pts - os->first_pts,
+                                         s->streams[0]->time_base,
+                                         AV_TIME_BASE_Q);
+    }
+    //dash_flush(s, 1, -1);
+    */
+    return 0;
+}
+
+/*
+static int dash_check_bitstream(struct AVFormatContext *s, const AVPacket *avpkt)
+{
+    GPAC_DASHContext *c = s->priv_data;
+    DashOutStream *os = &c->streams[avpkt->stream_index];
+    AVFormatContext *oc = s->ctx;
+    if (oc->oformat->check_bitstream) {
+        int ret;
+        AVPacket pkt = *avpkt;
+        pkt.stream_index = 0;
+        ret = oc->oformat->check_bitstream(oc, &pkt);
+        if (ret == 1) {
+            AVStream *st = s->streams[avpkt->stream_index];
+            AVStream *ost = oc->streams[0];
+            //st->internal->bsfcs = ost->internal->bsfcs;
+            //st->internal->nb_bsfcs = ost->internal->nb_bsfcs;
+            //ost->internal->bsfcs = NULL;
+            //ost->internal->nb_bsfcs = 0;
+        }
+        return ret;
+    }
+    return 1;
+}
+*/
+#define OFFSET(x) offsetof(GPAC_DASHContext, x)
+#define E AV_OPT_FLAG_ENCODING_PARAM
+static const AVOption options[] = {
+    { "adaptation_sets", "Adaptation sets. Syntax: id=0,streams=0,1,2 id=1,streams=3,4 and so on", OFFSET(adaptation_sets), AV_OPT_TYPE_STRING, { 0 }, 0, 0, AV_OPT_FLAG_ENCODING_PARAM },
+    { "window_size", "number of segments kept in the manifest", OFFSET(window_size), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, E },
+    { "extra_window_size", "number of segments kept outside of the manifest before removing from disk", OFFSET(extra_window_size), AV_OPT_TYPE_INT, { .i64 = 5 }, 0, INT_MAX, E },
+    { "split_tile", "need split the stream to tiles if input is tile-based hevc stream", OFFSET(split_tile), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 2, E },
+    { "seg_duration", "segment duration (in seconds, fractional value can be set)", OFFSET(seg_duration), AV_OPT_TYPE_DURATION, { .i64 = 5000000 }, 0, INT_MAX, E },
+    { "remove_at_exit", "remove all segments when finished", OFFSET(remove_at_exit), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "use_template", "Use SegmentTemplate instead of SegmentList", OFFSET(use_template), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, E },
+    { "use_timeline", "Use SegmentTimeline in SegmentTemplate", OFFSET(use_timeline), AV_OPT_TYPE_BOOL, { .i64 = 1 }, 0, 1, E },
+    { "utc_timing_url", "URL of the page that will return the UTC timestamp in ISO format", OFFSET(utc_timing_url), AV_OPT_TYPE_STRING, { 0 }, 0, 0, E },
+    { "streaming", "Enable/Disable streaming mode of output. Each frame will be moof fragment", OFFSET(streaming), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, E },
+    { "base_url", "MPD BaseURL", OFFSET(base_url), AV_OPT_TYPE_STRING, { 0 }, 0, 0, E },
+    { "out_name", "name prefix for all dash output files", OFFSET(out_name), AV_OPT_TYPE_STRING, {.str = "dash-stream"}, 0, 0, E },
+    { NULL },
+};
+
+static const AVClass dash_class = {
+    .class_name = "libgpac dash muxer",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+AVOutputFormat ff_tile_dash_muxer = {
+    .name           = "tile_dash",
+    .long_name      = "libgpac-based tiled DASH Muxer",
+    .extensions     = "mpd",
+    .priv_data_size = sizeof(GPAC_DASHContext),
+    .audio_codec    = AV_CODEC_ID_AAC,
+    .video_codec    = AV_CODEC_ID_HEVC,
+    .flags          = AVFMT_GLOBALHEADER | AVFMT_NOFILE | AVFMT_TS_NEGATIVE,
+    .init           = dash_init,
+    .write_header   = dash_write_header,
+    .write_packet   = dash_write_packet,
+    .write_trailer  = dash_write_trailer,
+    .deinit         = dash_free,
+ //   .check_bitstream = dash_check_bitstream,
+    .priv_class     = &dash_class,
+};
+
+
diff -urN FFmpeg/libavformat/tiled_dash_parse.c FFmpeg-patched/libavformat/tiled_dash_parse.c
--- FFmpeg/libavformat/tiled_dash_parse.c	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavformat/tiled_dash_parse.c	2020-09-27 13:35:13.558526536 +0800
@@ -0,0 +1,1624 @@
+/*
+ * Intel tile Dash muxer
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <stdio.h>
+
+#include "tiled_dash_parse.h"
+
+void format_date_now(char *buf, int size)
+{
+    time_t t = time(NULL);
+    struct tm *ptm, tmbuf;
+    ptm = gmtime_r(&t, &tmbuf);
+    if (ptm) {
+        if (!strftime(buf, size, "%Y-%m-%dT%H:%M:%SZ", ptm))
+            buf[0] = '\0';
+    }
+}
+
+/**
+ * A function which takes FFmpeg H264 extradata (SPS/PPS) and bring them ready to be pushed to the MP4 muxer.
+ * @param extradata
+ * @param extradata_size
+ * @param dstcfg
+ * @returns GF_OK is the extradata was parsed and is valid, other values otherwise.
+ */
+static GF_Err dc_avc_import_ffextradata(const u8 *extradata, const u64 extradata_size, GF_AVCConfig *dstcfg)
+{
+#ifdef GPAC_DISABLE_AV_PARSERS
+	return GF_OK;
+#else
+	u8 nal_size;
+	AVCState avc;
+	GF_BitStream *bs;
+	if (!extradata || (extradata_size < sizeof(u32)))
+		return GF_BAD_PARAM;
+	bs = gf_bs_new((const char *) extradata, extradata_size, GF_BITSTREAM_READ);
+	if (!bs)
+		return GF_BAD_PARAM;
+	if (gf_bs_read_u32(bs) != 0x00000001) {
+		gf_bs_del(bs);
+		return GF_BAD_PARAM;
+	}
+
+	//SPS
+	{
+		s32 idx;
+		char *buffer = NULL;
+		const u64 nal_start = 4;
+		nal_size = gf_media_nalu_next_start_code_bs(bs);
+		if (nal_start + nal_size > extradata_size) {
+			gf_bs_del(bs);
+			return GF_BAD_PARAM;
+		}
+		buffer = (char*)gf_malloc(nal_size);
+		gf_bs_read_data(bs, buffer, nal_size);
+		gf_bs_seek(bs, nal_start);
+		if ((gf_bs_read_u8(bs) & 0x1F) != GF_AVC_NALU_SEQ_PARAM) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		}
+
+		idx = gf_media_avc_read_sps(buffer, nal_size, &avc, 0, NULL);
+		if (idx < 0) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		}
+
+		dstcfg->configurationVersion = 1;
+		dstcfg->profile_compatibility = avc.sps[idx].prof_compat;
+		dstcfg->AVCProfileIndication = avc.sps[idx].profile_idc;
+		dstcfg->AVCLevelIndication = avc.sps[idx].level_idc;
+		dstcfg->chroma_format = avc.sps[idx].chroma_format;
+		dstcfg->luma_bit_depth = 8 + avc.sps[idx].luma_bit_depth_m8;
+		dstcfg->chroma_bit_depth = 8 + avc.sps[idx].chroma_bit_depth_m8;
+
+		{
+			GF_AVCConfigSlot *slc = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));
+			slc->size = nal_size;
+			slc->id = idx;
+			slc->data = buffer;
+			gf_list_add(dstcfg->sequenceParameterSets, slc);
+		}
+	}
+
+	//PPS
+	{
+		s32 idx;
+		char *buffer = NULL;
+		const u64 nal_start = 4 + nal_size + 4;
+		gf_bs_seek(bs, nal_start);
+		nal_size = gf_media_nalu_next_start_code_bs(bs);
+		if (nal_start + nal_size > extradata_size) {
+			gf_bs_del(bs);
+			return GF_BAD_PARAM;
+		}
+		buffer = (char*)gf_malloc(nal_size);
+		gf_bs_read_data(bs, buffer, nal_size);
+		gf_bs_seek(bs, nal_start);
+		if ((gf_bs_read_u8(bs) & 0x1F) != GF_AVC_NALU_PIC_PARAM) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		}
+
+		idx = gf_media_avc_read_pps(buffer, nal_size, &avc);
+		if (idx < 0) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		}
+
+		{
+			GF_AVCConfigSlot *slc = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));
+			slc->size = nal_size;
+			slc->id = idx;
+			slc->data = buffer;
+			gf_list_add(dstcfg->pictureParameterSets, slc);
+		}
+	}
+
+	gf_bs_del(bs);
+	return GF_OK;
+#endif
+}
+
+/**
+ * A function which takes FFmpeg H265 extradata (SPS/PPS) and bring them ready to be pushed to the MP4 muxer.
+ * @param extradata
+ * @param extradata_size
+ * @param dstcfg
+ * @returns GF_OK is the extradata was parsed and is valid, other values otherwise.
+ */
+static GF_Err dc_hevc_import_ffextradata(const u8 *extradata, const u64 extradata_size, HEVCState* hevc, GF_HEVCConfig *dst_cfg)
+{
+#ifdef GPAC_DISABLE_AV_PARSERS
+    return GF_OK;
+#else
+    //HEVCState hevc;
+    GF_HEVCParamArray *vpss = NULL, *spss = NULL, *ppss = NULL, *seis = NULL;
+    GF_BitStream *bs;
+    char *buffer = NULL;
+    u32 buffer_size = 0;
+    if (!extradata || (extradata_size < sizeof(u32)))
+  	return GF_BAD_PARAM;
+    bs = gf_bs_new((const char *) extradata, extradata_size, GF_BITSTREAM_READ);
+    if (!bs)
+ 	return GF_BAD_PARAM;
+    
+    if( NULL == dst_cfg->param_array ) dst_cfg->param_array = gf_list_new();
+    
+    memset(hevc, 0, sizeof(HEVCState));
+    hevc->sps_active_idx = -1;
+
+    while (gf_bs_available(bs)) {
+ 	s32 idx;
+	GF_AVCConfigSlot *slc;
+	u8 nal_unit_type, temporal_id, layer_id;
+	u64 nal_start, start_code;
+	u32 nal_size;
+
+	start_code = gf_bs_read_u32(bs);
+	if (start_code>>8 == 0x000001) {
+            nal_start = gf_bs_get_position(bs) - 1;
+	    gf_bs_seek(bs, nal_start);
+	    start_code = 1;
+	}
+	if (start_code != 0x00000001) {
+	    gf_bs_del(bs);
+	    if (buffer) gf_free(buffer);
+		if (vpss && spss && ppss) return GF_OK;
+		return GF_BAD_PARAM;
+	    }
+	    nal_start = gf_bs_get_position(bs);
+	    nal_size = gf_media_nalu_next_start_code_bs(bs);
+	    if (nal_start + nal_size > extradata_size) {
+		gf_bs_del(bs);
+		return GF_BAD_PARAM;
+	    }
+
+	    if (nal_size > buffer_size) {
+		buffer = (char*)gf_realloc(buffer, nal_size);
+		buffer_size = nal_size;
+	    }
+	    gf_bs_read_data(bs, buffer, nal_size);
+
+	    gf_media_hevc_parse_nalu(buffer, nal_size, hevc, &nal_unit_type, &temporal_id, &layer_id);
+	    if (layer_id) {
+		gf_bs_del(bs);
+		gf_free(buffer);
+		return GF_BAD_PARAM;
+	    }
+
+	    switch (nal_unit_type) {
+	    case GF_HEVC_NALU_VID_PARAM:
+		idx = gf_media_hevc_read_vps(buffer, nal_size , hevc);
+		if (idx < 0) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		}
+
+		assert(hevc.vps[idx].state == 1); //we don't expect multiple VPS
+		if (hevc->vps[idx].state == 1) {
+		    hevc->vps[idx].state = 2;
+		    hevc->vps[idx].crc = gf_crc_32(buffer, nal_size);
+
+                    dst_cfg->avgFrameRate = hevc->vps[idx].rates[0].avg_pic_rate;
+     		    dst_cfg->constantFrameRate = hevc->vps[idx].rates[0].constand_pic_rate_idc;
+		    dst_cfg->numTemporalLayers = hevc->vps[idx].max_sub_layers;
+		    dst_cfg->temporalIdNested = hevc->vps[idx].temporal_id_nesting;
+
+		    if (!vpss) {
+		 	GF_SAFEALLOC(vpss, GF_HEVCParamArray);
+			if (vpss) {
+			    vpss->nalus = gf_list_new();
+			    gf_list_add(dst_cfg->param_array, vpss);
+			    vpss->array_completeness = 1;
+			    vpss->type = GF_HEVC_NALU_VID_PARAM;
+			}
+		    }
+
+		    slc = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));
+		    if (slc) {
+			slc->size = nal_size;
+			slc->id = idx;
+			slc->data = (char*)gf_malloc(sizeof(char)*slc->size);
+			if (slc->data)
+		     	    memcpy(slc->data, buffer, sizeof(char)*slc->size);
+			if (vpss)
+			    gf_list_add(vpss->nalus, slc);
+		    }
+		}
+			break;
+		case GF_HEVC_NALU_SEQ_PARAM:
+		    idx = gf_media_hevc_read_sps(buffer, nal_size, hevc);
+		    if (idx < 0) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		    }
+
+		    assert(!(hevc->sps[idx].state & AVC_SPS_DECLARED)); //we don't expect multiple SPS
+		    if ((hevc->sps[idx].state & AVC_SPS_PARSED) && !(hevc->sps[idx].state & AVC_SPS_DECLARED)) {
+			hevc->sps[idx].state |= AVC_SPS_DECLARED;
+			hevc->sps[idx].crc = gf_crc_32(buffer, nal_size);
+		    }
+
+		    dst_cfg->configurationVersion = 1;
+		    dst_cfg->profile_space = hevc->sps[idx].ptl.profile_space;
+		    dst_cfg->tier_flag = hevc->sps[idx].ptl.tier_flag;
+		    dst_cfg->profile_idc = hevc->sps[idx].ptl.profile_idc;
+		    dst_cfg->general_profile_compatibility_flags = hevc->sps[idx].ptl.profile_compatibility_flag;
+		    dst_cfg->progressive_source_flag = hevc->sps[idx].ptl.general_progressive_source_flag;
+		    dst_cfg->interlaced_source_flag = hevc->sps[idx].ptl.general_interlaced_source_flag;
+		    dst_cfg->non_packed_constraint_flag = hevc->sps[idx].ptl.general_non_packed_constraint_flag;
+		    dst_cfg->frame_only_constraint_flag = hevc->sps[idx].ptl.general_frame_only_constraint_flag;
+
+		    dst_cfg->constraint_indicator_flags = hevc->sps[idx].ptl.general_reserved_44bits;
+		    dst_cfg->level_idc = hevc->sps[idx].ptl.level_idc;
+
+                    dst_cfg->chromaFormat = hevc->sps[idx].chroma_format_idc;
+		    dst_cfg->luma_bit_depth = hevc->sps[idx].bit_depth_luma;
+		    dst_cfg->chroma_bit_depth = hevc->sps[idx].bit_depth_chroma;
+
+		    if (!spss) {
+		 	GF_SAFEALLOC(spss, GF_HEVCParamArray);
+			if (spss) {
+		   	    spss->nalus = gf_list_new();
+			    gf_list_add(dst_cfg->param_array, spss);
+			    spss->array_completeness = 1;
+			    spss->type = GF_HEVC_NALU_SEQ_PARAM;
+			}
+		    }
+
+                    slc = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));
+		    if (slc) {
+			slc->size = nal_size;
+			slc->id = idx;
+			slc->data = (char*)gf_malloc(sizeof(char)*slc->size);
+			if (slc->data)
+		   	    memcpy(slc->data, buffer, sizeof(char)*slc->size);
+			    if (spss)
+				gf_list_add(spss->nalus, slc);
+		    }
+		    break;
+		case GF_HEVC_NALU_PIC_PARAM:
+		    idx = gf_media_hevc_read_pps(buffer, nal_size, hevc);
+		    if (idx < 0) {
+			gf_bs_del(bs);
+			gf_free(buffer);
+			return GF_BAD_PARAM;
+		    }
+
+		    assert(hevc->pps[idx].state == 1); //we don't expect multiple PPS
+		    if (hevc->pps[idx].state == 1) {
+			hevc->pps[idx].state = 2;
+			hevc->pps[idx].crc = gf_crc_32(buffer, nal_size);
+
+			if (!ppss) {
+		   	    GF_SAFEALLOC(ppss, GF_HEVCParamArray);
+			    if (ppss) {
+				ppss->nalus = gf_list_new();
+				gf_list_add(dst_cfg->param_array, ppss);
+				ppss->array_completeness = 1;
+				ppss->type = GF_HEVC_NALU_PIC_PARAM;
+			    }
+			}
+
+			slc = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));
+			if (slc) {
+			    slc->size = nal_size;
+			    slc->id = idx;
+			    slc->data = (char*)gf_malloc(sizeof(char)*slc->size);
+			    if (slc->data)
+				memcpy(slc->data, buffer, sizeof(char)*slc->size);
+    			        if (ppss)
+				    gf_list_add(ppss->nalus, slc);
+		        }
+		    }
+			break;
+		case GF_HEVC_NALU_SEI_PREFIX:
+		    if (!seis) {
+			GF_SAFEALLOC(seis, GF_HEVCParamArray);
+			if (seis) {
+			    seis->nalus = gf_list_new();
+			    seis->array_completeness = 0;
+			    seis->type = GF_HEVC_NALU_SEI_PREFIX;
+			}
+		    }
+		    slc = (GF_AVCConfigSlot*)gf_malloc(sizeof(GF_AVCConfigSlot));
+		    if (slc) {
+			slc->size = nal_size;
+			slc->data = (char*)gf_malloc(sizeof(char)*slc->size);
+			if (slc->data)
+		  	    memcpy(slc->data, buffer, sizeof(char)*slc->size);
+			if (seis)
+			     gf_list_add(seis->nalus, slc);
+		    }
+		    break;
+		default:
+		    break;
+	    }
+    }
+
+    gf_bs_del(bs);
+    if (buffer) gf_free(buffer);
+
+    return GF_OK;
+#endif
+}
+
+static int hevc_get_tile_info(HEVCState *hevc, u32 *tile_x, u32 *tile_y, u32 *tile_width, u32 *tile_height)
+{
+	HEVCSliceInfo *si = &hevc->s_info;
+	u32 i, tbX, tbY, PicWidthInCtbsY, PicHeightInCtbsY, tileX, tileY, oX, oY, val;
+
+        if( (0==si->sps->max_CU_width)||
+            (0==si->pps->num_tile_columns)||
+            (0==si->pps->num_tile_rows) ){
+            av_log(NULL, AV_LOG_ERROR, "si->slice_segment_address=%d, hevc_get_tile_info: si->sps->max_CU_width=%d, si->pps->num_tile_columns =%d, si->pps->num_tile_rows =%d \n", 
+                    si->slice_segment_address,
+                    si->sps->max_CU_width,
+                    si->pps->num_tile_columns,
+                    si->pps->num_tile_rows);
+            return -1;
+        }
+	PicWidthInCtbsY = si->sps->width / si->sps->max_CU_width;
+	if (PicWidthInCtbsY * si->sps->max_CU_width < si->sps->width) PicWidthInCtbsY++;
+	PicHeightInCtbsY = si->sps->height / si->sps->max_CU_width;
+	if (PicHeightInCtbsY * si->sps->max_CU_width < si->sps->height) PicHeightInCtbsY++;
+
+	tbX = si->slice_segment_address % PicWidthInCtbsY;
+	tbY = si->slice_segment_address / PicWidthInCtbsY;
+
+	tileX = tileY = 0;
+	oX = oY = 0;
+	for (i=0; i < si->pps->num_tile_columns; i++) {
+		if (si->pps->uniform_spacing_flag) {
+			val = (i+1)*PicWidthInCtbsY / si->pps->num_tile_columns - (i)*PicWidthInCtbsY / si->pps->num_tile_columns;
+		} else {
+			if (i<si->pps->num_tile_columns-1) {
+				val = si->pps->column_width[i];
+			} else {
+				val = (PicWidthInCtbsY - si->pps->column_width[i-1]);
+			}
+		}
+		*tile_x = oX;
+		*tile_width = val;
+
+		if (oX >= tbX) break;
+		oX += val;
+		tileX++;
+	}
+	for (i=0; i<si->pps->num_tile_rows; i++) {
+		if (si->pps->uniform_spacing_flag) {
+			val = (i+1)*PicHeightInCtbsY / si->pps->num_tile_rows - (i)*PicHeightInCtbsY / si->pps->num_tile_rows;
+		} else {
+			if (i<si->pps->num_tile_rows-1) {
+				val = si->pps->row_height[i];
+			} else {
+				val = (PicHeightInCtbsY - si->pps->row_height[i-1]);
+			}
+		}
+		*tile_y = oY;
+		*tile_height = val;
+
+		if (oY >= tbY) break;
+		oY += val;
+		tileY++;
+	}
+	*tile_x = *tile_x * si->sps->max_CU_width;
+	*tile_y = *tile_y * si->sps->max_CU_width;
+	*tile_width = *tile_width * si->sps->max_CU_width;
+	*tile_height = *tile_height * si->sps->max_CU_width;
+
+	if (*tile_x + *tile_width > si->sps->width)
+		*tile_width = si->sps->width - *tile_x;
+	if (*tile_y + *tile_height > si->sps->height)
+		*tile_height = si->sps->height - *tile_y;
+
+	return tileX + tileY * si->pps->num_tile_columns;
+}
+
+static int hevc_get_tile_rect(HEVCState hevc, int idx, u32 *tile_x, u32 *tile_y, u32 *tile_width, u32 *tile_height)
+{
+           
+    u32 i, tbX, tbY, PicWidthInCtbsY, PicHeightInCtbsY, tileX, tileY, oX, oY, val;
+
+    HEVC_SPS sps = hevc.sps[0];
+    HEVC_PPS pps = hevc.pps[0];
+    if( (0==sps.max_CU_width)||
+        (0==pps.num_tile_columns)||
+        (0==pps.num_tile_rows) ){
+            av_log(NULL, AV_LOG_ERROR, "hevc_get_tile_rect: sps->max_CU_width=%d, pps->num_tile_columns =%d, pps->num_tile_rows =%d \n", 
+                    sps.max_CU_width,
+                    pps.num_tile_columns,
+                    pps.num_tile_rows);
+            return -1;
+    }
+    
+    PicWidthInCtbsY = sps.width / sps.max_CU_width;
+    if (PicWidthInCtbsY * sps.max_CU_width < sps.width) PicWidthInCtbsY++;
+
+    PicHeightInCtbsY = sps.height / sps.max_CU_width;
+    if (PicHeightInCtbsY * sps.max_CU_width < sps.height) PicHeightInCtbsY++;
+
+    tbX = idx % pps.num_tile_columns;
+    tbY = idx / pps.num_tile_columns;
+
+    tileX = tileY = 0;
+    oX = oY = 0;
+    for (i=0; i < pps.num_tile_columns; i++) {
+        if (pps.uniform_spacing_flag) {
+	    val = (i+1)*PicWidthInCtbsY / pps.num_tile_columns - (i)*PicWidthInCtbsY / pps.num_tile_columns;
+	} else {
+	    if (i<pps.num_tile_columns-1) {
+		val = pps.column_width[i];
+	    } else {
+		val = (PicWidthInCtbsY - pps.column_width[i-1]);
+	    }
+        }
+	*tile_x = oX;
+	*tile_width = val;
+
+	if (oX >= (tbX * (PicWidthInCtbsY / pps.num_tile_columns))) break;
+	oX += val;
+	tileX++;
+    }
+    for (i=0; i<pps.num_tile_rows; i++) {
+        if (pps.uniform_spacing_flag) {
+            val = (i+1)*PicHeightInCtbsY / pps.num_tile_rows - (i)*PicHeightInCtbsY / pps.num_tile_rows;
+	} else {
+            if (i<pps.num_tile_rows-1) {
+	        val = pps.row_height[i];
+	    } else {
+		val = (PicHeightInCtbsY - pps.row_height[i-1]);
+	    }
+	}
+	*tile_y = oY;
+	*tile_height = val;
+
+	if (oY >= (tbY * (PicHeightInCtbsY / pps.num_tile_rows))) break;
+	oY += val;
+	tileY++;
+    }
+    
+    *tile_x = *tile_x * sps.max_CU_width;
+    *tile_y = *tile_y * sps.max_CU_width;
+    *tile_width = *tile_width * sps.max_CU_width;
+    *tile_height = *tile_height * sps.max_CU_width;
+
+    if (*tile_x + *tile_width > sps.width)
+	*tile_width = sps.width - *tile_x;
+    if (*tile_y + *tile_height > sps.height)
+	*tile_height = sps.height - *tile_y;
+
+    return tileX + tileY * pps.num_tile_columns;
+}
+
+static GF_Err dc_gpac_video_write_config(DashOutStream* os, int idx, u32 *di, u32 track) 
+{
+    GF_Err ret;
+    VideoOutput* video_output_file = os->video_out[idx];
+    
+    if (os->codec_ctx->codec_id == AV_CODEC_ID_H264){
+	ret = gf_isom_avc_config_new(video_output_file->isof, track, &os->avc_cfg, NULL, NULL, di);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_avc_config_new\n", gf_error_to_string(ret));
+		return ret;
+	}
+
+        //inband SPS/PPS
+	ret = gf_isom_avc_set_inband_config(video_output_file->isof, track, 1);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_avc_set_inband_config\n", gf_error_to_string(ret));
+		return ret;
+	}
+    } else if (os->codec_ctx->codec_id == AV_CODEC_ID_HEVC) { //FIXME CODEC_ID_HEVC would break on old releases
+	ret = gf_isom_hevc_config_new(video_output_file->isof, track, &os->hevc_cfg, NULL, NULL, di);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_hevc_config_new\n", gf_error_to_string(ret));
+		return ret;
+	}
+
+        //inband SPS/PPS
+	//ret = gf_isom_hevc_set_inband_config(video_output_file->isof, track, 1);
+	//if (ret != GF_OK) {
+	 //   av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_hevc_set_inband_config\n", gf_error_to_string(ret));
+	 //   return ret;
+	//}
+    }
+
+    return GF_OK;
+}
+
+static int dc_gpac_video_moov_create_tile(DashOutStream* os, int idx)
+{
+    GF_Err ret;
+    u32 TrackNum;
+    VideoOutput* video_output_file = os->video_out[idx];
+    char filename[1024]; 
+    snprintf(filename, sizeof(filename), "%s%s", 
+                 os->dir_name, 
+                 os->video_out[idx]->seg_init_name);
+    
+    if( idx == 0 ) return -1;
+    
+    video_output_file->isof = gf_isom_open(filename, GF_ISOM_OPEN_WRITE, NULL);
+    
+    ret = gf_isom_clone_movie( os->video_out[0]->isof, 
+                               video_output_file->isof, 
+                               GF_FALSE, GF_FALSE, GF_TRUE, 
+                               GF_FALSE );
+    if (ret) return -1;
+
+
+    /*because of movie fragments MOOF based offset, ISOM <4 is forbidden*/
+    gf_isom_set_brand_info(video_output_file->isof, GF_ISOM_BRAND_ISO5, 1);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISOM, 0);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISO1, 0);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISO2, 0);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISO3, 0);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_MP41, 0);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_MP42, 0);
+
+    gf_isom_remove_root_od(video_output_file->isof);
+    
+    ret = gf_isom_clone_track(os->video_out[0]->isof, idx+1, video_output_file->isof, GF_FALSE, &TrackNum);
+    if (ret) return -1;
+    
+    video_output_file->iso_track_ID = gf_isom_get_track_id(video_output_file->isof, TrackNum);
+    video_output_file->iso_track = TrackNum;
+    
+    ret = gf_isom_setup_track_fragment( video_output_file->isof, gf_isom_get_track_id(video_output_file->isof, TrackNum), 0, 0, 0, 0, 0, 0);
+
+    if (ret) return -1;
+  //"hvt1.1.6.L186.80"
+    gf_isom_set_brand_info(video_output_file->isof, GF_ISOM_BRAND_ISO5, 1);
+    gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_DASH, 1);
+    
+    ret = gf_isom_finalize_for_fragment(video_output_file->isof, 1);
+    
+    return 0;
+}
+
+static void hevc_add_trif(GF_ISOFile *file, u32 track, u32 id, Bool full_picture, u32 independent, Bool filtering_disable, u32 tx, u32 ty, u32 tw, u32 th, Bool is_default)
+{
+	char data[11];
+	u32 di, data_size=7;
+	GF_BitStream *bs;
+	//write TRIF sample group description
+	bs = gf_bs_new((const char*)data, 11, GF_BITSTREAM_WRITE);
+	gf_bs_write_u16(bs, id);	//groupID
+	gf_bs_write_int(bs, 1, 1); //tile Region flag always true for us
+	gf_bs_write_int(bs, independent, 2); //independentIDC: set to 1 (motion-constrained tiles but not all tiles RAP)
+	gf_bs_write_int(bs, full_picture, 1);//full picture: false since we don't do L-HEVC tiles
+	gf_bs_write_int(bs, filtering_disable, 1); //filtering disabled: set to 1 (always true on our bitstreams for now) - Check xPS to be sure ...
+	gf_bs_write_int(bs, 0, 1);//has dependency list: false since we don't do L-HEVC tiles
+	gf_bs_write_int(bs, 0, 2); //reserved
+	if (!full_picture) {
+		gf_bs_write_u16(bs, tx);
+		gf_bs_write_u16(bs, ty);
+		data_size+=4;
+	}
+	gf_bs_write_u16(bs, tw);
+	gf_bs_write_u16(bs, th);
+	gf_bs_del(bs);
+
+	gf_isom_add_sample_group_info(file, track, GF_ISOM_SAMPLE_GROUP_TRIF, data, data_size, is_default, &di);
+}
+
+static int dc_gpac_video_moov_create_root(DashOutStream* os)
+{
+	GF_Err ret;
+	u32 di=1, track;
+        u32 width, height;
+	s32 translation_x, translation_y;
+	s16 layer;
+
+        VideoOutput* video_output_file = os->video_out[0];
+        char filename[1024]; 
+        snprintf(filename, sizeof(filename), "%s%s", 
+                 os->dir_name, 
+                 os->video_out[0]->seg_init_name);
+	//TODO: For the moment it is fixed
+	//u32 sample_dur = video_output_file->codec_ctx->time_base.den;
+
+	//int64_t profile = 0;
+	//av_opt_get_int(video_output_file->codec_ctx->priv_data, "level", AV_OPT_SEARCH_CHILDREN, &profile);
+
+	video_output_file->isof = gf_isom_open(filename, GF_ISOM_OPEN_WRITE, NULL);
+	if (!video_output_file->isof) {
+		av_log(NULL, AV_LOG_ERROR, "Cannot open iso file %s\n", filename);
+		return -1;
+	}
+	//gf_isom_store_movie_config(video_output_file->isof, 0);
+
+	track = gf_isom_new_track(video_output_file->isof, 0, GF_ISOM_MEDIA_VISUAL, (int)(os->frame_rate + 0.5));
+        video_output_file->iso_track = track;
+	video_output_file->iso_track_ID = gf_isom_get_track_id(video_output_file->isof, track);
+
+	if (!video_output_file->frame_dur)
+		video_output_file->frame_dur = os->timescale.num / os->timescale.den;
+
+	if (!track) {
+		av_log(NULL, AV_LOG_ERROR, "Cannot create new track\n");
+		return -1;
+	}
+
+	ret = gf_isom_set_track_enabled(video_output_file->isof, track, 1);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_set_track_enabled\n", gf_error_to_string(ret));
+		return -1;
+	}
+
+	ret = dc_gpac_video_write_config(os, 0, &di, track);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: dc_gpac_video_write_config\n", gf_error_to_string(ret));
+		return -1;
+	}
+        gf_isom_set_nalu_extract_mode(video_output_file->isof, track, GF_ISOM_NALU_EXTRACT_INSPECT);
+	gf_isom_set_visual_info(video_output_file->isof, track, di, os->codec_ctx->width, os->codec_ctx->height);
+	gf_isom_set_sync_table(video_output_file->isof, track);
+
+        /*because of movie fragments MOOF based offset, ISOM <4 is forbidden*/
+        gf_isom_set_brand_info(video_output_file->isof, GF_ISOM_BRAND_ISO5, 1);
+        gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISOM, 0);
+        gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISO1, 0);
+        gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISO2, 0);
+        gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_ISO3, 0);
+        gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_MP41, 0);
+        gf_isom_modify_alternate_brand(video_output_file->isof, GF_ISOM_BRAND_MP42, 0);
+
+        gf_isom_remove_root_od(video_output_file->isof);
+        
+        ret = gf_isom_setup_track_fragment( video_output_file->isof, 
+                                            track, 1, 
+                                            video_output_file->use_source_timing ? (u32) video_output_file->frame_dur : 1, 
+                                            0, 0, 0, 0);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_setup_track_fragment\n", gf_error_to_string(ret));
+		return -1;
+	}
+        
+        for( int i=1; i<os->nb_tiles+1; i++){
+            ret = gf_isom_clone_track(video_output_file->isof, track, video_output_file->isof, GF_FALSE, &os->video_out[i]->iso_track );
+            if (ret) return ret;
+            os->video_out[i]->iso_track_ID = gf_isom_get_track_id(video_output_file->isof, os->video_out[i]->iso_track);
+        }
+        
+	for( int i=1; i<os->nb_tiles+1; i++){
+            width = 0; 
+            height = 0;
+	    translation_x = 0;
+            translation_y = 0;
+	    layer = 0;
+            
+            
+            gf_isom_hevc_set_tile_config(video_output_file->isof, os->video_out[i]->iso_track, 1, NULL, GF_FALSE);
+
+	    // setup track references from tile track to base
+            gf_isom_set_track_reference( video_output_file->isof, 
+                                         os->video_out[i]->iso_track,                                         
+                                         GF_ISOM_REF_TBAS, 
+                                         video_output_file->iso_track_ID);
+            if(ret != GF_OK){
+                   av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_set_track_reference failed\n", gf_error_to_string(ret));
+            }
+            
+            if (! gf_isom_has_track_reference(os->video_out[0]->isof, os->video_out[0]->iso_track, GF_ISOM_REF_SABT, os->video_out[i]->dash_track_ID)) {
+                ret = gf_isom_set_track_reference( os->video_out[0]->isof, 
+                                                  os->video_out[0]->iso_track, 
+                                                  GF_ISOM_REF_SABT, 
+                                                  os->video_out[i]->dash_track_ID);
+                if(ret != GF_OK){
+                   av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_set_track_reference failed\n", gf_error_to_string(ret));
+               }
+	    }
+           
+            hevc_add_trif( video_output_file->isof, 
+                           os->video_out[i]->iso_track, 
+                           os->video_out[i]->iso_track_ID, 
+                           GF_FALSE, 
+                           (os->video_out[i]->tile.all_intra) ? 2 : 1, 
+                           GF_TRUE, 
+                           os->video_out[i]->tile.tx, 
+                           os->video_out[i]->tile.ty, 
+                           os->video_out[i]->tile.tw,
+                           os->video_out[i]->tile.th, 
+                           GF_TRUE);
+            
+	    gf_isom_set_visual_info( video_output_file->isof, 
+                                     os->video_out[i]->iso_track, 
+                                     1, 
+                                     os->video_out[i]->tile.tw, 
+                                     os->video_out[i]->tile.th);
+
+	    gf_isom_get_track_layout_info( video_output_file->isof, 
+                                           track, 
+                                           &width, &height, 
+                                           &translation_x, &translation_y, 
+                                           &layer);
+	    gf_isom_set_track_layout_info( video_output_file->isof, 
+                                           os->video_out[i]->iso_track, 
+                                           width<<16, height<<16, 
+                                           translation_x, translation_y, 
+                                           layer);
+ 
+            ret = gf_isom_setup_track_fragment( video_output_file->isof, 
+                                                os->video_out[i]->iso_track, 1, 
+                                                video_output_file->use_source_timing ? (u32) video_output_file->frame_dur : 1, 
+                                                0, 0, 0, 0);
+	    if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_setup_track_fragment\n", gf_error_to_string(ret));
+		return -1;
+	    }
+        }
+        
+        
+
+	ret = gf_isom_finalize_for_fragment(video_output_file->isof, track);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_finalize_for_fragment\n", gf_error_to_string(ret));
+		return -1;
+	}
+
+	/*ret = gf_media_get_rfc_6381_codec_name(video_output_file->isof, track, video_output_file->video_data_conf->codec6381, GF_FALSE, GF_FALSE);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_finalize_for_fragment\n", gf_error_to_string(ret));
+		return -1;
+	}*/
+        
+	return 0;
+}
+
+static int dc_gpac_video_moov_create(DashOutStream* os, int idx)
+{
+	GF_Err ret;
+	u32 di=1, track;
+
+        VideoOutput* video_output_file = os->video_out[idx];
+        char filename[1024]; 
+        snprintf(filename, sizeof(filename), "%s%s", 
+                 os->dir_name, 
+                 os->video_out[idx]->seg_init_name );
+        
+        //TODO: For the moment it is fixed
+	//u32 sample_dur = video_output_file->codec_ctx->time_base.den;
+
+	//int64_t profile = 0;
+	//av_opt_get_int(video_output_file->codec_ctx->priv_data, "level", AV_OPT_SEARCH_CHILDREN, &profile);
+
+	video_output_file->isof = gf_isom_open(filename, GF_ISOM_OPEN_WRITE, NULL);
+	if (!video_output_file->isof) {
+		av_log(NULL, AV_LOG_ERROR, "Cannot open iso file %s\n", filename);
+		return -1;
+	}
+	//gf_isom_store_movie_config(video_output_file->isof, 0);
+	track = gf_isom_new_track(video_output_file->isof, 0, GF_ISOM_MEDIA_VISUAL, (int)(os->frame_rate + 0.5));
+	video_output_file->iso_track_ID = gf_isom_get_track_id(video_output_file->isof, track);
+
+	//video_output_file->timescale = os->timescale.den;
+	if (!video_output_file->frame_dur)
+		video_output_file->frame_dur = os->timescale.num / os->timescale.den;
+
+	if (!track) {
+		av_log(NULL, AV_LOG_ERROR, "Cannot create new track\n");
+		return -1;
+	}
+
+	ret = gf_isom_set_track_enabled(video_output_file->isof, track, 1);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_set_track_enabled\n", gf_error_to_string(ret));
+		return -1;
+	}
+
+	ret = dc_gpac_video_write_config(os, idx, &di, track);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: dc_gpac_video_write_config\n", gf_error_to_string(ret));
+		return -1;
+	}
+        
+	gf_isom_set_visual_info(video_output_file->isof, track, di, os->codec_ctx->width, os->codec_ctx->height);
+	gf_isom_set_sync_table(video_output_file->isof, track);
+
+	ret = gf_isom_setup_track_fragment(video_output_file->isof, track, 1, video_output_file->use_source_timing ? (u32) video_output_file->frame_dur : 1, 0, 0, 0, 0);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_setup_track_fragment\n", gf_error_to_string(ret));
+		return -1;
+	}
+
+	ret = gf_isom_finalize_for_fragment(video_output_file->isof, track);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_finalize_for_fragment\n", gf_error_to_string(ret));
+		return -1;
+	}
+
+	/*ret = gf_media_get_rfc_6381_codec_name(video_output_file->isof, track, video_output_file->video_data_conf->codec6381, GF_FALSE, GF_FALSE);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_finalize_for_fragment\n", gf_error_to_string(ret));
+		return -1;
+	}*/
+
+	return 0;
+}
+
+static int dc_gpac_video_isom_open_seg(DashOutStream* os, int idx)
+{
+	GF_Err ret;
+        VideoOutput* video_output_file = os->video_out[idx];
+	ret = gf_isom_start_segment(video_output_file->isof, os->video_out[idx]->seg_media_name, 1);
+	if (ret != GF_OK) {
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_start_segment\n", gf_error_to_string(ret));
+		return -1;
+	}
+	av_log(NULL, AV_LOG_ERROR, "[DashCast] Opening new segment %s at UTC "LLU" ms\n", os->video_out[idx]->seg_media_name, gf_net_get_utc() );
+	return 0;
+}
+
+static int dc_gpac_video_isom_write(DashOutStream* os, int idx)
+{
+	GF_Err ret;
+	VideoOutput* video_output_file = os->video_out[idx];
+
+	u32 sc_size = 0;
+	u32 nalu_size = 0;
+
+	u32 buf_len = video_output_file->encoded_frame_size;
+	u8 *buf_ptr = video_output_file->vbuf;
+
+	GF_BitStream *out_bs = gf_bs_new(NULL, 2 * buf_len, GF_BITSTREAM_WRITE);
+        nalu_size = gf_media_nalu_next_start_code(buf_ptr, buf_len, &sc_size);
+	if (0 != nalu_size) {
+		gf_bs_write_u32(out_bs, nalu_size);
+		gf_bs_write_data(out_bs, (const char*) buf_ptr, nalu_size);
+	}
+	
+        buf_ptr += (nalu_size + sc_size);
+	buf_len -= (nalu_size + sc_size);
+	
+	while (buf_len) {
+		nalu_size = gf_media_nalu_next_start_code(buf_ptr, buf_len, &sc_size);
+		if (nalu_size != 0) {
+			gf_bs_write_u32(out_bs, nalu_size );
+			gf_bs_write_data(out_bs, (const char*) buf_ptr, nalu_size );
+		}
+
+		buf_ptr += nalu_size;
+
+		if (!sc_size || (buf_len < nalu_size + sc_size))
+			break;
+		buf_len -= nalu_size + sc_size;
+		buf_ptr += sc_size;
+	}
+	gf_bs_get_content(out_bs, &video_output_file->sample->data, &video_output_file->sample->dataLength);
+	//video_output_file->sample->data = //(char *) (video_output_file->vbuf + nalu_size + sc_size);
+	//video_output_file->sample->dataLength = //video_output_file->encoded_frame_size - (sc_size + nalu_size);
+
+	video_output_file->sample->DTS = os->video_out[idx]->cur_pts;
+	video_output_file->sample->CTS_Offset = (s32) (os->video_out[idx]->cur_pts - video_output_file->sample->DTS);
+	video_output_file->sample->IsRAP = os->video_out[idx]->cur_keyframe;
+	av_log(NULL, AV_LOG_DEBUG, "%d, Isom Write: RAP %d , DTS "LLD" CTS offset %d \n",  
+                    video_output_file->iso_track_ID,  
+                    video_output_file->sample->IsRAP,  
+                    video_output_file->sample->DTS,  
+                    video_output_file->sample->CTS_Offset); 
+	ret = gf_isom_fragment_add_sample( video_output_file->isof, 
+                                           video_output_file->iso_track_ID, 
+                                           video_output_file->sample, 1, 
+                                           video_output_file->use_source_timing ? (u32) video_output_file->frame_dur : 1, 
+                                           0, 0, 0);
+	if (ret != GF_OK) {
+		gf_bs_del(out_bs);
+		av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_fragment_add_sample\n", gf_error_to_string(ret));
+		return -1;
+	}
+              
+        video_output_file->sample_count++;
+	//free data but keep sample structure alive
+	gf_free(video_output_file->sample->data);
+	video_output_file->sample->data = NULL;
+	video_output_file->sample->dataLength = 0;
+
+	gf_bs_del(out_bs);
+	return 0;
+}
+
+static int get_tile_output(DashOutStream* os, int x, int y, int w, int h)
+{
+    for(int i = 1; i < os->nb_tiles+1; i++){
+        if( (os->video_out[i]->tile.tx == x)&&
+            (os->video_out[i]->tile.ty == y)&&
+            (os->video_out[i]->tile.tw == w)&&
+            (os->video_out[i]->tile.th == h))
+            return i;
+    }
+    return 0;
+}
+
+static int dc_gpac_video_isom_tile_write(DashOutStream* os, AVPacket *pkt)
+{
+    int ret = 0;
+    GF_Err e = GF_OK;
+    u8 nal_type = 0;
+    u8 temporal_id, layer_id;
+    int cur_tile, tx, ty, tw, th, idx;
+    int nalu_size = 0;
+    int sc_size = 0;
+    int buf_len = pkt->size;
+    char *buf_ptr = pkt->data;
+    HEVCState hevc = os->hevc_state;
+
+    av_log(NULL, AV_LOG_DEBUG, "pkt->data=%p, pkt->size=%d,\n", buf_ptr, buf_len);
+    GF_BitStream *out_bs = NULL;  
+    GF_BitStream *bs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);
+    
+    nalu_size = gf_media_nalu_next_start_code(buf_ptr, buf_len, &sc_size);
+    if (nalu_size)
+    {
+        av_log(NULL, AV_LOG_ERROR, "The NALU size before first start code should be zero. \n");
+    } 
+    if (sc_size) {
+        buf_ptr += (nalu_size + sc_size);
+        buf_len -= (nalu_size + sc_size);
+    }
+    idx = 0;
+    while (buf_len) {
+        sc_size = 0;
+        if(NULL==out_bs) out_bs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);
+        nalu_size = gf_media_nalu_next_start_code(buf_ptr, buf_len, &sc_size);
+        av_log(NULL, AV_LOG_DEBUG, "buf_ptr=%p, buf_len=%d, nalu_size=%d, sc_size=%d\n", buf_ptr, buf_len, nalu_size, sc_size);
+        if (nalu_size) {
+            ret = gf_media_hevc_parse_nalu(buf_ptr, nalu_size, &hevc, &nal_type, &temporal_id, &layer_id);
+
+	    //error parsing NAL, set nal to fallback to regular import
+	    if (ret<0) nal_type = -1;
+
+	    switch (nal_type) {
+                case GF_HEVC_NALU_VID_PARAM:
+                case GF_HEVC_NALU_SEQ_PARAM:
+                case GF_HEVC_NALU_PIC_PARAM:
+                     break;
+                case GF_HEVC_NALU_SLICE_TRAIL_N:
+		case GF_HEVC_NALU_SLICE_TRAIL_R:
+		case GF_HEVC_NALU_SLICE_TSA_N:
+		case GF_HEVC_NALU_SLICE_TSA_R:
+		case GF_HEVC_NALU_SLICE_STSA_N:
+		case GF_HEVC_NALU_SLICE_STSA_R:
+		case GF_HEVC_NALU_SLICE_BLA_W_LP:
+		case GF_HEVC_NALU_SLICE_BLA_W_DLP:
+		case GF_HEVC_NALU_SLICE_BLA_N_LP:
+		case GF_HEVC_NALU_SLICE_IDR_W_DLP:
+		case GF_HEVC_NALU_SLICE_IDR_N_LP:
+		case GF_HEVC_NALU_SLICE_CRA:
+		case GF_HEVC_NALU_SLICE_RADL_R:
+		case GF_HEVC_NALU_SLICE_RADL_N:
+		case GF_HEVC_NALU_SLICE_RASL_R:
+		case GF_HEVC_NALU_SLICE_RASL_N:
+		    tx = ty = tw = th = 0;
+		    cur_tile = hevc_get_tile_info( &hevc, &tx, &ty, &tw, &th);
+		    if (cur_tile>=os->nb_tiles) {
+			av_log(NULL, AV_LOG_ERROR, "[HEVC Tiles] Tile index %d is greater than number of tiles %d in PPS\n", cur_tile, os->nb_tiles);
+			e = GF_NON_COMPLIANT_BITSTREAM;
+		    }
+		    if (e)
+			continue;
+                    idx = get_tile_output(os, tx, ty, tw, th);
+
+                    if (hevc.s_info.slice_type != GF_HEVC_SLICE_TYPE_I) {
+                        os->video_out[idx]->cur_keyframe = 0;
+		    }else{
+                        os->video_out[idx]->cur_keyframe = 1;
+                    }
+                    
+                    os->video_out[idx]->encoded_frame_size = nalu_size + sc_size;
+                    os->video_out[idx]->cur_pts = pkt->pts;
+                    gf_bs_write_u32(out_bs, nalu_size );
+		    gf_bs_write_data(out_bs, (const char*) buf_ptr, nalu_size );
+                        
+                    gf_bs_get_content(out_bs, &os->video_out[idx]->sample->data, &os->video_out[idx]->sample->dataLength);
+          	    os->video_out[idx]->sample->DTS = os->video_out[idx]->cur_pts;
+	            os->video_out[idx]->sample->CTS_Offset = (s32) (os->video_out[idx]->cur_pts - os->video_out[idx]->sample->DTS);
+	            os->video_out[idx]->sample->IsRAP = os->video_out[idx]->cur_keyframe;
+                    gf_bs_del(out_bs);
+                    out_bs = NULL;
+                    break;
+                default:
+                    os->video_out[0]->encoded_frame_size = nalu_size + sc_size;
+                    os->video_out[0]->cur_pts = pkt->pts;
+                    gf_bs_write_u32(bs, nalu_size );
+		    gf_bs_write_data(bs, (const char*) buf_ptr, nalu_size );
+                    
+                    break;
+            }
+            buf_ptr = buf_ptr + (nalu_size + sc_size);
+            buf_len = buf_len - (nalu_size + sc_size);
+
+        }
+
+    }
+    
+    gf_bs_get_content(bs, &os->video_out[0]->sample->data, &os->video_out[0]->sample->dataLength);
+    gf_bs_del(bs);
+    
+    for(int i=0; i<os->nb_tiles+1; i++){
+        ret = gf_isom_fragment_add_sample( os->video_out[i]->isof, 
+                                           os->video_out[i]->iso_track_ID, 
+                                           os->video_out[i]->sample, 1, 
+                                           os->video_out[i]->use_source_timing ? (u32) os->video_out[i]->frame_dur : 1, 
+                                           0, 0, 0);
+        if(ret != GF_OK){
+             av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_fragment_add_sample tiles=%d\n", gf_error_to_string(ret), i);
+        }
+        
+        if(i > 0 ){
+           /*if (! gf_isom_has_track_reference(os->video_out[0]->isof, os->video_out[0]->iso_track, GF_ISOM_REF_SABT, os->video_out[i]->dash_track_ID)) {
+               ret = gf_isom_set_track_reference(os->video_out[0]->isof, os->video_out[0]->iso_track, GF_ISOM_REF_SABT, os->video_out[i]->dash_track_ID);
+               if(ret != GF_OK){
+                   av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_set_track_reference failed\n", gf_error_to_string(ret));
+               }
+	    }*/
+            e = gf_isom_copy_sample_info(os->video_out[i]->isof, 1, os->video_out[0]->isof, 1, os->video_out[i]->sample_count+1);
+	    if (ret != GF_OK){
+                   av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_copy_sample_info failed\n", gf_error_to_string(ret));
+               }
+        }
+        os->video_out[i]->sample_count++;
+	//free data but keep sample structure alive
+        gf_free(os->video_out[i]->sample->data);
+        os->video_out[i]->sample->data = NULL;
+        os->video_out[i]->sample->dataLength = 0;
+    }
+    
+    return 0;
+}
+
+static int dc_gpac_video_isom_close_seg(DashOutStream* os, int idx)
+{
+    u64 seg_size;
+    VideoOutput* video_output_file = os->video_out[idx];
+    GF_Err ret = gf_isom_close_segment(video_output_file->isof, 0, 0, 0, 0, 0, 0, GF_TRUE, GF_FALSE, video_output_file->seg_marker, NULL, NULL, &seg_size);
+    if (ret != GF_OK) {
+	av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_close_segment\n", gf_error_to_string(ret));
+	return -1;
+    }
+    av_log(NULL, AV_LOG_DEBUG, "[DashCast] Rep %s Closing segment %s at UTC "LLU" ms - size "LLU" bytes\n", video_output_file->rep_id, gf_isom_get_segment_name(video_output_file->isof), gf_net_get_utc(), seg_size );
+
+    return 0;
+}
+
+static int gpac_video_isom_close(DashOutStream* os, int idx)
+{
+    GF_Err ret;
+    VideoOutput* video_output_file = os->video_out[idx];
+    //dc_gpac_video_isom_close_seg(os, idx);
+    os->video_out[idx]->iso_created = 0;
+    video_output_file->sample_count = 0;
+    ret = gf_isom_close(video_output_file->isof);
+    if (ret != GF_OK) {
+	av_log(NULL, AV_LOG_ERROR, "%s: gf_isom_close\n", gf_error_to_string(ret));
+	return -1;
+    }
+     
+    return 0;
+}
+
+static int gpac_video_isom_open(DashOutStream* os, int idx)
+{
+    GF_Err ret;
+    
+    if( idx == 0 ){
+        ret = dc_gpac_video_moov_create_root(os);
+    }else{
+        ret = dc_gpac_video_moov_create_tile(os, idx);
+    }
+    if(ret != GF_OK){
+        
+        av_log(NULL, AV_LOG_VERBOSE, "failed to init_video_ouput::dc_gpac_video_moov_create\n");
+        return -1;
+    }
+    
+    /*
+    ret = dc_gpac_video_isom_open_seg(os, idx);
+    if(ret != GF_OK){
+        av_log(NULL, AV_LOG_VERBOSE, "failed to init_video_ouput::dc_gpac_video_isom_open_seg\n");
+        return -1;
+    }*/
+    
+     return 0;
+}
+
+int dash_probe_extra_data(DashOutStream* os, char* buf, int size)
+{
+    GF_Err ret;
+    
+    if( NULL == buf || 0 == size){
+        av_log(NULL, AV_LOG_ERROR, "extra data buffer is NULL or size = 0; cannot proceed\n");
+        return -1;
+    }
+    
+    if( os->codec_ctx)
+    switch( os->codec_ctx->codec_id ){
+        case AV_CODEC_ID_HEVC:
+            ret = dc_hevc_import_ffextradata(buf, size, &os->hevc_state, &os->hevc_cfg);
+            break;
+        case AV_CODEC_ID_H264:
+            ret = dc_avc_import_ffextradata(buf, size, &os->avc_cfg);
+            break;
+        default:
+           break;
+    }
+    
+    if(ret != GF_OK){
+        av_log(NULL, AV_LOG_ERROR, "import_ffextradata; cannot proceed\n");
+        return -1;
+    }
+            
+    return 0;
+}
+
+static void get_timescale(DashOutStream* os, int *timescale)
+{
+    int fps_1000 = (int)(os->frame_rate * 1000 + 0.5);
+
+    if (fps_1000 == 29970)
+    {
+        *timescale = 30000;
+    }
+    else if (fps_1000 == 23976)
+    {
+        *timescale = 24000;
+    }
+    else if (fps_1000 == 59940)
+    {
+        *timescale = 60000;
+    }
+    else
+    {
+        *timescale = fps_1000;
+    }
+}
+static int init_video_ouput_tile(DashOutStream* os, int idx)
+{
+    //GF_Err ret;
+    int val;
+    
+    os->video_out[idx] = av_malloc(sizeof(VideoOutput));
+    
+#ifndef GPAC_DISABLE_ISOM
+    os->video_out[idx]->sample = gf_isom_sample_new();
+    os->video_out[idx]->isof = NULL;
+#endif
+    os->video_out[idx]->dash_track_ID = idx + 1;
+    os->video_out[idx]->iso_track_ID = 1;
+    /* Variables that encoder needs to encode data */
+    os->video_out[idx]->bit_rate = os->bit_rate / os->nb_tiles; 
+
+    os->video_out[idx]->seg_marker = 0;
+    //gdr;
+    os->video_out[idx]->use_source_timing = 0;
+    os->video_out[idx]->nb_segments = 0;
+    os->video_out[idx]->frame_dur = os->frame_dur;
+    os->video_out[idx]->encoded_frame_size = 0;
+    os->video_out[idx]->segment_index = 0;
+    os->video_out[idx]->sample_count = 0;
+    os->video_out[idx]->iso_created = 0;
+    get_timescale(os, &(os->video_out[idx]->timescale));
+    val = hevc_get_tile_rect(os->hevc_state,
+                             idx - 1,
+                             &(os->video_out[idx]->tile.tx),
+                             &(os->video_out[idx]->tile.ty),
+                             &(os->video_out[idx]->tile.tw),
+                             &(os->video_out[idx]->tile.th));
+    if(val < 0 || val > os->nb_tiles ){
+        av_log(NULL, AV_LOG_ERROR, "init_video_ouput_tile: %d; hevc_get_tile_rect failed\n", idx );
+        return -1;
+    }
+    
+    os->video_out[idx]->tile.data_offset = 0;
+    os->video_out[idx]->tile.nb_nalus_in_sample = 0;
+    os->video_out[idx]->tile.all_intra = 0;
+            
+    os->video_out[idx]->dependency_id = os->stream_index;
+    snprintf(os->video_out[idx]->rep_id, sizeof(os->video_out[idx]->rep_id), 
+            "%s_%d", os->video_out[0]->rep_id, idx );
+    snprintf(os->video_out[idx]->seg_init_name, sizeof(os->video_out[idx]->seg_init_name), 
+            "%s_track%d_init.mp4", os->out_name, os->video_out[idx]->dash_track_ID );
+    snprintf(os->video_out[idx]->seg_media_name_tmpl, sizeof(os->video_out[idx]->seg_media_name_tmpl), 
+            "%s_track%d_$Number$.m4s", os->out_name, os->video_out[idx]->dash_track_ID);
+    snprintf(os->video_out[idx]->seg_media_name, sizeof(os->video_out[idx]->seg_media_name), 
+            "%s%s_track%d_%d.m4s", os->dir_name, os->out_name, os->video_out[idx]->dash_track_ID, os->video_out[idx]->segment_index+1);
+    av_log(NULL, AV_LOG_VERBOSE, "main stream init mp4 name: %s; segment name templ: %s\n", 
+            os->video_out[idx]->seg_init_name, os->video_out[idx]->seg_media_name_tmpl);
+
+    return 0;
+}
+
+static int init_video_ouput(DashOutStream* os)
+{
+    //GF_Err ret;
+    
+    os->video_out[0] = malloc(sizeof(VideoOutput));
+    
+#ifndef GPAC_DISABLE_ISOM
+    os->video_out[0]->sample = gf_isom_sample_new();
+    os->video_out[0]->isof = NULL;
+#endif
+    
+    os->video_out[0]->dash_track_ID = 1;
+    os->video_out[0]->iso_track_ID = 1;
+    /* Variables that encoder needs to encode data */
+    
+    os->video_out[0]->seg_marker = 0;
+    //gdr;
+    os->video_out[0]->use_source_timing = 0;
+    os->video_out[0]->nb_segments = 0;
+    os->video_out[0]->segment_index = 0;
+    os->video_out[0]->frame_dur = os->frame_dur;
+    os->video_out[0]->encoded_frame_size = 0;
+    os->video_out[0]->iso_created = 0;
+    get_timescale(os, &(os->video_out[0]->timescale));
+
+    snprintf(os->video_out[0]->rep_id, sizeof(os->video_out[0]->rep_id), "%d", os->stream_index );
+    snprintf(os->video_out[0]->seg_init_name, sizeof(os->video_out[0]->seg_init_name), "%s_set1_init.mp4", os->out_name );
+    snprintf(os->video_out[0]->seg_media_name_tmpl, sizeof(os->video_out[0]->seg_media_name_tmpl), "%s_track1_$Number$.m4s", os->out_name);
+    snprintf(os->video_out[0]->seg_media_name, sizeof(os->video_out[0]->seg_media_name), "%s%s_track1_%d.m4s", os->dir_name, os->out_name, os->video_out[0]->segment_index+1);
+    av_log(NULL, AV_LOG_VERBOSE, "main stream init mp4 name: %s; segment name templ: %s\n", os->video_out[0]->seg_init_name, os->video_out[0]->seg_media_name);
+    
+    return 0;
+}
+
+void dash_end_output_stream(DashOutStream* os)
+{
+    for(int i=0; i<os->nb_tiles + 1; i++){
+        gf_isom_flush_fragments(os->video_out[i]->isof, GF_TRUE);
+        gpac_video_isom_close(os, i);
+    }
+}
+
+void dash_free_output_stream(DashOutStream* os)
+{
+    //if(NULL != os){
+    //    av_freep(os);
+    //    os = NULL;
+    //}    
+}
+
+int dash_init_output_stream(GPAC_DASHContext* ctx, DashOutStream* os)
+{
+    int ret = 0;
+    int sps_id = 0;
+
+    os->availability_time_offset = 0;
+    os->seg_dur = ctx->seg_duration / 1000;    //ms
+    os->frag_dur = ctx->seg_duration / 1000;  //ms
+    os->frame_dur = (int64_t)(1000 / os->frame_rate); //ms
+    if (ctx->window_size) {
+        os->minimum_update_period = (os->seg_dur * ctx->window_size) / 1000;
+    } else {
+        os->minimum_update_period = os->seg_dur / 1000;
+    }
+        
+    os->frame_per_segment= os->seg_dur / os->frame_dur;
+    os->frame_per_fragment = os->frag_dur / os->frame_dur;
+    os->first_dts_in_fragment = 0;
+    os->fragment_started = 0;
+    os->segment_started = 0;
+    os->last_pts = AV_NOPTS_VALUE;
+    os->last_dts = AV_NOPTS_VALUE;
+    os->first_pts = AV_NOPTS_VALUE;
+    os->start_pts = AV_NOPTS_VALUE;
+    
+    os->nb_tiles = 0;
+    
+    ret = init_video_ouput(os);
+    if(ret){
+        av_log(NULL, AV_LOG_ERROR, "failed to initial stream = %d, main output\n", os->vstream_idx );
+        dash_free_output_stream(os);
+    }
+    
+    sps_id = os->hevc_state.sps_active_idx;
+    os->max_width = os->hevc_state.sps[sps_id].width;
+    os->max_height = os->hevc_state.sps[sps_id].height;
+    if(os->hevc_state.pps[0].tiles_enabled_flag && os->split_tile){
+        os->nb_tiles = os->hevc_state.pps[0].num_tile_columns
+                    * os->hevc_state.pps[0].num_tile_rows;
+
+        for(int i = 1; i < os->nb_tiles+1; i++)
+        {
+            ret = init_video_ouput_tile(os, i);
+            if(ret){
+                dash_free_output_stream(os);
+                av_log(NULL, AV_LOG_ERROR, "failed to initial stream = %d, output tile =%d\n", os->vstream_idx, i);
+                break;
+            }
+        }
+    }
+    
+    return ret;
+}
+
+int dash_write_segment(GPAC_DASHContext* ctx, DashOutStream* os, AVPacket *pkt)
+{
+    int ret =0;
+    int i;
+    int start_idx = 0;
+    char filename[1024];
+    int fragment_idx = 0;
+ 
+    if(os->nb_frames % os->frame_per_segment == 0){
+        for(i=0; i<os->nb_tiles+1; i++){
+            if(0 == os->video_out[i]->iso_created){
+                gpac_video_isom_open(os, i); 
+                os->video_out[i]->iso_created = 1;
+            }
+            ret = dc_gpac_video_isom_open_seg(os, i);
+            if(ret != GF_OK){
+               av_log(NULL, AV_LOG_VERBOSE, "failed to init_video_ouput::dc_gpac_video_isom_open_seg\n");
+               return -1;
+            }
+                      
+        }
+        os->segment_started = 1;
+    }
+    
+    if(os->nb_frames % os->frame_per_fragment == 0){
+        for(i=0; i<os->nb_tiles+1; i++){
+            fragment_idx = i * (os->nb_tiles + 1) + 1;            
+            gf_isom_set_next_moof_number(os->video_out[i]->isof, fragment_idx);
+            gf_isom_start_fragment(os->video_out[i]->isof, 1);
+            gf_isom_set_traf_base_media_decode_time(os->video_out[i]->isof, os->video_out[i]->iso_track_ID, os->first_dts_in_fragment);
+        }
+        os->first_dts_in_fragment += os->frame_per_fragment;
+        os->fragment_started = 1;
+    }
+    
+    if(os->hevc_state.pps[0].tiles_enabled_flag && os->split_tile){
+        ret = dc_gpac_video_isom_tile_write(os, pkt);
+        if(ret)
+            av_log(NULL, AV_LOG_ERROR, "failed to write_segment:dc_gpac_video_isom_tile_write\n");
+    }else{
+        os->video_out[0]->encoded_frame_size = pkt->size;
+        os->video_out[0]->cur_pts = pkt->pts;
+	os->video_out[0]->cur_keyframe = (pkt->flags & AV_PKT_FLAG_KEY) ? 1 : 0;
+        
+        os->video_out[0]->vbuf = pkt->data;
+        os->video_out[0]->vbuf_size = pkt->size;
+        
+        ret = dc_gpac_video_isom_write(os, 0);
+        if(ret)
+            av_log(NULL, AV_LOG_ERROR, "failed to write_segment:dc_gpac_video_isom_write\n");
+    }
+    
+    av_log(NULL, AV_LOG_DEBUG, "frame_per_fragment=%d, os->nb_frames=%d, os->nb_frames MOD os->frame_per_fragment=%d \n",
+                                os->frame_per_fragment, os->nb_frames, 
+                                os->nb_frames%os->frame_per_fragment);
+    /// reach the segment duration, close current segment and init an new one.
+    if(os->nb_frames%os->frame_per_fragment == os->frame_per_fragment - 1){
+        for(i=0; i<os->nb_tiles+1; i++){
+            gf_isom_flush_fragments(os->video_out[i]->isof, GF_TRUE);
+        }
+        os->fragment_started = 0;
+    }
+    
+    av_log(NULL, AV_LOG_DEBUG, "frame_per_segment=%d, os->nb_frames%d, os->nb_frames MOD os->frame_per_segment=%d \n",
+                                os->frame_per_segment, os->nb_frames, 
+                                os->nb_frames%os->frame_per_segment);
+    if(os->nb_frames%os->frame_per_segment == os->frame_per_fragment - 1){
+        for(i=0; i<os->nb_tiles+1; i++){
+            gpac_video_isom_close(os, i);
+            os->video_out[i]->nb_segments++;
+            os->video_out[i]->segment_index++;
+            snprintf(os->video_out[i]->seg_media_name, sizeof(os->video_out[i]->seg_media_name), "%s%s_track%d_%d.m4s", 
+                os->dir_name, os->out_name, os->video_out[i]->dash_track_ID, os->video_out[i]->segment_index+1);
+        }
+        os->segment_started = 0;
+        
+        
+        if (ctx->streaming) {
+            for(i=0; i<os->nb_tiles+1; i++){
+                av_log(NULL, AV_LOG_DEBUG, "$$$$ windows_size=%d, extra_window_size %d, video_out[%d]->nb_segments=%d, segment_index=%d\n", 
+                                                    ctx->window_size, ctx->extra_window_size, i, os->video_out[i]->nb_segments,
+                                                    os->video_out[i]->segment_index);
+                int remove_cnt = os->video_out[i]->nb_segments - ctx->window_size - ctx->extra_window_size;
+                if (remove_cnt > 0)
+                {
+                        
+                    snprintf(filename, sizeof(filename), "%s%s_track%d_%d.m4s", 
+                                  os->dir_name, os->out_name, os->video_out[i]->dash_track_ID, remove_cnt);
+                    remove(filename);
+                    av_log(NULL, AV_LOG_DEBUG, "remove file %s\n", filename);
+                           
+                }
+            }
+        }
+    }
+    os->nb_frames++;
+    
+    return 0;
+}
+
+void dash_write_mpd(GPAC_DASHContext *ctx, int is_final)
+{
+	u32 sec;
+	time_t gtime;
+	struct tm *t;
+	FILE *f;
+        char mpd_name[1024];
+	char name[GF_MAX_PATH];
+        int duration = 0;
+        int hour, minute, second, msecond;
+        char presentation_duration[1024];
+        int start_number = 1;
+        DashOutStream *os = &ctx->streams[0];
+
+	snprintf(name, sizeof(name), "%s%s.mpd", ctx->dirname, ctx->out_name);
+        snprintf(mpd_name, sizeof(mpd_name), "%s.mpd", ctx->out_name);
+
+	f = gf_fopen(name, "w");
+	//TODO: if (!f) ...
+
+	//	time_t t = time(NULL);
+	//	time_t t2 = t + 2;
+	//	t += (2 * (cmddata->seg_dur / 1000.0));
+	//	tm = *gmtime(&t2);
+	//	snprintf(availability_start_time, "%d-%d-%dT%d:%d:%dZ", tm.tm_year + 1900,
+	//			tm.tm_mon + 1, tm.tm_mday, tm.tm_hour, tm.tm_min, tm.tm_sec);
+	//	fprintf(stdout, "%s \n", availability_start_time);
+
+	fprintf(f, "<?xml version=\"1.0\"?>\n");
+    fprintf(f, "<MPD xmlns=\"urn:mpeg:dash:schema:mpd:2011\"  minBufferTime=\"PT%fS\" maxSegmentDuration=\"PT%fS\"", (double)(os->seg_dur/1000), (double)(os->seg_dur/1000));
+    fprintf(f, " profiles=\"%s\"", ctx->streaming ? "urn:mpeg:dash:profile:isoff-live:2011" : "rn:mpeg:dash:profile:isoff-on-demand:2011");
+        fprintf(f, " type=\"%s\"", is_final ? "static" : "dynamic");
+
+    if (ctx->streaming)
+    {
+        start_number = 0;
+    }
+    if (is_final && ctx->streaming) {
+        ctx->streaming = 0;
+        os->total_frames = os->total_frames % os->frame_per_fragment;
+    }
+
+    if (is_final)
+    {
+        duration = (int)(os->total_frames * 1000 / os->frame_rate + 0.5);
+        hour = duration / 3600000;
+        duration = duration % 3600000;
+        minute = duration / 60000;
+        duration = duration % 60000;
+        second = duration / 1000;
+        msecond = duration % 1000;
+        snprintf(presentation_duration, sizeof(presentation_duration), "PT%02dH%02dM%02d.%03dS", hour, minute, second, msecond);
+        fprintf(f, " mediaPresentationDuration=\"%s\"", presentation_duration);
+    } else {
+        gf_net_get_ntp(&sec, NULL);
+        gtime = sec - GF_NTP_SEC_1900_TO_1970;
+        t = gmtime(&gtime);
+        if (os->video_out[0]->segment_index == 0) {
+            snprintf(os->available_start_time, sizeof(os->available_start_time), "%d-%d-%dT%d:%d:%dZ", 1900+t->tm_year,
+                    t->tm_mon+1, t->tm_mday, t->tm_hour, t->tm_min, t->tm_sec);
+        }
+        fprintf(f, " availabilityStartTime=\"%s\"", os->available_start_time);
+        fprintf(f, " timeShiftBufferDepth=\"PT5M\"");
+        if (os->minimum_update_period > 0)
+    	    fprintf(f, " minimumUpdatePeriod=\"PT%dS\"", os->minimum_update_period);
+
+        fprintf(f, " publishTime=\"%d-%02d-%02dT%02d:%02d:%02dZ\"", 1900+t->tm_year, t->tm_mon+1, t->tm_mday, t->tm_hour, t->tm_min, t->tm_sec);
+    }
+	fprintf(f, ">\n");
+
+	fprintf(f,
+	        " <ProgramInformation moreInformationURL=\"http://gpac.io\">\n"
+	        "  <Title>%s</Title>\n"
+	        " </ProgramInformation>\n", mpd_name);
+
+        if (ctx->base_url) {
+	    if (strcmp(ctx->base_url, "") != 0) {
+	        fprintf(f, " <BaseURL>%s</BaseURL>\n", ctx->base_url);
+	    }
+        }
+        if (!ctx->streaming)
+        {
+            fprintf(f, " <Period duration=\"%s\">\n", presentation_duration);
+        }
+        else
+        {
+	    fprintf(f, " <Period start=\"PT0H0M0.000S\" id=\"P1\">\n");
+        }
+        
+
+        for (int stream_idx = 0; stream_idx < ctx->nb_streams; stream_idx++)
+        {
+            os = &ctx->streams[stream_idx];
+	    fprintf(f, "  <AdaptationSet segmentAlignment=\"true\" maxWidth=\"%d\" maxHeight=\"%d\" bitstreamSwitching=\"false\">\n",
+                        os->max_width, os->max_height);
+            fprintf(f, "   <EssentialProperty schemeIdUri=\"urn:mpeg:dash:srd:2014\" value=\"1,0,0,0,0\"/>\n");
+            fprintf(f,
+	        "   <SegmentTemplate initialization=\"%s\"/>\n",
+	        os->video_out[0]->seg_init_name);
+            fprintf(f, "   <Representation id=\"%s\" mimeType=\"video/mp4\" codecs=\"%s\" "
+                        "width=\"%d\" height=\"%d\" frameRate=\"%d/%d\" sar=\"1:1\" startWithSAP=\"1\" bandwidth=\"%d\">\n",
+                        os->video_out[0]->rep_id,
+                        "hvc2.1.6.L186.80",
+                        os->max_width, os->max_height, os->timescale.den,
+                        os->timescale.num, os->bit_rate);
+            fprintf(f, "    <SegmentTemplate timescale=\"%d\" duration=\"%d\" media=\"%s\""
+                        " startNumber=\"%d\"/>\n",
+                        os->video_out[0]->timescale, (os->seg_dur * os->video_out[0]->timescale) / 1000, os->video_out[0]->seg_media_name_tmpl, start_number);
+            fprintf(f, "   </Representation>\n");
+            fprintf(f, "  </AdaptationSet>\n");
+
+	    for (int tile_idx = 1; tile_idx < os->nb_tiles + 1; tile_idx++) {
+		fprintf(f, "  <AdaptationSet segmentAlignment=\"true\" maxWidth=\"%d\" maxHeight=\"%d\" bitstreamSwitching=\"false\">\n",
+                            os->video_out[tile_idx]->tile.tw, os->video_out[tile_idx]->tile.th);
+                fprintf(f, "   <SupplementalProperty schemeIdUri=\"urn:mpeg:dash:srd:2014\" value=\"1,%d,%d,%d,%d\"/>\n",
+                            os->video_out[tile_idx]->tile.tx, os->video_out[tile_idx]->tile.ty,
+                            os->video_out[tile_idx]->tile.tw, os->video_out[tile_idx]->tile.th);
+		fprintf(f, "   <Representation id=\"%s\" mimeType=\"video/mp4\" codecs=\"%s\" "
+		        "width=\"%d\" height=\"%d\" frameRate=\"%d/%d\" sar=\"1:1\" startWithSAP=\"1\" bandwidth=\"%d\" dependencyId=\"%d\">\n",
+		        os->video_out[tile_idx]->rep_id, "hvc2.1.6.L186.80",
+		        os->video_out[tile_idx]->tile.tw, os->video_out[tile_idx]->tile.th, os->timescale.den, os->timescale.num,
+		        os->video_out[tile_idx]->bit_rate, os->video_out[tile_idx]->dependency_id);
+                fprintf(f, "    <SegmentTemplate timescale=\"%d\" duration=\"%d\" media=\"%s\""
+                            " startNumber=\"%d\"/>\n",
+                            os->video_out[tile_idx]->timescale, (os->seg_dur * os->video_out[tile_idx]->timescale) / 1000, os->video_out[tile_idx]->seg_media_name_tmpl, start_number);
+                fprintf(f, "   </Representation>\n");
+                fprintf(f, "  </AdaptationSet>\n");
+	    }
+
+        }
+
+	fprintf(f, " </Period>\n");
+
+	fprintf(f, "</MPD>\n");
+
+	gf_fclose(f);
+}
+int dash_update_mpd(GPAC_DASHContext* dash_ctx, int is_final)
+{
+    DashOutStream *os = &dash_ctx->streams[0];
+    if (dash_ctx->window_size) {
+        if (os->video_out[0]->segment_index % dash_ctx->window_size == 0)
+        {
+            dash_write_mpd(dash_ctx, is_final);
+            return 0;
+        }
+    }
+    else {
+        if (os->nb_frames % os->frame_per_fragment == 0)
+        {
+            dash_write_mpd(dash_ctx, is_final);
+            return 0;
+        }
+    }
+
+    if (is_final) {
+        dash_write_mpd(dash_ctx, is_final);
+        return 0;
+    }
+
+    return 0;
+}
diff -urN FFmpeg/libavformat/tiled_dash_parse.h FFmpeg-patched/libavformat/tiled_dash_parse.h
--- FFmpeg/libavformat/tiled_dash_parse.h	1970-01-01 08:00:00.000000000 +0800
+++ FFmpeg-patched/libavformat/tiled_dash_parse.h	2020-09-27 13:35:13.558526536 +0800
@@ -0,0 +1,168 @@
+/*
+ * Intel tile Dash muxer
+ *
+ * Copyright (c) 2018 Intel Cooperation 
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef TILE_DASH_PARSE_H
+#define TILE_DASH_PARSE_H
+
+#include "libavutil/avassert.h"
+#include "libavutil/avutil.h"
+#include "libavutil/avstring.h"
+#include "libavutil/intreadwrite.h"
+#include "libavutil/mathematics.h"
+#include "libavutil/opt.h"
+#include "libavutil/rational.h"
+#include "libavutil/time_internal.h"
+
+#include "avformat.h"
+#include "avio_internal.h"
+
+#include "gpac/constants.h"
+#include "gpac/internal/mpd.h"
+#include "gpac/media_tools.h"
+#include "gpac/isomedia.h"
+//#include "gpac/isom_tools.h"
+#include "gpac/internal/media_dev.h"
+
+#define MAX_TILE 1024
+
+typedef struct
+{
+	u32 tx, ty, tw, th;
+	u32 data_offset;
+	u32 nb_nalus_in_sample;
+	Bool all_intra;
+} HEVCTileImport;
+
+typedef struct {
+
+#ifndef GPAC_DISABLE_ISOM
+	GF_ISOFile        *isof;
+	GF_ISOSample      *sample;
+#endif
+	u32               iso_track_ID;
+        u32               iso_track;
+        int               dash_track_ID;
+	/* Variables that encoder needs to encode data */
+	uint8_t           *vbuf;
+	int               vbuf_size;
+        int               encoded_frame_size;
+        int64_t           cur_pts;
+        int               cur_keyframe;
+	u32               seg_marker;
+	int               gdr;
+        u32               nb_segments;
+        int               segment_index;
+        int64_t           frame_dur;
+	char              rep_id[64];
+        int               dependency_id;
+        HEVCTileImport    tile;
+        int               bit_rate;
+        char              seg_init_name[1024];
+        char              seg_media_name[1024];
+        char              seg_media_name_tmpl[1024];
+        int               timescale;
+        int               use_source_timing;
+        int               sample_count;
+        int               iso_created;
+} VideoOutput;
+
+typedef struct DashOutStream {
+    AVFormatContext       *fmt_ctx;
+    AVCodecParameters     *codec_ctx;
+    HEVCState             hevc_state;
+    GF_HEVCConfig         hevc_cfg;
+    GF_AVCConfig          avc_cfg;
+    int                   initialized;
+    int                   stream_index;
+    //int                   packets_written;
+    //int                   total_pkt_size;
+    int                   total_frames;
+    int                   nb_frames;
+    int                   bit_rate;
+    VideoOutput           *video_out[MAX_TILE];
+    int                   nb_tiles;
+    int                   max_width;
+    int                   max_height;
+    double                frame_rate;
+    
+    int64_t               last_pts;
+    int64_t               last_dts;
+    int64_t               first_pts;
+    int64_t               start_pts;
+    int64_t               first_dts_in_fragment;
+    double                availability_time_offset;
+    int                   frame_per_fragment;
+    int                   frame_per_segment;
+    Bool                  fragment_started;
+    Bool                  segment_started;
+    int                   seg_dur;
+    int                   frag_dur;
+    int                   minimum_update_period;
+    int64_t               frame_dur;
+    AVRational            timescale;
+    int                   vstream_idx;
+    int                   split_tile;
+    char                  out_name[256];
+    char                  dir_name[1024];
+    char                  available_start_time[1024];
+
+} DashOutStream;
+
+typedef struct {
+    const AVClass  *class;  /* Class for private options. */
+    char           *adaptation_sets;
+    int            nb_as;
+    int            window_size;
+    int            extra_window_size;
+    int64_t        seg_duration;
+    int            remove_at_exit;
+    int            use_template;
+    int            use_timeline;
+    DashOutStream  *streams;
+    int            nb_streams;
+    int64_t        last_duration;
+    int64_t        total_duration;
+    char           availability_start_time[100];
+    char           dirname[1024];
+    const char     *out_name;
+    const char     *base_url;
+    const char     *utc_timing_url;
+    int            master_playlist_created;
+    AVIOContext    *mpd_out;
+    int            streaming;
+    int            index_correction;
+    int            split_tile;
+    int            has_video;
+    int            has_audio;
+} GPAC_DASHContext;
+
+
+void format_date_now(char *buf, int size);
+int dash_init_output_stream(GPAC_DASHContext* ctx, DashOutStream* os);
+void dash_end_output_stream(DashOutStream* os);
+int dash_probe_extra_data(DashOutStream* os, char* buf, int size);
+int dash_update_mpd(GPAC_DASHContext* dash_ctx, int is_final);
+int dash_write_segment( GPAC_DASHContext* ctx, DashOutStream* os, AVPacket *pkt );
+void dash_free_output_stream(DashOutStream* os);
+void dash_write_mpd(GPAC_DASHContext *ctx, int is_final);
+#endif
+
